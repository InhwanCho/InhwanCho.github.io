<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Inhwan&#39;s Digital Space</title>
    <link>http://InhwanCho.github.io/</link>
    
    <atom:link href="http://inhwancho.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>I&#39;m Learning ML/DL</description>
    <pubDate>Mon, 23 Jan 2023 01:24:59 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>코랩(colab)에서 kaggle(캐글) 데이터 바로 다운받기</title>
      <link>http://inhwancho.github.io/2023/01/20/Colab_folder/2023-01-20-kaggle-colab/</link>
      <guid>http://inhwancho.github.io/2023/01/20/Colab_folder/2023-01-20-kaggle-colab/</guid>
      <pubDate>Fri, 20 Jan 2023 02:22:22 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="코랩에서-캐글-데이터를-바로-다운받는-방법"><a href="#코랩에서-캐글-데이터를-바로-다운받는-방법" class="headerlink" title="코랩에서 캐글 데이터를 바로 다운받는 방법"></a>코랩에서 캐글 데이터를 바로 다운받는 방법</h2><ul><li>kaggle 홈페이지의 오른쪽 프로필 -&gt; account -&gt; <code>create new api token</code> 누른 후 다운로드</li><li><code>kaggle.json</code> 파일을 업로드</li><li>맥북 로컬은 ~&#x2F;.kaggle에 파일을 옮겨서 사용하면 됩니다.</li></ul><img width="372" alt="캐글 오른쪽 프로필에서 Account 선택" src="https://user-images.githubusercontent.com/111936229/213606040-175f1dbd-c3a2-427f-9f06-501c8be91424.png"><img width="740" alt="Create New API Token 선택" src="https://user-images.githubusercontent.com/111936229/213606034-20d2da24-2a46-44ad-bfc7-bffb9618ff84.png"><figure class="highlight clean"><figcaption><span>in colab</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">import</span> kaggle # 요즘은 <span class="keyword">import</span> kaggle을 안해도 됩니다.</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line"></span><br><span class="line">files.upload()</span><br><span class="line"></span><br><span class="line"># api token(kaggle.json 파일)을 <span class="string">&#x27;파일 선택&#x27;</span> 눌러서 업로드</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>in colab</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .kaggle 폴더 생성</span></span><br><span class="line">!<span class="built_in">mkdir</span> -p ~/.kaggle</span><br><span class="line"><span class="comment"># json파일 .kaggle로 복사</span></span><br><span class="line">!<span class="built_in">cp</span> kaggle.json ~/.kaggle/</span><br><span class="line"><span class="comment"># Permission Warning이 발생하지 않도록 해줍니다.</span></span><br><span class="line">!<span class="built_in">chmod</span> 600 ~/.kaggle/kaggle.json</span><br><span class="line"><span class="comment"># 내가 참가한 대회 리스트 확인(옵션)</span></span><br><span class="line"><span class="comment"># !kaggle competitions list</span></span><br></pre></td></tr></table></figure><ul><li>다운 받고 싶은 데이터의 API 주소를 복사하려면<ul><li>밑의 스크린샷의 <code>UTKFace</code> 같은 데이터 셋 주소를 클릭합니다.</li><li>그 후 오른쪽 <code>...</code>을 누르고 <code>copy api command</code>를 누릅니다.</li></ul></li></ul><img width="666" alt="노트북에서 사용한 데이터 종류" src="https://user-images.githubusercontent.com/111936229/213606050-f07c7df0-6633-40a4-9ab4-613a29f96b4b.png"><img width="1241" alt="copy api command" src="https://user-images.githubusercontent.com/111936229/213606045-2a6ba84f-9f2c-4705-9fa0-59a1174ae82e.png"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!kaggle datasets download -d jangedoo/utkface-new</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><img width="527" alt="결과" src="https://user-images.githubusercontent.com/111936229/213606041-89d451b8-d503-423f-9a37-addc5c4bdef9.png"><h3 id="testing-plotly"><a href="#testing-plotly" class="headerlink" title="testing plotly"></a>testing plotly</h3><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/14.embed" height="525" width="100%"></iframe><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/12.embed" height="525" width="100%"></iframe><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/10.embed" height="525" width="100%"></iframe><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/8.embed" height="525" width="100%"></iframe><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/6.embed" height="525" width="100%"></iframe><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/4.embed" height="525" width="100%"></iframe>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Colab/">Colab</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Colab/">Colab</category>
      
      <category domain="http://InhwanCho.github.io/tags/Kaggle/">Kaggle</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/20/Colab_folder/2023-01-20-kaggle-colab/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV로 아는 얼굴인지 확인하기</title>
      <link>http://inhwancho.github.io/2023/01/19/Study_folder/OpneCV/2023-01-19-face-recognizion/</link>
      <guid>http://inhwancho.github.io/2023/01/19/Study_folder/OpneCV/2023-01-19-face-recognizion/</guid>
      <pubDate>Thu, 19 Jan 2023 04:16:37 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<ul><li>예제 코드</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> face_recognition</span><br><span class="line"></span><br><span class="line">imgElon = face_recognition.load_image_file(<span class="string">&#x27;elon1.png&#x27;</span>)</span><br><span class="line">imgTest = face_recognition.load_image_file(<span class="string">&#x27;surprised_man.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)</span><br><span class="line">imgElon = cv2.cvtColor(imgElon,cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">faceLoc = face_recognition.face_locations(imgElon)[<span class="number">0</span>]</span><br><span class="line">encodeElon = face_recognition.face_encodings(imgElon)[<span class="number">0</span>]</span><br><span class="line">cv2.rectangle(imgElon,(faceLoc[<span class="number">1</span>],faceLoc[<span class="number">2</span>]),(faceLoc[<span class="number">3</span>],faceLoc[<span class="number">0</span>]),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(faceLoc) <span class="comment"># (118, 304, 304, 118) top, right, bottom, left</span></span><br><span class="line"></span><br><span class="line">faceLocTest = face_recognition.face_locations(imgTest)[<span class="number">0</span>]</span><br><span class="line">encodeTest = face_recognition.face_encodings(imgTest)[<span class="number">0</span>]</span><br><span class="line">cv2.rectangle(imgTest,(faceLocTest[<span class="number">1</span>],faceLocTest[<span class="number">2</span>]),(faceLocTest[<span class="number">3</span>],faceLocTest[<span class="number">0</span>]),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">results = face_recognition.compare_faces([encodeElon], encodeTest)</span><br><span class="line">faceDis = face_recognition.face_distance([encodeElon], encodeTest)</span><br><span class="line"><span class="built_in">print</span>(results, faceDis)</span><br><span class="line">cv2.putText(imgTest, <span class="string">f&#x27;<span class="subst">&#123;results&#125;</span> <span class="subst">&#123;<span class="built_in">round</span>(faceDis[<span class="number">0</span>],<span class="number">2</span>)&#125;</span>&#x27;</span>, (<span class="number">50</span>,<span class="number">50</span>), cv2.FONT_HERSHEY_COMPLEX,<span class="number">1</span>,</span><br><span class="line">                            (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;imtest&#x27;</span>,imgTest)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;imelon&#x27;</span>,imgElon)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>results가 True면 동일 인물, False면 다른 인물로 판단</li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study/">Study</category>
      
      <category domain="http://InhwanCho.github.io/tags/OpenCV/">OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/19/Study_folder/OpneCV/2023-01-19-face-recognizion/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 얼굴, 눈 등 특정 객체 검출</title>
      <link>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-haarscascade/</link>
      <guid>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-haarscascade/</guid>
      <pubDate>Wed, 18 Jan 2023 06:23:12 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="정면-얼굴-검출"><a href="#정면-얼굴-검출" class="headerlink" title="정면 얼굴 검출"></a>정면 얼굴 검출</h2><ol><li><code>haarcascade file</code> 사용</li></ol><ul><li><code>haarcascade_frontalface_default.xml</code> 을 사용하여 검출하는 방법입니다.</li><li>이 파일은 다른 사람들이 이미 얼굴을 검출하는 학습을 해둔 파일이며 이를 이용하면 편하게 얼굴을 인식할 수 있습니다.</li><li>&lt;<a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">opencv-data-haarcascades</a>&gt;</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">faceCascade = cv2.CascadeClassifier(<span class="string">&#x27;Resources/haarcascade_frontalface_default.xml&#x27;</span>)</span><br><span class="line">img = cv2.imread(<span class="string">&#x27;Resources/lena.png&#x27;</span>)</span><br><span class="line">imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">faces = faceCascade.detectMultiScale(imgGray,<span class="number">1.1</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    cv2.rectangle(img, (x,y), (x+w, y+h), (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;result&#x27;</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="505" alt="얼굴 인식" src="https://user-images.githubusercontent.com/111936229/213099837-c577eb63-1dab-433f-8e14-d48ca4309471.png"><ol start="2"><li><code>opencv_face_detector.pbtxt</code> 파일 사용</li></ol><ul><li>haarcascade와 방법은 유사합니다</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">faceBox</span>(<span class="params">faceNet, frame</span>):</span><br><span class="line">    </span><br><span class="line">    frameWidth = frame.shape[<span class="number">1</span>]</span><br><span class="line">    frameHeight = frame.shape[<span class="number">0</span>]</span><br><span class="line">    blob = cv2.dnn.blobFromImage(frame, <span class="number">1.0</span>, (<span class="number">227</span>,<span class="number">227</span>), [<span class="number">104</span>,<span class="number">117</span>,<span class="number">123</span>], swapRB=<span class="literal">False</span>)</span><br><span class="line">    faceNet.setInput(blob)</span><br><span class="line">    detection = faceNet.forward()</span><br><span class="line">    bboxs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(detection.shape[<span class="number">2</span>]):</span><br><span class="line">        confidence = detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> confidence &gt; <span class="number">0.7</span> :</span><br><span class="line">            x1 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">3</span>] * frameWidth)</span><br><span class="line">            y1 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">4</span>] * frameHeight) </span><br><span class="line">            x2 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">5</span>] * frameWidth)</span><br><span class="line">            y2 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">6</span>] * frameHeight)</span><br><span class="line">            bboxs.append([x1,y1,x2,y2])</span><br><span class="line">            cv2.rectangle(frame, (x1,y1), (x2,y2), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> frame, bboxs</span><br><span class="line"></span><br><span class="line">faceProto = <span class="string">&quot;opencv_face_detector.pbtxt&quot;</span></span><br><span class="line">faceModel = <span class="string">&quot;opencv_face_detector_uint8.pb&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">faceNet = cv2.dnn.readNet(faceModel, faceProto)</span><br><span class="line">video = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">padding = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ret, frame = video.read()</span><br><span class="line">    frame, bboxs = faceBox(faceNet, frame)</span><br><span class="line">    </span><br><span class="line">    detect = faceBox(faceNet, frame)</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;age_gender&#x27;</span>,frame)</span><br><span class="line">    k = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> k == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">video.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study/">Study</category>
      
      <category domain="http://InhwanCho.github.io/tags/OpenCV/">OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-haarscascade/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 윤곽선 검출</title>
      <link>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-contour/</link>
      <guid>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-contour/</guid>
      <pubDate>Wed, 18 Jan 2023 05:11:30 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="contour"><a href="#contour" class="headerlink" title="contour"></a>contour</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 이미지 여러 장 출력 함수</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stackImages</span>(<span class="params">scale,imgArray</span>):</span><br><span class="line">    rows = <span class="built_in">len</span>(imgArray)</span><br><span class="line">    cols = <span class="built_in">len</span>(imgArray[<span class="number">0</span>])</span><br><span class="line">    rowsAvailable = <span class="built_in">isinstance</span>(imgArray[<span class="number">0</span>], <span class="built_in">list</span>)</span><br><span class="line">    width = imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">1</span>]</span><br><span class="line">    height = imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> rowsAvailable:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span> ( <span class="number">0</span>, rows):</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cols):</span><br><span class="line">                <span class="keyword">if</span> imgArray[x][y].shape[:<span class="number">2</span>] == imgArray[<span class="number">0</span>][<span class="number">0</span>].shape [:<span class="number">2</span>]:</span><br><span class="line">                    imgArray[x][y] = cv2.resize(imgArray[x][y], (<span class="number">0</span>, <span class="number">0</span>), <span class="literal">None</span>, scale, scale)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">1</span>], imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]), <span class="literal">None</span>, scale, scale)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(imgArray[x][y].shape) == <span class="number">2</span>: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)</span><br><span class="line">        imageBlank = np.zeros((height, width, <span class="number">3</span>), np.uint8)</span><br><span class="line">        hor = [imageBlank]*rows</span><br><span class="line">        hor_con = [imageBlank]*rows</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, rows):</span><br><span class="line">            hor[x] = np.hstack(imgArray[x])</span><br><span class="line">        ver = np.vstack(hor)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, rows):</span><br><span class="line">            <span class="keyword">if</span> imgArray[x].shape[:<span class="number">2</span>] == imgArray[<span class="number">0</span>].shape[:<span class="number">2</span>]:</span><br><span class="line">                imgArray[x] = cv2.resize(imgArray[x], (<span class="number">0</span>, <span class="number">0</span>), <span class="literal">None</span>, scale, scale)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                imgArray[x] = cv2.resize(imgArray[x], (imgArray[<span class="number">0</span>].shape[<span class="number">1</span>], imgArray[<span class="number">0</span>].shape[<span class="number">0</span>]), <span class="literal">None</span>,scale, scale)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(imgArray[x].shape) == <span class="number">2</span>: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)</span><br><span class="line">        hor= np.hstack(imgArray)</span><br><span class="line">        ver = hor</span><br><span class="line">    <span class="keyword">return</span> ver</span><br><span class="line"></span><br><span class="line"><span class="comment">#윤곽선 검출 함수</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getContour</span>(<span class="params">img</span>):</span><br><span class="line">    contours, hierarchy = cv2.findContours(img,mode = cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)</span><br><span class="line">    <span class="keyword">for</span> cnt <span class="keyword">in</span> contours:</span><br><span class="line">        area = cv2.contourArea(cnt)</span><br><span class="line">        <span class="comment"># imgContour이미지에 contour를 파란색으로 drawing한다는 의미</span></span><br><span class="line">        <span class="keyword">if</span> area &gt; <span class="number">500</span> :</span><br><span class="line">            cv2.drawContours(imgContour, cnt, -<span class="number">1</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">3</span>) </span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;Resources/shapes.png&#x27;</span>)</span><br><span class="line">empty = np.zeros_like(img)</span><br><span class="line">imgContour = img.copy()</span><br><span class="line"></span><br><span class="line">imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">imgBlur = cv2.GaussianBlur(imgGray, (<span class="number">7</span>,<span class="number">7</span>),<span class="number">1</span>)</span><br><span class="line">imgCanny = cv2.Canny(imgBlur,<span class="number">50</span>,<span class="number">50</span>)</span><br><span class="line"><span class="comment"># 보통 contour는 img-&gt;gray-&gt;blur-&gt;canny-&gt;contour를 이용하여 검출한다.</span></span><br><span class="line">getContour(imgCanny)</span><br><span class="line"></span><br><span class="line">stackimg = stackImages(<span class="number">0.5</span>,[[img,imgGray, imgBlur],</span><br><span class="line">                            [imgCanny,imgContour,empty]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, stackimg)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>보통 contour는 img-&gt;gray-&gt;blur-&gt;canny-&gt;contour를 이용하여 검출한다.</li><li>5번째 이미지(imgContour)가 윤곽선이 검출된 이미지</li></ul><img width="855" alt="5번째가 윤곽선 검출 이미지" src="https://user-images.githubusercontent.com/111936229/213089692-458299d7-6141-4f31-ba0b-b6903f0f5f0d.png"><h2 id="contour를-통하여-bounding-box-검출하는-방법입니다"><a href="#contour를-통하여-bounding-box-검출하는-방법입니다" class="headerlink" title="contour를 통하여 bounding box 검출하는 방법입니다"></a>contour를 통하여 bounding box 검출하는 방법입니다</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getContour</span>(<span class="params">img</span>):</span><br><span class="line">    contours, hierarchy = cv2.findContours(img,mode = cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)</span><br><span class="line">    <span class="keyword">for</span> cnt <span class="keyword">in</span> contours:</span><br><span class="line">        area = cv2.contourArea(cnt)</span><br><span class="line">        <span class="comment"># imgContour이미지에 contour를 파란색으로 drawing한다는 의미</span></span><br><span class="line">        <span class="keyword">if</span> area &gt; <span class="number">500</span> :</span><br><span class="line">            cv2.drawContours(imgContour, cnt, -<span class="number">1</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">3</span>) </span><br><span class="line">            param = cv2.arcLength(cnt, <span class="literal">True</span>)</span><br><span class="line">            approx = cv2.approxPolyDP(cnt, <span class="number">0.02</span> * param, <span class="literal">True</span>) <span class="comment">#근접한 포인트(점)이 있는지 확인</span></span><br><span class="line">            <span class="comment">#print(len(approx)) #3이면 삼각형, 4는 사격형, 그 이상이면 원</span></span><br><span class="line">            obj_corner = <span class="built_in">len</span>(approx)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># object corner를 검출했으면 그걸로 바운딩 박스를 만듭니다.</span></span><br><span class="line">            x,y,w,h = cv2.boundingRect(approx)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> obj_corner == <span class="number">3</span> :</span><br><span class="line">                object_type = <span class="string">&#x27;triangle&#x27;</span></span><br><span class="line">            <span class="keyword">elif</span> obj_corner ==<span class="number">4</span> :</span><br><span class="line">                aspRatio = w/<span class="built_in">float</span>(h)</span><br><span class="line">                <span class="keyword">if</span> aspRatio &gt; <span class="number">0.95</span> <span class="keyword">and</span> aspRatio &lt; <span class="number">1.05</span>:</span><br><span class="line">                    object_type = <span class="string">&#x27;sqare&#x27;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    object_type = <span class="string">&#x27;rectangle&#x27;</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                object_type = <span class="string">&#x27;circle&#x27;</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#rectangle을 만들고, 텍스트를 붙여서 출력합니다.</span></span><br><span class="line">            cv2.rectangle(imgContour, (x,y), (x+w, y+h), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">            cv2.putText(imgContour, object_type, (x+(w//<span class="number">2</span>)-<span class="number">7</span>, y +(h//<span class="number">2</span>)-<span class="number">10</span>),cv2.FONT_HERSHEY_SIMPLEX,<span class="number">0.6</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">        </span><br></pre></td></tr></table></figure><ul><li>윤곽선 검출 및 바운딩 박스 생성 이미지(5번째 이미지)</li></ul><img width="1375" alt="윤곽선 -> 바운딩 박스 생성" src="https://user-images.githubusercontent.com/111936229/213092755-f603d629-3933-448d-b1cc-7559e47a558f.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study/">Study</category>
      
      <category domain="http://InhwanCho.github.io/tags/OpenCV/">OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-contour/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 여러장의 이미지를 한장으로 출력하는 방법</title>
      <link>http://inhwancho.github.io/2023/01/17/Study_folder/OpneCV/2023-01-18-opencv/</link>
      <guid>http://inhwancho.github.io/2023/01/17/Study_folder/OpneCV/2023-01-18-opencv/</guid>
      <pubDate>Tue, 17 Jan 2023 13:20:05 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="OpenCV에서-여러-장의-이미지-한-윈도우로-출력하기"><a href="#OpenCV에서-여러-장의-이미지-한-윈도우로-출력하기" class="headerlink" title="OpenCV에서 여러 장의 이미지 한 윈도우로 출력하기"></a>OpenCV에서 여러 장의 이미지 한 윈도우로 출력하기</h2><ul><li>기본적으로 np.hstack, np,vstack 을 이용해 이미지를 복붙하는 원리입니다.</li><li>예시 코드를 보겠습니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">imglena = cv2.imread(<span class="string">&#x27;Resources/lena.png&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(imglena.shape)</span><br><span class="line"><span class="comment"># (512, 512, 3)</span></span><br><span class="line"></span><br><span class="line">imgHor = np.hstack((imglena,imglena))</span><br><span class="line"><span class="built_in">print</span>(imgHor.shape)</span><br><span class="line"><span class="comment"># (512, 1024, 3) 이미지 numpy를 더 붙인 형태입니다.</span></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;hori&#x27;</span>, imgHor)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="1016" alt="가로로 사진 확장해서 붙이기" src="https://user-images.githubusercontent.com/111936229/213087314-4f90ce0c-ca59-4f54-8820-6ad3ea01dee8.png"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stackImages</span>(<span class="params">scale,imgArray</span>):</span><br><span class="line">    rows = <span class="built_in">len</span>(imgArray)</span><br><span class="line">    cols = <span class="built_in">len</span>(imgArray[<span class="number">0</span>])</span><br><span class="line">    rowsAvailable = <span class="built_in">isinstance</span>(imgArray[<span class="number">0</span>], <span class="built_in">list</span>)</span><br><span class="line">    width = imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">1</span>]</span><br><span class="line">    height = imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> rowsAvailable:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span> ( <span class="number">0</span>, rows):</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cols):</span><br><span class="line">                <span class="keyword">if</span> imgArray[x][y].shape[:<span class="number">2</span>] == imgArray[<span class="number">0</span>][<span class="number">0</span>].shape [:<span class="number">2</span>]:</span><br><span class="line">                    imgArray[x][y] = cv2.resize(imgArray[x][y], (<span class="number">0</span>, <span class="number">0</span>), <span class="literal">None</span>, scale, scale)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">1</span>], imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]), <span class="literal">None</span>, scale, scale)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(imgArray[x][y].shape) == <span class="number">2</span>: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)</span><br><span class="line">        imageBlank = np.zeros((height, width, <span class="number">3</span>), np.uint8)</span><br><span class="line">        hor = [imageBlank]*rows</span><br><span class="line">        hor_con = [imageBlank]*rows</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, rows):</span><br><span class="line">            hor[x] = np.hstack(imgArray[x])</span><br><span class="line">        ver = np.vstack(hor)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, rows):</span><br><span class="line">            <span class="keyword">if</span> imgArray[x].shape[:<span class="number">2</span>] == imgArray[<span class="number">0</span>].shape[:<span class="number">2</span>]:</span><br><span class="line">                imgArray[x] = cv2.resize(imgArray[x], (<span class="number">0</span>, <span class="number">0</span>), <span class="literal">None</span>, scale, scale)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                imgArray[x] = cv2.resize(imgArray[x], (imgArray[<span class="number">0</span>].shape[<span class="number">1</span>], imgArray[<span class="number">0</span>].shape[<span class="number">0</span>]), <span class="literal">None</span>,scale, scale)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(imgArray[x].shape) == <span class="number">2</span>: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)</span><br><span class="line">        hor= np.hstack(imgArray)</span><br><span class="line">        ver = hor</span><br><span class="line">    <span class="keyword">return</span> ver</span><br><span class="line"></span><br><span class="line">img = cv2.imread(Resources/shapes.png)</span><br><span class="line">imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">imglena = cv2.imread(<span class="string">&#x27;Resources/lena.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">stackimg = stackImages(<span class="number">0.5</span>,[[img,imgGray],</span><br><span class="line">                            [imglena,imglena]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;img&#x27;</span>, stackimg)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>결과</li></ul><img width="570" alt="여러 이미지 한번에 같이 출력" src="https://user-images.githubusercontent.com/111936229/213086778-8c55e1cf-bbf2-47e1-8f30-0a8cfde458f6.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study/">Study</category>
      
      <category domain="http://InhwanCho.github.io/tags/OpenCV/">OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/17/Study_folder/OpneCV/2023-01-18-opencv/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Icarus 테마 커스터마이징</title>
      <link>http://inhwancho.github.io/2023/01/16/Blogs_folder/2023-01-16-customizeing/</link>
      <guid>http://inhwancho.github.io/2023/01/16/Blogs_folder/2023-01-16-customizeing/</guid>
      <pubDate>Sun, 15 Jan 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="테마의-프로필-영역-사이즈-변경"><a href="#테마의-프로필-영역-사이즈-변경" class="headerlink" title="테마의 프로필 영역 사이즈 변경"></a>테마의 프로필 영역 사이즈 변경</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- layout/widget/profile.jsx --&gt;</span><br><span class="line"></span><br><span class="line">&#123;/* &lt;figure class=&quot;image is-128x128 mx-auto mb-2&quot;&gt; */&#125;</span><br><span class="line">&lt;figure class=&quot;image mx-auto mb-2&quot;&gt;</span><br></pre></td></tr></table></figure><h2 id="font-변경"><a href="#font-변경" class="headerlink" title="font 변경"></a>font 변경</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 51 line</span><br><span class="line">const fontCssUrl = &#123;</span><br><span class="line">  default: fontcdn(&quot;Ubuntu:wght@400;600&amp;family=Source+Code+Pro&quot;, &quot;css2&quot;),</span><br><span class="line">  cyberpunk: fontcdn(&quot;Oxanium:wght@300;400;600&amp;family=Roboto+Mono&quot;, &quot;css2&quot;),</span><br><span class="line">  nanumgothic: fontcdn(&quot;Nanum+Gothic:wght@400&amp;family=Roboto&quot;, &quot;css2&quot;),</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// 151 line</span><br><span class="line">&lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;</span><br><span class="line">&lt;link href=&#123;fontCssUrl[&#x27;nanumgothic&#x27;]&#125; rel=&quot;stylesheet&quot; /&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><figcaption><span>8 line</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$family-sans-serif ?= &#x27;Nanum Gothic&#x27;, Ubuntu, Roboto, &#x27;Open Sans&#x27;, &#x27;Microsoft YaHei&#x27;, sans-serif</span><br><span class="line">// $family-sans-serif ?= Ubuntu, Roboto,&#x27;Nanum Gothic Coding&#x27;, &#x27;Open Sans&#x27;, &#x27;Microsoft YaHei&#x27;, sans-serif</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><figcaption><span>4 line</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$article-font-size ?= 1.3rem</span><br></pre></td></tr></table></figure><h2 id="disqus-댓글-설정"><a href="#disqus-댓글-설정" class="headerlink" title="disqus(댓글) 설정"></a>disqus(댓글) 설정</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">comment:</span><br><span class="line">  type: disqus</span><br><span class="line">  # Disqus shortname</span><br><span class="line">  shortname: inhwancho-github-io #disqus아이디 생성 후 shortname이 생성되는데 그거 입력하면 됩니다.</span><br></pre></td></tr></table></figure><h2 id="google-analytics"><a href="#google-analytics" class="headerlink" title="google_analytics"></a>google_analytics</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># id칸에 입력해야됩니다</span><br><span class="line">google_analytics: </span><br><span class="line">    tracking_id: G-8RGKYVDD5B</span><br></pre></td></tr></table></figure><h2 id="버튼-follow-버튼"><a href="#버튼-follow-버튼" class="headerlink" title="버튼(follow 버튼)"></a>버튼(follow 버튼)</h2><ul><li>기존에 follow 버튼 -&gt; home으로 돌아가는 버튼으로 변경</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;/nav&gt;</span><br><span class="line">&#123;followLink ? &lt;div class=&quot;level&quot;&gt;</span><br><span class="line">// 재수정</span><br><span class="line">    &lt;a class=&quot;level-item button is-round is-info is-outlined is-rounded is-light&quot; href=&quot;/&quot; target=&quot;_self&quot; rel=&quot;noopener&quot;&gt;Home&lt;/a&gt;</span><br><span class="line">// 기존꺼(수정된거)</span><br><span class="line">    &#123;/* &lt;a class=&quot;level-item button is-round is-link is-outlined&quot; href=&#123;followLink&#125; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&#123;followTitle&#125;&lt;/a&gt; */&#125;</span><br><span class="line">&lt;/div&gt; : null&#125;</span><br></pre></td></tr></table></figure><h3 id="맨-밑에-총-방문자수-설정"><a href="#맨-밑에-총-방문자수-설정" class="headerlink" title="맨 밑에 총 방문자수 설정"></a>맨 밑에 총 방문자수 설정</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">busuanzi: true</span><br></pre></td></tr></table></figure><ul><li>donate 부분 주석 처리</li><li>adsense 위젯 주석 처리</li></ul><h2 id="column-변경"><a href="#column-변경" class="headerlink" title="column 변경"></a>column 변경</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&#123;classname(&#123;</span><br><span class="line">    column: true,</span><br><span class="line">    &#x27;order-2&#x27;: true,</span><br><span class="line">    &#x27;column-main&#x27;: true,</span><br><span class="line">    &#x27;is-12&#x27;: columnCount === 1,</span><br><span class="line">    &#x27;is-8-tablet is-8-desktop is-9-widescreen&#x27;: columnCount === 2,</span><br><span class="line">    &#x27;is-8-tablet is-8-desktop is-6-widescreen&#x27;: columnCount === 3</span><br><span class="line">&#125;)&#125; dangerouslySetInnerHTML=&#123;&#123; __html: body &#125;&#125;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure><h2 id="navbar-font-설정"><a href="#navbar-font-설정" class="headerlink" title="navbar font 설정"></a>navbar font 설정</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.navbar-logo</span><br><span class="line">    </span><br><span class="line">    img</span><br><span class="line">        max-height: $logo-height</span><br><span class="line">    font-size: 1.5rem</span><br></pre></td></tr></table></figure><h2 id="제목-설명-폰트"><a href="#제목-설명-폰트" class="headerlink" title="제목 설명 폰트"></a>제목 설명 폰트</h2><ul><li>7 -&gt; 9</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;page.layout !== &#x27;page&#x27; ? &lt;div class=&quot;article-meta is-size-9 is-uppercase level is-mobile&quot;&gt;</span><br></pre></td></tr></table></figure><h2 id="코드블럭-테스트-중"><a href="#코드블럭-테스트-중" class="headerlink" title="코드블럭 테스트 중"></a>코드블럭 테스트 중</h2><figure class="highlight excel"><figcaption><span>_.compact 112Underscore.js</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">안녕</span><br><span class="line">_.compact([<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">false</span>, <span class="number">2</span>, &#x27;&#x27;, <span class="number">3</span>]);</span><br><span class="line">=&gt; [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><blockquote><p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.</p></blockquote><blockquote><p>Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy.</p><footer><strong>David Levithan</strong><cite>Wide Awake</cite></footer></blockquote><blockquote><p>NEW: DevDocs now comes with syntax highlighting. <a href="http://devdocs.io/">http://devdocs.io</a></p><footer><strong>@DevDocs <https://twitter.com/devdocs/status/356095192085962752></strong></footer></blockquote><blockquote><p>Every interaction is both precious and an opportunity to delight.</p><footer><strong>Seth Godin <http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html> Welcome to Island Marketing</strong></footer></blockquote>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Errors/">Errors</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Blog/">Blog</category>
      
      <category domain="http://InhwanCho.github.io/tags/Icarus/">Icarus</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/16/Blogs_folder/2023-01-16-customizeing/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 코랩에서 웹캠 사용하기</title>
      <link>http://inhwancho.github.io/2023/01/15/Study_folder/OpneCV/2023-01-15-webcam-in-colab/</link>
      <guid>http://inhwancho.github.io/2023/01/15/Study_folder/OpneCV/2023-01-15-webcam-in-colab/</guid>
      <pubDate>Sat, 14 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;Javascript를-이용하여-코랩에서-웹캠을-켜는-방법입니다&quot;&gt;&lt;a href=&quot;#Javascript를-이용하여-코랩에서-웹캠을-켜는-방법입니다&quot; class=&quot;headerlink&quot; title=&quot;Javascript를 이용하여 코랩에서 웹캠</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="Javascript를-이용하여-코랩에서-웹캠을-켜는-방법입니다"><a href="#Javascript를-이용하여-코랩에서-웹캠을-켜는-방법입니다" class="headerlink" title="Javascript를 이용하여 코랩에서 웹캠을 켜는 방법입니다"></a>Javascript를 이용하여 코랩에서 웹캠을 켜는 방법입니다</h2><ul><li>filename은 <code>photo.jpg</code>로 저장 되는데 변경해서 사용하시면 됩니다.</li><li>js로 함수를 설정합니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, Javascript</span><br><span class="line"><span class="keyword">from</span> google.colab.output <span class="keyword">import</span> eval_js</span><br><span class="line"><span class="keyword">from</span> base64 <span class="keyword">import</span> b64decode</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">take_photo</span>(<span class="params">filename=<span class="string">&#x27;photo.jpg&#x27;</span>, quality=<span class="number">0.8</span></span>):</span><br><span class="line">  <span class="comment">#javascript 작성 시작</span></span><br><span class="line">  js = Javascript(<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    async function takePhoto(quality) &#123;</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">      //div(공간) 생성</span></span><br><span class="line"><span class="string">      const div = document.createElement(&#x27;div&#x27;);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      //button 생성</span></span><br><span class="line"><span class="string">      const capture = document.createElement(&#x27;button&#x27;);</span></span><br><span class="line"><span class="string">      capture.textContent = &#x27;Capture&#x27;;</span></span><br><span class="line"><span class="string">      div.appendChild(capture);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      //video 생성</span></span><br><span class="line"><span class="string">      const video = document.createElement(&#x27;video&#x27;);</span></span><br><span class="line"><span class="string">      //비디오 모양 네모네모</span></span><br><span class="line"><span class="string">      video.style.display = &#x27;block&#x27;;</span></span><br><span class="line"><span class="string">      //카메라(웹캠) 불러오기</span></span><br><span class="line"><span class="string">      const stream = await navigator.mediaDevices.getUserMedia(&#123;video: true&#125;);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      //div 밑에 child 공간 추가</span></span><br><span class="line"><span class="string">      document.body.appendChild(div);</span></span><br><span class="line"><span class="string">      //공간에 video 넣기</span></span><br><span class="line"><span class="string">      div.appendChild(video);</span></span><br><span class="line"><span class="string">      //video와 웹캠 연결</span></span><br><span class="line"><span class="string">      video.srcObject = stream;</span></span><br><span class="line"><span class="string">      //await -&gt; 비동기식 처리 (thread와 관련)(async와 세트)</span></span><br><span class="line"><span class="string">      await video.play();</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      // Resize the output to fit the video element.</span></span><br><span class="line"><span class="string">      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      // Wait for Capture to be clicked.</span></span><br><span class="line"><span class="string">      await new Promise((resolve) =&gt; capture.onclick = resolve);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      //canvas 생성</span></span><br><span class="line"><span class="string">      const canvas = document.createElement(&#x27;canvas&#x27;);</span></span><br><span class="line"><span class="string">      //크기 맞추기</span></span><br><span class="line"><span class="string">      canvas.width = video.videoWidth;</span></span><br><span class="line"><span class="string">      canvas.height = video.videoHeight;</span></span><br><span class="line"><span class="string">      //이미지 그리기</span></span><br><span class="line"><span class="string">      canvas.getContext(&#x27;2d&#x27;).drawImage(video, 0, 0);</span></span><br><span class="line"><span class="string">      //비디오 끄기</span></span><br><span class="line"><span class="string">      stream.getVideoTracks()[0].stop();</span></span><br><span class="line"><span class="string">      //div 삭제</span></span><br><span class="line"><span class="string">      div.remove();</span></span><br><span class="line"><span class="string">      // 파일 주소 반환</span></span><br><span class="line"><span class="string">      return canvas.toDataURL(&#x27;image/jpeg&#x27;, quality);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  display(js)</span><br><span class="line"> </span><br><span class="line">  data = eval_js(<span class="string">&#x27;takePhoto(&#123;&#125;)&#x27;</span>.<span class="built_in">format</span>(quality))</span><br><span class="line">  <span class="comment">#웹 브라우저에서 데이터를 저장할때 base64로 저장</span></span><br><span class="line">  binary = b64decode(data.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">  <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(binary)</span><br><span class="line">  <span class="keyword">return</span> filename</span><br></pre></td></tr></table></figure><ul><li>실행 코드입니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  filename = take_photo()</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;Saved to &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(filename))</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Show the image which was just taken.</span></span><br><span class="line">  display(Image(filename))</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">  <span class="comment"># Errors will be thrown if the user does not have a webcam or if they do not</span></span><br><span class="line">  <span class="comment"># grant the page permission to access it.</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="built_in">str</span>(err))</span><br></pre></td></tr></table></figure><ul><li>실행 결과 입니다.(<code>capture button</code>을 누르면 실행 종료)</li></ul><img width="714" alt="코랩 캡쳐 결과" src="https://user-images.githubusercontent.com/111936229/212513521-0c8d24b4-c925-4979-9f0a-427b40d15418.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Colab/">Colab</category>
      
      <category domain="http://InhwanCho.github.io/tags/Study/">Study</category>
      
      <category domain="http://InhwanCho.github.io/tags/OpenCV/">OpenCV</category>
      
      <category domain="http://InhwanCho.github.io/tags/Webcam/">Webcam</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/15/Study_folder/OpneCV/2023-01-15-webcam-in-colab/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>깃허브블로그를 변경 후 기존 페이지 잔존 시</title>
      <link>http://inhwancho.github.io/2023/01/13/Blogs_folder/2023-01-13-blogmoving/</link>
      <guid>http://inhwancho.github.io/2023/01/13/Blogs_folder/2023-01-13-blogmoving/</guid>
      <pubDate>Thu, 12 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;깃허브-블로그-기존-페이지-잔존-시&quot;&gt;&lt;a href=&quot;#깃허브-블로그-기존-페이지-잔존-시&quot; class=&quot;headerlink&quot; title=&quot;깃허브 블로그 기존 페이지 잔존 시&quot;&gt;&lt;/a&gt;깃허브 블로그 기존 페이지 잔존 시&lt;/h2&gt;&lt;p&gt;깃허</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="깃허브-블로그-기존-페이지-잔존-시"><a href="#깃허브-블로그-기존-페이지-잔존-시" class="headerlink" title="깃허브 블로그 기존 페이지 잔존 시"></a>깃허브 블로그 기존 페이지 잔존 시</h2><p>깃허브 블로그를 jekyll에서 hexo로 변경 후<br>로컬 서버에서는 잘 나오지만, 배포후에 메인 페이지는 출력이 잘 되는데, About, Archives, Tags, Categories가 기존의 블로그가 출력이 되었습니다.<br>결론은 <code>캐시를 지우지 않아서 그렇습니다.</code><br>css를  수정하고 새로 고침을 해도 서버에서 새로운 css를 받아오는것이 아닌 캐시에 저장된 이미 있는 캐시 파일만을 계속 받아오므로 이런 현상이 나올 수 있습니다.</p><ul><li>맥에서는 해당 페이지에서 <code>Command + Shift + R</code> 혹은 <code>캐시 삭제</code>로 해결 가능합니다.</li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Errors/">Errors</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Blog/">Blog</category>
      
      <category domain="http://InhwanCho.github.io/tags/Errors/">Errors</category>
      
      <category domain="http://InhwanCho.github.io/tags/Logs/">Logs</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/13/Blogs_folder/2023-01-13-blogmoving/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 기초</title>
      <link>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-cv2/</link>
      <guid>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-cv2/</guid>
      <pubDate>Tue, 10 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;OpenCV-이미지-확인&quot;&gt;&lt;a href=&quot;#OpenCV-이미지-확인&quot; class=&quot;headerlink&quot; title=&quot;OpenCV 이미지 확인&quot;&gt;&lt;/a&gt;OpenCV 이미지 확인&lt;/h2&gt;&lt;figure class=&quot;highlight pyth</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="OpenCV-이미지-확인"><a href="#OpenCV-이미지-확인" class="headerlink" title="OpenCV 이미지 확인"></a>OpenCV 이미지 확인</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># imread로 이미지 읽어오기</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;cat_img.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># imshow(&#x27;이미지 표시 이름&#x27;,이미지파일)입력</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;output&#x27;</span>,img)</span><br><span class="line">waitKey(<span class="number">0</span>) <span class="comment">#(0을 넣으면 == 계속 딜레이 - 대기하라는 의미)</span></span><br></pre></td></tr></table></figure><ul><li>imshow의 앞 ‘output’이름으로 img 파일이 출력됩니다.</li><li>사진, 영상을 끄려면 키보드 <code>q</code>를 누르시면 됩니다.</li></ul><img width="1026" alt="스크린샷 2023-01-11 오후 1 07 21" src="https://user-images.githubusercontent.com/111936229/211715668-3db417b0-b1ff-4eaa-9173-73241c8cf7e5.png"><h2 id="내장-카메라-웹캠-실행"><a href="#내장-카메라-웹캠-실행" class="headerlink" title="내장 카메라(웹캠) 실행"></a>내장 카메라(웹캠) 실행</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 웹캠</span></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>) <span class="comment">#노트북은 0번이 기본 내장 웹캠</span></span><br><span class="line"></span><br><span class="line">cap.<span class="built_in">set</span>(<span class="number">3</span>,<span class="number">640</span>) <span class="comment">#id_nubmer, width</span></span><br><span class="line">cap.<span class="built_in">set</span>(<span class="number">4</span>,<span class="number">480</span>) <span class="comment">#id_number, height</span></span><br><span class="line">cap.<span class="built_in">set</span>(<span class="number">10</span>,<span class="number">100</span>) <span class="comment">#id_number,bright</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 웹캠은 프레임 단위로 계속 출력되기 때문에 일반적으로 while문으로 실행한다.</span></span><br><span class="line"><span class="comment"># 키보드 &#x27;q&#x27;버튼을 누르면 실행이 종료됩니다.</span></span><br><span class="line"><span class="comment"># success는 Ture,False이고, img는 프레임 단위의 이미지로 저장되는 형태이다.</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    success, img = cap.read()</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;video_mp4&#x27;</span>, img)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><ul><li>실행 결과</li></ul><img width="705" alt="스크린샷 2023-01-15 오전 11 00 45" src="https://user-images.githubusercontent.com/111936229/212514462-86cdbf15-6286-4151-9a76-55a2e15c7cad.png"><h2 id="이미지-저장"><a href="#이미지-저장" class="headerlink" title="이미지 저장"></a>이미지 저장</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">loaded_img = cv2.imread(<span class="string">&#x27;cat_img.jpg&#x27;</span>)</span><br><span class="line">cv2.imwrite(<span class="string">&#x27;folder/folder1/img.jpg&#x27;</span>,loaded_img)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study/">Study</category>
      
      <category domain="http://InhwanCho.github.io/tags/OpenCV/">OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-cv2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV에 관한 정보</title>
      <link>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-tip-cv2/</link>
      <guid>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-tip-cv2/</guid>
      <pubDate>Tue, 10 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;OpenCV&quot;&gt;&lt;a href=&quot;#OpenCV&quot; class=&quot;headerlink&quot; title=&quot;OpenCV&quot;&gt;&lt;/a&gt;OpenCV&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;openCV를 주피터 환경에서 실행 시 동영상이나 사진의 (&lt;code&gt;x&lt;/cod</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h2><ul><li><p>openCV를 주피터 환경에서 실행 시 동영상이나 사진의 (<code>x</code>)버튼을 누르면 주피터가 먹통이 될 때가 많다.</p><ul><li>키보드 ‘q’를 눌러서 끄는걸 권장한다.</li></ul></li><li><p>맥북 주피터 환경에서는 (<code>x</code>)버튼이 없어서 아래 명령어를 입력해주면 꺼지기는 한다.(터미널을 종료해도 꺼짐)</p><ul><li>다만, 파이참이나 VScode를 활용해 <code>.py파일을 인터프리터로 실행하기를 권장</code>한다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cv2.destroyAllWindows()</span><br><span class="line">cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">cv2.waitKey(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="인터프리터로-실행-시-경로-설정하기"><a href="#인터프리터로-실행-시-경로-설정하기" class="headerlink" title="인터프리터로 실행 시 경로 설정하기"></a>인터프리터로 실행 시 경로 설정하기</h2><ul><li>인터프리터 환경(터미널환경)에서 실행 시 주피터의 실행 경로와 다를 수 있기 때문에 경로를 수정해줘야 오류가 안나온다.<ul><li>VScode에서 경로를 확인, 수정하는 방법은 다음과 같다.</li><li>먼저, 주피터 노트북에서도 아래의 명령어를 입력하고 실행을 한다.</li><li>그 다음 py 파일에에도 같은 입력을 하고 저장 &amp; 실행을 한다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sys.executable)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 출력 결과</span></span><br><span class="line"><span class="comment"># &#x27;/opt/anaconda3/bin/python&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>VScode의 경우는 <ul><li><code>명령 팔레트</code>를 열고 (Shift + command + P) <code>Python: Select Interpreter</code>을 검색 &amp; 누른다.</li><li>제 경우는 <code>/opt/anaconda3/bin/python</code> 앞의 출력 결과(주피터)에 동일한 결과를 선택한다. </li><li>실행해서 잘 되는지 확인한다.</li></ul></li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study-OpenCV/">Study,OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-tip-cv2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 이미지 변환</title>
      <link>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-img_change/</link>
      <guid>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-img_change/</guid>
      <pubDate>Tue, 10 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;Grayscale-GaussianBlur&quot;&gt;&lt;a href=&quot;#Grayscale-GaussianBlur&quot; class=&quot;headerlink&quot; title=&quot;Grayscale, GaussianBlur&quot;&gt;&lt;/a&gt;Grayscale, Gaussian</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="Grayscale-GaussianBlur"><a href="#Grayscale-GaussianBlur" class="headerlink" title="Grayscale, GaussianBlur"></a>Grayscale, GaussianBlur</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;cat_img.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 컬러 -&gt; 흑백으로 변환</span></span><br><span class="line">imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ksize == kernel size이므로 홀수만 사용 가능, sigmaX는 블러 정도라고 생각하면 편하며,</span></span><br><span class="line"><span class="comment"># 보통 -3~3사이의 값을 사용</span></span><br><span class="line">imgBlur = cv2.GaussianBlur(imgGray, ksize=(<span class="number">7</span>,<span class="number">7</span>),sigmaX=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;output&#x27;</span>,imgGray)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;output2&#x27;</span>,imgBlur)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>결과 imgGray</li></ul><img width="1020" alt="스크린샷 2023-01-11 오후 1 15 37" src="https://user-images.githubusercontent.com/111936229/211717325-d4d896f0-630b-4450-8977-a492fa691bd5.png"><ul><li>결과 imgBlur</li></ul><img width="1014" alt="스크린샷 2023-01-11 오후 1 25 13" src="https://user-images.githubusercontent.com/111936229/211717481-1721d754-f9f4-4ef3-bf6d-ea4e4b041f3a.png"><h2 id="Canny-Dialation"><a href="#Canny-Dialation" class="headerlink" title="Canny, Dialation"></a>Canny, Dialation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;cat_img.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">imgCanny = cv2.Canny(img,<span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>), np.uint8)</span><br><span class="line"><span class="comment"># iterations에 높은 수를 넣으면 윤곽선이 더 커집니다.</span></span><br><span class="line">imgDialation = cv2.dilate(imgCanny, kernel=kernel,iterations=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">imgEroded = cv2.erode(imgDialation, kernel=kernel, iterations=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;output3&#x27;</span>,imgCanny)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;output4&#x27;</span>,imgDialation)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;output5&#x27;</span>,imgEroded)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>결과 imgCanny</li></ul><img width="1019" alt="스크린샷 2023-01-11 오후 1 32 21" src="https://user-images.githubusercontent.com/111936229/211718228-2469f803-60dd-4930-bf20-7c1111fa6378.png"><ul><li>결과 imgDialation</li></ul><img width="1021" alt="스크린샷 2023-01-11 오후 1 37 22" src="https://user-images.githubusercontent.com/111936229/211718825-08992f1e-f210-491f-8b42-14c337b9c85c.png"><ul><li>결과 imgEroded</li></ul><img width="1023" alt="스크린샷 2023-01-11 오후 1 42 18" src="https://user-images.githubusercontent.com/111936229/211719388-c8fa40b9-a489-44b0-810d-bb201e9ed1fb.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study-OpenCV/">Study,OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-img_change/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV shape 변환</title>
      <link>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-shape/</link>
      <guid>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-shape/</guid>
      <pubDate>Tue, 10 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;OpenCV와-PIL의-이미지-형태&quot;&gt;&lt;a href=&quot;#OpenCV와-PIL의-이미지-형태&quot; class=&quot;headerlink&quot; title=&quot;OpenCV와 PIL의 이미지 형태&quot;&gt;&lt;/a&gt;OpenCV와 PIL의 이미지 형태&lt;/h2&gt;&lt;ul&gt;
</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="OpenCV와-PIL의-이미지-형태"><a href="#OpenCV와-PIL의-이미지-형태" class="headerlink" title="OpenCV와 PIL의 이미지 형태"></a>OpenCV와 PIL의 이미지 형태</h2><ul><li>결과를 보시면 알겠지만 width, height이 반대입니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;Resources/cards.jpg&#x27;</span>)</span><br><span class="line">h, w, c = img.shape <span class="comment">#가로 세로 채널(색)</span></span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#(500, 477, 3)</span></span><br><span class="line"></span><br><span class="line">pil_img = Image.<span class="built_in">open</span>(<span class="string">&#x27;Resources/cards.jpg&#x27;</span>)</span><br><span class="line">w, h = pil_img <span class="comment">#세로 가로</span></span><br><span class="line"><span class="built_in">print</span>(a.size)</span><br><span class="line"><span class="comment">#(477, 500)</span></span><br></pre></td></tr></table></figure><h3 id="openCV-사진-좌표-형태"><a href="#openCV-사진-좌표-형태" class="headerlink" title="openCV 사진 좌표 형태"></a>openCV 사진 좌표 형태</h3><ul><li>openCV에서 좌표는 아래 사진처럼 표현 됩니다.</li><li><code>x축</code>은 오른쪽으로 가지만 <code>y축</code>은 아래로 가는게 중요합니다.</li></ul><p><img src="https://user-images.githubusercontent.com/111936229/211719711-ece15f56-7602-42cb-81ce-890fb441a9dd.png" alt="스크린샷 2023-01-11 오후 1 45 04"></p><h3 id="Resize"><a href="#Resize" class="headerlink" title="Resize"></a>Resize</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;lena.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="comment">#(512,512,3)</span></span><br><span class="line"></span><br><span class="line">imgResize = cv2.resize(img,(<span class="number">200</span>,<span class="number">150</span>))</span><br><span class="line"><span class="built_in">print</span>(imgResize.shape)</span><br><span class="line"><span class="comment">#(200,150,3)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;origin&#x27;</span>,img)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;resize&#x27;</span>,imgResize)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="713" alt="리사이즈와 원본" src="https://user-images.githubusercontent.com/111936229/211721385-670192b3-699c-44a8-9319-6ce9f7b45235.png"><h3 id="Crop"><a href="#Crop" class="headerlink" title="Crop"></a>Crop</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;lena.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="comment">#(512,512,3)</span></span><br><span class="line">h, w, c = img.shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imgResize = cv2.resize(img,(<span class="number">500</span>,<span class="number">400</span>))</span><br><span class="line"><span class="built_in">print</span>(imgResize.shape)</span><br><span class="line"><span class="comment">#(500,400,3)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># cv에서 crop은 [width(세로), height(가로), 색상 채널]입니다</span></span><br><span class="line">imgCropped = img[<span class="number">0</span>:<span class="number">200</span>,<span class="number">200</span>:<span class="number">400</span>]</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;resize&#x27;</span>,imgResize)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;cropped&#x27;</span>,imgCropped)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="499" alt="Cropped img & original img" src="https://user-images.githubusercontent.com/111936229/211722258-0aebaa91-908e-4298-8f68-6447d7de3fb3.png"><h3 id="Drawing"><a href="#Drawing" class="headerlink" title="Drawing"></a>Drawing</h3><ul><li>영역 만들기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment">#0값은 black으로 표현됨</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파란색 영역을 그림</span></span><br><span class="line">img[<span class="number">200</span>:<span class="number">300</span>, <span class="number">100</span>:<span class="number">500</span>] = <span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span> <span class="comment">#BGR(Blue, Green, Red)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image1&#x27;</span>, img)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="505" alt="black(zeros) & blue img" src="https://user-images.githubusercontent.com/111936229/211735317-36f4c027-a54c-4f91-b8ff-fed892b5c02f.png"><ul><li>line, rectangle 그리기</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment">#start_point, end_point, color, thickness</span></span><br><span class="line">cv2.line(img,(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">300</span>,<span class="number">300</span>),color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),thickness=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image1&#x27;</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="507" alt="red line" src="https://user-images.githubusercontent.com/111936229/211735334-1b952961-a3c4-4c06-b300-54d5a928ccc8.png"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cv2.rectangle(img,(<span class="number">50</span>,<span class="number">50</span>),(<span class="number">500</span>,<span class="number">200</span>),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image1&#x27;</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="510" alt="green rectangle" src="https://user-images.githubusercontent.com/111936229/211736029-28c5615a-7ab3-4792-af15-58b181df1c3f.png"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cv2.circle(img,(<span class="number">200</span>,<span class="number">200</span>), <span class="number">30</span>, (<span class="number">255</span>,<span class="number">20</span>,<span class="number">50</span>),thickness=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image1&#x27;</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="502" alt="blue circle" src="https://user-images.githubusercontent.com/111936229/211737151-6eaf5118-be4a-48f8-ab7d-732ce897bcfd.png"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cv2.putText(img, <span class="string">&#x27;THIS IS Text&#x27;</span>, (<span class="number">50</span>,<span class="number">300</span>),fontFace=cv2.FONT_HERSHEY_COMPLEX,fontScale=<span class="number">1</span>,</span><br><span class="line">color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),thickness=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image1&#x27;</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="508" alt="blue text" src="https://user-images.githubusercontent.com/111936229/211737145-9de7a045-0394-4cb8-8c1a-5528e46c8916.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Study-OpenCV/">Study,OpenCV</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/11/Study_folder/OpneCV/2023-01-11-shape/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>XAI(eXplainable AI) - 설명하는 AI</title>
      <link>http://inhwancho.github.io/2023/01/10/Study_folder/TensorFlow/2023-01-10-XAI/</link>
      <guid>http://inhwancho.github.io/2023/01/10/Study_folder/TensorFlow/2023-01-10-XAI/</guid>
      <pubDate>Mon, 09 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;설명-가능한-AI-eXplainable-AI-XAI&quot;&gt;&lt;a href=&quot;#설명-가능한-AI-eXplainable-AI-XAI&quot; class=&quot;headerlink&quot; title=&quot;설명 가능한 AI(eXplainable AI) - XAI&quot;&gt;&lt;/a</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="설명-가능한-AI-eXplainable-AI-XAI"><a href="#설명-가능한-AI-eXplainable-AI-XAI" class="headerlink" title="설명 가능한 AI(eXplainable AI) - XAI"></a>설명 가능한 AI(eXplainable AI) - XAI</h2><ul><li>XAI는 인공지능의 행위와 도출한 결과를 사람이 이해할 수 있는 형태로 이를 설명하는 방법론과 분야를 일컫는다. 흔히 인공지능 기술은 복잡한 일련의 과정(딥러닝)을 통해 결론을 도출하나, 그 과정을 설명할 수 없는 블랙 박스로 여겨진다. XAI는 이를 해소 시킬 수 있는 개념으로 인공지능의 신뢰성을 높이는 역할하고 있습니다.</li></ul><h3 id="1-CAM"><a href="#1-CAM" class="headerlink" title="(1) CAM"></a>(1) CAM</h3><pre><code>1 - flatten 작업 직전 단계에서 이때까지 만들어진 중간 결과들(feature map)을 수집2 - 중간 결과들에 대한 평균값을 구함3 - 평균값과 최종 예측값 사이에서 한번 더 학습 -&gt; 어떤 중간값이 최종 결정에 영향을 크게 줬는지 확인</code></pre><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">!pip install tf-explain</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line">zipfile.ZipFile(<span class="string">&#x27;img.zip&#x27;</span>).extractall()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> load_img, img_to_array</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tf_explain.core.grad_cam <span class="keyword">import</span> GradCAM</span><br><span class="line"><span class="keyword">from</span> tf_explain.core.occlusion_sensitivity <span class="keyword">import</span> OcclusionSensitivity</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br></pre></td></tr></table></figure><ul><li>원본 사진 파일 확인</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(glob.glob(<span class="string">&#x27;*_0.jpg&#x27;</span>))</span><br><span class="line"><span class="comment"># [&#x27;yawl_0.jpg&#x27;, &#x27;squirrel_monkey_0.jpg&#x27;, &#x27;persian_cat_0.jpg&#x27;, </span></span><br><span class="line"><span class="comment"># &#x27;maltese_0.jpg&#x27;, &#x27;grand_piano_0.jpg&#x27;]</span></span><br><span class="line"></span><br><span class="line">images_originals = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> img_name <span class="keyword">in</span> glob.glob(<span class="string">&quot;*_0.jpg&quot;</span>):</span><br><span class="line">    images_originals.append(mpimg.imread(img_name))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> i, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(images_originals):</span><br><span class="line">    plt.subplot(<span class="number">5</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(img)</span><br></pre></td></tr></table></figure><img width="1286" alt="스크린샷 2023-01-10 오전 10 50 11" src="https://user-images.githubusercontent.com/111936229/211443584-83cdcb57-9d75-4f79-90ba-2364b7469d0b.png"><ul><li>이제 VGG16에서 이미지 분류된 결과를 통해 원본 사진을 왜 카테고리(input_list)로 분류하였는지를 확인하겠습니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">model = VGG16(weights=<span class="string">&quot;imagenet&quot;</span>, include_top=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_list = [<span class="string">&quot;maltese&quot;</span>, <span class="string">&quot;persian_cat&quot;</span>, <span class="string">&quot;squirrel_monkey&quot;</span>, <span class="string">&quot;grand_piano&quot;</span>, <span class="string">&quot;yawl&quot;</span>]</span><br><span class="line">imagenet_index = [<span class="string">&quot;153&quot;</span>, <span class="string">&quot;283&quot;</span>, <span class="string">&quot;382&quot;</span>, <span class="string">&quot;579&quot;</span>, <span class="string">&quot;914&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#gradient CAM 알고리즘으로 XAI 생성</span></span><br><span class="line">explainer = GradCAM()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> li, i <span class="keyword">in</span> <span class="built_in">zip</span>(input_list, imagenet_index):</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">    img = (load_img(<span class="string">f&#x27;<span class="subst">&#123;li&#125;</span>_0.jpg&#x27;</span>, target_size=(<span class="number">224</span>,<span class="number">224</span>)))</span><br><span class="line">    img = img_to_array(img)</span><br><span class="line">    data = ([img], <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># print(data)</span></span><br><span class="line">    <span class="comment"># print(&#x27;--&#x27;*50)</span></span><br><span class="line">    grid = explainer.explain(data, model, <span class="built_in">int</span>(i))<span class="comment"># 설명하는 ai 생성</span></span><br><span class="line">    explainer.save(grid, <span class="string">&#x27;.&#x27;</span>, <span class="string">f&#x27;./<span class="subst">&#123;li&#125;</span>_cam.jpg&#x27;</span>) <span class="comment">#_cam.jpg파일이란 이름으로 저장</span></span><br></pre></td></tr></table></figure><ul><li>저장된 사진을 확인해봅시다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#gradient CAM 알고리즘이 적용된 이미지를 저장할 리스트 정의</span></span><br><span class="line">images_cams = []</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> glob.glob(<span class="string">&quot;*_cam.jpg&quot;</span>):</span><br><span class="line">    images_cams.append(mpimg.imread(img))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 출력</span></span><br><span class="line"><span class="keyword">for</span> i, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(images_cams):</span><br><span class="line">    plt.subplot(<span class="number">5</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(img)</span><br></pre></td></tr></table></figure><img width="1265" alt="스크린샷 2023-01-10 오전 11 01 44" src="https://user-images.githubusercontent.com/111936229/211445060-ccee085e-ff83-4b22-96e5-19b73e226fcc.png"><h3 id="2-이미지를-일부를-가려서-가려진-일부가-이미지-분류하는데-있어서-어느-정도-영향을-줬는지-계산하는-방식"><a href="#2-이미지를-일부를-가려서-가려진-일부가-이미지-분류하는데-있어서-어느-정도-영향을-줬는지-계산하는-방식" class="headerlink" title="(2) 이미지를 일부를 가려서, 가려진 일부가 이미지 분류하는데 있어서 어느 정도 영향을 줬는지 계산하는 방식"></a>(2) 이미지를 일부를 가려서, 가려진 일부가 이미지 분류하는데 있어서 어느 정도 영향을 줬는지 계산하는 방식</h3><p>작성 중</p>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Tensorflow/">Deeplearning,Study,Tensorflow</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/10/Study_folder/TensorFlow/2023-01-10-XAI/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>파이토치에서 model 정보(summary) 확인</title>
      <link>http://inhwancho.github.io/2023/01/09/Study_folder/Pytorch/2023-01-09-model-info/</link>
      <guid>http://inhwancho.github.io/2023/01/09/Study_folder/Pytorch/2023-01-09-model-info/</guid>
      <pubDate>Sun, 08 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;파이토치에서-만들어진-모델-정보-확인하기&quot;&gt;&lt;a href=&quot;#파이토치에서-만들어진-모델-정보-확인하기&quot; class=&quot;headerlink&quot; title=&quot;파이토치에서 만들어진 모델 정보 확인하기&quot;&gt;&lt;/a&gt;파이토치에서 만들어진 모델 정보 확인</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="파이토치에서-만들어진-모델-정보-확인하기"><a href="#파이토치에서-만들어진-모델-정보-확인하기" class="headerlink" title="파이토치에서 만들어진 모델 정보 확인하기"></a>파이토치에서 만들어진 모델 정보 확인하기</h2><ul><li>keras에서는 <code>model.summary()</code>의 내장 함수를 이용하면 간단하게 모델 정보를 확인 가능합니다.</li><li>파이토치에서도 여러 가지 방법을 통해 정보를 확인할 수 있습니다.</li></ul><h3 id="1-print를-하면-summary가-출력된다"><a href="#1-print를-하면-summary가-출력된다" class="headerlink" title="1. print를 하면 summary가 출력된다"></a>1. <code>print</code>를 하면 summary가 출력된다</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure><img width="943" alt="스크린샷 2023-01-09 오후 2 47 20" src="https://user-images.githubusercontent.com/111936229/211247463-dffbfede-2625-4d50-b1f7-e48369abcc2f.png"><h3 id="2-torchinfo-통해-summary를-출력한다"><a href="#2-torchinfo-통해-summary를-출력한다" class="headerlink" title="2. torchinfo 통해 summary를 출력한다"></a>2. <code>torchinfo</code> 통해 summary를 출력한다</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!pip install torchinfo</span><br><span class="line"><span class="keyword">from</span> torchinfo <span class="keyword">import</span> summary</span><br><span class="line"></span><br><span class="line">summary(model)</span><br></pre></td></tr></table></figure><img width="719" alt="스크린샷 2023-01-09 오후 2 47 04" src="https://user-images.githubusercontent.com/111936229/211247503-5e2ae136-14ec-4091-b65f-1cec173f4982.png"><h3 id="3-torchsummary를-통해-summary출력-input-size를-알아야만-출력-가능"><a href="#3-torchsummary를-통해-summary출력-input-size를-알아야만-출력-가능" class="headerlink" title="3. torchsummary를 통해 summary출력 (input_size를 알아야만 출력 가능)"></a>3. <code>torchsummary</code>를 통해 summary출력 (input_size를 알아야만 출력 가능)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!pip install torchsummary</span><br><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br><span class="line"></span><br><span class="line">summary(model, input_size = (<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>), batch_size= <span class="number">6</span>)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Pytorch/">Deeplearning,Study,Pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/09/Study_folder/Pytorch/2023-01-09-model-info/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Attention 코드로 구현하기</title>
      <link>http://inhwancho.github.io/2023/01/08/Study_folder/NLP(Natural_Language_Processing)/2023-01-08-attention-imp/</link>
      <guid>http://inhwancho.github.io/2023/01/08/Study_folder/NLP(Natural_Language_Processing)/2023-01-08-attention-imp/</guid>
      <pubDate>Sat, 07 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;스케일드-닷-프로덕트-어텐션&quot;&gt;&lt;a href=&quot;#스케일드-닷-프로덕트-어텐션&quot; class=&quot;headerlink&quot; title=&quot;스케일드 닷-프로덕트 어텐션&quot;&gt;&lt;/a&gt;스케일드 닷-프로덕트 어텐션&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;참조 : &amp;lt;&lt;a </description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="스케일드-닷-프로덕트-어텐션"><a href="#스케일드-닷-프로덕트-어텐션" class="headerlink" title="스케일드 닷-프로덕트 어텐션"></a>스케일드 닷-프로덕트 어텐션</h2><ul><li>참조 : &lt;<a href="https://wikidocs.net/31379">위키독스</a>&gt;</li><li>닷-프로덕트 어텐션(dot-product attention)에서 스케일링하는 것을 추가하면<br><br> <code>스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)</code>이라고 합니다</li><li>scaled_dot_product_attention을 tensorflow로 구현, 살펴보겠습니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scaled_dot_product_attention</span>(<span class="params">query, key, value, mask</span>):</span><br><span class="line">  <span class="comment"># query 크기    : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)</span></span><br><span class="line">  <span class="comment"># key 크기      : (batch_size, num_heads, key의 문장 길이,   d_model/num_heads)</span></span><br><span class="line">  <span class="comment"># value 크기    : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)</span></span><br><span class="line">  <span class="comment"># padding_mask : (batch_size, 1, 1, key의 문장 길이)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Q와 K의 곱. 어텐션 스코어 행렬.</span></span><br><span class="line">  matmul_qk = tf.matmul(query, key, transpose_b=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 스케일링</span></span><br><span class="line">  depth = tf.cast(tf.shape(key)[-<span class="number">1</span>], tf.float32)</span><br><span class="line">  logits = matmul_qk / tf.math.sqrt(depth)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 마스킹, 매우 작은 값이므로 소프트맥스 함수에 의해 0이 된다.</span></span><br><span class="line">  <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    logits += (mask * -<span class="number">1e9</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행(axis=-1)</span></span><br><span class="line">  <span class="comment"># attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)</span></span><br><span class="line">  attention_weights = tf.nn.softmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)</span></span><br><span class="line">  output = tf.matmul(attention_weights, value)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> output, attention_weights</span><br></pre></td></tr></table></figure><h3 id="테스트"><a href="#테스트" class="headerlink" title="테스트"></a>테스트</h3><ul><li>temp_q의 값 [0, 10, 0]은 Key에 해당하는 temp_k의 두번째 값 [0, 10, 0]과 일치하게 설정</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 임의의 Query, Key, Value인 Q, K, V 행렬 생성</span></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">True</span>) <span class="comment">#옵션 넣어줘야 보기 편함(소수점 반올림)</span></span><br><span class="line">temp_k = tf.constant([[<span class="number">10</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">10</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>]], dtype=tf.float32)  <span class="comment"># (4, 3)</span></span><br><span class="line"></span><br><span class="line">temp_v = tf.constant([[<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">10</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">100</span>,<span class="number">5</span>],</span><br><span class="line">                      [<span class="number">1000</span>,<span class="number">6</span>]], dtype=tf.float32)  <span class="comment"># (4, 2)</span></span><br><span class="line">temp_q = tf.constant([[<span class="number">0</span>, <span class="number">10</span>, <span class="number">0</span>]], dtype=tf.float32)  <span class="comment"># (1, 3) #transpose_b</span></span><br></pre></td></tr></table></figure><ul><li>어텐션 분포는 [0, 1, 0, 0]의 값을 가지며</li><li>Value의 두번째 값인 [10, 0]이 출력되는 것을 확인할 수 있습니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 함수 실행</span></span><br><span class="line">temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(temp_attn) <span class="comment"># 어텐션 분포(어텐션 가중치의 나열)</span></span><br><span class="line"><span class="comment"># tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(temp_out) <span class="comment"># 어텐션 값</span></span><br><span class="line"><span class="comment"># tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP-Study/">NLP,Study</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/08/Study_folder/NLP(Natural_Language_Processing)/2023-01-08-attention-imp/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>torch를 boolean값으로 변경</title>
      <link>http://inhwancho.github.io/2023/01/08/Study_folder/Pytorch/2023-01-08-boolean/</link>
      <guid>http://inhwancho.github.io/2023/01/08/Study_folder/Pytorch/2023-01-08-boolean/</guid>
      <pubDate>Sat, 07 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;operation-참조&quot;&gt;&lt;a href=&quot;#operation-참조&quot; class=&quot;headerlink&quot; title=&quot;operation 참조&quot;&gt;&lt;/a&gt;operation 참조&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;예시를 통해 알아보겠습니다.&lt;/li&gt;
&lt;/u</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="operation-참조"><a href="#operation-참조" class="headerlink" title="operation 참조"></a>operation 참조</h2><ul><li>예시를 통해 알아보겠습니다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x&gt;<span class="number">2</span>)</span><br><span class="line"><span class="comment"># tensor([False, False,  True,  True])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>((x&gt;<span class="number">2</span>).<span class="built_in">type</span>(torch.float32))</span><br><span class="line"><span class="comment"># tensor([0., 0., 1., 1.])</span></span><br></pre></td></tr></table></figure><h2 id="gt-함수를-활용"><a href="#gt-함수를-활용" class="headerlink" title="gt() 함수를 활용"></a>gt() 함수를 활용</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.gt(<span class="number">2</span>))</span><br><span class="line"><span class="comment"># tensor([False, False,  True,  True])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.gt(<span class="number">2</span>).to(torch.int32))</span><br><span class="line"><span class="comment"># tensor([0, 0, 1, 1], dtype=torch.int32)</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Pytorch/">Deeplearning,Study,Pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/08/Study_folder/Pytorch/2023-01-08-boolean/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>tf.cast()</title>
      <link>http://inhwancho.github.io/2023/01/08/Study_folder/TensorFlow/2023-01-08-cast/</link>
      <guid>http://inhwancho.github.io/2023/01/08/Study_folder/TensorFlow/2023-01-08-cast/</guid>
      <pubDate>Sat, 07 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;tf-cast-x-dtype-name-x3D-None&quot;&gt;&lt;a href=&quot;#tf-cast-x-dtype-name-x3D-None&quot; class=&quot;headerlink&quot; title=&quot;tf.cast(x, dtype, name&amp;#x3D;None)&quot;</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="tf-cast-x-dtype-name-x3D-None"><a href="#tf-cast-x-dtype-name-x3D-None" class="headerlink" title="tf.cast(x, dtype, name&#x3D;None)"></a>tf.cast(x, dtype, name&#x3D;None)</h2><blockquote><p>The operation casts x (in case of Tensor) or x.values (in case of SparseTensor or IndexedSlices) to dtype.<br><br>해석하자면 x값을 새로운 형태의 dtype으로 캐스팅한다는 의미입니다.{:.prompt-info}</p></blockquote><ul><li><p>부동 소수점형에서 정수형으로 바꾼 경우 소수점을 버린다.</p></li><li><p>Boolean으로 참조한 경우 True이면 1, False이면 0을 출력한다.</p></li><li><p>예시를 보면 이해가 될겁니다.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1.8</span>, <span class="number">2.2</span>, <span class="number">3.3</span>], dtype=tf.float32)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># tf.Tensor([1.8 2.2 3.3], shape=(3,), dtype=float32)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.cast(x, tf.int32)</span><br><span class="line"><span class="comment"># 출력 결과를 보시면 반올림, 내림이 아닌 소수점을 버립니다.</span></span><br><span class="line"><span class="comment"># &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.cast(x&gt;<span class="number">2</span>, tf.float32)</span><br><span class="line"><span class="comment"># &lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 1.], dtype=float32)&gt;</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Tensorflow/">Deeplearning,Study,Tensorflow</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/08/Study_folder/TensorFlow/2023-01-08-cast/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>torch.tril</title>
      <link>http://inhwancho.github.io/2023/01/07/Study_folder/Pytorch/2023-01-07-tril/</link>
      <guid>http://inhwancho.github.io/2023/01/07/Study_folder/Pytorch/2023-01-07-tril/</guid>
      <pubDate>Fri, 06 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;torch-tril&quot;&gt;&lt;a href=&quot;#torch-tril&quot; class=&quot;headerlink&quot; title=&quot;torch.tril&quot;&gt;&lt;/a&gt;torch.tril&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;torch.tril(input, diago</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="torch-tril"><a href="#torch-tril" class="headerlink" title="torch.tril"></a>torch.tril</h2><ul><li><p><code>torch.tril(input, diagonal=0, *, out=None)</code></p></li><li><p>행렬의 아래쪽 삼각형 부분 (2 차원 텐서) 또는 행렬의 배치 input 을 반환합니다 .[행렬의 오른쪽 부분을(0으로 만듬)]</p></li><li><p>attention 구조의 mask를 만들 때 많이 사용되는 함수입니다.</p></li><li><p>무슨 말인지 이해가 잘 안가실겁니다. 예제 출력 코드를 보면 바로 이해가 갈겁니다.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones((<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">torch.tril(a)</span><br><span class="line"></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = torch.ones((<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">torch.tril(a, diagonal=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Pytorch/">Deeplearning,Study,Pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/07/Study_folder/Pytorch/2023-01-07-tril/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>nn.Embedding</title>
      <link>http://inhwancho.github.io/2023/01/07/Study_folder/Pytorch/2023-01-07-nn.Embedding/</link>
      <guid>http://inhwancho.github.io/2023/01/07/Study_folder/Pytorch/2023-01-07-nn.Embedding/</guid>
      <pubDate>Fri, 06 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;nn-Embedding&quot;&gt;&lt;a href=&quot;#nn-Embedding&quot; class=&quot;headerlink&quot; title=&quot;nn.Embedding&quot;&gt;&lt;/a&gt;nn.Embedding&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;출처 : &amp;lt;&lt;a href=&quot;htt</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="nn-Embedding"><a href="#nn-Embedding" class="headerlink" title="nn.Embedding"></a>nn.Embedding</h2><ul><li><p>출처 : &lt;<a href="https://wikidocs.net/64779">위키독스</a>&gt;</p></li><li><p>임베딩 층(embedding layer)을 만들어 훈련 데이터로부터 처음부터 임베딩 벡터를 학습하는 방법을 <code>nn.Embedding</code>을 이용하여 구현합니다.</p></li><li><p>주요 파라미터는 2개입니다.</p><ul><li>num_embeddings : 임베딩을 할 단어들의 개수. (단어 집합의 크기)</li><li>embedding_dim : 임베딩 할 벡터의 차원입니다. (사용자 정의)</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">train_data = <span class="string">&#x27;we can do lots of things like climbing do&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 중복을 제거한 단어들의 집합인 단어 집합 생성.(num_embeddings 인자)</span></span><br><span class="line">word_set = <span class="built_in">set</span>(train_data.split())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 단어 집합의 각 단어에 고유한 정수 맵핑.</span></span><br><span class="line">vocab = &#123;tkn: i+<span class="number">2</span> <span class="keyword">for</span> i, tkn <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_set)&#125;</span><br><span class="line">vocab[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>] = <span class="number">0</span></span><br><span class="line">vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>] = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(vocab)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;things&#x27;: 2, &#x27;lots&#x27;: 3, &#x27;can&#x27;: 4, &#x27;like&#x27;: 5, &#x27;do&#x27;: 6, &#x27;climbing&#x27;: 7, &#x27;of&#x27;: 8, &#x27;we&#x27;: 9, &#x27;&lt;unk&gt;&#x27;: 0, &#x27;&lt;pad&gt;&#x27;: 1&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 단어 집합의 크기의 행을 가지는 임베딩 테이블 생성</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">embedding_layer = nn.Embedding(num_embeddings=<span class="built_in">len</span>(vocab), </span><br><span class="line">                               embedding_dim=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">embedding_layer</span><br><span class="line"><span class="comment"># Embedding(10, 3, padding_idx=1)</span></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="built_in">print</span>(embedding_layer.weight)</span><br><span class="line"></span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">0.2915</span>,  <span class="number">0.8197</span>,  <span class="number">0.1080</span>],</span><br><span class="line">        [ <span class="number">0.4103</span>,  <span class="number">1.2429</span>, -<span class="number">0.7658</span>],</span><br><span class="line">        [ <span class="number">0.4185</span>, -<span class="number">0.0410</span>,  <span class="number">2.1945</span>],</span><br><span class="line">        [-<span class="number">0.9706</span>, -<span class="number">0.6196</span>, -<span class="number">1.3778</span>],</span><br><span class="line">        [-<span class="number">1.8044</span>, -<span class="number">0.8070</span>, -<span class="number">1.0277</span>],</span><br><span class="line">        [ <span class="number">0.7752</span>, -<span class="number">0.1011</span>,  <span class="number">1.5459</span>],</span><br><span class="line">        [ <span class="number">0.2195</span>,  <span class="number">1.2008</span>,  <span class="number">0.1253</span>],</span><br><span class="line">        [ <span class="number">0.6568</span>,  <span class="number">1.3255</span>,  <span class="number">0.5347</span>],</span><br><span class="line">        [-<span class="number">1.2790</span>,  <span class="number">0.3015</span>, -<span class="number">0.2819</span>],</span><br><span class="line">        [-<span class="number">0.0371</span>, -<span class="number">0.0291</span>, -<span class="number">0.2894</span>]], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Pytorch/">Deeplearning,Study,Pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/07/Study_folder/Pytorch/2023-01-07-nn.Embedding/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Squeeze, Unsqueeze</title>
      <link>http://inhwancho.github.io/2023/01/06/Study_folder/Pytorch/2023-01-06-squeeze/</link>
      <guid>http://inhwancho.github.io/2023/01/06/Study_folder/Pytorch/2023-01-06-squeeze/</guid>
      <pubDate>Thu, 05 Jan 2023 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;squeeze&quot;&gt;&lt;a href=&quot;#squeeze&quot; class=&quot;headerlink&quot; title=&quot;squeeze&quot;&gt;&lt;/a&gt;squeeze&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;squeeze와 unsqueeze는 1인 차원을 제거, 생성할때 매</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a>squeeze</h2><blockquote><p>squeeze와 unsqueeze는 1인 차원을 제거, 생성할때 매우 유용한 함수이다.</p></blockquote><ul><li>squeeze는 차원이 1인 차원을 제거해준다.(default값)</li><li>차원을 설정해주면 그 차원만 제거한다.(1인 차원만 제거되니 참고)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.rand(<span class="number">3</span>, <span class="number">20</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 20, 1, 1])</span></span><br><span class="line"></span><br><span class="line">x = x.squeeze()</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 20])</span></span><br><span class="line"></span><br><span class="line">x = torch.squeeze(x, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 20])</span></span><br></pre></td></tr></table></figure><h2 id="unsqueeze"><a href="#unsqueeze" class="headerlink" title="unsqueeze"></a>unsqueeze</h2><ul><li>unsqueeze는 차원이 1인 차원을 생성해준다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">3</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 20, 30, 40])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = x.unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 1, 20, 30, 40])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 20, 30, 40])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = torch.unsqueeze(x,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 1, 20, 30, 40])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([3, 20, 30, 40])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = x.unsqueeze(dim = <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 3, 20, 30, 40])</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Study/">Study</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/Deeplearning-Study-Pytorch/">Deeplearning,Study,Pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/06/Study_folder/Pytorch/2023-01-06-squeeze/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
