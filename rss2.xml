<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Inhwan&#39;s Digital Space</title>
    <link>http://InhwanCho.github.io/</link>
    
    <atom:link href="http://inhwancho.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>I&#39;m Learning ML/DL</description>
    <pubDate>Wed, 23 Aug 2023 15:00:00 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Prompt Engineering</title>
      <link>http://inhwancho.github.io/2023/08/24/Study_folder/LLM/2023-08-24-PromptE/</link>
      <guid>http://inhwancho.github.io/2023/08/24/Study_folder/LLM/2023-08-24-PromptE/</guid>
      <pubDate>Wed, 23 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h2><p><a href="https://arxiv.org/abs/2205.09712" title="paper">Selection-Inference 논문</a></p><p><a href="https://platform.openai.com/playground" title="openai playground">OpenAI Playground</a></p><h2 id="Prompt-란"><a href="#Prompt-란" class="headerlink" title="Prompt 란 ?"></a>Prompt 란 ?</h2><pre><code>- 과거에는 컴퓨터에 사람의 언어를 입력하면 컴퓨터가 인식을 제대로 할 수 없었기 때문에   [ls, cd, pwd]같은 명령어들이 프롬프트이며,  현재는 ChatGPT같은 모델에 입력하는 명령어   &#39;ex) ChatGPT가 무엇인지 설명해줘&#39; 같은 인간의 언어도 프롬프트이다.</code></pre><h2 id="Prompt-Engineering-이란"><a href="#Prompt-Engineering-이란" class="headerlink" title="Prompt Engineering 이란 ?"></a>Prompt Engineering 이란 ?</h2><p>답변을 위한 <code>적절한 컨텍스트</code> , <code>원하는 결과와 포맷(json, markdown, ...)의 출력을 위한 프롬프트 작성</code>을 하는 엔지니어링입니다.</p><p>즉, <code>어쩌다 한 번 결과를 내는 것이 아닌, 항상 일관성 있게 의도한 결과를 내도록 프롬프트를 작성하는 것</code>입니다.</p><pre><code>- ChatGPT같은 생성 모델에서 더 나은 결과 값을 얻기위해 프롬프트(입력문)를 최적화하는 직업- ex) ChatGPT가 무엇인지 2줄로 요약을 해줘. 문장 시작은 1,2로 시작해줘&#39;수능 예상 문제 만들어줘&#39;가 아닌 &#39;수능 수리영역에 피타고라스의 정의가 들어가는 예상 문제 3개 만들어줘&#39;처럼 작성하는 것입니다.</code></pre><hr><h2 id="프롬프트-엔지니어링-방법"><a href="#프롬프트-엔지니어링-방법" class="headerlink" title="프롬프트 엔지니어링 방법"></a>프롬프트 엔지니어링 방법</h2><p>대략적인 엔지니어링 설계 방법은 다음의 방법을 활용하면 됩니다.</p><ol><li>프롬프트 예상 결과 설정</li><li>프롬프트 평가 설계</li><li>그라운딩 설계 및 평가</li><li>프롬프트 디자인</li><li>모니터링 및 개선</li></ol><hr><h3 id="프롬프트-구성-요소"><a href="#프롬프트-구성-요소" class="headerlink" title="프롬프트 구성 요소"></a>프롬프트 구성 요소</h3><ul><li><p>Role(역할) 설정</p><pre><code>페르소나를 설정(배경 지식을 가지고 답하므로 정확도 향상)예시 1) 당신은 바리스타입니다. 나는 산미를 좋아하는데 원두 추천해줘.예시 2) 당신은 스포츠기자입니다. 주요 해외 축구 기사 이벤트를 보고서를 markdown 형식으로 작성해줘</code></pre></li><li><p>Policy(rule)</p><pre><code>예시 1)가짜 정보를 사용하여 뉴스를 작성해주세요예시 2)공손한 말투로 위의 답변을 200자 내로 변경해주세요</code></pre></li><li><p>Audience(constraint)</p><pre><code>특정 그룹을 설정예시 1)기타 입문자를 위한 곡을 추천해줘예시 2)숙련된 클라이머를 위한 손가락 트레이닝 루틴을 작성해줘</code></pre></li><li><p>Knowledge(info)</p><pre><code>참고할 정보 출처를 지정예시 1)위키피디아의 내용에 따라 세종대왕에 대해 설명을 요약해줘</code></pre></li><li><p>Task</p><pre><code>수행해야 할 특정 작업 및 목표를 지정예시 1)ChatGPT가 무엇인지 3줄로 작성해줘예시 2)프롬프트를 개선하기 위한 제안을 제시해주세요</code></pre></li><li><p>Format</p><pre><code>예시 1)markdown 형식으로 결과를 출력해줘</code></pre></li><li><p>Examples(few-shot learning)</p><pre><code>예시 1)질문 : 기억, 학습답변 : 이것은 기억력 향상에 도움을 주는 학습 방법이다.질문 : 휴대폰, 기술답변 : 휴대폰은 현대 기술으로 만들어진 무선 이어폰이다.질문 : 볼펜, 코끼리답변 :</code></pre></li></ul><h3 id="위의-기술들을-기반으로-프롬프트를-작성하면-다음과-같습니다"><a href="#위의-기술들을-기반으로-프롬프트를-작성하면-다음과-같습니다" class="headerlink" title="위의 기술들을 기반으로 프롬프트를 작성하면 다음과 같습니다."></a>위의 기술들을 기반으로 프롬프트를 작성하면 다음과 같습니다.</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">당신은 유머러스한 영어 선생님입니다.</span><br><span class="line">다음의 정보를 참고하여 초등학생에게 이순신 장군에 대해 설명해주세요.</span><br><span class="line">위키피디아의 설명을 참고해 답변해주세요.</span><br><span class="line">---</span><br><span class="line">다음의 규칙에 따라 답변을 작성해주세요.</span><br><span class="line">- 교육적인 톤으로 작성</span><br><span class="line">- 쉬운 영어로 작성</span><br><span class="line">- 500자 내의 길이로 작성</span><br><span class="line">- 대화 형식으로 작성</span><br><span class="line"></span><br><span class="line">결과 예시 :</span><br><span class="line">Q : 이순신 장군이 누구야?</span><br><span class="line">A : 이순신 장군은 16세기 말 조선의 명장이자 구국영웅인 충무공 ...</span><br><span class="line">Q :</span><br></pre></td></tr></table></figure><hr><h2 id="프롬프트-엔지니어링의-대표적-기술"><a href="#프롬프트-엔지니어링의-대표적-기술" class="headerlink" title="프롬프트 엔지니어링의 대표적 기술"></a>프롬프트 엔지니어링의 대표적 기술</h2><pre><code>1. Zero-shot/ One-shot/ Few-shot learning(examples)2. Chain of Thought(CoT)3. Self-Consistency4. Selection-Inference5. Least-to-Most6. React7. Self Evaluation</code></pre><ol><li><code>few-shot learning</code>은 예시를 주고 예상 답변을 기대하는 것입니다.</li></ol><ul><li>예시가 없을 경우 zero-shot</li><li>예시가 1개면 one-shot, 여러개면 few-shot learning이라 합니다.</li></ul><ol start="2"><li><code>Chain of Thouhgt(CoT)</code>은</li></ol><ul><li>이유에 대해 설명하도록 만들어 답을 더 정확하게 만드는 기술</li><li>중간 추론 단계를 거치도록 하여 복잡한 작업에 정확도를 향상하는 방법</li></ul><p>LLM은 산술연산에 약한 편이라서 중간 추론 단계를 작성해줘야 정확한 답변을 낼 확률이 높아집니다.</p><p><code>Zero-Shot Chain of Thought</code>은 <code>천천히 생각해</code> 라고 지시를 하면 보다 나은 답변을 내주는 기술입니다.</p><ul><li>ChatGPT의 경우 <code>zero-shot CoT</code>가 default로 지정되 있습니다.</li></ul><ol start="3"><li><p><code>Self-Consistency</code>은 같은 질문(프롬프트)로 여러번 반복 실행하고, 그 중 좋은 결과를 선책</p></li><li><p><code>Selection-Inference</code>은 여러 추론 단계를 연결하기 위한 방법입니다.</p></li></ol><ul><li><p>context에서 질문에 답할 수 있는 정보를 선택 -&gt; 그 답변을 기반으로 선택하게 유도</p></li><li><p>이 방법은 추론 단계를 추적 가능하여 디버깅에 유용합니다.</p><p>  예시)<br>  context : …</p><p>  Question : A &#x3D;&#x3D; B가 True일까요?</p><p>  질문의 답에 필요한 내용을 context에서 추출해서 나열하세요</p><hr><p>  selection : …</p><hr><p>  selection에 기반해서 Question에 답해주세요</p><hr><p>  Answer : 아니오, A &#x3D;&#x3D; B는 True가 아닙니다.</p></li></ul><ol start="5"><li><code>Least-to-Most</code> 최종 답변이 나올때까지 여러번 질문을 변경하는 방법입니다.</li></ol><ul><li>Task를 분할하여 작은 문제를 순차적으로 풀어해치는 방법.</li><li>CoT + Selection-inference</li></ul><ol start="6"><li><code>ReAct</code> 실행 계획을 유도하고 추적하여 작업별 실행할 액션을 선택하고 실행하는 방법</li></ol><ul><li><p>외부 API&#x2F;검색엔진을 통해 정보를 사용하거나 계산기나 이미지 생성 등의 도구를 사용할 수 있음.</p></li><li><p>실제로 사용할 때는 각 단계별로 끊어서 결과를 제어할 필요가 있음.(+ 토큰 제어 유의)</p><pre><code>예시)생각, 행동, 관찰 단계를 번갈아 가며 질문 응답 작업을 해결합니다.생각은 현재 상황에 대해 추론 할 수 있고, 행동은 세가지 유형이 있습니다.1) Serch[entity],이는 위키 백과에서 정확한 entity를 검색하고 존재하는 경우 첫 번째 문단을 반환합니다. 존재하지 않는 경우, 검색할 수 있는 유사한 entity를 반환합니다.2) Lookup[keyword], 이는 현재 문단에서 키워드를 포함하는 다음 문장을 반환합니다.3) Finish[keyword], 이는 답을 반환하고 작업을 종료합니다.질문 : 대한민국의 인천 인구는 몇 명인가요?---GPT :생각 1 : 대한민국의 인천 인구를 찾아야 합니다.행동 1 : Search[대한민국 인천 인구]관찰 1 : 인천의 인구는 ... 명 입니다.생각 2 : 인천의 인구는 ... 명 입니다.행동 2: finish[약 ...명]</code></pre></li></ul><ol start="7"><li><code>Self Evaluation</code> AI가 스스로 결과를 평가하고 향상시키는 방법</li></ol><hr><h2 id="프롬프트-보안"><a href="#프롬프트-보안" class="headerlink" title="프롬프트 보안"></a>프롬프트 보안</h2><pre><code>- 구분자를 사용하여 프롬프트에 입력- 사용자의 입력값 이전과 이후를 나눠서 구성- 사용자의 입력 이전의 프롬프트 내용에 답변하지 말라고 지시</code></pre><p>예시) </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x27;&#x27;&#x27; 구분자 안의 내용을 번역하세요.</span><br><span class="line"></span><br><span class="line">번역할 내용 :</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">&#123;사용자가 입력한, 번역을 요청한 내용&#125;</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure><h2 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h2><p>한글에 대한 토큰 사용이 비효율적이므로 (영어와 언어 체계가 다름) 보통 바이트 단위로 토큰화함.</p><p>-&gt; 이를 해결하기 위해 프롬프트의 <code>입/출력을 영어로 작성</code>하거나 <code>입/출력을 번역하여 사용</code></p><h3 id="Context-Window"><a href="#Context-Window" class="headerlink" title="Context Window"></a>Context Window</h3><p>CNN의 stride와 유사한 개념입니다.<br>문맥을 판단하거나 다음 단어를 <code>예측하기 위해 참고할 토큰의 범위</code>입니다.</p><h3 id="LLM-생성의-주요-하이퍼파라미터"><a href="#LLM-생성의-주요-하이퍼파라미터" class="headerlink" title="LLM 생성의 주요 하이퍼파라미터"></a>LLM 생성의 주요 하이퍼파라미터</h3><ul><li><p>Temperature</p><pre><code>값이 높을 수록 다양한 출력을 만들어줍니다.(무작위적 &amp; 높은 환각)낮으면 일관적인 답변을 출력합니다.</code></pre></li><li><p>Top P, Top k</p><pre><code>Top P는 확률이 상위 &#39;P %&#39;인 토큰을 선택Top K는 확률이 상위 K개의 토큰을 선택매우 높은 Temperature를 설정 시 너무 무작위의 답변이 나오는 것을 방지</code></pre></li><li><p>Maximum length</p><pre><code>최대 토큰 수 설정입력 가능한 토큰 수 = 모델의 최대 토큰 수 - Maximum length</code></pre></li><li><p>Frequency Penalty</p><pre><code>동일한 표현을 주는 출력을 할 시 패널티를 줘서 반복하지 않게 함</code></pre></li><li><p>Presence Penalty</p><pre><code>Frequency Penalty와 반대되는 옵션</code></pre></li><li><p>Injection Start</p><pre><code>답변의 시작 단어를 지정해줍니다.</code></pre></li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/LLM/">LLM</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/PROMPT/">PROMPT</category>
      
      <category domain="http://InhwanCho.github.io/tags/LLM/">LLM</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/24/Study_folder/LLM/2023-08-24-PromptE/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>LLM</title>
      <link>http://inhwancho.github.io/2023/08/23/Study_folder/LLM/2023-08-23-LLM/</link>
      <guid>http://inhwancho.github.io/2023/08/23/Study_folder/LLM/2023-08-23-LLM/</guid>
      <pubDate>Tue, 22 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="Autoregressive-Model"><a href="#Autoregressive-Model" class="headerlink" title="Autoregressive Model"></a>Autoregressive Model</h2><p>GPT는 대표적인 <code>Autoregressive Model</code> 입니다.</p><pre><code>예를들어,- &#39;나는 학교에&#39; -&gt; GPT [다음 단어 예측]  &#39;가방을&#39;(70%), &#39;밥을(30%)&#39; - &#39;나는 학교에 가방을&#39; -&gt; GPT [다음 단어 예측]  &#39;가지러(70%)&#39;, &#39;매고(30%)&#39; ...  이런 식으로 진행되는 모델이 `Autoregressive Model`입니다.</code></pre><h2 id="Scaling-Laws"><a href="#Scaling-Laws" class="headerlink" title="Scaling Laws"></a>Scaling Laws</h2><p>언어 모델을 키웠더니 모델에 따로 추가 학습을 하지 않아도 <code>번역</code>, <code>감정 분류</code>등의 기술들이 알아서 생김 -&gt; 점점 더 큰 모델을 생성</p><h2 id="Instruction-tuning"><a href="#Instruction-tuning" class="headerlink" title="Instruction tuning"></a>Instruction tuning</h2><p>지시된 텍스트를 이해하여 지시한 작업을 수행 -&gt; 그냥 다음 단어의 무작위로 연결하여 예측(생성)이 아닌 지시한 작업을 수행</p><h2 id="RLHF-Reinforce-Learning-from-Human-Feedback"><a href="#RLHF-Reinforce-Learning-from-Human-Feedback" class="headerlink" title="RLHF(Reinforce Learning from Human Feedback)"></a>RLHF(Reinforce Learning from Human Feedback)</h2><p>GPT_A, GPT_B를 사람의 평가를 통해 조금 더 사람이 보기 좋는 텍스트에 좋은 점수를 줘서 보다 나은 글이 생성됨.<br><em>중요</em> 나중에 자세하게 추가 예정</p><ul><li>언어 모델이 자가 학습의 기반이 되는 기술(언어를 생성하고 그것을 모델이 평가함)</li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/NLP/">NLP</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/RNN/">RNN</category>
      
      <category domain="http://InhwanCho.github.io/tags/LSTM/">LSTM</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/23/Study_folder/LLM/2023-08-23-LLM/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>파이토치에서 dataset 만들기</title>
      <link>http://inhwancho.github.io/2023/08/18/Study_folder/Pytorch/2023-08-18-dataset/</link>
      <guid>http://inhwancho.github.io/2023/08/18/Study_folder/Pytorch/2023-08-18-dataset/</guid>
      <pubDate>Thu, 17 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h3 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h3><p><a href="https://klue-benchmark.com/tasks" title="KLUE ner file">KLUE benchmark ner file</a>  </p><h2 id="Dataset-만들기"><a href="#Dataset-만들기" class="headerlink" title="Dataset 만들기"></a>Dataset 만들기</h2><ol><li>Dataset을 Preprosessing 작업하기</li><li>Dataloader에 넣고 배치(batch) 단위로 만들기</li><li>필요 시 collate_funtion으로 작업하기<br>  [미니 배치를 생성하기 위해 샘플 리스트를 병합하는 역할 등]</li></ol><h3 id="collate-fn을-Dataset-class가-아닌-function을-사용하는-이유"><a href="#collate-fn을-Dataset-class가-아닌-function을-사용하는-이유" class="headerlink" title="collate_fn을 Dataset class가 아닌 function을 사용하는 이유"></a>collate_fn을 Dataset class가 아닌 function을 사용하는 이유</h3><ul><li>Class에서 구현은 가능함.</li><li>그러나 디버깅 단계에서 index값이 아닌 <code>str</code>으로 확인하는게 편하하기 때문입니다.<br>[&#x3D;&#x3D; token index나 label index를 <code>str</code>로 변환해서 확인하는게 불편합니다.]</li></ul><h3 id="KLUE-benchmark-dataset-NER을-기준으로-예시입니다"><a href="#KLUE-benchmark-dataset-NER을-기준으로-예시입니다" class="headerlink" title="KLUE-benchmark dataset-NER을 기준으로 예시입니다."></a>KLUE-benchmark dataset-NER을 기준으로 예시입니다.</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#허깅페이스의 load_data 전처리</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">file_path: <span class="built_in">str</span>, tokenizer: PreTrainedTokenizer = <span class="literal">None</span></span>):</span><br><span class="line">    klue_data = Path(file_path)</span><br><span class="line">    klue_text = klue_data.read_text().strip()</span><br><span class="line">    documents = klue_text.split(<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_list = []</span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> documents:</span><br><span class="line">        char_labels = []</span><br><span class="line">        token_labels = []</span><br><span class="line">        chars = []</span><br><span class="line">        sentence = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> doc.split(<span class="string">&quot;\n&quot;</span>):</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">&quot;##&quot;</span>):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            token, tag = line.split(<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">            sentence += token</span><br><span class="line">            char_labels.append(tag)</span><br><span class="line">            chars.append(token)</span><br><span class="line"></span><br><span class="line">        offset_mappings = tokenizer(sentence, return_offsets_mapping=<span class="literal">True</span>)[<span class="string">&quot;offset_mapping&quot;</span>]</span><br><span class="line">        <span class="keyword">for</span> offset <span class="keyword">in</span> offset_mappings:</span><br><span class="line">            start, end = offset</span><br><span class="line">            <span class="keyword">if</span> start == end == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            token_labels.append(char_labels[start])</span><br><span class="line"></span><br><span class="line">        instance = &#123;</span><br><span class="line">            <span class="string">&quot;sentence&quot;</span>: sentence,</span><br><span class="line">            <span class="string">&quot;token_label&quot;</span>: token_labels,</span><br><span class="line">            <span class="string">&quot;char_label&quot;</span>: char_labels,</span><br><span class="line">            <span class="string">&quot;offset_mapping&quot;</span>: offset_mappings</span><br><span class="line">        &#125;</span><br><span class="line">        data_list.append(instance)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data_list</span><br><span class="line"></span><br><span class="line">labels = [</span><br><span class="line">    <span class="string">&quot;B-PS&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I-PS&quot;</span>,</span><br><span class="line">    <span class="string">&quot;B-LC&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I-LC&quot;</span>,</span><br><span class="line">    <span class="string">&quot;B-OG&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I-OG&quot;</span>,</span><br><span class="line">    <span class="string">&quot;B-DT&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I-DT&quot;</span>,</span><br><span class="line">    <span class="string">&quot;B-TI&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I-TI&quot;</span>,</span><br><span class="line">    <span class="string">&quot;B-QT&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I-QT&quot;</span>,</span><br><span class="line">    <span class="string">&quot;O&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">label2id = &#123;label: i <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels)&#125;</span><br><span class="line">id2label = &#123;i: label <span class="keyword">for</span> label, i <span class="keyword">in</span> label2id.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataset</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NerDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        tokenizer: PreTrainedTokenizer,</span></span><br><span class="line"><span class="params">        examples: <span class="type">List</span>,</span></span><br><span class="line"><span class="params">        shuffle: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        **kwargs</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        self.dataset = examples</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.max_length = max_length</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        instance = self.dataset[index]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> instance</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;klue/bert-base&quot;</span>)</span><br><span class="line">examples = load_data(file_path, tokenizer)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(examples[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#&#123;&#x27;sentence&#x27;: &#x27;경찰은 또 ..... </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset</span></span><br><span class="line">dataset = NerDataset(</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    examples=examples,</span><br><span class="line">    max_length=max_length</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataloader, collate_fn</span></span><br><span class="line">data_loader = DataLoader(</span><br><span class="line">    dataset=dataset,</span><br><span class="line">    collate_fn=collate_fn</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이렇게하면 data_loader가 완성되어 전처리가 다 끝납니다.</span></span><br><span class="line"><span class="comment"># 이 데이터를 확인하기 위해서는 아래 코드 실행(1배치만 확인)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> data_loader:</span><br><span class="line">  <span class="built_in">print</span>(batch)</span><br><span class="line">  <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/deeplearning/">deeplearning</category>
      
      <category domain="http://InhwanCho.github.io/tags/torch/">torch</category>
      
      <category domain="http://InhwanCho.github.io/tags/pytorch/">pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/18/Study_folder/Pytorch/2023-08-18-dataset/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>NLP 분야의 MRC</title>
      <link>http://inhwancho.github.io/2023/08/18/Study_folder/Pytorch/2023-08-22-QnA(NLP)/</link>
      <guid>http://inhwancho.github.io/2023/08/18/Study_folder/Pytorch/2023-08-22-QnA(NLP)/</guid>
      <pubDate>Thu, 17 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="질의-응답-개념"><a href="#질의-응답-개념" class="headerlink" title="질의 응답 개념"></a>질의 응답 개념</h2><ul><li><p>질의 응답(Question Answering, QA)</p><p>  주어진 지문에 대하여 질문에 답변하는 과제<br>  대답 할 수 없는 질문이 등장하면 ‘No-answer’를 해야함</p></li><li><p>기계 독해(Machine Reading Comprehension, MRC)</p><p>  기계가 주어진 지문과 질문을 ‘이해’하여 답변</p><p>  ex) context - ‘서울은 한국의 수도이며, …’<br>  Question(user) - ‘한국의 수도가 어디야?’<br>  Answer(AI) - ‘서울’</p></li></ul><h3 id="task-1-Cross-Lingual-Question-Answering"><a href="#task-1-Cross-Lingual-Question-Answering" class="headerlink" title="task 1. Cross-Lingual Question Answering"></a>task 1. Cross-Lingual Question Answering</h3><ul><li>질문의 언어와 영어의 자료 사이의 정보 비대칭이 존재</li><li>질문의 언어가 다른 언어의 답변 내용을 통해 답변이 될 수 있도록<br>언어 교차(Cross-lingual)로 문제를 해결</li></ul><h3 id="task-2-Visual-Question-Answering"><a href="#task-2-Visual-Question-Answering" class="headerlink" title="task 2. Visual Question Answering"></a>task 2. Visual Question Answering</h3><ul><li>이미지와 이미지 내용에 관한 질문이 주어졌을 때, 적절한 답변을 하는 과제(멀티모달)</li><li>CVPR에서 VQA Challenge를 하고 있으며 <code>VQA</code> 데이터셋 또한 연구 및 개발에 널리 사용됨</li></ul><h2 id="질의-응답-관련-서비스"><a href="#질의-응답-관련-서비스" class="headerlink" title="질의 응답 관련 서비스"></a>질의 응답 관련 서비스</h2><ol><li>AI 챗봇</li></ol><ul><li>MRC를 활용하여 기본적 응답 외 고객이 궁금해 할 수 있는 정보를 제공</li><li>기존의 챗봇은 모든 예상 답변을 등록해야 하지만(Rule-base), MRC 기반은 설계가 간단하며<br>추가 학습도 가능하여 업무에 맞게 변경가능.</li></ul><ol start="2"><li>AI 콜센터</li></ol><ul><li>사람이 아닌 AI와 상담을 통해 서비스를 제공(STT, TTS 필요)</li><li>기존의 ARS보다 빠른 대응으 가능하며 24시간 운영 가능.</li></ul><h2 id="질의-응답-관련-데이터셋"><a href="#질의-응답-관련-데이터셋" class="headerlink" title="질의 응답 관련 데이터셋"></a>질의 응답 관련 데이터셋</h2><p><a href="www.paperswithcode.com" title="papers with code">Paperswithcode</a>  </p><h3 id="KLUE"><a href="#KLUE" class="headerlink" title="KLUE"></a>KLUE</h3><p><a href="https://klue-benchmark.com/tasks" title="KLUE ner file">KLUE benchmark ner file</a>  </p><h3 id="SQuAD-The-Stanford-Question-Answering-Dataset"><a href="#SQuAD-The-Stanford-Question-Answering-Dataset" class="headerlink" title="SQuAD(The Stanford Question Answering Dataset)"></a>SQuAD(The Stanford Question Answering Dataset)</h3><ul><li>가장 많이 사용되는 QA 데이터셋 중 하나</li><li>SQuAD 1.0과 2.0(답변 할 수 없는 데이터도 있음)이 존재</li><li>이를 벤치마킹한 다른 언어 데이터셋 다수 존재(KorQuAD(한국어 버전), …)</li></ul><h4 id="KorQuAD"><a href="#KorQuAD" class="headerlink" title="KorQuAD"></a>KorQuAD</h4><p><a href="https://korquad.github.io/KorQuad%201.0/" title="KorQuAD">KorQuAD</a></p><p>SQuAD의 한국어 버전입니다.<br>1.0과 2.0의 차이점은 1.0은 1-2개의 문단을 대상으로 하지만,<br>2.0은 위키 문서 전체를 대상으로 합니다.</p><h2 id="ELECTRA"><a href="#ELECTRA" class="headerlink" title="ELECTRA"></a>ELECTRA</h2><p>ELECTRA : Pre-training Text Encoders as Discriminators Rather Than Generators(Google, 2020)</p><ul><li><p>RTD(Replaced Token Detection)이라는 새로운 사전 학습 과제 제안</p><p>  기존의 BERT는 MLM의 문제점 :</p><ul><li>전체 토큰 중 15%에 대해서만 loss발생(비용 증가)</li><li>추론 시 MASK가 존재하지 않음</li></ul></li></ul><h3 id="RTD-Replaced-Token-Detection"><a href="#RTD-Replaced-Token-Detection" class="headerlink" title="RTD(Replaced Token Detection)"></a>RTD(Replaced Token Detection)</h3><ol><li>Generator를 이용해 <code>입력의 일부를 가짜 토큰으로 변환</code></li><li>각 토큰이 실제 입력에 있는 <code>진짜 토큰</code>인지 <code>가짜 토큰</code>인지 맞히는 이진 분류로 해석.</li><li>모든 토큰에 대해 학습하므로 BERT에 비해 효율적이다.</li><li>Generator와 Discriminator 둘 다 Transformer의 Encoder 구조를 사용.</li></ol><h4 id="Generator-G"><a href="#Generator-G" class="headerlink" title="Generator G"></a>Generator G</h4><pre><code>BERT의 MLM과 같은 학습 메커니즘.= 주어진 위치 t에 대해 토큰 x_t를 생성할 확률을 출력으로 설정t번째 토큰이 원래 어떤 토큰인지 예측</code></pre><p>$$ P_G(X_t | X_{maksed} &#x3D; \exp (e(X_t)^T\cdot h_G(X_{masked})<em>t) &#x2F; \Sigma</em>{x^\prime}\exp (e(x^\prime)^T\cdot h_G)(X_{masked})) $$</p><p>$$ X_{maksed} &#x3D; REPLACE(X, m, [MASK]) $$</p><h4 id="Discriminator-D"><a href="#Discriminator-D" class="headerlink" title="Discriminator D"></a>Discriminator D</h4><pre><code>입력 토큰 시퀀스의 각 토큰이 진짜인지 가짜(replaced)인지 이진 분류Generator의 softmax 분포에 대해 샘플링한 토큰으로 치환한 입력이 원래 입력과 동일한지 예측</code></pre><p>$$ D(X_{corrupt},t) &#x3D; sigmoid(W^T\cdot h_D(X_{corrupt})_t) $$</p><p>$$ X_{corrupt} &#x3D; REPLACE(X, m, \hat X) $$<br>-&gt; Generator의 softmax 분포의 수식은 아래와 같습니다.<br> $$ P_G(X_i | X_{masked} for i \in m) $$</p><h3 id="GAN과의-차이점"><a href="#GAN과의-차이점" class="headerlink" title="GAN과의 차이점"></a>GAN과의 차이점</h3><ul><li>G가 기존 토큰과 같은 토큰값을 복원하면 GAN에서는 <code>fake</code>(negative)로 간주하지만, RTD에서는 <code>real</code>(positive)로 간주</li><li>속이기 위해 학습하지 않고 Maximum likelihood를 통해 학습</li><li>노이즈 벡터를 입력으로 넣지 않음</li></ul><p>G와 D의 loss 합을 최소화하여 사전 학습(pre-train)</p><h3 id="ELECTRA의-특징"><a href="#ELECTRA의-특징" class="headerlink" title="ELECTRA의 특징"></a>ELECTRA의 특징</h3><ol><li><p>Weight sharing</p><ul><li>임베딩 가중치만 공유</li></ul></li><li><p>Smaller generators</p><ul><li>layer의 크기 조절</li><li>Unigram generator(unigram의 분포를 기반으로 샘플링)</li></ul></li><li><p>Training algorithms</p><ul><li>tow-stage(G만 MLM loss로 학습-&gt; D의 weight을 초기화하고 학습)</li></ul></li></ol><p>fine-tuneing시 D모델만 사용. - 다시 논문 찾아서 적기</p>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/deeplearning/">deeplearning</category>
      
      <category domain="http://InhwanCho.github.io/tags/torch/">torch</category>
      
      <category domain="http://InhwanCho.github.io/tags/pytorch/">pytorch</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/18/Study_folder/Pytorch/2023-08-22-QnA(NLP)/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>BERT(Bidirectional Encoder Representations Transformer)</title>
      <link>http://inhwancho.github.io/2023/08/15/Paper_Review/2023-08-15-BERT/</link>
      <guid>http://inhwancho.github.io/2023/08/15/Paper_Review/2023-08-15-BERT/</guid>
      <pubDate>Mon, 14 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h3 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h3><p><a href="https://arxiv.org/abs/1706.03762" title="Transformer 논문">Transformer 논문</a><br><a href="https://arxiv.org/abs/1810.04805?source=post_page" title="bert paper">BERT paper</a><br><a href="https://www.youtube.com/watch?v=o_Wl29aW5XM&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=19" title="고려대 유튜브">고려대 유튜브</a><br><a href="https://jalammar.github.io/illustrated-gpt2/" title="Jay alammar blog">Jay alammar 블로그</a></p><h2 id="BERT-개요"><a href="#BERT-개요" class="headerlink" title="BERT 개요"></a>BERT 개요</h2><ul><li>GPT : <code>Transformer</code>의 <code>디코더 아키텍쳐</code>를 활용</li><li>BERT : <code>Transformer</code>의 <code>인코더 아키텍쳐</code>를 활용</li></ul><p>BERT(Bidirectional Encoder Representations Transformer)는 딥러닝 언어 모델로, 트랜스포머의 인코더 부분을 기반으로 합니다.<br>이 모델은 양방향으로 문맥을 이해하며, 텍스트의 의미를 더 정확하게 파악하는 데 도움을 줍니다.<br>기본적으로 BERT는 Fine-tuning을 위해 만들어진 <code>Pre-trained model</code>입니다. (&#x3D;&#x3D;fine-tuning approach)<br>주로 <code>Fine-tuning을 통해 특정 작업에 적용</code>되며, 자연어 처리 분야에서 다양한 언어 관련 작업에서 높은 성능을 보여줍니다.<br>BERT의 등장은 언어 모델의 발전을 대표하는 중요한 마일스톤으로 평가되고 있습니다.</p><img width="650" alt="BERT 구조" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/dab3b2c3-b0c1-4cbe-85a7-7044f07c67cb"><p>위의 그림은 BERT논문에서 가져온 그림으로 BERT를 잘 설명해주고 있습니다.</p><hr><p>Pre-training이 어떻게 되는지 자세하게 살펴보겠습니다.</p><img width="250" alt="Transformer의 Encoder block" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/4b4b90e5-9d7d-4e84-b6b4-5a6eee54b117"><p>BERT의 model architecture를 살펴보면 위의 그림의 Transformer의 encoder block을 사용합니다.</p><hr><p>다음으로 BERT의 input값이 어떻게 들어가는지 살펴보겠습니다.</p><img width="500" alt="BERT의 input" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/1016d7cd-c23e-44c8-9535-baa333564c78"><p>논문의 그림입니다. Input 값은 3가지 embeddings의 합입니다.<br><code>Token Embeddings</code>, <code>Segment Embeddings</code>,<code>Postion Embeddings</code> 입니다.</p><p>먼저 <code>Token Embeddings</code>은 특징은 <code>WordPiece</code>를 30,000개의 vocab을 사용한 embedding입니다.</p><pre><code>WordPiece는 문장을 공백 문자(space)단위로 나누는게 아닌 특징 단어(ex playing -&gt; [play, ##ing])로 나누어 보다 의미있는 학습을 도와줍니다.</code></pre><p><code>Segment Embeddings</code>은 문장 A와 문장 B를 구분해서 embedding하는 것입니다.</p><p>마지막 <code>Postion Embeddings</code>은 transformer에 사용된 것과 동일하며 단어들의 포지션을 알려주는 embedding입니다.</p><p>이 3가지 임베딩의 합이 input으로 사용됩니다.</p><hr><p>BERT-base를 기준으로 layer의 수는 12개, hidden size는 768, Attention heads는 12개, parameters는 110M개 입니다.</p><img width="500" alt="BERT pre-training" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/2db35731-4cf2-47f9-93f8-a5a1294ab012"><p>Input data는 <code>Unlabeled Sentence A and B Pair</code>가 사용되었습니다.<br>다시 말해, 라벨이 없는 일반적인 문장 데이터가 활용되었습니다. 이는 두 개의 문장이 쌍으로 구성될 수 있으며(예: QnA 문장), 또는 하나의 단일 문장으로 구성될 수도 있습니다.</p><p>여기서 sentence는 Masked sentence A, B로 들어오는데, A와 B는 스페셜 토큰 중 1개인 [SEP]를 통해 문장이 구분 됩니다. 또한 맨 앞에 보이는 [CLS]토큰을 통해 문장의 시작을 알 수 있습니다.</p><p>게다가 Masked라는 단어에서 유추할 수 있겠지만, 일정 비율만큼 Masking을 하여 사용한다는 의미입니다.</p><p>그리고 final hidden vector의 맨 첫번째 토큰(그림에서는 맨 위의 대문자 C) 또한 [CLS] 토큰이며 이는 이를 활용하여 <code>감성 분류</code>인지 <code>다음 문장 예측</code>인지 등을 확인하는 토큰입니다.</p><p>이 input 문장들을 Task 2가지를 사용합니다. task 1 :Masked Language Model(MLM)과 task 2 :Next Sentence Prediction(NSP)을 사용하여 Pre-training을 합니다.</p><p><code>MLM</code>이란, input tokens의 일정 비율(15%)을 마스킹하고 마스킹 된 토큰을 예측하는 것이고,<br><code>NSP</code>는 A, B 문장 사이의 관계가 B가 A의 다음(next) 문장인지 아닌지 학습합니다.</p><p>MLM을 자세히 살펴보겠습니다.</p><img width="650" alt="MLM" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/85ab03dd-dd82-43e7-bcce-d8ac92e48688"><p>위의 그림은 MLM을 설명하는 그림입니다.</p><p>input은 [$W_1$, $W_2$, $W_3$, $W_4$, $W_5$]인데 일정 %(15%)만큼을 [MASK] 토큰으로 바꿔줍니다. 그림에서는 $W_4$가 마스킹되어 학습이 진행됩니다.</p><p>즉, 여기서는 output값인 $O_4$를 FC layer+GELU+Norm을 통해 나온 $W^\prime_4$가 $W_4$가 되도록 학습한다는 의미입니다.</p><p>다만, 논문에서는 이러한 방식을 통해 pre-trained model은 얻을 수 있지만, fine-tuning 사이의 mismatch가 발생하고 이를 해결 할 필요가 있다고 합니다.</p><p>이를 해결하기위해 위에서 언급한 %(15%)의 [MASK] token에서 추가적인 처리를 더 해줘야 합니다.</p><pre><code>15%의 마스킹된 것의 `80%`는 token을 `[MASK] token`으로 변경.`10%`는 token을 `random word`로 변경.나머지 `10%`는 token을 `원래 단어 그대로` 놔둡니다.</code></pre><p>위의 방식을 통해 BERT의 <code>pre-trained model</code>을 얻을 수 있습니다.</p><hr><p>마지막으로 BERT의 <code>Fine-tuning</code>에 대해 알아보겠습니다.</p><img width="700" alt="BERT fine-tuning" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/f935c7be-16c0-403a-954a-765852bb19a2"><p>BERT의 파인튜닝에는 크게 4가지가 있습니다.</p><p>(a)는 문장 A, B가 들어왔을때 단순히 특정한 Class에 속하는지 아닌지는 이 구조(범주의 예측)</p><p>(b)는 문장 1개가 들어왔을때 특정한 Class에 속하는지 아닌지는 이 구조(범주의 예측)</p><p>(c)는 문장 Question, Answer를 맞추는 구조입니다.(answer 문장의 생성)</p><p>(d)는 문장 1개가 들어왔을때 객체명 인식, 형태소 분석 등을 하는 구조입니다.</p>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Paper/">Paper</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/paper/">paper</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/15/Paper_Review/2023-08-15-BERT/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Seq2Seq</title>
      <link>http://inhwancho.github.io/2023/08/14/Study_folder/NLP(Natural_Language_Processing)/2023-08-14-RNN/</link>
      <guid>http://inhwancho.github.io/2023/08/14/Study_folder/NLP(Natural_Language_Processing)/2023-08-14-RNN/</guid>
      <pubDate>Sun, 13 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h3 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h3><p><a href="https://www.youtube.com/watch?v=mFhiGKI3LZM&list=PLBiQZMT3oSxV3RxoFgNcUNV4R7AlvUMDx&index=7&t=2791s" title="수원대 유튜브">수원대 유튜브</a>  </p><p><a href="http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" title="jay alammar blog">Jay Alammar 자료</a></p><h2 id="Seq2Seq2-시퀀스-투-시퀀스"><a href="#Seq2Seq2-시퀀스-투-시퀀스" class="headerlink" title="Seq2Seq2(시퀀스 투 시퀀스)"></a>Seq2Seq2(시퀀스 투 시퀀스)</h2><p>seq2seq는 이름 그대로 sequence(시계열 데이터)에서 sequence(시계열 데이터)로 보내는 방법입니다.</p><pre><code>ex) 나는 학생이다 -&gt; I am a student</code></pre><p>seq2seq의 <code>구조는 Encoder와 Decoder로 구성</code>되어있습니다.</p><h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>Encoder에서는 문장을 입력 받아서 Context vector(&#x3D;hidden state)를 생성합니다.</p><p>그림으로 보면 다음과 같습니다.</p><img width="900" alt="seq2seq" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/4641dd5c-1d1f-45a3-8c42-c6821102d860"><p>Encoder는 Embedding층과 LSTM층으로 구성되있고, 보통의 신경망에서의 위로 올라가는 <code>Affine 층</code>은 여기서는 사용하지 않고, <code>Cell state</code>는 마지막 embedding까지 사용하고 <code>폐기</code>하며, <code>Hidden state만 최종적으로 출력</code>한다(이를 <code>context vecotr</code>라 부름)</p><p>이 최종 Hidden state는 하이퍼 파라미터이며, 어찌되었건 이는 길이이며, 이 고정 길이 안에서 입력 문장을 번역하는데 필요한 정보를 인코딩하는게 encoder의 목적입니다.</p><ul><li><code>[인코더 - 컨텍스트백터(hidden state) - 디코더]</code>로 이루어져 있고</li><li>seq2seq는 인코더와 디코더 아키텍처의 내부는 사실 <code>두 개의 RNN 구조</code>로 이루어진 모델</li><li>시퀀스-투-시퀀스(Sequence-to-Sequence, seq2seq)는 챗봇과 기계 번역에서 많이 사용됩니다.</li><li>대략적인 구조는 <code>입력 시퀀스</code>(질문)와 <code>출력 시퀀스</code>(대답)으로 이루어져 있습니다.</li></ul><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><img width="700" alt="디코더" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/0b62e21b-7fb8-4076-8401-3bda9dcc0677"><p>디코더에서는 그림과 같이 진행됩니다.</p><p><code>embedding값</code>과 <code>hidden state인 context vector</code>가 LSTM으로 연산됩니다. </p><p>자세히 살펴보면 &lt;end of sentence&gt;를 input data로 사용하여 hidden state와 연산한 값을 Affine과 softmax를 통해 <code>I</code> 인 출력값을 얻습니다. 그 <code>I</code>가 다음 input으로 들어와서 반복합니다</p><ul><li>아래 동영상을 보시면 쉽게 이해될 것입니다(10초)</li></ul><video controls width="800">    <source src="/assets/videos/seq2seq.mp4" type="video/mp4"></video>   <h2 id="seq2seq의-한계점"><a href="#seq2seq의-한계점" class="headerlink" title="seq2seq의 한계점"></a>seq2seq의 한계점</h2><ul><li><p>항상 고정된 크기의 벡터에(컨텍스트 벡터) 모든 정보를 저장하기 때문에 bottle neck현상이 발생하여 정보 손실이 발생한다.</p></li><li><p>입력의 길이가 길어지면 기울기 소실 문제가 발생한다.<br><br>(context vector를 기준으로 Encoder, Decoder가 완전히 분리되어 있으므로 입출력의 연관 관계가 너무 떨어져 있어서 역전파 시 기울기 소실 발생)</p></li><li><p>결국은 RNN계열 대신 Attention을 사용하게 됨</p></li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/NLP/">NLP</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/seq2seq/">seq2seq</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/14/Study_folder/NLP(Natural_Language_Processing)/2023-08-14-RNN/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RNN &amp; LSTM</title>
      <link>http://inhwancho.github.io/2023/08/14/Study_folder/NLP(Natural_Language_Processing)/2023-08-14-seq2seq/</link>
      <guid>http://inhwancho.github.io/2023/08/14/Study_folder/NLP(Natural_Language_Processing)/2023-08-14-seq2seq/</guid>
      <pubDate>Sun, 13 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h3 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h3><p><a href="https://www.youtube.com/watch?v=mFhiGKI3LZM&list=PLBiQZMT3oSxV3RxoFgNcUNV4R7AlvUMDx&index=7&t=2791s" title="수원대 유튜브">수원대 유튜브</a><br><a href="https://wikidocs.net/152773" title="위키 독스">Wiki docs</a>  </p><h2 id="CBOW-Continuous-Bag-of-Words"><a href="#CBOW-Continuous-Bag-of-Words" class="headerlink" title="CBOW(Continuous Bag of Words)"></a>CBOW(Continuous Bag of Words)</h2><p>자연어 분야에서 초창기에는 <code>Continuous Bag of Words(CBOW)</code>이라는 word2vec을 사용하였습니다. CBOW는 주변 단어(Context Word) 중간에 있는 단어를 예측하는 방법입니다. </p><ol><li>그러나 단어 집합의 크기가 수 백만 이상에 달하면 코스트가 큰 무거운 작업이 되고,</li><li>문장이 길어지면 뒤의 문장에 대한 답을 제대로 할 수 없고,</li><li>맥락 안의 단어 순서가 무시되기 때문에 (ex. [you,say], [say,you]의 행렬곱 층을 거쳐서 평균하면 값이 동일하다)</li></ol><h2 id="RNN-Recurrent-Neural-Network"><a href="#RNN-Recurrent-Neural-Network" class="headerlink" title="RNN(Recurrent Neural Network)"></a>RNN(Recurrent Neural Network)</h2><p>RNN은 순환 신경망(Recurrent Neural Network, RNN)이라고 합니다.<br>RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖고있습니다.</p><img width="800" alt="RNN" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/95b26b07-4c80-4d61-98c6-b7fa728826a9"><p>$X_0$ 일때, Affine 변환을 거쳐서 hidden layer에 들어가게 되고 activation을 하면 $h_0$가 출력이 되고 바로 옆의 $X_1$로도 그 값을 넘겨주는 식으로 진행이 됩니다. </p><p>최근의 정보가 더 많이 남아있고, 먼 과거의 정보는 적게 남아있기는 하지만 값들이 작더라도 계속 남아있습니다.</p><p>참고로 RNN 계열의 활성화 함수는 <code>하이퍼볼릭 탄젠트(tanh)</code>를 사용합니다. </p><h2 id="LSTM-Long-Short-Term-Memory"><a href="#LSTM-Long-Short-Term-Memory" class="headerlink" title="LSTM(Long Short Term Memory)"></a>LSTM(Long Short Term Memory)</h2><p>기존의 RNN(Vanilla RNN)은 성능이 좋지 않기 때문에 보통 RNN이라고 하면 LSTM이나 GRU 등을 의미합니다.</p><p>LSTM은 기존의 RNN이 출력과 먼 위치에 있는 정보를 기억할 수 없다는 단점(기울기 소실, 기울기 폭주의 문제)을 보완하여 장&#x2F;단기 기억을 가능하게 설계한 신경망의 구조입니다.</p><pre><code>기울기 소실 : 활성화 함수를 tanh를 사용하기 때문에             그 값이 0~1인 값이기 때문에 계속 계산(곱)하다보면 기울기 소실이 됩니다.기울기 폭주 : tanh가 아닌 matmul 단계에서             1이상인 값을 계속 곱하게되어 큰 값이 되어 결국 발산되는 현상.</code></pre><img width="650" alt="RNN" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/ff0114e8-75b7-45dd-ab59-c6759099ba37"><img width="650" alt="LSTM" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/08bd154a-1715-4d16-8d3d-77ac137db277"><p>먼저 <code>RNN</code>의 구조와 <code>LSTM</code>의 구조를 비교 해보겠습니다. </p><p><code>LSTM</code>은 RNN과 같이 체인 구조를 가지고 있지만, 4개의 Layer가 특별한 방식으로 서로 정보를 주고 받도록 되어있습니다.</p><p>그럼 자세히 분석해보겠습니다.</p><img width="400" alt="cell state" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/7af23d7d-2e52-485e-82c9-37bc1dd8fb87"><p>LSTM은 <code>Cell State</code>와 <code>Hidden State</code>가 있습니다.</p><p><code>Cell State</code>는 LSTM의 핵심으로 정보가 전혀 바뀌지 않고 그대로만 흐르게 하는 부분입니다. 또한 꽤 경과하더라도 기울기가가 잘 전파 됩니다. 그리고 Gate(게이트)라는 구조에 의해서 정보가 추가되거나 제거 되며, 이 게이트는 어떤 정보를 유지하고 버릴지 학습합니다.</p><p>그리고 3개의 게이트가 있습니다. 이 게이트 모두 <code>시그모이드</code> 사용합니다.</p><p>위의 그림 중 <code>시그마</code>($\sigma$)가 보이는 부분이 모두 게이트입니다.</p><hr><p>이 3개의 게이트는 <code>Forget Gate</code>, <code>Input Gate</code>, <code>Output Gate</code>라고 불립니다.</p><h3 id="Forget-Gate"><a href="#Forget-Gate" class="headerlink" title="Forget Gate"></a>Forget Gate</h3><img width="400" alt="Forget Gate" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/8e14e76c-3ce4-46df-8ff7-df0e686cdc5e"><p>이름 그대로 <code>과거의 정보를 얼마나 버릴지 결정</code>하는 게이트입니다. 수식은 다음과 같습니다. </p><p>$$f_t &#x3D; \sigma (W_f\cdot [h_{t-1},x_t]+b_f)$$</p><p>input embedding값인 x_t와 전 단계의 hidden_state($h_{t-1}$)와의 affine연산을 시그모이드를 통해 0~1사이의 값으로 나와서 1이면 모든 정보를 수용하고, 0이되면 모든 정보는 버리는 식이 됩니다.</p><h3 id="Input-Gate"><a href="#Input-Gate" class="headerlink" title="Input Gate"></a>Input Gate</h3><img width="400" alt="Input Gate" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/1945d1f1-fed4-4335-a220-c83836c0c8a5"><p>$$i_t &#x3D; \sigma (W_i\cdot [h_{t-1},x_t]+b_i)$$<br>$$\tilde C_t &#x3D; tanh(W_C\cdot [h_{t-1},x_t + b_C)$$</p><p>이 게이트는 현재 정보를 기억하기 위한 게이트 입니다. 현재의 <code>Cell state 에 무엇을 얼마나 더할지 말지를 결정</code>합니다.</p><img width="400" alt="cell state의 업데이트" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/91f91fd9-4118-490c-9b35-111869ac712d"><p>앞의 Forget Gate와, Input Gate에서 얼마나 버릴지 더할지를 정했으므로 이 업데이트를 계산을 해서 Cell State로 업데이트를 해줍니다.</p><p>$$ C_t &#x3D; f_t \odot C_{t-1} + i_t \odot \tilde C_t $$</p><h3 id="Output-Gate"><a href="#Output-Gate" class="headerlink" title="Output Gate"></a>Output Gate</h3><img width="400" alt="Output Gate" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/c226ef13-2e2b-4726-99cb-0a69542b6f71"><p>$$o_t &#x3D; \sigma (W_o\cdot [h_{t-1},x_t]+b_o)$$<br>$$h_t &#x3D; o_t \odot tanh{(C_t)} $$</p><p>새로운 cell state에서 <code>얼마나 hidden state로 출력할지 결정</code>하는 게이트입니다.</p><ul><li>$\odot$은 아다마르 곱으로 행렬곱이 아닌 단순 곱입니다.</li></ul><p>계산을 보면 무척 복잡해보이지만 여기에 규칙들이 있어서 동일한 규칙을 가진 것들끼리는 묶어줍니다.</p><p>$$ x_t\cdot W_x +h_{t-1}\cdot W_h + b $$</p><p>여기서 Weight이랑 bias는 행렬 속 행렬로 보면 됩니다.<br>(예를들어 위의 수식의 b는 아래의 4가지 bias를 가진 행렬과 같습니다.)</p><p>$$b &#x3D;&#x3D; [[b^f], [b^c], [b^i], [b^o]]$$</p>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/NLP/">NLP</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/RNN/">RNN</category>
      
      <category domain="http://InhwanCho.github.io/tags/LSTM/">LSTM</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/14/Study_folder/NLP(Natural_Language_Processing)/2023-08-14-seq2seq/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>GPT(Generative Pre-Training of Language Model)</title>
      <link>http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/</link>
      <guid>http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/</guid>
      <pubDate>Wed, 09 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h3 id="참고-자료"><a href="#참고-자료" class="headerlink" title="참고 자료"></a>참고 자료</h3><p><a href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf" title="GPT-1 논문">GPT-1 논문</a><br><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" title="GPT-2 논문">GPT-2 논문</a><br><a href="https://www.youtube.com/watch?v=o_Wl29aW5XM&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=19" title="고려대 유튜브">고려대 유튜브</a><br><a href="https://jalammar.github.io/illustrated-gpt2/" title="Jay alammar blog">Jay alammar 블로그</a></p><h2 id="GPT-개요"><a href="#GPT-개요" class="headerlink" title="GPT 개요"></a>GPT 개요</h2><ul><li>GPT : <code>Transformer</code>의 <code>디코더 아키텍쳐</code>를 활용(Masked Attention)</li><li>BERT : <code>Transformer</code>의 <code>인코더 아키텍쳐</code>를 활용</li></ul><p>일반적으로 우리는 레이블이 있는 데이터를 사용하여 지도 학습을 수행해왔습니다. 그러나 대부분의 데이터는 레이블이 없는 데이터입니다.</p><p>실제로 레이블이 있는 데이터의 양은 제한적입니다.</p><p>GPT는 이러한 상황에서 발전할 수 있는 방안을 모색하기 위해 제안되었습니다. 이는 주로 레이블이 없는 다양한 텍스트 말뭉치에서 사전 훈련을 수행하고, 각 작업에 특화된 파인튜닝을 통해 이점을 얻을 수 있는 접근 방식입니다.</p><p>그러나 레이블이 없는 데이터를 다룰 때는 세 가지 주요 단점이 있습니다.</p><p><code>1. 단어 수준 이상의 정보를 추출하기 어렵습니다.</code></p><p><code>2. 어떤 최적화 목표가 전이 학습을 위한 효과적인 텍스트 표현을 학습하는 데 가장 효율적인지 불분명합니다.</code></p><p><code>3. 이러한 불확실성으로 인해 반지도 학습 접근 방식이 어려움을 겪습니다.</code></p><p>따라서 GPT에서는 다음과 같은 방식으로 이러한 문제를 해결하고자 합니다.</p><p><code>1. 비지도 사전 훈련과 지도 파인튜닝을 결합한 반지도 학습 접근 방식을 제안합니다. (ELMo와 유사하지만 ELMo는 양방향 LSTM을 사용합니다.)</code></p><p><code>2. 다양한 작업에 적용할 수 있는 범용적인 표현을 학습하기 위해 작업에 약간의 조정만으로 전이 가능하도록 합니다.</code></p><pre><code>학습은 다음의 단계를 거쳐 이루어집니다. 1.먼저 레이블이 없는 데이터에서 언어 모델 목표를 사용하여 사전 훈련을 수행한 후, 2.레이블이 있는 목표 작업에 맞추어 지도 학습을 진행합니다.(이를 위해 Transformer 디코더 블록을 활용합니다.)</code></pre><p>GPT는 기존 언어 모델의 트렌드를 이어가면서 유연한 전이(transfer)가 가능하며, 지도 학습 형태의 미세 조정(Fine-tuning) 없이도 제로샷(Zero-shot) 다운스트림 작업을 수행할 수 있는 일반화된 모델입니다.</p><p>쉽게 풀어서 말하자면 GPT-2에서는 먼저 레이블이 없는 데이터셋(Unlabeled corpora)을 언어 모델에 학습시킵니다. 이 과정을 <code>Pre-training(사전 학습)</code>이라고 합니다. pre-training을 마친 모델에 추가로 태스크에 맞는 데이터셋(Labeled corpora)을 추가 학습시킵니다. 이를 <code>Fine-tuning</code>이라고 합니다. GPT는 이러한 “전이 학습(Transfer learning) 방법으로 이전의 모델보다 더 좋은 성능을 낼 수 있을 것이다”라는 아이디어에서 고안되었습니다.</p><h2 id="GPT-2-pre-training-gt-fine-tuning"><a href="#GPT-2-pre-training-gt-fine-tuning" class="headerlink" title="GPT-2(pre-training -&gt; fine-tuning)"></a>GPT-2(pre-training -&gt; fine-tuning)</h2><p>GPT-2는 4가지 크기의 모델이 있으며, 각각의 파라미터와 decoder의 수 및 input encoding dim의 차이는 아래의 그림들과 같습니다.</p><img width="700" alt="GPT-2의 모델 크기 비교" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/adc5aa2d-d6f0-4f8a-b77f-910cf2947477"><img width="700" alt="GPT-2의 모델 크기 비교2" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/13bf5a56-b10c-45c9-8f5d-5ab89e0cfdf6"><img width="500" alt="GPT의 input encoding" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/b8069bb4-bf20-4d82-a42f-5c7fd128177b"><p>위의 그림처럼 GPT는 모델별로 input encoding을 다르게 하였습니다.</p><h2 id="GPT-2-Model-Architecture"><a href="#GPT-2-Model-Architecture" class="headerlink" title="GPT-2 Model Architecture"></a>GPT-2 Model Architecture</h2><img width="200" alt="GPT의 decoder block" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/f13f8a93-f1ae-48ff-bd98-f2b713b9d74f"><p>위의 그림의 <code>블럭</code>이 부분이 GPT-2의 <code>Decoder Block</code>입니다.</p><p>이러한 <code>Decoder Block</code>이 n 개로 구성된게 GPT-2입니다.(하이퍼 파라미터)</p><p>여기서 attention을 <code>masked self-attention</code>을 사용하기 때문에 아래의 그림과 같이 output의 단어가 input의 단어로 와서 다음 output단어를 예측하게 됩니다.</p><pre><code>(이를 Auto-regressive라 합니다)예를 들어 단어 &#39;A&#39;가 output으로 나오면 그 단어가 input token으로 들어가고 그 후 &#39;robot&#39;이라는 단어가 output으로 나오게 되고 ..(반복).. 이러한 과정이 반복됩니다.</code></pre><img width="700" alt="output의 단어가 input의 끝 단어로 온다" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/b92ed524-85c3-4e96-abe7-5c3bb46ea244"><h3 id="이제-어떻게-GPT-2가-학습되는지-자세히-살펴보겠습니다"><a href="#이제-어떻게-GPT-2가-학습되는지-자세히-살펴보겠습니다" class="headerlink" title="이제 어떻게 GPT-2가 학습되는지 자세히 살펴보겠습니다."></a>이제 어떻게 GPT-2가 학습되는지 자세히 살펴보겠습니다.</h3><img width="700" alt="gpt2 input" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/128700a9-4ead-4b1b-a98e-b54c45b4f728"><ol><li>input으로는 <code>Transformer</code>의 decoder 방식과 동일하게 token embeddings + positional embeddings가 더한 백터값이 들어옵니다.</li></ol><img width="700" alt="gpt2" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/c20be424-7a76-4358-9afc-330a1448bf14"><ol start="2"><li><p>첫 번째 블록은 이제 토큰을 처리할 수 있습니다.<br>먼저, self-attention 과정을 통해 토큰을 전달한 다음 신경망 계층을 통과시킵니다.<br>첫 번째 변환기 블록이 토큰을 처리하면 결과 벡터를 스택 상위 블록으로 보내 해당 블록에서 처리됩니다.<br>각 블록에서의 과정은 동일하지만,<br>각 블록은 self-attention과 신경망 서브레이어에서 고유한 가중치를 가지고 있습니다.</p></li><li><p>pre-training을 먼저 하는데 이때의 모델의 목적 함수 $L_1$은 다음과 같습니다.</p></li></ol><p>$$ L_1(u) &#x3D; \sum_{i} logP(u_i|u_{i-k}, … , u_{i-1};\Theta) $$</p><p>[여기서 input_tokens $u$는 unsupervised dataset에서의 input_tokens입니다.]<br>[확률 P, input_tokens $u$, 파라미터 $\Theta$, 목적 함수 $L_1$]</p><ol start="4"><li>GPT : Supervised fine-tuning(3번의 pre-train과 달리 supervised dataset을 사용)</li></ol><ul><li><p>레이블이 지정된 데이터셋 $C$는 각 인스턴스가 입력 토큰의 시퀀스 [$x^l, … , x^m$]와 레이블 $y$로 구성됩니다.</p></li><li><p>입력은 사전 훈련된 모델을 통해 최종 변환기 블록의 활성화 $h_{l}^{m}$를 얻습니다. 이 활성화는 추가된 선형 출력 계층에 공급되며, 여기에는 매개변수 $W_y$가 있어 $y$를 예측합니다.</p></li></ul><p>$$ P(y|x^1, … , x^m) &#x3D; softmax(h_l^m W_y) $$</p><p>[확률 $P$, label $y$, input_tokens $x$, final_transformer_blokck’s_activation $h_l^m$, 최종 목적함수 $L_2$, 데이터셋 $C$],<br>[h_l^m W_y는 마지막 디코더 블럭의 아웃풋 값이Linear layer를 통과를 의미]</p><ul><li>위의 수식을 통해 아래의 목적 함수를 극대화할 수 있습니다.</li></ul><p>$$ L_2(C) &#x3D; \sum_{(x,y)} logP(y|x^1, … , x^m) $$</p><ol start="4"><li>위의 목적 함수들을 합해서 GPT-2는 다음과 같은 목적 함수를 사용합니다.</li></ol><p>$$ L_3(C) &#x3D; L_2(C) + \lambda \cdot L_1(C) $$</p><ul><li>논문에서는 이와 같은 방법이 모델의 일반화를 돕고 수렴 속도를 더 빠르게 하는 효과가 있다고 합니다.</li></ul><p>요약 하자면,</p><pre><code>Unlabeled dataset에 대한 pre-training을 한 뒤,Labeled dataset의 목적 함수와 같이 섞어 사용한 fine-tuning을 하고, 그 두 가지를 조합하여 사용한 최종 목적 함수(objective function)를 사용하면,더 나은 결과를 얻을 수 있다고 합니다.</code></pre>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Paper/">Paper</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/paper/">paper</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Transformer(Attention is all you need)</title>
      <link>http://inhwancho.github.io/2023/08/09/Paper_Review/2023-08-09-transformer/</link>
      <guid>http://inhwancho.github.io/2023/08/09/Paper_Review/2023-08-09-transformer/</guid>
      <pubDate>Tue, 08 Aug 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<p>NLP분야에서, 기존의 RNN에서의 한계때문에<br>[Context vector의 크기가 제한적이기 때문에 문장의 모든 정보를 보낼 수 없음 &#x3D;&#x3D;long term dependency problem]<br>seq2seq모델(문장을 입력받아 문장을 출력해주는)에서 RNN대신 제안된 모델이 Attention이라는 모델입니다.<br>이 Attention을 통해 만든 Transformer 분석해보겠습니다.</p><h3 id="참고-자료-Transformer에-관한-글"><a href="#참고-자료-Transformer에-관한-글" class="headerlink" title="참고 자료(Transformer에 관한 글)"></a>참고 자료(Transformer에 관한 글)</h3><p><a href="https://arxiv.org/abs/1706.03762" title="Transformer 논문">Transformer 논문</a><br><a href="https://www.youtube.com/watch?v=Yk1tV_cXMMU&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=17" title="고려대 유튜브">고려대 유튜브</a><br><a href="https://jalammar.github.io/illustrated-transformer/" title="Jay alammar blog">Jay alammar 블로그</a></p><img width="700" alt="Transformer 구조" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/3ced3af7-c1af-4dfc-9b1f-ca6fa3d4f67f"><p>그림의 왼쪽 부분은 Encoder, 오른쪽 부분은 Decoder부분입니다.<br>먼저, 왼쪽의 빨간색 박스의 inputs이 어떻게 들어가는지 확인해보겠습니다.</p><img width="700" alt="Transformer의 inputs" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/71671c01-b56c-47f1-a2ae-55e02990c7b9"><pre><code>1. input으로 문장이 들어오면 (&quot;je suis etudiant&quot;)2. 문장 -&gt; 단어로 변경 (&quot;je&quot;, &quot;suis&quot;, &quot;etudiant&quot;)    3. 토큰화 -&gt; embedding[x1, x2, x3]해 줍니다.4. 그 후 positional encoding 값[t1, t2, t3]을 더하여   최종 input값인 [x1, x2, x3]를 얻게 됩니다.</code></pre><p>포지셔널 인코딩의 코드가 궁금하시다면 아래 링크를 통해 확인 가능합니다.</p><p><a href="https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb" title="positional encoding">positional encoding 코드</a>  </p><h2 id="Attention-self-attention"><a href="#Attention-self-attention" class="headerlink" title="Attention(self-attention)"></a>Attention(self-attention)</h2><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>위에서 구한 input값을 self_attention의 input값으로 넣어줍니다.<br>그 후 이 input으로 3종류의 vector를 만들어 사용합니다.</p><p>그 벡터들은 <code>Query</code>, <code>Key</code>, <code>Value</code>라 부르는데 각각의 의미는 다음과 같습니다.</p><pre><code>Query : 현재 보고 있는 단어의 대표 값(기준점)Key   : 단어의 label과 같은 역할을 하는 값Value : 실제 단어의 값</code></pre><p>이 Q, K, V를 구하기 위해서는 앞에서 구한 <code>input vector</code>에 weight matrix를 곱하여 얻게 됩니다.</p><img width="700" alt="attention의 q,k,v를 얻는 과정" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/8bdbc042-8820-471e-b412-be4838be19db"><p>위의 사진을 통해 보면 $X_1$, $X_2$가 <code>input vector</code>고 $W^Q$, $W^K$, $W^V$ 가 weight matrix로 학습을 통해 구해야할 파라미터입니다.</p><p>예를 들어 Query중 $q_1$을 구하기 위해서는 $X_1 \cdot W^Q$를 연산하여 구할 수 있습니다.</p><p>일반적으로 Q,K,V의 dim을 적게 잡는 편입니다. 이유는 나중에 이 self-attention을 여러번 연산하는 Multi-headed attention의 관점에서 보면, 이 연산된 q,k,v 를 concat하기 때문입니다.(ex. 64(dim) * 8(heads) &#x3D;&#x3D; 512dim)</p><p>그렇다면, 여기서 attention이 진행되는 과정과 의미가 어떻게 되는지 알아보겠습니다.</p><img width="700" alt="어텐션의 메커니즘" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/ecc392cb-17de-4e57-a3ea-33eae6610867"><ol><li>위의 사진을 보면 먼저 score를 구합니다($q_1 \cdot k_1$)</li><li>그 후 $\sqrt {dim_k}$ 만큼 나눠줍니다. 여기서는 64차원이기 때문에 $\sqrt{64} &#x3D; 8$ 으로 나눠줍니다.</li><li>나눠진 스코어값을 softmax를 취해 값을 얻습니다.</li><li>이렇게 나온 스코어값(0.88)이랑 $v_1$이랑 곱하여 $v_1$을 얻고, 두 번째 인풋 $x_2$값과 연산하여 나온 스코어값(0.12)랑 $v_2$랑 곱하여 $v_2$를 얻게되고(흐릿한 $v_2$) </li><li>최종적으로 인풋($x_1$)에 대한 output값인 $z_1$값을 두 개의 값을 더하여 얻게됩니다, ($v_1 + v_2 &#x3D; z_1$)</li></ol><p>여기까지는 단 1개의 self-attention을 기준으로 설명하였고, 실제로는 multi-headed attention이기 때문에 위의 self-attention이 여러개 연산됩니다.(아래 그림 참조)</p><img width="700" alt="멀티해드 어텐션" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/dfeaeeda-4547-4c61-85c6-175ea9639eb9"><p>아래 그림은 최종적으로 multi-headed attention의 값을 얻는 과정입니다.</p><img width="700" alt="멀티해드 어텐션의 최종 과정" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/f67d6d08-e664-4ecd-a621-53f85507a7a3"><ol start="6"><li><p>$z_0, z_1, z_2, … , z_7$의 값을 concat한 값과 $W^O$값을 연산하여 최종 $Z$값을 얻습니다. [여기서 W_O의 열은 concat한 z들의 차원과 동일하고 행은 input embedding($x$)값의 차원과 동일하기 때문에 $Z$의 차원은 input차원과 동일합니다.]($W^O$는 학습을 통해 구하는 파라미터)</p></li><li><p>Add(<code>Residual</code>) &amp; <code>Normalize</code></p></li><li><p>Position-wise Feed-forward Network 연산을 진행합니다.<br>[$FFN(x) &#x3D; max(0,x W_1 + b_1)W_2 +b_2$]</p></li></ol><img width="700" alt="FFN" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/173ed316-d309-4f03-8b41-b8e1ae0aac8e"><p>FFN을 그림으로 살펴보면 다음과 같습니다.<br>여기서는 <code>1x1 conv연산</code>을 통해 차원을 늘리고 Relu를 취한뒤 다시 <code>1x1 conv연산</code>를 통해 줄인다고 생각하면 편합니다.</p><p>여기까지가 Transformer의 <code>Encoder</code> 부분이였습니다.</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><img width = "700" alt ="decoder" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/b4fdca5d-509f-45dc-81bd-284944319196"><p>이제 <code>Decoder</code>에 대해 설명하겠습니다.</p><ol><li>디코더에서는 Multi-head attention 대신 <code>Masked Multi-head attention</code>을 먼저 수행합니다.<br>(이 self-attention은 연산을 수행 할 때, 앞에 있는 attention score만 볼 수 있습니다)</li></ol><img width="700" alt="decoder의 masked attention" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/c3964977-cebb-433e-9672-9f0f7d74d323"><p>위의 그림을 보면, $z_1$의 연산을 수행 할 때, $x_2$의 값들은 <code>inf</code>로 가려있어서 연산에 포함되지 않습니다.</p><img width="700" alt="masked attention의 연산" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/e340218f-8123-4b01-8b3b-e99918ab337f"><p>하지만 실제로는 sequential하게 연산하지 않고 위의 그림과 같은 방식으로 softmax로 연산하기 전에 <code>-inf</code>로 처리하고 연산하게됩니다.</p><ol start="2"><li>이 output값인 $Z$값을 decoder의 Multi-head attention에서 $Q$값으로 사용하고, encoder의 output값을 $K$, $V$로 사용하여 연산을 합니다.</li></ol><img width="700" alt="Leaner & softmax & argmax" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/771f7b11-8cc8-4eb5-a991-938b09249e7d"><ol start="3"><li>마지막으로 위의 그림과 같이 Linear(vocab size) and softmax를 통하여 output 값을 얻고 거기에 <code>argmax</code>를 통해 최종적으로 우리가 얻고 싶은 단어를 얻습니다.</li></ol>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Paper/">Paper</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/NLP/">NLP</category>
      
      <category domain="http://InhwanCho.github.io/tags/paper/">paper</category>
      
      
      <comments>http://inhwancho.github.io/2023/08/09/Paper_Review/2023-08-09-transformer/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>ViT(Vision Transformer)</title>
      <link>http://inhwancho.github.io/2023/07/16/Paper_Review/2023-07-16-VIT/</link>
      <guid>http://inhwancho.github.io/2023/07/16/Paper_Review/2023-07-16-VIT/</guid>
      <pubDate>Sat, 15 Jul 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<p>NLP분야에서, 기존의 RNN에서의 한계때문에 [Context vector의 크기가 제한적이기 때문에 문장의 모든 정보를 보낼 수 없음]<br>seq2seq모델(문장을 입력받아 문장을 출력해주는)에서 RNN대신 제안된 모델이 Attention이라는 모델입니다.<br>이 Attention을 통해 만든 Transformer가 NLP분야에서 너무 좋은 성능을 보여줘서<br>CNN이 아닌Attention을 통해 vision분야에도 적용해 본 모델이 Vit입니다.</p><h3 id="참고-문헌"><a href="#참고-문헌" class="headerlink" title="참고 문헌"></a>참고 문헌</h3><p>Transformer에 관한 글 [페이지 작성 예정]</p><p><a href="https://arxiv.org/pdf/2010.11929.pdf" title="ViT 논문">ViT 논문</a><br><a href="https://www.youtube.com/watch?v=91Qipj5NMnk" title="유튜브">관련 유튜브</a><br><a href="https://towardsdatascience.com/implementing-visualttransformer-in-pytorch-184f9f16f632" title="코드">코드 구현</a></p><p>먼저, ViT에 들어가기 전에 Attention, Transformer의 개념을 간단하게 잡고 가겠습니다.</p><h4 id="Attention과-Self-Attention의-차이"><a href="#Attention과-Self-Attention의-차이" class="headerlink" title="Attention과 Self-Attention의 차이"></a>Attention과 Self-Attention의 차이</h4><p>Attention &#x3D; (Decoder -&gt; Query)(Encoder -&gt; Key, Value) &#x3D;&#x3D; encoder와 decoder의 상관관계를 통해 특징 추출<br>Self-Attention &#x3D; (입력데이터에서 동일한  Query, Key, Value을 얻음) &#x3D;&#x3D; 입력데이터 내에서의 상관관계를 통해 특징 추출<br>(ViT는 self-Attention만 사용)</p><h4 id="Transformer와-CNN의-차이"><a href="#Transformer와-CNN의-차이" class="headerlink" title="Transformer와 CNN의 차이"></a>Transformer와 CNN의 차이</h4><p>Transformer는 하나의 layer에서 전체 이미지 정보를 통합 가능하나<br>CNN의 경우 멀리 떨어진 두 정보를 통합할때 여러개의 layer를 통과해야 정보가 통합이 됩니다.</p><p>CNN에서의 Inductive bias는 convolution filer라는 것을 통하여 <strong>지역적 정보</strong>를 추출할 수 있습니다.<br>Transfoer에서는 1차원 벡터로 만든 후 self-attention을 통해 특징을 추출하기 때문에 지역적 정보는 없습니다.<br>그러나 그렇기 때문에 모델의 자유도는 증가합니다.(inductivie bias가 CNN보다 적다)</p><h2 id="ViT-ViT-Base-x2F-16-설명"><a href="#ViT-ViT-Base-x2F-16-설명" class="headerlink" title="ViT(ViT-Base &#x2F; 16) 설명"></a>ViT(ViT-Base &#x2F; 16) 설명</h2><p>아래는 논문에 나와있는 전체적인 ViT overview 입니다.</p><img width="800" alt="VIT overview" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/9cbd8a18-8ba0-476b-bebb-4ec4e896234f"><p>여기서 16은 패치의 사이즈를 의미합니다. 즉, 논문의 그림으로 설명하자면 기존의 이미지 사이즈가 48x48이고 이를 9개의 16x16의 패치로 자른 모델을 의미합니다.<br>(실제 이미지넷 데이터 기준으로 설명하면 H&#x3D;W&#x3D;224, Patch_size&#x3D;16이면 실제 패치의 수 &#x3D; 14*14 &#x3D;&#x3D; 196이 됩니다.)</p><p>ViT의 연산 과정은 다음과 같습니다.</p><p>16x16사이즈의 패치를 1차원으로 만들어줍니다(컬러 이미지이기 때문에 3채널이라 곱하기3) &#x3D;&#x3D;&gt; 16x16x3 &#x3D; 768차원<br>이를 batch가 있는 실제 코드로 살펴보면 다음과 같습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input_img[batch, channel, height, width]</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 16 pixels</span></span><br><span class="line">patch_size = <span class="number">16</span> </span><br><span class="line">pathes = rearrange(x, <span class="string">&#x27;b c (h s1) (w s2) -&gt; b (h w) (s1 s2 c)&#x27;</span>, s1=patch_size, s2=patch_size)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pathes.shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 196, 768])</span></span><br></pre></td></tr></table></figure><p>이를 Linear Projection을 통과하고 그 값에(768차원)</p><p>position embedding값과 Classification token(CLS token과 동일한 기능)을 더해줍니다.<br>[여기서 position embedding값과 Classification token은 학습을 통해 결정되는 파라미터 값] &#x3D;&#x3D; z값<br>코드로 살펴보면 다음과 같습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbedding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span> = <span class="number">3</span>, patch_size: <span class="built_in">int</span> = <span class="number">16</span>, emb_size: <span class="built_in">int</span> = <span class="number">768</span>, img_size: <span class="built_in">int</span> = <span class="number">224</span></span>):</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.projection = nn.Sequential(</span><br><span class="line">            <span class="comment"># using a conv layer instead of a linear one -&gt; performance gains</span></span><br><span class="line">            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),</span><br><span class="line">            Rearrange(<span class="string">&#x27;b e (h) (w) -&gt; b (h w) e&#x27;</span>),</span><br><span class="line">        )</span><br><span class="line">        self.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>,<span class="number">1</span>, emb_size))</span><br><span class="line">        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **<span class="number">2</span> + <span class="number">1</span>, emb_size))</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        b, _, _, _ = x.shape</span><br><span class="line">        x = self.projection(x)</span><br><span class="line">        cls_tokens = repeat(self.cls_token, <span class="string">&#x27;() n e -&gt; b n e&#x27;</span>, b=b)</span><br><span class="line">        <span class="comment"># prepend the cls token to the input</span></span><br><span class="line">        x = torch.cat([cls_tokens, x], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># add position embedding</span></span><br><span class="line">        x += self.positions</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">PatchEmbedding()(x).shape</span><br><span class="line"><span class="comment">#torch.Size([1, 197, 768])</span></span><br></pre></td></tr></table></figure><p>그리고 여기서 나온 값을 Transformer의 Encoder의 input값으로 사용합니다.<br>또한, Transformer의 인코더와 약간 차이가 있습니다. <br>기존의 Transformer에서는 연산 후 normalization을 수행하였지만, ViT에서는 Norm을 먼저 진행하고 attention연산&#x2F;MLP연산을 진행합니다.<br>여기서 Normalization은 batch norm이 아닌 layer normalization입니다.(batch단위가 아닌 instance(sample)단위로 norm을 진행)</p><p>input(768차원)값으로 사용되는 z값에 Weight matrix(학습되는 파라미터)인 $W_Q$ 값을 곱하여 [$ z \bullet W_Q$]-&gt; q(64차원)값을 얻고</p><p>$W_K$를 곱하여 [$ z \bullet W_K$] -&gt; k(64차원)를 얻고 $W_V$를 곱하여 [$ z \bullet W_V$] -&gt; v값(64차원)을 얻습니다.</p><p>그리고 얻어진 q,k를 곱한 값에 softmax를 취한 a값[$a &#x3D; Softmax(q^T\dot k)$]을 구하고 (a&#x3D;attention score)<br>a와 v를 곱한 최종 score(64차원)를 구합니다.</p><p>ViT에서는 이 self-attention을 12번 수행하게 됩니다. </p><p>여기서 12번 수행하고 concate을 하면 12*64 -&gt; 768차원으로 다시 복귀됩니다.</p><p>그 후 인코더의 두번째 부분은 norm을 수행하고, 768차원 -&gt; 3072차원(히든 레이어) -&gt; 768차원인 MLP를 통과합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, emb_size: <span class="built_in">int</span> = <span class="number">768</span>, num_heads: <span class="built_in">int</span> = <span class="number">8</span>, dropout: <span class="built_in">float</span> = <span class="number">0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.emb_size = emb_size</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        <span class="comment"># fuse the queries, keys and values in one matrix</span></span><br><span class="line">        self.qkv = nn.Linear(emb_size, emb_size * <span class="number">3</span>)</span><br><span class="line">        self.att_drop = nn.Dropout(dropout)</span><br><span class="line">        self.projection = nn.Linear(emb_size, emb_size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x : Tensor, mask: Tensor = <span class="literal">None</span></span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># split keys, queries and values in num_heads</span></span><br><span class="line">        qkv = rearrange(self.qkv(x), <span class="string">&quot;b n (h d qkv) -&gt; (qkv) b h n d&quot;</span>, h=self.num_heads, qkv=<span class="number">3</span>)</span><br><span class="line">        queries, keys, values = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]</span><br><span class="line">        <span class="comment"># sum up over the last axis</span></span><br><span class="line">        energy = torch.einsum(<span class="string">&#x27;bhqd, bhkd -&gt; bhqk&#x27;</span>, queries, keys) <span class="comment"># batch, num_heads, query_len, key_len</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            fill_value = torch.finfo(torch.float32).<span class="built_in">min</span></span><br><span class="line">            energy.mask_fill(~mask, fill_value)</span><br><span class="line">            </span><br><span class="line">        scaling = self.emb_size ** (<span class="number">1</span>/<span class="number">2</span>)</span><br><span class="line">        att = F.softmax(energy, dim=-<span class="number">1</span>) / scaling</span><br><span class="line">        att = self.att_drop(att)</span><br><span class="line">        <span class="comment"># sum up over the third axis</span></span><br><span class="line">        out = torch.einsum(<span class="string">&#x27;bhal, bhlv -&gt; bhav &#x27;</span>, att, values)</span><br><span class="line">        out = rearrange(out, <span class="string">&quot;b h n d -&gt; b n (h d)&quot;</span>)</span><br><span class="line">        out = self.projection(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line">patches_embedded = PatchEmbedding()(x)</span><br><span class="line">MultiHeadAttention()(patches_embedded).shape</span><br><span class="line"><span class="comment">#torch.Size([1, 197, 768])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualAdd</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fn</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.fn = fn</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        res = x</span><br><span class="line">        x = self.fn(x, **kwargs)</span><br><span class="line">        x += res</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForwardBlock</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, emb_size: <span class="built_in">int</span>, expansion: <span class="built_in">int</span> = <span class="number">4</span>, drop_p: <span class="built_in">float</span> = <span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            nn.Linear(emb_size, expansion * emb_size),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Dropout(drop_p),</span><br><span class="line">            nn.Linear(expansion * emb_size, emb_size),</span><br><span class="line">        )</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerEncoderBlock</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 emb_size: <span class="built_in">int</span> = <span class="number">768</span>,</span></span><br><span class="line"><span class="params">                 drop_p: <span class="built_in">float</span> = <span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 forward_expansion: <span class="built_in">int</span> = <span class="number">4</span>,</span></span><br><span class="line"><span class="params">                 forward_drop_p: <span class="built_in">float</span> = <span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 ** kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            ResidualAdd(nn.Sequential(</span><br><span class="line">                nn.LayerNorm(emb_size),</span><br><span class="line">                MultiHeadAttention(emb_size, **kwargs),</span><br><span class="line">                nn.Dropout(drop_p)</span><br><span class="line">            )),</span><br><span class="line">            ResidualAdd(nn.Sequential(</span><br><span class="line">                nn.LayerNorm(emb_size),</span><br><span class="line">                FeedForwardBlock(</span><br><span class="line">                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),</span><br><span class="line">                nn.Dropout(drop_p)</span><br><span class="line">            )))</span><br><span class="line">TransformerEncoderBlock()(patches_embedded).shape</span><br><span class="line"><span class="comment">#torch.Size([1, 197, 768])</span></span><br></pre></td></tr></table></figure><p>그 후 최종 Classification을 위해 MLP head를 통과하여 분류를 합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerEncoder</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, depth: <span class="built_in">int</span> = <span class="number">12</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*[TransformerEncoderBlock(**kwargs) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClassificationHead</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, emb_size: <span class="built_in">int</span> = <span class="number">768</span>, n_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            Reduce(<span class="string">&#x27;b n e -&gt; b e&#x27;</span>, reduction=<span class="string">&#x27;mean&#x27;</span>),</span><br><span class="line">            nn.LayerNorm(emb_size), </span><br><span class="line">            nn.Linear(emb_size, n_classes))</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ViT</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,     </span></span><br><span class="line"><span class="params">                in_channels: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">                patch_size: <span class="built_in">int</span> = <span class="number">16</span>,</span></span><br><span class="line"><span class="params">                emb_size: <span class="built_in">int</span> = <span class="number">768</span>,</span></span><br><span class="line"><span class="params">                img_size: <span class="built_in">int</span> = <span class="number">224</span>,</span></span><br><span class="line"><span class="params">                depth: <span class="built_in">int</span> = <span class="number">12</span>,</span></span><br><span class="line"><span class="params">                n_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            PatchEmbedding(in_channels, patch_size, emb_size, img_size),</span><br><span class="line">            TransformerEncoder(depth, emb_size=emb_size, **kwargs),</span><br><span class="line">            ClassificationHead(emb_size, n_classes)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>아래는 논문에 나와있는 ViT 수식입니다.</p><img width="800" alt="VIT 수식" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/518dd7b5-0b7a-4551-919f-786511454021"><p>수식으로 설명하면 다음과 같습니다.</p><p>(1) 각각의 Linear projection된 패치들에 position encoding값을 더합니다.(+CLS token)<br>    그리고 이 값을 layer normalization 시켜준 뒤 Multi head self-attention에 input으로 넣어줍니다.(12번 연산)</p><p>(2) residual connection이기 때문에 기존의 값에 더해주어 값을 보존합니다.[MSA는 Multihead Self Attention]</p><p>(3) transformer를 통해 구한output값을 한번 더 Layer normalization 시켜준 뒤 MLP를 통과합니다. 그 후 기존의 값을 더해줍니다.</p><p>(4) 최종적으로 Layer normalization을 통해 최종 y vector값이 나오게 됩니다.</p><p>-&gt; 이 y값에 MLP를 통과하여 최종 이미지 classification을 수행합니다.</p>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Paper/">Paper</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/paper/">paper</category>
      
      
      <comments>http://inhwancho.github.io/2023/07/16/Paper_Review/2023-07-16-VIT/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>논문 리뷰 R-CNN</title>
      <link>http://inhwancho.github.io/2023/02/09/Paper_Review/2023-02-09-RCNN/</link>
      <guid>http://inhwancho.github.io/2023/02/09/Paper_Review/2023-02-09-RCNN/</guid>
      <pubDate>Wed, 08 Feb 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>&lt;<a href="https://arxiv.org/pdf/1311.2524.pdf">논문 pdf</a>&gt;</li><li>&lt;<a href="https://yeomko.tistory.com/13">갈아먹는 머신러닝</a>&gt;</li><li>&lt;<a href="https://wikidocs.net/148633">위키독스</a>&gt;</li><li>&lt;<a href="https://wikidocs.net/142645">위키독스2</a>&gt;</li></ul><hr><h2 id="서론"><a href="#서론" class="headerlink" title="서론"></a>서론</h2><p><code>Region proposals with CNNs(R-CNN</code> 이라는 Object Detect 분야의 새로운 방향을 제시하는 논문입니다.</p><p>그 이전까지 최고의 성능을 나타낸 기법의 mAP보다 30% 높은 53.3%를 달성하여 detection 분야에 새로운 방향을 제시하게 됩니다.<br>object detection의 성능 평가 지표는 mAP(mean average precision)입니다.</p><p>물체 인식(Object Detection)은</p><p>이미지 내에 관심이 있는 객체의 위치(Region of Interest)에</p><p>물체의 위치를 알려주기 위한 Bounding Box를 그려줘야 하고,</p><p>다수의 Bounding Box를 다양한 Object 종류에 대하여 찾아줘야 하기 때문에</p><p>이미지 분류 보다는 훨씬 복잡한 문제입니다.</p><img width="453" alt="물체 인식" src="https://user-images.githubusercontent.com/111936229/217687292-37e272fa-1e60-4353-9e0d-46d8a2224194.png"><p>일단, R-CNN의 구조는 다음과 같습니다</p><img width="697" alt="R-CNN 구조" src="https://user-images.githubusercontent.com/111936229/217687794-e73444b0-919b-4eb4-876f-d39fca5d1539.png"><hr><h2 id="본론"><a href="#본론" class="headerlink" title="본론"></a>본론</h2><p>일단 전체적 구조는 다음과 같습니다.</p><ol><li>입력 이미지에 Selective Search 알고리즘을 적용하여 bounding box(region proposal) 2000개를 추출합니다.</li><li>croping &amp; wraping을 사용해 추출된 bounding box를 CNN에 입력합니다.(227 x 227 pixel size)</li></ol><blockquote><p>(논문에서는 warp 과정에서 object 주변 16 픽셀도 포함하여 성능을 높였다고 합니다.)<br><br>Prior to warping, we dilate the<br>tight bounding box so that at the warped size there are exactly p pixels of warped image context around the original<br>box (we use p &#x3D; 16). </p></blockquote><ol start="3"><li>fine tunning 되어 있는 pre-trained CNN(AlexNet)을 사용하여 bounding box의 4096차원의 특징 벡터를 추출합니다.</li><li>추출된 특징 벡터를 SVM을 이용하여 class를 분류합니다.</li><li>bounding box regression을 적용하여 bounding box의 위치를 조정합니다.</li></ol><p>R-CNN은 <code>2-stage Detector</code>방식으로서 전체 Task를 크게 <code>두 가지 단계</code>로 나누어 진행합니다.</p><ol><li><code>첫 번째 단계</code>는 <code>Region Proposal</code>입니다. (물체의 위치를 찾는 일)<br>Region Proposal은 물체가 있을법한 위치를 찾는 작업이며,<br>R-CNN에서는 region proposal의 단계에서 <code>Selective Search</code>이라는 모듈을 사용하였습니다.</li></ol><blockquote><p>Selective Search알고리즘은 Segmentation 분야에 많이 쓰이는 알고리즘이며,<br>객체와 주변간의 색감(Color), 질감(Texture) 차이, 다른 물체에 애워쌓여있는지(Enclosed) 여부 등을<br>파악해서 다양한 전략으로 물체의 위치를 파악할 수 있도록 하는 알고리즘입니다.<br>아래의 그림과 같이 Bounding box들을 Random 하게 많이 생성을하고<br>이들을 조금씩 Merge하며 물체를 인식해나가는 방식으로 되어있습니다.</p></blockquote><p><img src="https://wikidocs.net/images/page/141994/Selective_Search_Algorithm.png" alt="selective search"></p><p>Feature Extraction<br>Selective Search를 통해서 찾아낸 2천개의 박스 영역은 227 x 227 크기로 리사이즈 됩니다. (warp)<br>그리고 Image Classification으로 미리 학습되어 있는 CNN 모델을 통과하여 4096 크기의 특징 벡터를 추출합니다. </p><p>이때, 미리 학습된 모델(AlexNet)이 구체적으로 어떤 것을 의미하는지 살펴보겠습니다. </p><p>저자들은 이미지넷 데이터(ILSVRC2012 classification)로 미리 학습된 CNN 모델을 가져온 다음, fine tune하는 방식을 취했습니다.</p><p>fine tune 시에는 실제 Object Detection을 적용할 데이터 셋에서 ground truth에 해당하는 이미지들을 가져와 학습시켰습니다.</p><p>그리고 Classification의 마지막 레이어를 Object Detection의 클래스 수 N과 아무 물체도 없는 배경까지 포함한 N+1로 맞춰주었습니다.</p><p>fine tune을 적용했을 떄와 하지 않았을 때의 성능을 비교해보면 아래와 같습니다.</p><p><code>FT</code>는 fine tune의 약자이며, 각 CNN 레이어 층에서 추출된 벡터로 SVM Classifier를 학습시켜서 얻은 mAP를 비교한 것입니다.</p><p>그리고 <code>BB</code>로 적힌 것은 Bounding Box Regression을 적용한 것으로 조금 아래에서 설명하겠습니다.</p><img width="1007" alt="파인튜닝 후 결과가 좋아짐(표)" src="https://user-images.githubusercontent.com/111936229/217694744-4ce8b0fd-474a-41e3-b30c-526945b044e2.png"><ol><li><code>두 번째 단계</code>는 <code>Region Classification</code> (물체를 분류하는 일)</li></ol><p>정리하자면, 미리 이미지 넷으로 학습된 CNN(AlexNet)을 가져와서, Object Detection용 데이터 셋으로 fine tuning 한 뒤, selective search 결과로 뽑힌 이미지들로부터 특징 벡터를 추출합니다. 그리고 이 벡터들을 각각의 클래스 별로 SVM Classifier를 학습시킵니다.</p><p>이때 CNN Classifier를 두고 왜 SVM을 별도로 학습시키는 이유는 SVM이 더 성능이 좋아서 였다고 합니다.</p><p>SVM을 통해 분류된 각각의 박스들은 어떤 물체일 확률 값(Confidence Score)을 가지게 되었습니다.</p><p>이 2천개의 박스 중 동일한 물체에 여러 개의 박스가 있는것이라면 가장 높은 스코어의 박스만 남기고 나머지를 제거해야되는데, 이 과정을 <code>Non-Maximum Suppression</code>이라고 합니다. 자세한 내용은 아래에서 보겠습니다.</p><hr><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><p>R-CNN에서 학습이 일어나는 부분은 3가지나 되어 [<code>AlexNet 모델 fine tuning</code>, <code>SVM Classifier</code>, <code>Bounding Box Regression</code>] 시간이 엄청 소요됩니다.<br></p><blockquote><p>(Computation sharing이 안됩니다. 위의 세 가지의 모델이 결합된 형태로 한 번에 학습이 불가능합니다. 즉, end-to-end 훈련이 불가능하다는 뜻입니다. SVM, Bounding Box Regression을 학습시켜도 Back propagation이 안되므로 CNN은 업데이트 되지 않습니다. )</p></blockquote><p>테스트 시에 R-CNN은 이미지 하나 당 GPU에서는 13초, CPU에서 54초가 걸린다고 합니다.</p><p>속도 저하의 가장 큰 병목 구간은 selective search를 통해서 찾은 2천개의 영역에 모두 CNN inference를 진행하기 때문입니다.</p><p>정확도의 경우 Pascal VOC  2010을 기준으로 53.7%를 기록하였습니다.</p><p>이는 당시 기존의 기록들을 모두 갈아치우며 획기적으로 Object Detection 분야에 발전을 이끌었던 스코어입니다.</p><p>warping 하는 과정에서 input 이미지가 왜곡되고 정보 손실이 발생합니다</p><p>Selective Search나 SVM이 GPU에 적합한 구조가 아닙니다.</p><hr><h3 id="NMS-Non-Maximum-Suppression-에-대한-설명"><a href="#NMS-Non-Maximum-Suppression-에-대한-설명" class="headerlink" title="NMS (Non-Maximum Suppression)에 대한 설명"></a>NMS (Non-Maximum Suppression)에 대한 설명</h3><p>대다수의 object detection algorithm은 object가 존재하는 위치 주변에 여러개의 score가 높은 bounding box를 만든다는 문제점이 있습니다. 이 중 하나의 bounding box만을 선택해야 하는데, 이때 적용하는 기법이 non-max suppression 입니다. 즉, object detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법입니다. optimal 한 solution일 수는 없고 local maxima를 찾는 방법이라고 볼 수 있습니다.</p><p>일반적인 NMS의 과정은 다음과 같습니다.</p><ol><li>모든 Bounding box는 객체를 얼마나 잘 잡아내는지에 대한 스코어(confidence score)를 가집니다. 모든 bounding box에 대하여 threshold 이하의 confidence score를 가지는 Bounding Box는 제거합니다. Confidence score가 일정 수준 이하인 bounding box들에 대해 일차적으로 필터링을 거치는 과정입니다.</li><li>맨 앞에 있는 Bounding box 하나를 기준으로 잡고, 다른 bounding box와 IoU 값을 구합니다. IoU가 threshold 이상인 Bounding box들은 제거합니다. Bounding box끼리 IoU가 높을수록, 즉 많이 겹쳐질수록 같은 물체를 검출하고 있다고 판단하기 때문입니다.</li><li>Confidense threshold가 높을수록, IoU threshold가 낮을수록 더 많은 bounding box가 제거됩니다.<br>예를 들어 Confidence score의 threshold를 0.5라고 지정하면 Confidence score가 0.5 이하인 bounding box들은 모두 제거됩니다.</li></ol><p>IoU는 (Intersection over Union)의 약자로서 이름 그대로<br>$교집합(Intersection) \over 합집합(Union)$ 입니다. 즉, 박스의 IOU는 겹치는 부분의 넓이는 전체 합집합의 넓이로 나눈 값입니다.</p><img width="500" alt="IoU" src="https://user-images.githubusercontent.com/111936229/217699272-58d80b13-29c6-476f-b482-064072020a01.png"><img width="463" alt="IoU scores" src="https://user-images.githubusercontent.com/111936229/217697379-b6e1d404-0415-4f43-a9bb-318c7ccd6adf.png"><hr><h3 id="Bounding-Box-Regression"><a href="#Bounding-Box-Regression" class="headerlink" title="Bounding Box Regression"></a>Bounding Box Regression</h3><p><code>Selective search</code>로 물체가 있을 법한 위치를 찾았고, 해당 물체의 종류를 판별할 수 있는 분류 모델을 학습시켰습니다. 하지만 이 기존의 박스 위치는 상당히 정확하지 않습니다.</p><p>그렇기 때문에 성능을 끌어올릴 필요가 있는데, 이 위치를 교정해주는 부분을 <code>Bounding Box Regression</code>이라 합니다.</p><p>즉, Predicted box(예측 박스)와 ground truth box(정답 박스)와의 차이를 줄여주는 </p><p>bounding box regression이 필요하고, 이는 <code>Linear regression model</code>로 볼 수 있다.</p><p>Bounding box regression의 최종 목표는 predicted box가 ground truth box와 유사하도록 학습하는 것이며 </p><p>먼저 하나의 박스를 다음과 같이 표기할 수 있습니다.</p><p>여기서 x, y는 이미지의 중심점, w, h는 각각 너비와 높이입니다.<br>P는 predctied box, G는 ground truth box입니다.</p><p>$$ P^i &#x3D; (P_x^i, P_y^i, P_w^i, P_h^i) $$<br>$$ G &#x3D; (G_x, G_y, G_w, G_h) $$</p><p>목표를 위해서는 P에 해당하는 박스를 최대한 G에 가깝도록 이동시키는 함수를 학습시켜야 합니다.</p><p>박스가 인풋으로 들어왔을 때, x, y, w, h를 각각 이동 시켜주는 함수들을 표현해보면 다음과 같습니다.</p><p>$$ d_x(P),d_y(P),d_w(P), d_h(P) $$</p><p>이러한 특성을 반영하여 P를 이동시키는 함수의 식을 짜보면 다음과 같습니다.</p><p>$$ \hat{G_x} &#x3D; P_w * d_x(P) + P_x $$<br>$$ \hat{G_y} &#x3D; P_h * d_y(P) + P_y $$<br>$$ \hat{G_w} &#x3D; P_w \exp(d_w(P)) $$<br>$$ \hat{G_h} &#x3D; P_h \exp(d_h(P)) $$</p><p>논문에서는 d 함수를 구하기 위해서 앞서 CNN을 통과할 때 pool5 레이어에서 얻어낸 특징 벡터를 사용합니다.<br>(d(P)는 transformation 함수입니다.</p><p>$$ d_*(P) &#x3D; w_*^T \varnothing_5(P)$$</p><p>$\varnothing_5$ : 학습한 CNN layer 중 pool5에서 구한 feature vector</p><p>w : 학습 가능한 weight vector</p><p>이제 웨이트를 학습시킬 로스 펑션을 세워보면 다음과 같습니다.</p><p>일반적인 MSE 에러 함수에 L2 normalization을 추가한 형태입니다.</p><p>저자들은 람다를 1000으로 설정하였습니다.</p><img width="489" alt="w" src="https://user-images.githubusercontent.com/111936229/217702435-4fb4b82b-b47c-4fca-9d13-67ef1511a2d8.png"><p>여기서 t는 P를 G로 이동시키기 위해서 필요한 이동량을 의미하며 식으로 나타내면 아래와 같습니다.</p><img width="257" alt="최종 수식" src="https://user-images.githubusercontent.com/111936229/217702534-b160c646-29f8-4103-8abf-b45e42e8c068.png"><p>정리를 해보면 CNN을 통과하여 추출된 벡터와 x, y, w, h를 조정하는 함수의 웨이트를 곱해서</p><p>바운딩 박스를 조정해주는 선형 회귀를 학습시키는 것입니다.</p>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Paper/">Paper</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/paper/">paper</category>
      
      <category domain="http://InhwanCho.github.io/tags/review/">review</category>
      
      <category domain="http://InhwanCho.github.io/tags/rcnn/">rcnn</category>
      
      
      <comments>http://inhwancho.github.io/2023/02/09/Paper_Review/2023-02-09-RCNN/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>VScode에서 유용한 정보</title>
      <link>http://inhwancho.github.io/2023/01/31/Mac_Fundamental_Concept/2023-01-31-vscode/</link>
      <guid>http://inhwancho.github.io/2023/01/31/Mac_Fundamental_Concept/2023-01-31-vscode/</guid>
      <pubDate>Mon, 30 Jan 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="여러-단어를-다중-선택할-경우"><a href="#여러-단어를-다중-선택할-경우" class="headerlink" title="여러 단어를 다중 선택할 경우"></a>여러 단어를 다중 선택할 경우</h2><p><code>command(윈도우는 control) + shift + L</code> 은 선택된 단어와 동일한 단어를 <code>모두</code> 선택하는 단축키</p><p><code>command(윈도우는 control) + d</code> 은 선택된 단어와 동일한 단어를 <code>1개씩</code> 추가하는 단축키</p><h2 id="인터프리터로-실행-시-경로-설정하기"><a href="#인터프리터로-실행-시-경로-설정하기" class="headerlink" title="인터프리터로 실행 시 경로 설정하기"></a>인터프리터로 실행 시 경로 설정하기</h2><ul><li>인터프리터 환경(터미널환경)에서 실행 시 주피터의 실행 경로와 다를 수 있기 때문에 경로를 수정해줘야 오류가 안나온다.<ul><li>VScode에서 경로를 확인, 수정하는 방법은 다음과 같다.</li><li>먼저, 주피터 노트북에서도 아래의 명령어를 입력하고 실행을 한다.</li><li>그 다음 py 파일에에도 같은 입력을 하고 저장 &amp; 실행을 한다.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sys.executable)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 출력 결과</span></span><br><span class="line"><span class="comment"># &#x27;/opt/anaconda3/bin/python&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>VScode의 경우는 <ul><li>(보기 -&gt; <code>명령 팔레트</code>)를 열고 (Shift + command + P) <code>Python: Select Interpreter</code>을 검색 &amp; 누른다.</li><li>제 경우는 <code>/opt/anaconda3/bin/python</code> 앞의 출력 결과(주피터)에 동일한 결과를 선택한다.</li><li>실행해서 잘 되는지 확인한다.</li></ul></li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/VScode/">VScode</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/vscode/">vscode</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EB%8B%A8%EC%B6%95%ED%82%A4/">단축키</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EA%B2%BD%EB%A1%9C/">경로</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EC%97%AC%EB%9F%AC/">여러</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EB%8B%A8%EC%96%B4/">단어</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EC%84%A0%ED%83%9D/">선택</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EB%8B%A4%EC%A4%91/">다중</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/31/Mac_Fundamental_Concept/2023-01-31-vscode/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Mac에서 ls -al에서의 의미</title>
      <link>http://inhwancho.github.io/2023/01/29/Mac_Fundamental_Concept/2023-01-29-mac/</link>
      <guid>http://inhwancho.github.io/2023/01/29/Mac_Fundamental_Concept/2023-01-29-mac/</guid>
      <pubDate>Sat, 28 Jan 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">❯ ls -la</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">648개의 파일(폴더 포함)이 있다는 의미</span></span><br><span class="line">total 648</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">현재 명령어를 실행한 폴더가 있다는 의미(무조건 나옴)</span></span><br><span class="line">drwxr-xr-x  18 inhwan  staff     576  1 24 12:18 .</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">현재 명령어를 실행한 폴더의 상위 폴더가 있다는 의미(무조건 나옴)</span></span><br><span class="line">drwxr-xr-x   4 inhwan  staff     128  1 23 21:23 ..</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-rw-r--r--@  1 inhwan  staff    6148  1 25 09:40 .DS_Store</span><br><span class="line">drwxr-xr-x   3 inhwan  staff      96  1 23 20:59 .ipynb_checkpoints</span><br><span class="line">-rw-r--r--   1 inhwan  staff    3321  1 23 19:26 README.md</span><br><span class="line">drwxr-xr-x   8 inhwan  staff     256  1 23 19:31 __pycache__</span><br></pre></td></tr></table></figure><p>맨 앞의 <code>drwxr-xr-x</code>이런 문자열들은 권한을 의미<br>그 다음의 <code>inhwan</code>은 파일(폴더 포함)의 소유자가 누군지<br>그 뒤 <code>staff</code>는 소유자의 그룹이 어디인지를 의미<br>그 다음의 <code>576</code> 등의 큰 숫자는 파일의 크기를 의미</p><h2 id="리다이렉션-Redirection"><a href="#리다이렉션-Redirection" class="headerlink" title="리다이렉션(Redirection)"></a>리다이렉션(Redirection)</h2><p><code>&gt;</code> 와 <code>&lt;</code> 의 기호로 표현되며 입-출력 위치를 변경해줍니다.</p><p>예를 들어 ls -la를 하면 기본적으로 터미널에 출력이 되지만, ls -la &gt; test_file.txt 로 입력을 하면<br>test_file.txt라는 파일이 생성되며 출력 결과가 test_file.txt에 생성됩니다.</p><p><code>&gt;&gt;</code>를 사용하게 된다면 ls -la &gt;&gt; test_file.txt의 경우<br>기존의 test_file.txt 내용에 추가적으로 ls -la의 내용이 생성됩니다.(덮어씌우기가 아닌 추가)</p><h2 id="파이프-Pipe"><a href="#파이프-Pipe" class="headerlink" title="파이프(Pipe)"></a>파이프(Pipe)</h2><p><code>|</code> 기호로 표현되며 출력되는 위치를 다른 명령어로 넘어가게 해주는 표현</p><p>예를 들어 ls -la를 입력하면 너무 많은 정보가 나오게 되는데<br>특정 단어 <code>data</code>라는 게 들어있는 값만 찾으려 한다면 다음과 같이 사용하면 됩니다</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ls -la | grep data</span><br><span class="line"></span><br><span class="line"># 출력 결과</span><br><span class="line">-rw-r--r--   1 inhwan  staff    2248  1 23 19:26 data_loaders.py</span><br><span class="line">drwxr-xr-x   8 inhwan  staff     256  1 23 19:31 dataset</span><br></pre></td></tr></table></figure><h2 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h2><p><code>chmod</code>를 활용하여 권한을 수정 할 수 있습니다.</p><p><code>chmod -option 777 file_name</code>을 입력하면 file_name에 대해 모든 권한을 전부 준다는 의미입니다.</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1은 실행 권한, 2는 쓰기 권한, 4는 읽기 권한을 나타냅니다</span><br><span class="line"></span><br><span class="line">r: 읽기 권한, w: 쓰기 권한 x: 실행 권한 이라 부른다.</span><br><span class="line"></span><br><span class="line">chmode 777 file_name을 입력하면 user, group, other에게 모든 권한을 전부 준다는 의미</span><br><span class="line">따라서, user권한(1+2+4) group권한(1+2+4) other권한(1+2+4)</span><br><span class="line">1(읽기 가능) + 2(쓰기 가능) + 4(실행 가능) == 7</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Mac/">Mac</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/mac/">mac</category>
      
      <category domain="http://InhwanCho.github.io/tags/setting/">setting</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/29/Mac_Fundamental_Concept/2023-01-29-mac/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>파이썬에서 기호 *과 **의 의미</title>
      <link>http://inhwancho.github.io/2023/01/28/Study_folder/Basic_study/2023-01-28-def/</link>
      <guid>http://inhwancho.github.io/2023/01/28/Study_folder/Basic_study/2023-01-28-def/</guid>
      <pubDate>Fri, 27 Jan 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="Python에서-기호의-의미"><a href="#Python에서-기호의-의미" class="headerlink" title="Python에서 기호의 의미"></a>Python에서 기호의 의미</h2><h3 id="파이썬에서-은-일반적으로-모든-것을-의미합니다"><a href="#파이썬에서-은-일반적으로-모든-것을-의미합니다" class="headerlink" title="파이썬에서 *은 일반적으로 모든 것을 의미합니다"></a>파이썬에서 <code>*</code>은 일반적으로 <code>모든 것</code>을 의미합니다</h3><p><code>from math import *</code> 이런 식으로 사용 가능하나, 권장하지는 않습니다.</p><h3 id="가변인자로서의-args-kwargs"><a href="#가변인자로서의-args-kwargs" class="headerlink" title="가변인자로서의 *args **kwargs"></a>가변인자로서의 *args **kwargs</h3><ul><li>*args(arguments) : list of arguments - as positional arguments</li><li>**kwargs(keyword arguments) : dictionary -<br>whose keys become separate keyword arguments and the values become values of these arguments.</li></ul><blockquote><p><code>*</code>은 list 또는 tuple <code>**</code>은 dictionary<br><code>*</code>, <code>**</code> 모두 함수에 다수의 매개 변수를 허용하기 위해 사용하며<br>인자의 개수에 제한을 두고 싶지 않을 경우 사용합니다.</p></blockquote><p>만약 딕셔너리를 인자로 넣는 함수를 생성한다면 아래와 같은 방법으로 사용합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dic_sample</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    <span class="built_in">print</span>(kwargs)</span><br><span class="line"></span><br><span class="line">dic_sample(math=<span class="number">90</span>, english=<span class="number">70</span>, korean=<span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 출력 결과</span></span><br><span class="line">&#123;<span class="string">&#x27;math&#x27;</span>: <span class="number">90</span>, <span class="string">&#x27;english&#x27;</span>: <span class="number">70</span>, <span class="string">&#x27;korean&#x27;</span>: <span class="number">80</span>&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Python/">Python</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/python/">python</category>
      
      <category domain="http://InhwanCho.github.io/tags/star/">star</category>
      
      <category domain="http://InhwanCho.github.io/tags/def/">def</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EB%B3%84/">별</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EB%B3%84%EB%B3%84/">별별</category>
      
      <category domain="http://InhwanCho.github.io/tags/args/">args</category>
      
      <category domain="http://InhwanCho.github.io/tags/kwargs/">kwargs</category>
      
      <category domain="http://InhwanCho.github.io/tags/arguments/">arguments</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/28/Study_folder/Basic_study/2023-01-28-def/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>if __name__ == &quot;__main__&quot;의 의미</title>
      <link>http://inhwancho.github.io/2023/01/27/Study_folder/Basic_study/2023-01-27-main/</link>
      <guid>http://inhwancho.github.io/2023/01/27/Study_folder/Basic_study/2023-01-27-main/</guid>
      <pubDate>Thu, 26 Jan 2023 15:00:00 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="name-x3D-x3D-“main“의-의미"><a href="#name-x3D-x3D-“main“의-의미" class="headerlink" title="name &#x3D;&#x3D; “main“의 의미"></a><strong>name</strong> &#x3D;&#x3D; “<strong>main</strong>“의 의미</h2><p><code>결론</code>부터 말하면 모듈을 import 하지 않고 <code>직접 실행</code>을 하냐의 의미입니다.<br>메인 실행 파일에서 <code>__name__</code>을 실행하면 <code>__main__</code>이 출력됩니다<br>예시 코드를 보며 설명드리겠습니다.</p><ul><li><code>firt.py</code>파일과 <code>second.py</code>파일이 있고 각각의 실행 결과입니다.</li></ul><figure class="highlight stylus"><figcaption><span>first.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(__name__)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(f<span class="string">&#x27;First module name : &#123;__name__&#125;&#x27;</span>)</span></span></span><br><span class="line"></span><br><span class="line">---------- 출력 결과 ----------</span><br><span class="line">__main__</span><br><span class="line">First module name : __main__</span><br></pre></td></tr></table></figure><ul><li>first.py를 import 하고 결과를 비교합니다.</li></ul><figure class="highlight fortran"><figcaption><span>second.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> first_test</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&#x27;Second module name : &#123;__name__&#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">---------- 출력 결과 ----------</span><br><span class="line">first_test</span><br><span class="line">First <span class="keyword">module</span> <span class="keyword">name</span> : first_test</span><br><span class="line">Second <span class="keyword">module</span> <span class="keyword">name</span> : __main__</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Python/">Python</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/python/">python</category>
      
      <category domain="http://InhwanCho.github.io/tags/name/">name</category>
      
      <category domain="http://InhwanCho.github.io/tags/main/">main</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EC%9D%B8%ED%84%B0%ED%94%84%EB%A6%AC%ED%84%B0/">인터프리터</category>
      
      <category domain="http://InhwanCho.github.io/tags/if/">if</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/27/Study_folder/Basic_study/2023-01-27-main/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>탄소 중립을 위한 기후 기술 정보 시각화(프로젝트)</title>
      <link>http://inhwancho.github.io/2023/01/23/Portfolio/2023-01-23-visual-project/</link>
      <guid>http://inhwancho.github.io/2023/01/23/Portfolio/2023-01-23-visual-project/</guid>
      <pubDate>Mon, 23 Jan 2023 01:35:35 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="서론"><a href="#서론" class="headerlink" title="서론"></a>서론</h2><p><code>발표자 : 조인환</code></p><blockquote><p>탄소 중립이란? 인간의 활동에 의한 온실가스 배출을 최대한 줄이고, 남은 온실가스는 흡수, 제거해서 실질적인 배출량을 0으로 만든다는 개념이다.</p></blockquote><br><p><strong>Intro</strong> : 전 세계는 현재 기후 변화에 대응하기 위해 에너지 사회로의 전환을 목표로 하면서 “기후 기술 개발”을 목표로 하고 있습니다.<br><br></p><blockquote><p>따라서, 기후 변화가 어떻게 진행되가는지를 먼저 살펴보고, 아래의 내용을 확인</p><blockquote><ol><li>세계 평균 기온 증감량(°C)<br></li><li>전세계 국가별 탄소배출량<br> </li><li>연도별 탄소배출량</li></ol></blockquote></blockquote><p><strong>Main</strong> : 글로벌 기후 기술 수요와 국내 보유 기술의 매칭 전략 리포트<br><br></p><blockquote><p>국가에서 분류한 기후 기술 분류 체계를 웹크롤링을 이용하여 분석</p><blockquote><ol><li>전세계 국가들이 어떤 기후 기술을 수요하는지<br></li><li>연구비&amp; 연구원, 종사자수 비교 그래프<br></li><li>매출액, 수출액 비교 그래프 <br></li><li>총 매출액 대비 수익 그래프</li></ol></blockquote></blockquote><p><strong>Current Trend in this field</strong> : 기후 기술과 관련하여 어떠한 트랜드로 가고있는지 살펴보기<br><br></p><blockquote><p>기후 기술과 관련된 카테고리의 뉴스 기사를 웹크롤링을 이용하여 분석</p><blockquote><ol><li>뉴스 제목에 가장 많이 언급된 단어들을 추출<br></li><li>그 단어들이 모두 들어간 기사를 검색, 추출<br></li><li>워드 클라우드로 살펴보기<br></li></ol></blockquote></blockquote><p><strong>Conclusion</strong></p><br><h2 id="본론"><a href="#본론" class="headerlink" title="본론"></a>본론</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter <span class="comment"># 개수 세는 함수</span></span><br><span class="line"><span class="keyword">import</span> plotly</span><br><span class="line"><span class="keyword">import</span> plotly.figure_factory <span class="keyword">as</span> ff <span class="comment"># 표 그리는 함수</span></span><br><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go <span class="comment"># 표 그리는 함수</span></span><br><span class="line"><span class="keyword">from</span> plotly <span class="keyword">import</span> express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud </span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO <span class="comment">#이미지 읽는 함수</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#url의 소스 따오는 함수</span></span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd <span class="comment">#지도 그리는 함수</span></span><br><span class="line"><span class="keyword">import</span> chart_studio </span><br><span class="line"><span class="keyword">import</span> chart_studio.plotly <span class="keyword">as</span> py <span class="comment">#plotly파일을 주피터 노트북 이외의 환경에서 열 수 있게 만드는 모듈</span></span><br><span class="line"><span class="keyword">import</span> chart_studio.tools <span class="keyword">as</span> tls</span><br><span class="line"><span class="keyword">import</span> folium</span><br><span class="line"><span class="keyword">from</span> folium.plugins <span class="keyword">import</span> MarkerCluster <span class="comment">#지도</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> rc</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> ConnectionPatch</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> os <span class="comment">#이미지 따오는 함수</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image <span class="comment">#이미지 삽입하는 함수</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML <span class="comment">#주피터 노트북 화면 확장해주는 함수</span></span><br><span class="line">warnings.filterwarnings(action=<span class="string">'ignore'</span>) <span class="comment"># 경고(엑셀 불러오기 시 스타일 없다는 문구) 제거</span></span><br><span class="line">display(HTML(<span class="string">"&lt;style&gt;.container { width:90% !important; }&lt;/style&gt;"</span>))  <span class="comment"># 주피터 노트북 화면 늘리기</span></span><br><span class="line"><span class="keyword">from</span> plotly.offline <span class="keyword">import</span> init_notebook_mode, iplot</span><br><span class="line">init_notebook_mode(connected=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">df10 = pd.read_csv(<span class="string">'../../Downloads/modeul/temperature-anomaly.csv'</span>)</span><br><span class="line">filt = df10[<span class="string">'Entity'</span>] == <span class="string">'Global'</span></span><br><span class="line">df10 = df10.loc[filt]</span><br><span class="line">x = df10[<span class="string">'Year'</span>]</span><br><span class="line">y = df10[<span class="string">'Median temperature anomaly from 1961-1990 average'</span>]</span><br><span class="line">y_upper = df10[<span class="string">'Upper bound (95% CI)'</span>]</span><br><span class="line">y_lower = df10[<span class="string">'Lower bound (95% CI)'</span>]</span><br><span class="line">y_zeros = [z <span class="keyword">for</span> z <span class="keyword">in</span> np.zeros(<span class="built_in">len</span>(x))]</span><br><span class="line"></span><br><span class="line">fig = go.Figure([</span><br><span class="line">    go.Scatter(</span><br><span class="line">        x=x,</span><br><span class="line">        y=y,</span><br><span class="line">        line=<span class="built_in">dict</span>(color=<span class="string">'rgb(0,100,80)'</span>),</span><br><span class="line">        mode=<span class="string">'lines'</span>,text =<span class="string">'평균 기온 증감'</span>,name = <span class="string">'전세계 평균 기온 증감 °C'</span></span><br><span class="line">    ),</span><br><span class="line">    go.Scatter(</span><br><span class="line">        name=<span class="string">'Upper bound (95% CI)'</span>,</span><br><span class="line">        x=x,</span><br><span class="line">        y=y_upper,</span><br><span class="line">        mode=<span class="string">'lines'</span>,</span><br><span class="line">        marker=<span class="built_in">dict</span>(color=<span class="string">'#444'</span>),</span><br><span class="line">        line=<span class="built_in">dict</span>(width=<span class="number">0</span>),</span><br><span class="line">        showlegend=<span class="literal">False</span></span><br><span class="line">    ),</span><br><span class="line">    go.Scatter(</span><br><span class="line">        name=<span class="string">'Lower bound (95% CI)'</span>,</span><br><span class="line">        x=x,</span><br><span class="line">        y=y_lower,</span><br><span class="line">        marker=<span class="built_in">dict</span>(color=<span class="string">'#444'</span>),</span><br><span class="line">        line=<span class="built_in">dict</span>(width=<span class="number">0</span>),</span><br><span class="line">        mode=<span class="string">'lines'</span>,</span><br><span class="line">        fillcolor=<span class="string">'rgba(68, 68, 68, 0.3)'</span>,</span><br><span class="line">        fill=<span class="string">'tonexty'</span>,</span><br><span class="line">        showlegend=<span class="literal">False</span>),</span><br><span class="line">    go.Scatter(x = x, y = y_zeros, </span><br><span class="line">               mode=<span class="string">'lines'</span>, name = <span class="string">'0 Line'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">fig.update_layout(</span><br><span class="line">    xaxis_title=<span class="string">'Year'</span>,</span><br><span class="line">    yaxis_title=<span class="string">'Median temperature'</span>,</span><br><span class="line">    title=<span class="string">'세계 평균 기온 증감 °C'</span>,</span><br><span class="line">    hovermode=<span class="string">'x'</span></span><br><span class="line">)</span><br><span class="line">fig.show()</span><br><span class="line"><span class="comment"># iplot(fig,show_link=False)</span></span><br><span class="line"><span class="comment"># fig.update_yaxes(rangemode='tozero')</span></span><br><span class="line"><span class="comment"># tls.get_embed('https://plotly.com/~InhwanCho/14')</span></span><br><span class="line"><span class="comment"># &lt;iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/14.embed" height="525" width="100%"&gt;&lt;/iframe&gt;</span></span><br></pre></td></tr></table></figure><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/14.embed" height="525" width="100%"></iframe><h3 id="세계-국가별-탄소배출량"><a href="#세계-국가별-탄소배출량" class="headerlink" title="세계 국가별 탄소배출량"></a>세계 국가별 탄소배출량</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">countries = gpd.read_file(gpd.datasets.get_path(<span class="string">'naturalearth_lowres'</span>))</span><br><span class="line"></span><br><span class="line">dd = pd.read_csv(<span class="string">'../../Downloads/modeul/annual-co2-emissions-per-country.csv'</span>)</span><br><span class="line"></span><br><span class="line">countries.rename(columns={<span class="string">'name'</span>:<span class="string">'Entity'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge_outer = pd.merge(df1,df2, how='outer',on='id')</span></span><br><span class="line">d = pd.merge(dd,countries, how=<span class="string">'outer'</span>, on=<span class="string">'Entity'</span>)</span><br><span class="line"></span><br><span class="line">filt = (d[<span class="string">'Year'</span>] ==<span class="number">2020</span>) &amp; (d[<span class="string">'geometry'</span>] != <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">a = d.loc[filt,[<span class="string">'Entity'</span>,<span class="string">'Annual CO2 emissions'</span>,<span class="string">'geometry'</span>]]</span><br><span class="line">a.rename(columns={<span class="string">'Annual CO2 emissions'</span>:<span class="string">'emissions'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">countries = pd.merge(countries,a,on=<span class="string">'Entity'</span>,how=<span class="string">'outer'</span>)</span><br><span class="line"></span><br><span class="line">countries = countries.drop(columns=<span class="string">'geometry_y'</span>)</span><br><span class="line"></span><br><span class="line">countries.rename(columns={<span class="string">'geometry_x'</span> : <span class="string">'geometry'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">filt = countries[<span class="string">'emissions'</span>] &gt; countries[<span class="string">'emissions'</span>].quantile(<span class="number">0.6</span>)</span><br><span class="line">countries_filt = countries.loc[filt,[<span class="string">'continent'</span>,<span class="string">'Entity'</span>,<span class="string">'iso_a3'</span>,<span class="string">'emissions'</span>,<span class="string">'geometry'</span>]]</span><br><span class="line"></span><br><span class="line">ax = countries_filt.plot(column=<span class="string">'emissions'</span>, legend=<span class="literal">True</span>,figsize=(<span class="number">13</span>,<span class="number">6</span>),cmap=<span class="string">"tab20b"</span>)</span><br><span class="line">ax.set_axis_off()</span><br><span class="line">ax.set_title(<span class="string">"World Carbon Emissions"</span>)</span><br><span class="line">ax.plot() </span><br><span class="line"><span class="comment">### 중국이 너무 탄소배출량 자체가 압도적 -&gt; 국가 인구별 탄소배출량 시각화 필요</span></span><br></pre></td></tr></table></figure><img width="688" alt="geopandas 시각화 결과" src="https://user-images.githubusercontent.com/111936229/213953007-fa68db61-a141-4dfb-a8cf-817a52dac7e8.png"><h3 id="연간-탄소-배출량을-StackPlot으로-시각화"><a href="#연간-탄소-배출량을-StackPlot으로-시각화" class="headerlink" title="연간 탄소 배출량을 StackPlot으로 시각화"></a>연간 탄소 배출량을 StackPlot으로 시각화</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">df6 = pd.read_csv(<span class="string">'../../Downloads/modeul/annual-co-emissions-by-region.csv'</span>)</span><br><span class="line"><span class="comment">#stack할 국가들을 나누는 작업</span></span><br><span class="line">year = np.unique(df6[<span class="string">'Year'</span>].values)</span><br><span class="line">chi = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"China"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line">usa = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"United States"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line">afr = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"Africa"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line">ind = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"India"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line">south_a = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"South America"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line">eu = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"Europe (excl. EU-27)"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line">ocea = (df6[df6[<span class="string">'Entity'</span>]==<span class="string">"Oceania"</span>][<span class="string">'Annual CO2 emissions (zero filled)'</span>])</span><br><span class="line"><span class="comment"># chi, usa, afr, ind, south_a, eu27, ocea</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">palette = sns.color_palette(<span class="string">"Spectral"</span>, <span class="number">7</span>).as_hex()</span><br><span class="line">colors = <span class="string">','</span>.join(palette)</span><br><span class="line">labels = [<span class="string">"China"</span>, <span class="string">"USA"</span>, <span class="string">"Africa"</span>, <span class="string">"India"</span>, <span class="string">"South_Africa"</span>, <span class="string">"Europe"</span>, <span class="string">"Oceania"</span>]</span><br><span class="line">plt.stackplot(year, chi, usa, afr, ind, south_a, eu, ocea, labels=labels, colors=colors)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>, bbox_to_anchor=(<span class="number">1.1</span>, <span class="number">0.8</span>), shadow=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">'Annual CO2 emissions'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img width="660" alt="연간 탄소 배출량 Stack plot" src="https://user-images.githubusercontent.com/111936229/213953134-9522113c-44fb-497b-9bd9-566ab1c7e822.png"><h3 id="세계-국가-인구별-탄소-배출량-도식화"><a href="#세계-국가-인구별-탄소-배출량-도식화" class="headerlink" title="세계 국가 인구별 탄소 배출량 도식화"></a>세계 국가 인구별 탄소 배출량 도식화</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">df7 = pd.read_csv(<span class="string">'../../Downloads/modeul/co-emissions-per-capita.csv'</span>)</span><br><span class="line">filt = df7[<span class="string">'Year'</span>] == <span class="number">2020</span></span><br><span class="line">df7 = df7.loc[filt,[<span class="string">'Entity'</span>,<span class="string">'Annual CO2 emissions (per capita)'</span>]]</span><br><span class="line"></span><br><span class="line">url_geo = <span class="string">'https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json'</span></span><br><span class="line"><span class="comment"># geo.json파일 보단 url을 선호해서 url스타일로 해봤습니다</span></span><br><span class="line">world_map = folium.Map(location = [<span class="number">37.63772494531694</span>, <span class="number">24.785517601541628</span>], zoom_start = <span class="number">2</span>,</span><br><span class="line">               max_bounds = <span class="literal">True</span>, </span><br><span class="line">               min_zoom = <span class="number">2</span>, min_lat = -<span class="number">84</span>, </span><br><span class="line">               max_lat = <span class="number">84</span>, min_lon = -<span class="number">175</span>, max_lon = <span class="number">187</span>)  <span class="comment">#뼈대맵 작성</span></span><br><span class="line">cp = folium.Choropleth(  <span class="comment"># 농도별 색상으로 나타냄</span></span><br><span class="line">    geo_data=url_geo,</span><br><span class="line">    data = df7, columns = [<span class="string">'Entity'</span>,<span class="string">'Annual CO2 emissions (per capita)'</span>], key_on = <span class="string">'properties.name'</span>,</span><br><span class="line">    name=<span class="string">"choropleth"</span>,</span><br><span class="line">    fill_color=<span class="string">"RdYlGn"</span>,</span><br><span class="line">    fill_opacity=<span class="number">0.7</span>,</span><br><span class="line">    line_opacity=<span class="number">0.5</span>,</span><br><span class="line">    highlight=<span class="literal">True</span>,</span><br><span class="line">    legend_name=<span class="string">"Annual CO2 emissions (per capita)"</span>,</span><br><span class="line">    ).add_to(world_map)</span><br><span class="line"></span><br><span class="line">cp.geojson.data[<span class="string">'features'</span>][-<span class="number">10</span>][<span class="string">'properties'</span>][<span class="string">'name'</span>] = <span class="string">'United States'</span> <span class="comment"># 미국이름이 독특하게 등록되어있어 변경</span></span><br><span class="line">df7_a = df7.set_index(<span class="string">'Entity'</span>) <span class="comment"># index를 국가명으로 하여 코드 간결화</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> cp.geojson.data[<span class="string">'features'</span>]:   <span class="comment"># geo.json파일이 url이라 str취급되어 geojson파일의 data형식으로 변경</span></span><br><span class="line">    <span class="keyword">try</span>:  <span class="comment">#나라 이름에 해당 안되는 경우 KeyError가 발생하여 국가명만 추출</span></span><br><span class="line">        i[<span class="string">'properties'</span>][<span class="string">'Annual CO2 emissions (per capita)'</span>] = df7_a.loc[i[<span class="string">'properties'</span>][<span class="string">'name'</span>],<span class="string">'Annual CO2 emissions (per capita)'</span>] </span><br><span class="line">        <span class="comment"># geojson파일에 keys, values 추가</span></span><br><span class="line">    <span class="keyword">except</span> KeyError:  </span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">folium.GeoJsonTooltip([<span class="string">'name'</span>,<span class="string">'Annual CO2 emissions (per capita)'</span>]).add_to(cp.geojson) <span class="comment"># choropleth(색상그림에 툴팁 추가)</span></span><br><span class="line"></span><br><span class="line">folium.LayerControl().add_to(world_map)</span><br><span class="line">world_map.save(<span class="string">"세계 국가 인구별 탄소 배출량 도식화.html"</span>)</span><br><span class="line">world_map</span><br></pre></td></tr></table></figure><img width="1908" alt="탄소 배출 인구별 세계지도(folium)" src="https://user-images.githubusercontent.com/111936229/213953352-d90cac80-ddd4-47c3-a46b-68a7bd0f50c9.png"><h3 id="1인당-GDP가-높은-국가와-탄소-배출량의-상관-분석"><a href="#1인당-GDP가-높은-국가와-탄소-배출량의-상관-분석" class="headerlink" title="1인당 GDP가 높은 국가와 탄소 배출량의 상관 분석"></a>1인당 GDP가 높은 국가와 탄소 배출량의 상관 분석</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">df8 = pd.read_csv(<span class="string">'../../Downloads/modeul/co2-emissions-and-gdp-per-capita.csv'</span>)</span><br><span class="line"></span><br><span class="line">df8= df8.loc[df8[<span class="string">'Year'</span>]==<span class="number">2020</span>]</span><br><span class="line"></span><br><span class="line">df8.drop(columns=<span class="string">'Annual consumption-based CO2 emissions (per capita)'</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">sns.regplot(data = df8, x=<span class="string">'GDP per capita, PPP (constant 2017 international $)'</span>,y = <span class="string">'Annual CO2 emissions (per capita)'</span>)</span><br><span class="line">df8.corrwith(df8[<span class="string">'Annual CO2 emissions (per capita)'</span>])</span><br><span class="line"><span class="comment"># 상관계수 = + 0.616106 으로 높은 편이다. </span></span><br><span class="line"><span class="comment"># -&gt; 잘 사는 국가가 높은 탄소 배출량을 보여주는 경향이 있다.</span></span><br></pre></td></tr></table></figure><img width="858" alt="상관 관계 분석" src="https://user-images.githubusercontent.com/111936229/213953469-56675607-4a94-4fc4-9e59-2769ed51a865.png"><blockquote><p>상관계수 =&gt; 0.616106 으로 높은 편이다. </p><blockquote><p>잘 사는 국가가 높은 탄소 배출량을 보여주는 경향이 있다. <br><br>중국이 세계 탄소배출량의 절반을 차지하고있다. <br><br>탄소 배출량을 줄여야 한다.(기후 기술이 필요함)</p></blockquote></blockquote><h3 id="기후-기술-분류-체계를-대분류-중분류-소분류로-분류-웹크롤링"><a href="#기후-기술-분류-체계를-대분류-중분류-소분류로-분류-웹크롤링" class="headerlink" title="기후 기술 분류 체계를 (대분류 - 중분류 - 소분류로 분류) - 웹크롤링"></a>기후 기술 분류 체계를 (대분류 - 중분류 - 소분류로 분류) - 웹크롤링</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 대분류 - 중분류 - 소분류로 표 분류작업 &gt; urlopen으로 분류</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.ctis.re.kr/ko/techClass/classification.do?key=1141'</span></span><br><span class="line"></span><br><span class="line">html = urlopen(url)</span><br><span class="line">soup = BeautifulSoup(html,<span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line">column1 = ([<span class="string">'감축'</span>]*<span class="number">22</span>) + ([<span class="string">'적응'</span>]*<span class="number">18</span>) + ([<span class="string">'융복합'</span>]*<span class="number">5</span>) <span class="comment">#대분류 열 생성</span></span><br><span class="line"></span><br><span class="line">info1 = soup.select(<span class="string">'#table_box &gt; table &gt; tbody &gt; tr &gt; td'</span>) <span class="comment">#중분류 html파일</span></span><br><span class="line">middle_sort = [] <span class="comment">#중분류</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(info1)):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'('</span> <span class="keyword">in</span> info1[i].text:</span><br><span class="line">        middle_sort.append(re.findall(<span class="string">'\(..?\) ?[가-힣]+'</span>,info1[i].text))</span><br><span class="line"></span><br><span class="line">indexnum = [<span class="number">3</span>,<span class="number">8</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>] <span class="comment">#중분류 개수 분할</span></span><br><span class="line">a = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(indexnum)):</span><br><span class="line">    a.append(middle_sort[i] * indexnum[i])</span><br><span class="line"></span><br><span class="line">middle_sort = <span class="built_in">sum</span>(a, []) <span class="comment">#2차원리스트 -&gt; 1차원리스트로 바꿔서 데이터 프레임형식으로 바꿈</span></span><br><span class="line">df_md = pd.DataFrame(middle_sort)</span><br><span class="line"></span><br><span class="line">info = soup.select(<span class="string">'td.bgw'</span>) <span class="comment">#소분류 html파일</span></span><br><span class="line">reduction = [] <span class="comment">#1~22 까지 '감축'으로 분류</span></span><br><span class="line">adaptation = [] <span class="comment">#23~40 까지 '적응'으로 분류</span></span><br><span class="line">convergence = [] <span class="comment">#41~45 까지 '융복합'으로 분류</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(info)): </span><br><span class="line">    <span class="keyword">if</span> i&lt;<span class="number">22</span>:</span><br><span class="line">        reduction.append(info[i].text.lstrip())</span><br><span class="line">    <span class="keyword">elif</span> i&gt;<span class="number">21</span> <span class="keyword">and</span> i &lt;<span class="number">40</span>:</span><br><span class="line">        adaptation.append(info[i].text.lstrip())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        convergence.append(info[i].text.lstrip())</span><br><span class="line"></span><br><span class="line">df1 = pd.concat([pd.DataFrame(reduction),pd.DataFrame(adaptation),pd.DataFrame(convergence)])  <span class="comment"># 소분류 합치기</span></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(column1,columns=[<span class="string">'대분류'</span>]) <span class="comment">#대분류 데이터프레임 만들기</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'중분류'</span>] =df_md <span class="comment">#대분류에 중분류 합치기</span></span><br><span class="line"></span><br><span class="line">df1 = df1.reset_index()</span><br><span class="line"></span><br><span class="line">df[<span class="string">'소분류'</span>] = df1[<span class="number">0</span>] <span class="comment">#대분류,중분류에 소분류까지 추가하기</span></span><br><span class="line"></span><br><span class="line">df = df.reindex([<span class="string">'대분류'</span>, <span class="string">'중분류'</span>, <span class="string">'소분류'</span>], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">df.rename(columns={<span class="number">0</span>:<span class="string">'대분류'</span>},inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="기후-기술-수요량-웹크롤링"><a href="#기후-기술-수요량-웹크롤링" class="headerlink" title="기후 기술 수요량 웹크롤링"></a>기후 기술 수요량 웹크롤링</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">'https://www.ctis.re.kr/ko/dmandTchnlgy/dmandTchnlgyList.do?key=1543#{%22tchnlgyNm%22:%22%22,%22sclasSn%22:%22%22,%22keyword%22:%22[]%22,%22lang%22:%22ko%22,%22sortOrder%22:%22desc%22,%22total%22:%22%22,%22ltN2Cd%22:%22%22,%22infoPrvd%22:%22%22,%22size%22:%2250%22,%22hasParam%22:true}'</span></span><br><span class="line"></span><br><span class="line">driver = webdriver.Chrome(<span class="string">'../../Downloads/chromedriver'</span>) </span><br><span class="line"></span><br><span class="line">driver.get(url)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">total = []</span><br><span class="line">click_list = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">7</span>] <span class="comment">#페이지 클릭 순서 리스트</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>): <span class="comment">#의미없는 숫자 -&gt; except나올때까지 웹크롤링</span></span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">4</span>) | (i == <span class="number">10</span>) | (i == <span class="number">16</span>) : <span class="comment">#다음페이지(' &gt; ') 버튼</span></span><br><span class="line">            click = driver.find_elements(By.XPATH,<span class="string">'//*[@id="m_content"]/div[9]/div/div[2]/div[2]/div/span['</span> + <span class="built_in">str</span>(click_list[i]) + <span class="string">']/a'</span>)</span><br><span class="line">            click[<span class="number">0</span>].click()</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            html = driver.page_source</span><br><span class="line">            soup = BeautifulSoup(html,<span class="string">'html.parser'</span>)</span><br><span class="line">            a = soup.select(<span class="string">'#_grid td.jsgrid-cell.jsgrid-align-center'</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line">                <span class="keyword">if</span> j%<span class="number">4</span> == <span class="number">1</span> : <span class="comment">#1,5,9 ...</span></span><br><span class="line">                    total.append(a[j].text)</span><br><span class="line"></span><br><span class="line">            click = driver.find_elements(By.XPATH,<span class="string">'//*[@id="m_content"]/div[9]/div/div[2]/div[2]/div/span['</span> + <span class="built_in">str</span>(click_list[i]) + <span class="string">']/a'</span>)</span><br><span class="line">            click[<span class="number">0</span>].click() <span class="comment">#다음페이지</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'No page'</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'소분류'</span>] = df[<span class="string">'소분류'</span>].<span class="built_in">str</span>[<span class="number">3</span>:] <span class="comment">#소분류의 숫자, 공백, &amp;문자를 제거 등 작업하여 열병합을 위한 양식 통일</span></span><br><span class="line">df[<span class="string">'소분류'</span>] = df[<span class="string">'소분류'</span>].<span class="built_in">str</span>.replace(<span class="string">'&amp;'</span>,<span class="string">'·'</span>)</span><br><span class="line">df[<span class="string">'소분류'</span>] = df[<span class="string">'소분류'</span>].<span class="built_in">str</span>.replace(<span class="string">','</span>,<span class="string">'·'</span>)</span><br><span class="line">df[<span class="string">'소분류'</span>] = df[<span class="string">'소분류'</span>].<span class="built_in">str</span>.replace(<span class="string">' '</span>,<span class="string">''</span>)</span><br><span class="line">df[<span class="string">'소분류'</span>] = df[<span class="string">'소분류'</span>].<span class="built_in">str</span>.replace(<span class="string">'Non-Co2'</span>,<span class="string">'Non-CO2'</span>)</span><br><span class="line"></span><br><span class="line">df_web = pd.DataFrame(total)</span><br><span class="line">df_web_val = pd.DataFrame(df_web.value_counts())</span><br><span class="line">df_web_val.rename(columns={<span class="number">0</span>:<span class="string">'기후 기술 수요량'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line">df_web_val.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line">df_web_val.rename(columns={<span class="number">0</span>:<span class="string">'소분류'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line">df_web_val[<span class="string">'소분류'</span>] = df_web_val[<span class="string">'소분류'</span>].<span class="built_in">str</span>.replace(<span class="string">' '</span>,<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">df = pd.merge(df,df_web_val,on=<span class="string">'소분류'</span>,how=<span class="string">'outer'</span>)</span><br><span class="line"><span class="comment"># df['기후 기술 수요'] = df['기후 기술 수요'].fillna(0)  # outer값으로 NaN인 값을 0으로 변경</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'기후 기술 수요량'</span>] = df[<span class="string">'기후 기술 수요량'</span>].fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">fig =  ff.create_table(df)</span><br><span class="line">fig.layout.width=<span class="number">900</span></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/12.embed" height="525" width="100%"></iframe><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig = px.sunburst(df,</span><br><span class="line">                  path=[<span class="string">'대분류'</span>, <span class="string">'소분류'</span>],</span><br><span class="line">                  values=<span class="string">'기후 기술 수요량'</span>,</span><br><span class="line">                  title=<span class="string">"기후 기술 분류별 수요량"</span>,</span><br><span class="line">                  width=<span class="number">1000</span>, height=<span class="number">750</span>,</span><br><span class="line">                 )</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/10.embed" height="700" width="100%"></iframe><h3 id="기후-기술-데이터-작업-코드"><a href="#기후-기술-데이터-작업-코드" class="headerlink" title="기후 기술 데이터 작업 코드"></a>기후 기술 데이터 작업 코드</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">df1 = pd.read_excel(<span class="string">'../../Downloads/modeul/기후기술_영역별_기관규모별_매출액_20221005135150.xlsx'</span>)</span><br><span class="line">df2 = pd.read_excel(<span class="string">'../../Downloads/modeul/기후기술_영역별_기관규모별_수출액_20221005143231.xlsx'</span>)</span><br><span class="line">df3 = pd.read_excel(<span class="string">'../../Downloads/modeul/기후기술_영역별_기관규모별_연구개발비_20221005143219.xlsx'</span>)</span><br><span class="line">df4 = pd.read_excel(<span class="string">'../../Downloads/modeul/기후기술_영역별_기관규모별_연구원_수_20221005143206.xlsx'</span>)</span><br><span class="line">df5 = pd.read_excel(<span class="string">'../../Downloads/modeul/기후기술_영역별_기관규모별_종사자_수_20221005143100.xlsx'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터프레임 정리</span></span><br><span class="line">filt = df1[<span class="string">'기후기술분류별(2)'</span>].isin([<span class="string">'소계'</span>]) <span class="comment">#소계 들어있는행만 냅두기</span></span><br><span class="line">df1 = df1[filt]</span><br><span class="line">filt1 = df1[<span class="string">'기후기술분류별(1)'</span>].isin([<span class="string">'합계'</span>]) <span class="comment">#첫번째 인덱스(분류인덱스) 제거</span></span><br><span class="line">df1 = df1[~filt1]</span><br><span class="line"></span><br><span class="line">filt = df2[<span class="string">'기후기술분류별(2)'</span>].isin([<span class="string">'소계'</span>]) <span class="comment">#소계 들어있는행 제거 필요</span></span><br><span class="line">df2 = df2[filt]</span><br><span class="line">filt1 = df2[<span class="string">'기후기술분류별(1)'</span>].isin([<span class="string">'합계'</span>]) <span class="comment">#첫번째 인덱스(분류인덱스) 제거</span></span><br><span class="line">df2 = df2[~filt1]</span><br><span class="line"></span><br><span class="line">filt = df3[<span class="string">'기후기술분류별(2)'</span>].isin([<span class="string">'소계'</span>]) <span class="comment">#소계 들어있는행만 냅두기</span></span><br><span class="line">df3 = df3[filt]</span><br><span class="line">filt1 = df3[<span class="string">'기후기술분류별(1)'</span>].isin([<span class="string">'합계'</span>]) <span class="comment">#첫번째 인덱스(분류인덱스) 제거</span></span><br><span class="line">df3 = df3[~filt1]</span><br><span class="line"></span><br><span class="line">filt = df4[<span class="string">'기후기술분류별(2)'</span>].isin([<span class="string">'소계'</span>]) <span class="comment">#소계 들어있는행만 냅두기</span></span><br><span class="line">df4 = df4[filt]</span><br><span class="line">filt1 = df4[<span class="string">'기후기술분류별(1)'</span>].isin([<span class="string">'합계'</span>]) <span class="comment">#첫번째 인덱스(분류인덱스) 제거</span></span><br><span class="line">df4 = df4[~filt1]</span><br><span class="line"></span><br><span class="line">filt = df5[<span class="string">'기후기술분류별(2)'</span>].isin([<span class="string">'소계'</span>]) <span class="comment">#소계 들어있는행만 냅두기</span></span><br><span class="line">df5 = df5[filt]</span><br><span class="line">filt1 = df5[<span class="string">'기후기술분류별(1)'</span>].isin([<span class="string">'합계'</span>]) <span class="comment">#첫번째 인덱스(분류인덱스) 제거</span></span><br><span class="line">df5 = df5[~filt1]</span><br></pre></td></tr></table></figure><h3 id="기후기술-영역별-매출액-수출액-비교-그래프"><a href="#기후기술-영역별-매출액-수출액-비교-그래프" class="headerlink" title="기후기술 영역별 매출액, 수출액 비교 그래프"></a>기후기술 영역별 매출액, 수출액 비교 그래프</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터프레임 정리</span></span><br><span class="line">df1[<span class="string">'2020 수출액'</span>] = df2[<span class="string">'2020'</span>] </span><br><span class="line">df1.rename(columns={<span class="string">'기후기술분류별(1)'</span> : <span class="string">'기후 기술 분류'</span>, <span class="string">'2020'</span> : <span class="string">'2020 국내 매출액'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line">df1 = df1[[<span class="string">'기후 기술 분류'</span>,<span class="string">'2020 국내 매출액'</span>, <span class="string">'2020 수출액'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 생성(표)</span></span><br><span class="line">fig = ff.create_table(df1, height_constant=<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터</span></span><br><span class="line">x_axis = df1[<span class="string">'기후 기술 분류'</span>]</span><br><span class="line">y1_axis = df1[<span class="string">'2020 국내 매출액'</span>]</span><br><span class="line">y2_axis = df1[<span class="string">'2020 수출액'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 바 그래프 생성</span></span><br><span class="line">trace1 = go.Bar(x=x_axis, y=y1_axis, xaxis=<span class="string">'x2'</span>, yaxis=<span class="string">'y2'</span>,</span><br><span class="line">                marker=<span class="built_in">dict</span>(color=<span class="string">'#0099ff'</span>),</span><br><span class="line">                name=<span class="string">'2020 국내 매출액 '</span>)</span><br><span class="line">trace2 = go.Bar(x=x_axis, y=y2_axis, xaxis=<span class="string">'x2'</span>, yaxis=<span class="string">'y2'</span>,</span><br><span class="line">                marker=<span class="built_in">dict</span>(color=<span class="string">'#404040'</span>),</span><br><span class="line">                name=<span class="string">'2020 수출액'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 바 그래프 합치기</span></span><br><span class="line">fig.add_traces([trace1, trace2])</span><br><span class="line">fig[<span class="string">'layout'</span>][<span class="string">'xaxis2'</span>] = {}</span><br><span class="line">fig[<span class="string">'layout'</span>][<span class="string">'yaxis2'</span>] = {}</span><br><span class="line"></span><br><span class="line"><span class="comment"># Edit layout for subplots</span></span><br><span class="line">fig.layout.yaxis.update({<span class="string">'domain'</span>: [<span class="number">0</span>, <span class="number">.45</span>]})</span><br><span class="line">fig.layout.yaxis2.update({<span class="string">'domain'</span>: [<span class="number">.6</span>, <span class="number">1</span>]})</span><br><span class="line"></span><br><span class="line"><span class="comment"># The graph's yaxis2 MUST BE anchored to the graph's xaxis2 and vice versa</span></span><br><span class="line">fig.layout.yaxis2.update({<span class="string">'anchor'</span>: <span class="string">'x2'</span>})</span><br><span class="line">fig.layout.xaxis2.update({<span class="string">'anchor'</span>: <span class="string">'y2'</span>})</span><br><span class="line">fig.layout.yaxis2.update({<span class="string">'title'</span>: <span class="string">'단위 (1백만)'</span>})</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update the margins to add a title and see graph x-labels.</span></span><br><span class="line">fig.layout.margin.update({<span class="string">'t'</span>:<span class="number">75</span>, <span class="string">'l'</span>:<span class="number">50</span>})</span><br><span class="line">fig.layout.update({<span class="string">'title'</span>: <span class="string">'2020년 기후 기술 매출액, 수출액 비교'</span>})</span><br><span class="line"></span><br><span class="line">fig.layout.update({<span class="string">'height'</span>:<span class="number">800</span>})</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot!</span></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/8.embed" height="850" width="100%"></iframe><h3 id="기후기술-영역별-연구비-amp-연구원-종사자수-비교-그래프"><a href="#기후기술-영역별-연구비-amp-연구원-종사자수-비교-그래프" class="headerlink" title="기후기술 영역별 연구비& 연구원, 종사자수 비교 그래프"></a>기후기술 영역별 연구비&amp; 연구원, 종사자수 비교 그래프</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#데이터프레임 정리</span></span><br><span class="line">df3[<span class="string">'연구원_수'</span>] = df4[<span class="string">'2020'</span>]</span><br><span class="line">df3[<span class="string">'종사자_수'</span>] = df5[<span class="string">'2020'</span>]</span><br><span class="line">df3.rename(columns = {<span class="string">'기후기술분류별(1)'</span> : <span class="string">'기후 기술 분류'</span>, <span class="string">'2020'</span> : <span class="string">'연구개발비'</span>},inplace=<span class="literal">True</span>)</span><br><span class="line">df3 = df3[[<span class="string">'기후 기술 분류'</span>, <span class="string">'연구개발비'</span>, <span class="string">'연구원_수'</span>, <span class="string">'종사자_수'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테이블 생성(표)</span></span><br><span class="line">fig = ff.create_table(df3, height_constant=<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add graph data</span></span><br><span class="line">x_axis = df3[<span class="string">'기후 기술 분류'</span>]</span><br><span class="line">y1_axis = df3[<span class="string">'연구원_수'</span>]</span><br><span class="line">y2_axis = df3[<span class="string">'종사자_수'</span>]</span><br><span class="line">y3_axis = (df3[<span class="string">'연구개발비'</span>]/<span class="number">50</span>) <span class="comment"># 스케일이 너무 커서 1/50로 줄임</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 바 그래프 생성</span></span><br><span class="line">trace1 = go.Bar(x=x_axis, y=y1_axis, xaxis=<span class="string">'x2'</span>, yaxis=<span class="string">'y2'</span>,</span><br><span class="line">                marker=<span class="built_in">dict</span>(color=<span class="string">'#0099ff'</span>),</span><br><span class="line">                name=<span class="string">'2020 연구원_수 '</span>)</span><br><span class="line">trace2 = go.Bar(x=x_axis, y=y2_axis, xaxis=<span class="string">'x2'</span>, yaxis=<span class="string">'y2'</span>,</span><br><span class="line">                marker=<span class="built_in">dict</span>(color=<span class="string">'#404040'</span>),</span><br><span class="line">                name=<span class="string">'2020 종사자_수'</span>)</span><br><span class="line">trace3 = go.Line(x=x_axis, y= y3_axis,</span><br><span class="line">                  xaxis=<span class="string">'x2'</span>, yaxis=<span class="string">'y2'</span>, name = <span class="string">'2020 연구개발비 1/50 scale'</span>)</span><br><span class="line">               </span><br><span class="line"><span class="comment"># 데이터 합치기</span></span><br><span class="line">fig.add_traces([trace1, trace2, trace3])</span><br><span class="line">fig[<span class="string">'layout'</span>][<span class="string">'xaxis2'</span>] = {}</span><br><span class="line">fig[<span class="string">'layout'</span>][<span class="string">'yaxis2'</span>] = {}</span><br><span class="line"></span><br><span class="line"><span class="comment"># Edit layout for subplots</span></span><br><span class="line">fig.layout.yaxis.update({<span class="string">'domain'</span>: [<span class="number">0</span>, <span class="number">.45</span>]})</span><br><span class="line">fig.layout.yaxis2.update({<span class="string">'domain'</span>: [<span class="number">.6</span>, <span class="number">1</span>]})</span><br><span class="line"></span><br><span class="line"><span class="comment"># The graph's yaxis2 MUST BE anchored to the graph's xaxis2 and vice versa</span></span><br><span class="line">fig.layout.yaxis2.update({<span class="string">'anchor'</span>: <span class="string">'x2'</span>})</span><br><span class="line">fig.layout.xaxis2.update({<span class="string">'anchor'</span>: <span class="string">'y2'</span>})</span><br><span class="line">fig.layout.yaxis2.update({<span class="string">'title'</span>: <span class="string">'단위 (1k)'</span>})</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update the margins to add a title and see graph x-labels.</span></span><br><span class="line">fig.layout.margin.update({<span class="string">'t'</span>:<span class="number">75</span>, <span class="string">'l'</span>:<span class="number">50</span>})</span><br><span class="line">fig.layout.update({<span class="string">'title'</span>: <span class="string">'2020년 기후 기술 연구비와 연구원, 종사자 수 비교'</span>})</span><br><span class="line">fig.layout.update({<span class="string">'height'</span>:<span class="number">800</span>})</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot!</span></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/4.embed" height="850" width="100%"></iframe><h3 id="기후-기술-분류별-1인당-매출-액"><a href="#기후-기술-분류별-1인당-매출-액" class="headerlink" title="기후 기술 분류별 1인당 매출 액"></a>기후 기술 분류별 1인당 매출 액</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df11 = pd.merge(df1,df3,how=<span class="string">'outer'</span>)</span><br><span class="line">df11[<span class="string">'1인당 매출액'</span>] = (df11[<span class="string">'2020 국내 매출액'</span>] + df11[<span class="string">'2020 수출액'</span>]) / (df11[<span class="string">'연구원_수'</span>] + df11[<span class="string">'종사자_수'</span>])</span><br><span class="line">fig = px.bar(df11,x= <span class="string">'기후 기술 분류'</span>, y = <span class="string">'1인당 매출액'</span>,color=<span class="string">'기후 기술 분류'</span>,title=<span class="string">'기후 기술 분류별 1인당 매출 액'</span>)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~InhwanCho/6.embed" height="525" width="100%"></iframe><blockquote><p>기후 기술 중 감축, 적응의 수요량은 비슷하나 돈은 감축이 훨씬 많이 된다. 적응 기술은 약간 노후화된 기술들로 보인다.</p><blockquote><p>기후 기술 사업은(친환경에너지사업) 돈이 안된다</p></blockquote></blockquote><h3 id="뉴스-자료-웹크롤링-기후-기술-관련-트렌디한-기사-추출"><a href="#뉴스-자료-웹크롤링-기후-기술-관련-트렌디한-기사-추출" class="headerlink" title="뉴스 자료 웹크롤링(기후 기술 관련 트렌디한 기사 추출)"></a>뉴스 자료 웹크롤링(기후 기술 관련 트렌디한 기사 추출)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">click_pat = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]*<span class="number">1000</span> <span class="comment"># 30000건 이상의 뉴스 자료</span></span><br><span class="line">url = <span class="string">'https://www.ctis.re.kr/ko/selectBbsNttList.do?key=1692&amp;bbsNo=312&amp;searchBbsType=&amp;searchCtgry=&amp;searchCnd=ADITFIELD2&amp;searchKrwdType=&amp;chgPage=50'</span></span><br><span class="line">driver.get(url)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">df_news = pd.DataFrame()</span><br><span class="line">df_news[<span class="string">'제목'</span>] = np.nan</span><br><span class="line">df_news[<span class="string">'본문'</span>] = np.nan</span><br><span class="line">df_news[<span class="string">'주소'</span>] = np.nan</span><br><span class="line">word_count = [] </span><br><span class="line">pat = re.<span class="built_in">compile</span>(<span class="string">'국내 정책동향|행사|[가-힣][가-힣]부|위한|개최|산림청|국내|장관|차관|참석|참고자료|분야|선정|계기|위해|억원'</span>) <span class="comment">#필터링 단어</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>): <span class="comment">#최근 1000건의 자료만 수집(다 수집하려면 시간이 너무 오래걸림)</span></span><br><span class="line">        html = driver.page_source</span><br><span class="line">        soup = BeautifulSoup(html,<span class="string">'html.parser'</span>)</span><br><span class="line">        info1 = soup.select(<span class="string">'#m_content &gt; div.jsgrid.scroll &gt; div &gt; table &gt; tbody'</span>)[<span class="number">0</span>].text</span><br><span class="line">        a = re.sub(pat,<span class="string">''</span>,info1)</span><br><span class="line">        word_count.append(re.findall(<span class="string">'[가-힣]+[가-힣]+'</span>,a)) <span class="comment">#뉴스 타이틀에서 글자 추출</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">            scr = soup.select(<span class="string">'tr &gt; td &gt; a'</span>)[j]</span><br><span class="line">            title = soup.select(<span class="string">'tr &gt; td &gt; a'</span>)[j].text.strip()</span><br><span class="line">            title = re.sub(<span class="string">'\s+|NEW'</span>,<span class="string">''</span>,title) <span class="comment">#뉴스 타이틀 추출</span></span><br><span class="line">            href = scr.get(<span class="string">'href'</span>)</span><br><span class="line">            article = requests.get(<span class="string">"https://www.ctis.re.kr/ko"</span> + href[<span class="number">1</span>:]) <span class="comment">#뉴스 본문 추출 requests함수 url</span></span><br><span class="line">            article_html = BeautifulSoup(article.text,<span class="string">"html.parser"</span>) </span><br><span class="line">            article_body = article_html.find(<span class="string">"td"</span>, class_=<span class="string">"bd-content"</span>)</span><br><span class="line">            article_body = article_body.text.strip()</span><br><span class="line">            article_body =  re.sub(<span class="string">'\s+'</span>,<span class="string">''</span>,article_body)</span><br><span class="line">            address = <span class="string">"https://www.ctis.re.kr/ko"</span> + href[<span class="number">1</span>:]</span><br><span class="line">            df_news.loc[i*<span class="number">50</span>+j] = [title, article_body, address]</span><br><span class="line"></span><br><span class="line">        click = driver.find_elements(By.XPATH,<span class="string">'//*[@id="m_content"]/div[3]/div/span['</span>+<span class="built_in">str</span>(click_pat[i])+<span class="string">']/a'</span>)</span><br><span class="line">        click[<span class="number">0</span>].click() <span class="comment">#다음페이지</span></span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'No Page'</span>)</span><br><span class="line">    </span><br><span class="line">word_count_sum = <span class="built_in">sum</span>(word_count, []) <span class="comment"># 2차원 리스트-&gt;1차원 리스트 변경</span></span><br><span class="line">most_common_words = Counter(word_count_sum).most_common(<span class="number">30</span>) <span class="comment"># 뉴스에서 가장 많이 언급된 단어 20개 추출</span></span><br></pre></td></tr></table></figure><h3 id="뉴스-제목에서-가장-많이-언급된-단어-TOP-30"><a href="#뉴스-제목에서-가장-많이-언급된-단어-TOP-30" class="headerlink" title="뉴스 제목에서 가장 많이 언급된 단어 TOP 30"></a>뉴스 제목에서 가장 많이 언급된 단어 TOP 30</h3><p><code>most_common_words</code></p><img width="213" alt="관련 뉴스 Top 30" src="https://user-images.githubusercontent.com/111936229/213954221-59bad582-d4b3-4735-8817-bb1d443a873a.png"><h3 id="가장-많이-언급된-단어-TOP10이-모두-들어가-있는-본문-추출"><a href="#가장-많이-언급된-단어-TOP10이-모두-들어가-있는-본문-추출" class="headerlink" title="가장 많이 언급된 단어 TOP10이 모두 들어가 있는 본문 추출"></a>가장 많이 언급된 단어 TOP10이 모두 들어가 있는 본문 추출</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 뉴스 본문에서 가장 많이 언급된 단어 top 9이 전부 들어간 항목을 추출</span></span><br><span class="line">words = [most_common_words[x][<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)]</span><br><span class="line">trendy_news = df_news[df_news[<span class="string">'본문'</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">all</span>(word <span class="keyword">in</span> x <span class="keyword">for</span>  word <span class="keyword">in</span> words))]</span><br><span class="line">filt = trendy_news[<span class="string">'제목'</span>].<span class="built_in">str</span>.contains(<span class="string">'참고자료'</span>) <span class="comment">#제목에 참고자표 있는 기사 제거</span></span><br><span class="line">trendy_news = trendy_news.loc[~filt]</span><br><span class="line">trendy_news</span><br></pre></td></tr></table></figure><img width="1288" alt="가장 트렌디한 뉴스 기사 추출" src="https://user-images.githubusercontent.com/111936229/213954312-ecd817a1-fcc2-4199-9d88-15a11acdaf14.png"><h3 id="url주소에서-이미지-추출하여-저장하기-세계지도-모양의-워드클라우드-작성"><a href="#url주소에서-이미지-추출하여-저장하기-세계지도-모양의-워드클라우드-작성" class="headerlink" title="url주소에서 이미지 추출하여 저장하기 + 세계지도 모양의 워드클라우드 작성"></a>url주소에서 이미지 추출하여 저장하기 + 세계지도 모양의 워드클라우드 작성</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    driver.get(trendy_news.iloc[i,<span class="number">2</span>])  <span class="comment">#[n,2] 로 검색(뉴스 자료 확인)</span></span><br><span class="line">    time.sleep(<span class="number">20</span>)</span><br><span class="line"><span class="comment"># driver.get(trendy_news.iloc[0,2]</span></span><br><span class="line">url = <span class="string">'https://www.creativefabrica.com/wp-content/uploads/2021/03/09/World-Map-in-Different-Shapes-Graphics-9396076-2-580x385.jpg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 에러 방지용 함수 #에러 안나오면 사용하지 않아도 됨</span></span><br><span class="line"><span class="comment"># 의미 : userAgent를 통해 Chrome임을 확인 (가끔 파일 불러오기할때 에러가 생성되는데 그 오류를 해결)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AppURLopener</span>(urllib.request.FancyURLopener): </span><br><span class="line">    version = <span class="string">"Mozilla/5.0"</span> </span><br><span class="line">urllib._urlopener = AppURLopener()</span><br><span class="line"></span><br><span class="line"><span class="comment">#url로 들어가서 파일을 저장(주피터 폴더)</span></span><br><span class="line">urllib._urlopener.retrieve(url, <span class="string">"test_2.jpg"</span>) </span><br><span class="line"><span class="comment">#저장된 파일을 불러오기(세계지도 모양)</span></span><br><span class="line">urlretrieve_img = Image.<span class="built_in">open</span>(<span class="string">"test_2.jpg"</span>) </span><br><span class="line"></span><br><span class="line">cand_mask=np.array(Image.<span class="built_in">open</span>(<span class="string">'test_2.jpg'</span>))</span><br><span class="line">most_common_words1 = Counter(word_count_sum).most_common(<span class="number">800</span>) <span class="comment">#상위 800개 단어를 워드클라우드로 작성</span></span><br><span class="line">words = <span class="built_in">dict</span>(most_common_words1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#워드클라우드 생성</span></span><br><span class="line">wordcloud = WordCloud(</span><br><span class="line">    font_path = <span class="string">'AppleGothic.ttf'</span>, <span class="comment"># 한글 글씨체 설정(Mac)</span></span><br><span class="line">    background_color=<span class="string">'white'</span>, <span class="comment"># 배경색은 흰색으로 </span></span><br><span class="line">    colormap=<span class="string">'seismic'</span>, <span class="comment"># 글씨색은 seismic(지진) 스타일로</span></span><br><span class="line">    mask=cand_mask, <span class="comment"># 워드클라우드 모양 설정(세계지도)</span></span><br><span class="line">).generate_from_frequencies(words)</span><br><span class="line"></span><br><span class="line"><span class="comment">#사이즈 설정 및 출력</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">plt.imshow(wordcloud,interpolation=<span class="string">'lanczos'</span>) <span class="comment">#이미지 부드러움 정도</span></span><br><span class="line">plt.axis(<span class="string">'off'</span>) <span class="comment"># 차트로 나오지 않게</span></span><br><span class="line">plt.savefig(<span class="string">'wordcloud.png'</span>) <span class="comment"># 필요시 저장</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img width="853" alt="세계지도 모양의 워드 클라우드" src="https://user-images.githubusercontent.com/111936229/213954437-bbdddafe-01ae-40c8-b48b-418c6b20a201.png"><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">'https://ourworldindata.org/uploads/2018/04/Greenhouse-gas-emission-scenarios-01-1536x1059.png'</span></span><br><span class="line"></span><br><span class="line">os.system(<span class="string">"curl "</span> + url + <span class="string">" &gt; conclusion.jpg"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 저장 된 이미지 확인</span></span><br><span class="line">curl_img = Image.<span class="built_in">open</span>(<span class="string">"./conclusion.jpg"</span>)</span><br><span class="line">newsize = (<span class="number">1050</span>,<span class="number">700</span>)</span><br><span class="line">curl_img.resize(newsize)</span><br></pre></td></tr></table></figure><img width="1056" alt="결론" src="https://user-images.githubusercontent.com/111936229/213954516-2c6539ed-85cc-46c8-ba1c-83d6acee742a.png"><p>돈이 안되더라도 기후 기술을 미래를 위해 꾸준히 개발해야만 지구온난화가 적어질 것이다.</p><h3 id="Data-출처"><a href="#Data-출처" class="headerlink" title="Data 출처"></a>Data 출처</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> 기후 기술 분류 체계 : <span class="language-xml">&lt;https://www.ctis.re.kr/ko/techClass/classification.do?key=1141&gt;</span></span><br><span class="line"><span class="bullet">-</span> 기후 기술 수요량 : <span class="language-xml">&lt;https://www.ctis.re.kr/ko/dmandTchnlgy/dmandTchnlgyList.do?key=1543{%22tchnlgyNm%22:%22%22&gt;</span>,%22sclasSn%22:%22%22,%22keyword%22:%22[]%22,%22lang%22:%22ko%22,%22sortOrder%22:%22desc%22,%22total%22:%22%22,%22ltN2Cd%22:%22%22,%22infoPrvd%22:%22%22,%22size%22:%2250%22,%22hasParam%22:true}</span><br><span class="line"><span class="bullet">-</span> 기후 기술 자료들 : <span class="language-xml">&lt;https://kosis.kr/statHtml/statHtml.do?orgId=442&amp;tblId=DT_21_01&amp;vw_cd=MT_ZTITLE&amp;list_id=N2_5&amp;scrId=&amp;seqNo=&amp;lang_mode=ko&amp;obj_var_id=&amp;itm_id=&amp;conn_path=B4&amp;path=%252FstatisticsList%252FstatisticsListIndex.do&gt;</span></span><br><span class="line"><span class="bullet">-</span> 세계 탄소 배출량 : <span class="language-xml">&lt;https://ourworldindata.org/&gt;</span></span><br><span class="line"><span class="bullet">-</span> 기후 기술 뉴스 자료 : <span class="language-xml">&lt;https://www.ctis.re.kr/ko/selectBbsNttList.do?key=1692&amp;bbsNo=312&amp;searchBbsType=&amp;searchCtgry=&amp;searchCnd=ADITFIELD2&amp;searchKrwdType=&amp;chgPage=50&gt;</span></span><br><span class="line"><span class="bullet">-</span> geo.json file : <span class="language-xml">&lt;https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json&gt;</span></span><br><span class="line"><span class="bullet">-</span> 세계 지도 이미지 : <span class="language-xml">&lt;https://www.creativefabrica.com/wp-content/uploads/2021/03/09/World-Map-in-Different-Shapes-Graphics-9396076-2-580x385.jpg&gt;</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Portfolio/">Portfolio</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/project/">project</category>
      
      <category domain="http://InhwanCho.github.io/tags/portfolio/">portfolio</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/23/Portfolio/2023-01-23-visual-project/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>코랩(colab)에서 kaggle(캐글) 데이터 바로 다운받기</title>
      <link>http://inhwancho.github.io/2023/01/20/Colab_folder/2023-01-20-kaggle-colab/</link>
      <guid>http://inhwancho.github.io/2023/01/20/Colab_folder/2023-01-20-kaggle-colab/</guid>
      <pubDate>Fri, 20 Jan 2023 02:22:22 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="코랩에서-캐글-데이터를-바로-다운받는-방법"><a href="#코랩에서-캐글-데이터를-바로-다운받는-방법" class="headerlink" title="코랩에서 캐글 데이터를 바로 다운받는 방법"></a>코랩에서 캐글 데이터를 바로 다운받는 방법</h2><ul><li>kaggle 홈페이지의 오른쪽 프로필 -&gt; account -&gt; <code>create new api token</code> 누른 후 다운로드</li><li><code>kaggle.json</code> 파일을 업로드</li><li>맥북 로컬은 ~/.kaggle에 파일을 옮겨서 사용하면 됩니다.</li></ul><img width="372" alt="캐글 오른쪽 프로필에서 Account 선택" src="https://user-images.githubusercontent.com/111936229/213606040-175f1dbd-c3a2-427f-9f06-501c8be91424.png"><img width="740" alt="Create New API Token 선택" src="https://user-images.githubusercontent.com/111936229/213606034-20d2da24-2a46-44ad-bfc7-bffb9618ff84.png"><figure class="highlight clean"><figcaption><span>in colab</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line"></span><br><span class="line">files.upload()</span><br><span class="line"></span><br><span class="line"># api token(kaggle.json 파일)을 <span class="string">'파일 선택'</span> 눌러서 업로드</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>in colab</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .kaggle 폴더 생성</span></span><br><span class="line">!<span class="built_in">mkdir</span> -p ~/.kaggle</span><br><span class="line"><span class="comment"># json파일 .kaggle로 복사</span></span><br><span class="line">!<span class="built_in">cp</span> kaggle.json ~/.kaggle/</span><br><span class="line"><span class="comment"># Permission Warning이 발생하지 않도록 해줍니다.</span></span><br><span class="line">!<span class="built_in">chmod</span> 600 ~/.kaggle/kaggle.json</span><br><span class="line"><span class="comment"># 내가 참가한 대회 리스트 확인(옵션)</span></span><br><span class="line"><span class="comment"># !kaggle competitions list</span></span><br></pre></td></tr></table></figure><ul><li>다운 받고 싶은 데이터의 API 주소를 복사하려면<ul><li>밑의 스크린샷의 <code>UTKFace</code> 같은 데이터 셋 주소를 클릭합니다.</li><li>그 후 오른쪽 <code>...</code>을 누르고 <code>copy api command</code>를 누릅니다.</li></ul></li></ul><img width="666" alt="노트북에서 사용한 데이터 종류" src="https://user-images.githubusercontent.com/111936229/213606050-f07c7df0-6633-40a4-9ab4-613a29f96b4b.png"><img width="1241" alt="copy api command" src="https://user-images.githubusercontent.com/111936229/213606045-2a6ba84f-9f2c-4705-9fa0-59a1174ae82e.png"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!kaggle datasets download -d jangedoo/utkface-new</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><ul><li>아래와 같은 결과가 나옵니다</li></ul><img width="527" alt="결과" src="https://user-images.githubusercontent.com/111936229/213606041-89d451b8-d503-423f-9a37-addc5c4bdef9.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/Colab/">Colab</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/colab/">colab</category>
      
      <category domain="http://InhwanCho.github.io/tags/kaggle/">kaggle</category>
      
      <category domain="http://InhwanCho.github.io/tags/json/">json</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/20/Colab_folder/2023-01-20-kaggle-colab/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV로 아는 얼굴인지 확인하기</title>
      <link>http://inhwancho.github.io/2023/01/19/Study_folder/OpneCV/2023-01-19-face-recognizion/</link>
      <guid>http://inhwancho.github.io/2023/01/19/Study_folder/OpneCV/2023-01-19-face-recognizion/</guid>
      <pubDate>Thu, 19 Jan 2023 04:16:37 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<ul><li>예제 코드</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> face_recognition</span><br><span class="line"></span><br><span class="line">imgElon = face_recognition.load_image_file(<span class="string">'elon1.png'</span>)</span><br><span class="line">imgTest = face_recognition.load_image_file(<span class="string">'surprised_man.jpg'</span>)</span><br><span class="line"></span><br><span class="line">imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)</span><br><span class="line">imgElon = cv2.cvtColor(imgElon,cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">faceLoc = face_recognition.face_locations(imgElon)[<span class="number">0</span>]</span><br><span class="line">encodeElon = face_recognition.face_encodings(imgElon)[<span class="number">0</span>]</span><br><span class="line">cv2.rectangle(imgElon,(faceLoc[<span class="number">1</span>],faceLoc[<span class="number">2</span>]),(faceLoc[<span class="number">3</span>],faceLoc[<span class="number">0</span>]),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(faceLoc) <span class="comment"># (118, 304, 304, 118) top, right, bottom, left</span></span><br><span class="line"></span><br><span class="line">faceLocTest = face_recognition.face_locations(imgTest)[<span class="number">0</span>]</span><br><span class="line">encodeTest = face_recognition.face_encodings(imgTest)[<span class="number">0</span>]</span><br><span class="line">cv2.rectangle(imgTest,(faceLocTest[<span class="number">1</span>],faceLocTest[<span class="number">2</span>]),(faceLocTest[<span class="number">3</span>],faceLocTest[<span class="number">0</span>]),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">results = face_recognition.compare_faces([encodeElon], encodeTest)</span><br><span class="line">faceDis = face_recognition.face_distance([encodeElon], encodeTest)</span><br><span class="line"><span class="built_in">print</span>(results, faceDis)</span><br><span class="line">cv2.putText(imgTest, <span class="string">f'<span class="subst">{results}</span> <span class="subst">{<span class="built_in">round</span>(faceDis[<span class="number">0</span>],<span class="number">2</span>)}</span>'</span>, (<span class="number">50</span>,<span class="number">50</span>), cv2.FONT_HERSHEY_COMPLEX,<span class="number">1</span>,</span><br><span class="line">                            (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'imtest'</span>,imgTest)</span><br><span class="line">cv2.imshow(<span class="string">'imelon'</span>,imgElon)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>results가 True면 동일 인물, False면 다른 인물로 판단</li></ul>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/study/">study</category>
      
      <category domain="http://InhwanCho.github.io/tags/opencv/">opencv</category>
      
      <category domain="http://InhwanCho.github.io/tags/cv2/">cv2</category>
      
      <category domain="http://InhwanCho.github.io/tags/face-recognition/">face_recognition</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/19/Study_folder/OpneCV/2023-01-19-face-recognizion/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 얼굴, 눈 등 특정 객체 검출</title>
      <link>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-haarscascade/</link>
      <guid>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-haarscascade/</guid>
      <pubDate>Wed, 18 Jan 2023 06:23:12 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="정면-얼굴-검출"><a href="#정면-얼굴-검출" class="headerlink" title="정면 얼굴 검출"></a>정면 얼굴 검출</h2><ol><li><code>haarcascade file</code> 사용</li></ol><ul><li><code>haarcascade_frontalface_default.xml</code> 을 사용하여 검출하는 방법입니다.</li><li>이 파일은 다른 사람들이 이미 얼굴을 검출하는 학습을 해둔 파일이며 이를 이용하면 편하게 얼굴을 인식할 수 있습니다.</li><li>&lt;<a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">opencv-data-haarcascades</a>&gt;</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">faceCascade = cv2.CascadeClassifier(<span class="string">'Resources/haarcascade_frontalface_default.xml'</span>)</span><br><span class="line">img = cv2.imread(<span class="string">'Resources/lena.png'</span>)</span><br><span class="line">imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">faces = faceCascade.detectMultiScale(imgGray,<span class="number">1.1</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (x,y,w,h) <span class="keyword">in</span> faces:</span><br><span class="line">    cv2.rectangle(img, (x,y), (x+w, y+h), (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'result'</span>,img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><img width="505" alt="얼굴 인식" src="https://user-images.githubusercontent.com/111936229/213099837-c577eb63-1dab-433f-8e14-d48ca4309471.png"><ol start="2"><li><code>opencv_face_detector.pbtxt</code> 파일 사용</li></ol><ul><li>haarcascade와 방법은 유사합니다</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">faceBox</span>(<span class="params">faceNet, frame</span>):</span><br><span class="line">    </span><br><span class="line">    frameWidth = frame.shape[<span class="number">1</span>]</span><br><span class="line">    frameHeight = frame.shape[<span class="number">0</span>]</span><br><span class="line">    blob = cv2.dnn.blobFromImage(frame, <span class="number">1.0</span>, (<span class="number">227</span>,<span class="number">227</span>), [<span class="number">104</span>,<span class="number">117</span>,<span class="number">123</span>], swapRB=<span class="literal">False</span>)</span><br><span class="line">    faceNet.setInput(blob)</span><br><span class="line">    detection = faceNet.forward()</span><br><span class="line">    bboxs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(detection.shape[<span class="number">2</span>]):</span><br><span class="line">        confidence = detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> confidence &gt; <span class="number">0.7</span> :</span><br><span class="line">            x1 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">3</span>] * frameWidth)</span><br><span class="line">            y1 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">4</span>] * frameHeight) </span><br><span class="line">            x2 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">5</span>] * frameWidth)</span><br><span class="line">            y2 = <span class="built_in">int</span>(detection[<span class="number">0</span>,<span class="number">0</span>,i,<span class="number">6</span>] * frameHeight)</span><br><span class="line">            bboxs.append([x1,y1,x2,y2])</span><br><span class="line">            cv2.rectangle(frame, (x1,y1), (x2,y2), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> frame, bboxs</span><br><span class="line"></span><br><span class="line">faceProto = <span class="string">"opencv_face_detector.pbtxt"</span></span><br><span class="line">faceModel = <span class="string">"opencv_face_detector_uint8.pb"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">faceNet = cv2.dnn.readNet(faceModel, faceProto)</span><br><span class="line">video = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">padding = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ret, frame = video.read()</span><br><span class="line">    frame, bboxs = faceBox(faceNet, frame)</span><br><span class="line">    </span><br><span class="line">    detect = faceBox(faceNet, frame)</span><br><span class="line">    cv2.imshow(<span class="string">'age_gender'</span>,frame)</span><br><span class="line">    k = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> k == <span class="built_in">ord</span>(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">video.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/opencv/">opencv</category>
      
      <category domain="http://InhwanCho.github.io/tags/cv2/">cv2</category>
      
      <category domain="http://InhwanCho.github.io/tags/object/">object</category>
      
      <category domain="http://InhwanCho.github.io/tags/detection/">detection</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EA%B0%9D%EC%B2%B4/">객체</category>
      
      <category domain="http://InhwanCho.github.io/tags/harrcascade/">harrcascade</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-haarscascade/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OpenCV 윤곽선 검출</title>
      <link>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-contour/</link>
      <guid>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-contour/</guid>
      <pubDate>Wed, 18 Jan 2023 05:11:30 GMT</pubDate>
      
      <description>Click to read more in detail</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="contour"><a href="#contour" class="headerlink" title="contour"></a>contour</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 이미지 여러 장 출력 함수</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stackImages</span>(<span class="params">scale,imgArray</span>):</span><br><span class="line">    rows = <span class="built_in">len</span>(imgArray)</span><br><span class="line">    cols = <span class="built_in">len</span>(imgArray[<span class="number">0</span>])</span><br><span class="line">    rowsAvailable = <span class="built_in">isinstance</span>(imgArray[<span class="number">0</span>], <span class="built_in">list</span>)</span><br><span class="line">    width = imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">1</span>]</span><br><span class="line">    height = imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> rowsAvailable:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span> ( <span class="number">0</span>, rows):</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cols):</span><br><span class="line">                <span class="keyword">if</span> imgArray[x][y].shape[:<span class="number">2</span>] == imgArray[<span class="number">0</span>][<span class="number">0</span>].shape [:<span class="number">2</span>]:</span><br><span class="line">                    imgArray[x][y] = cv2.resize(imgArray[x][y], (<span class="number">0</span>, <span class="number">0</span>), <span class="literal">None</span>, scale, scale)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">1</span>], imgArray[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]), <span class="literal">None</span>, scale, scale)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(imgArray[x][y].shape) == <span class="number">2</span>: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)</span><br><span class="line">        imageBlank = np.zeros((height, width, <span class="number">3</span>), np.uint8)</span><br><span class="line">        hor = [imageBlank]*rows</span><br><span class="line">        hor_con = [imageBlank]*rows</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, rows):</span><br><span class="line">            hor[x] = np.hstack(imgArray[x])</span><br><span class="line">        ver = np.vstack(hor)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, rows):</span><br><span class="line">            <span class="keyword">if</span> imgArray[x].shape[:<span class="number">2</span>] == imgArray[<span class="number">0</span>].shape[:<span class="number">2</span>]:</span><br><span class="line">                imgArray[x] = cv2.resize(imgArray[x], (<span class="number">0</span>, <span class="number">0</span>), <span class="literal">None</span>, scale, scale)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                imgArray[x] = cv2.resize(imgArray[x], (imgArray[<span class="number">0</span>].shape[<span class="number">1</span>], imgArray[<span class="number">0</span>].shape[<span class="number">0</span>]), <span class="literal">None</span>,scale, scale)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(imgArray[x].shape) == <span class="number">2</span>: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)</span><br><span class="line">        hor= np.hstack(imgArray)</span><br><span class="line">        ver = hor</span><br><span class="line">    <span class="keyword">return</span> ver</span><br><span class="line"></span><br><span class="line"><span class="comment">#윤곽선 검출 함수</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getContour</span>(<span class="params">img</span>):</span><br><span class="line">    contours, hierarchy = cv2.findContours(img,mode = cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)</span><br><span class="line">    <span class="keyword">for</span> cnt <span class="keyword">in</span> contours:</span><br><span class="line">        area = cv2.contourArea(cnt)</span><br><span class="line">        <span class="comment"># imgContour이미지에 contour를 파란색으로 drawing한다는 의미</span></span><br><span class="line">        <span class="keyword">if</span> area &gt; <span class="number">500</span> :</span><br><span class="line">            cv2.drawContours(imgContour, cnt, -<span class="number">1</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">3</span>) </span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">'Resources/shapes.png'</span>)</span><br><span class="line">empty = np.zeros_like(img)</span><br><span class="line">imgContour = img.copy()</span><br><span class="line"></span><br><span class="line">imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">imgBlur = cv2.GaussianBlur(imgGray, (<span class="number">7</span>,<span class="number">7</span>),<span class="number">1</span>)</span><br><span class="line">imgCanny = cv2.Canny(imgBlur,<span class="number">50</span>,<span class="number">50</span>)</span><br><span class="line"><span class="comment"># 보통 contour는 img-&gt;gray-&gt;blur-&gt;canny-&gt;contour를 이용하여 검출한다.</span></span><br><span class="line">getContour(imgCanny)</span><br><span class="line"></span><br><span class="line">stackimg = stackImages(<span class="number">0.5</span>,[[img,imgGray, imgBlur],</span><br><span class="line">                            [imgCanny,imgContour,empty]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.imshow(<span class="string">'img'</span>, stackimg)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>보통 contour는 img-&gt;gray-&gt;blur-&gt;canny-&gt;contour를 이용하여 검출한다.</li><li>5번째 이미지(imgContour)가 윤곽선이 검출된 이미지</li></ul><img width="855" alt="5번째가 윤곽선 검출 이미지" src="https://user-images.githubusercontent.com/111936229/213089692-458299d7-6141-4f31-ba0b-b6903f0f5f0d.png"><h2 id="contour를-통하여-bounding-box-검출하는-방법입니다"><a href="#contour를-통하여-bounding-box-검출하는-방법입니다" class="headerlink" title="contour를 통하여 bounding box 검출하는 방법입니다"></a>contour를 통하여 bounding box 검출하는 방법입니다</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getContour</span>(<span class="params">img</span>):</span><br><span class="line">    contours, hierarchy = cv2.findContours(img,mode = cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)</span><br><span class="line">    <span class="keyword">for</span> cnt <span class="keyword">in</span> contours:</span><br><span class="line">        area = cv2.contourArea(cnt)</span><br><span class="line">        <span class="comment"># imgContour이미지에 contour를 파란색으로 drawing한다는 의미</span></span><br><span class="line">        <span class="keyword">if</span> area &gt; <span class="number">500</span> :</span><br><span class="line">            cv2.drawContours(imgContour, cnt, -<span class="number">1</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">3</span>) </span><br><span class="line">            param = cv2.arcLength(cnt, <span class="literal">True</span>)</span><br><span class="line">            approx = cv2.approxPolyDP(cnt, <span class="number">0.02</span> * param, <span class="literal">True</span>) <span class="comment">#근접한 포인트(점)이 있는지 확인</span></span><br><span class="line">            <span class="comment">#print(len(approx)) #3이면 삼각형, 4는 사격형, 그 이상이면 원</span></span><br><span class="line">            obj_corner = <span class="built_in">len</span>(approx)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># object corner를 검출했으면 그걸로 바운딩 박스를 만듭니다.</span></span><br><span class="line">            x,y,w,h = cv2.boundingRect(approx)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> obj_corner == <span class="number">3</span> :</span><br><span class="line">                object_type = <span class="string">'triangle'</span></span><br><span class="line">            <span class="keyword">elif</span> obj_corner ==<span class="number">4</span> :</span><br><span class="line">                aspRatio = w/<span class="built_in">float</span>(h)</span><br><span class="line">                <span class="keyword">if</span> aspRatio &gt; <span class="number">0.95</span> <span class="keyword">and</span> aspRatio &lt; <span class="number">1.05</span>:</span><br><span class="line">                    object_type = <span class="string">'sqare'</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    object_type = <span class="string">'rectangle'</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                object_type = <span class="string">'circle'</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#rectangle을 만들고, 텍스트를 붙여서 출력합니다.</span></span><br><span class="line">            cv2.rectangle(imgContour, (x,y), (x+w, y+h), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">            cv2.putText(imgContour, object_type, (x+(w//<span class="number">2</span>)-<span class="number">7</span>, y +(h//<span class="number">2</span>)-<span class="number">10</span>),cv2.FONT_HERSHEY_SIMPLEX,<span class="number">0.6</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br><span class="line">        </span><br></pre></td></tr></table></figure><ul><li>윤곽선 검출 및 바운딩 박스 생성 이미지(5번째 이미지)</li></ul><img width="1375" alt="윤곽선 -> 바운딩 박스 생성" src="https://user-images.githubusercontent.com/111936229/213092755-f603d629-3933-448d-b1cc-7559e47a558f.png">]]></content:encoded>
      
      
      <category domain="http://InhwanCho.github.io/categories/OpenCV/">OpenCV</category>
      
      
      <category domain="http://InhwanCho.github.io/tags/opencv/">opencv</category>
      
      <category domain="http://InhwanCho.github.io/tags/cv2/">cv2</category>
      
      <category domain="http://InhwanCho.github.io/tags/contour/">contour</category>
      
      <category domain="http://InhwanCho.github.io/tags/%EC%9C%A4%EA%B3%BD%EC%84%A0/">윤곽선</category>
      
      
      <comments>http://inhwancho.github.io/2023/01/18/Study_folder/OpneCV/2023-01-18-contour/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
