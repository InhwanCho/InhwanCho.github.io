{"posts":[{"title":"Konplyì„¤ì¹˜ in colab","text":"1. bash ì…¸ë¡œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ì„¤ì¹˜(ê¸°ë³¸ ì„¤ì •ì´ zshë¼ë„ bash ìƒê´€ ì—†ìŒ)12345%%bashapt-get updateapt-get install g++ openjdk-8-jdk python-dev python3-devpip3 install JPype1pip3 install konlpy 12345### ë˜ëŠ” ì•„ë˜ì²˜ëŸ¼ 1ê°œì”© ì…ë ¥í•´ë„ ê°€ëŠ¥(ìœ„ì—ê±° ë¬¸ì œì—†ì´ ì‹¤í–‰ ì‹œ ìŠ¤í‚µí•˜ì„¸ìš”)!apt-get update!apt-get install g++ openjdk-8-jdk python-dev python3-dev!pip3 install JPype1!pip3 install konlpy 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •1%env JAVA_HOME &quot;/usr/lib/jvm/java-8-openjdk-amd64&quot; 3. mecab ì„¤ì¹˜123%%bashbash &lt;(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)pip3 install /tmp/mecab-python-0.996 4. í™•ì¸12345678910111213import konlpyfrom konlpy.tag import Kkma, Komoran, Hannanum, Oktfrom konlpy.utils import pprintfrom konlpy.tag import Mecab###################mecab = Mecab()sentence = 'ì•ˆë…•í•˜ì„¸ìš” í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ ì…ë‹ˆë‹¤.'temp_X = mecab.morphs(sentence)temp_X# ì¶œë ¥ ê²°ê³¼['ì•ˆë…•', 'í•˜', 'ì„¸ìš”', 'í…ŒìŠ¤íŠ¸', 'ìš©', 'í…ìŠ¤íŠ¸', 'ì…ë‹ˆë‹¤', '.']","link":"/2022/11/22/Colab_folder/2022-11-22-konlpy-install/"},{"title":"Colab Symbolic link(ì½”ë© íŒ¨í‚¤ì§€ ì˜êµ¬ ì„¤ì¹˜)","text":"Google Colabì—ì„œ python íŒ¨í‚¤ì§€ë¥¼ ì˜êµ¬ì ìœ¼ë¡œ ì„¤ì¹˜í•˜ëŠ” ë°©ë²• êµ¬ê¸€ë“œë¼ì´ë¸Œë¡œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ì½ì–´ë“¤ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì„¤ì¹˜ë¥¼ í•˜ì§€ ì•Šì„ ê²½ìš°, ëŸ°íƒ€ì„ ì´ˆê¸°í™” ë§ˆë‹¤ ì¬ì„¤ì¹˜ë¥¼ í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤. í˜¹ì‹œ, ì™¼ìª½ íƒìƒ‰ê¸° íƒ­ì„ í†µí•´ ìˆ˜ë™ìœ¼ë¡œ ë§ˆìš´íŠ¸ í•œ ê²½ìš°, drive.mount('/content/drive')ëŠ” ì•ˆí•˜ì…”ë„ ë©ë‹ˆë‹¤. 1.êµ¬ê¸€ ì½”ë©ì„ ì—´ê³  ë§ˆìš´íŠ¸ë¥¼ í•©ë‹ˆë‹¤. 1234import os, sysfrom google.colab import drive# ì¼ë‹¨ ë§ˆìš´íŠ¸ë¥¼ í•´ì¤ë‹ˆë‹¤(êµ¬ê¸€ ë“œë¼ì´ë¸Œì™€ ì—°ë™)drive.mount('/content/drive') 2.ìƒˆë¡œìš´ í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (my_env) 123if not os.path.exists('drive/My Drive/Colab Notebooks/my_env'): print('create directory.....') os.mkdir('drive/My Drive/Colab Notebooks/my_env') 3.ìƒˆë¡œìš´ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. 12345# ë§ˆìš´íŠ¸ ëœ ìƒíƒœì—ì„œ í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.my_path = '/content/notebooks'# Notebooks í´ë”ì˜ my_env í´ë”ì— íŒ¨í‚¤ì§€ ì €ì¥os.symlink('/content/drive/My Drive/Colab Notebooks/my_env', my_path)sys.path.insert(0, my_path) 4.ì½”ë©ì— ì›í•˜ëŠ” íŒ¨í‚¤ì§€ë¥¼ my_path ê²½ë¡œë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤. 12# konlpyë¥¼ ì„¤ì¹˜í•˜ë ¤ë©´ ì´ëŸ°ì‹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì‹œë©´ ë©ë‹ˆë‹¤.!pip install --target=$my_path konlpy (í•„ìˆ˜)ì¬ ì‹¤í–‰ ì‹œ ì•„ë˜ì˜ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤ í…ŒìŠ¤íŠ¸í•  ê²½ìš° ìƒˆ íƒ­ì´ ì•„ë‹Œ ìƒˆë¡œìš´ ìœˆë„ìš°ì—ì„œ í…ŒìŠ¤íŠ¸í•´ì•¼ ì œëŒ€ë¡œ ë©ë‹ˆë‹¤. 12345678910import os, sysfrom google.colab import drivedrive.mount('/content/drive')my_path = '/content/notebooks'os.symlink('/content/drive/My Drive/Colab Notebooks/my_env', my_path)sys.path.insert(0, my_path)import konlpy ì½”ë©ì˜ ì™¼ìª½ íƒìƒ‰ê¸° íƒ­ì˜ /content/drive/My Drive/Colab Notebooks/my_env í´ë”ì—ì„œ ë‹¤ìš´ ë°›ì€ íŒŒì¼ì´ ì˜ ì„¤ì¹˜ë˜ì–´ìˆëŠ”ì§€ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.","link":"/2022/11/22/Colab_folder/2022-11-22-Symbolic-Link/"},{"title":"nltk.download() in colab","text":"nltk.download()ì—ì„œ ë¦¬ìŠ¤íŠ¸ì˜ íŒŒì¼ì„ ëª¨ë‘ ë‹¤ìš´ ë°›ê³  ì‹¶ì€ ê²½ìš°123import nltknltk.download() 12345678910NLTK Downloader--------------------------------------------------------------------------- d) Download l) List u) Update c) Config h) Help q) Quit---------------------------------------------------------------------------Downloader&gt; dDownload which package (l=list; x=cancel)? Identifier&gt; alldownload which packageì—ì„œ allì„ ì…ë ¥í•˜ë©´ ëª¨ë‘ ì„¤ì¹˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë˜ëŠ” 1234# ëŸ°íƒ€ì„ ì´ˆê¸°í™” ë ë•Œë§ˆë‹¤ ê¹ŒëŠ”ê²Œ ë¶€ë‹´ë ë•ŒëŠ”(íŠ¹ì • íŒŒì¼ë§Œ ì„¤ì¹˜ë¥¼ ì›í•˜ëŠ” ê²½ìš°)nltk.download('popular')# ë‹¤ ê¹”ê³  ì‹¶ì„ ê²½ìš°nltk.download('all')","link":"/2022/11/22/Colab_folder/2022-11-22-nltk-download/"},{"title":"ì£¼í”¼í„°ë…¸íŠ¸ë¶ì²˜ëŸ¼ ì½”ë©ì—ì„œ Tapí‚¤ ì‚¬ìš©í•˜ê¸°","text":"Google Colabì—ì„œ Tapí‚¤ ì‚¬ìš©í•˜ê¸°(ìë™ì™„ì„±) ë„êµ¬ -&gt; ì„¤ì • -&gt; í¸ì§‘ê¸° -&gt; ì½”ë“œ ì™„ì„± ì œì•ˆì„ ìë™ìœ¼ë¡œ í‘œì‹œ í´ë¦­í•˜ì—¬ í•´ì œí•˜ë©´ ì£¼í”¼í„°ë…¸íŠ¸ë¶ì²˜ëŸ¼ ìë™ ì™„ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.","link":"/2022/11/24/Colab_folder/2022-11-23-setting-tap/"},{"title":"[Github Blog] ë§ˆí¬ë‹¤ìš´(Markdown) ë¬¸ë²•","text":"Mathematics jekyllì˜ md í¬ìŠ¤íŠ¸ íŒŒì¼ ìƒë‹¨ì— math : trueë¡œ ì„¤ì •í•´ì•¼ ë©ë‹ˆë‹¤. hexo ì˜ ê²½ìš° mathjax: true`ë¡œ ì„¤ì • (configíŒŒì¼ì—ì„œ ìë™ìœ¼ë¡œ ì„¤ì • ë˜ìˆìœ¼ë©´ ì•ˆí•´ë„ ë©ë‹ˆë‹¤) $$ \\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6} $$ When $a \\ne 0$, there are two solutions to $ax^2 + bx + c = 0$ and they are $$ x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a} $$ 12345$$ \\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6} $$When $a \\ne 0$, there are two solutions to $ax^2 + bx + c = 0$ and they are$$ x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a} $$ ë°‘ì¤„ ë„£ê¸° &lt;u&gt; ì…ë ¥ &lt;/u&gt; ê¸€ì ìƒ‰(ë…¸ë€ìƒ‰) ë„£ê¸° `ì…ë ¥` ë§¥ë¶ì—ì„œëŠ” option + â‚©(~) ë²„íŠ¼ ì¤„ë°”ê¿ˆì„ í•˜ê³  ì‹¶ë‹¤ë©´ ë¬¸ì¥ ë’¤ì— ìŠ¤í˜ì´ìŠ¤ë°”ë¥¼ ë‘ë²ˆ + Enter í•´ì¤€ë‹¤. copyê°€ ê°€ëŠ¥í•œ ì…€(ì½”ë“œë¸”ëŸ­) ë§Œë“¤ê¸°```markdownì…ë ¥ì€ ì—¬ê¸°ì— í•´ì£¼ì„¸ìš”.``` 12ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì¡°ì¸í™˜ ì´ë¼ê³  í•©ë‹ˆë‹¤. ì•ˆë…•í•˜ì„¸ìš”.ì €ëŠ” ì¡°ì¸í™˜ ì´ë¼ê³  í•©ë‹ˆë‹¤. &lt;br&gt; ë˜í•œ ì¤„ë°”ê¿ˆì„ í•´ì£¼ëŠ” HTML íƒœê·¸ì´ë‹¤. 1ì•ˆë…•í•˜ì„¸ìš”. &lt;br&gt; ì €ëŠ” ì¡°ì¸í™˜ ì´ë¼ê³  í•©ë‹ˆë‹¤. ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì¡°ì¸í™˜ ì´ë¼ê³  í•©ë‹ˆë‹¤. ë¬¸ë‹¨ ë‚˜ëˆ„ê¸°í•œ ì¤„ì˜ ê³µë°±ì„ ë‘ì–´ ì‘ì„± í•˜ë©´ ëœë‹¤. (ì´ ë‘ ì¤„) 123ì•ˆë…•í•˜ì„¸ìš”.ì €ëŠ” ì¡°ì¸í™˜ í•©ë‹ˆë‹¤. ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì¡°ì¸í™˜ í•©ë‹ˆë‹¤. ì¤‘ì²©ëœ êµ¬ì¡°ì•„ë˜ì™€ ê°™ì´ ì¤‘ì²©ëœ êµ¬ì¡°ë¥¼ ë§Œë“œë ¤ë©´ ë‘ë²ˆì§¸ ì¤„ì„ ìŠ¤í˜ì´ìŠ¤ë°” 2ë²ˆ ëˆŒëŸ¬ ë„ì–´ì¤€ í›„ ì‘ì„±í•œë‹¤. ì„¸ë²ˆ ì¤‘ì²©ëœ ì¤„ì„ ë§Œë“œë ¤ë©´ ìŠ¤í˜ì´ìŠ¤ë°” 4ë²ˆ. 123- hi - hello - ì•ˆë…• hi hello ì•ˆë…• ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ê³  ì‹¶ì„ ë•Œë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì•ì— \\ë¥¼ ë¶™ì—¬ì¤€ë‹¤. 1\\&lt;u&gt;ì•ˆë…•&lt;/u&gt; &lt;u&gt;ì•ˆë…•ì›ë˜ ê°™ìœ¼ë©´ ë°‘ì¤„ ê·¸ì–´ì§„ í˜•íƒœë¡œ ì•ˆë…•ìœ¼ë¡œ ë³´ì¼í…ë° \\ë¥¼ ì•ì— ë¶™ì—¬ì£¼ì–´ ë¬¸ë²• ê·¸ëŒ€ë¡œ &lt;u&gt;ê°€ ë³´ì—¬ì§„ë‹¤. Headerê¸€ì˜ ì œëª©ì´ ëœë‹¤. ê° ì œëª©ë§ˆë‹¤ permalinkê°€ ìˆëŠ” ê²ƒì´ íŠ¹ì§•! # ~ ###### ë¡œ ì œëª© í¬ê¸°ì— ë”°ë¼ h1 ~ h6ì„ ë‚˜íƒ€ë‚¸ë‹¤. 123456# h1## h2### h3#### h4##### h5###### h6 h1h2h3h4h5h6í…ìŠ¤íŠ¸ê°•ì¡°1**ê°•ì¡°ëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤** ê¸°ìš¸ì„12*ê¸°ìš¸ì—¬ì§„ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤****êµµê³  ê¸°ìš¸ì—¬ì§„ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤*** ê¸°ìš¸ì—¬ì§„ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤êµµê³  ê¸°ìš¸ì—¬ì§„ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤ ì·¨ì†Œì„ 1~~ì·¨ì†Œëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤~~ ì·¨ì†Œëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤ ë°‘ì¤„1&lt;u&gt;ë°‘ì¤„ ìˆëŠ” í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤&lt;/u&gt; ë°‘ì¤„ ìˆëŠ” í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤ ê¸€ì”¨ ìƒ‰123456789101112131415&lt;span style=&quot;color:yellow&quot;&gt;ë…¸ë€ ê¸€ì”¨ì…ë‹ˆë‹¤.&lt;/span&gt;``` &lt;span style=&quot;color:yellow&quot;&gt;ë…¸ë€ ê¸€ì”¨ì…ë‹ˆë‹¤.&lt;/span&gt;&lt;br&gt;## ë§í¬### ë§í¬ë§Œ ìˆëŠ” inline ë§í¬\\&lt;ë§í¬ì£¼ì†Œ&gt;```html&lt;https://www.google.com&gt; https://www.google.com ì„¤ëª… ìˆëŠ” inline ë§í¬[ë§í¬ì„¤ëª…](ë§í¬ì£¼ì†Œ) 1[êµ¬ê¸€ í™ˆí˜ì´ì§€](https://www.google.com) êµ¬ê¸€ í™ˆí˜ì´ì§€ ë™ì¼ íŒŒì¼ ë‚´ì—ì„œì˜ ë¬¸ë‹¨(í—¤ë”) ì´ë™ ë§í¬[ì„¤ëª…ì–´](ë¬¸ë‹¨ì˜ ì£¼ì†Œ) ë¬¸ë‹¨ì˜ ì£¼ì†Œ ë”°ëŠ” ë°©ë²• theorydbë‹˜ ë¸”ë¡œê·¸ ì°¸ê³  í—¤ë” ì œëª© ë¬¸ìì—´ì„ ë³µì‚¬í•˜ê³  (ë¬¸ë‹¨ì˜ ì£¼ì†Œ)ì— ë³µì‚¬í•œë‹¤. íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì œê±°í•œë‹¤. ê³µë°±ì„ -ë¡œ ë³€ê²½í•œë‹¤. ëŒ€ë¬¸ìëŠ” ì†Œë¬¸ìë¡œ ë³€ê²½í•œë‹¤.ì˜ˆì‹œ) â€œ#Markdown! ì¥ì â€ &gt; â€œ#markdown-ì¥ì â€ 1[ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ê³  ì‹¶ì„ ë•Œ](#ë§ˆí¬ë‹¤ìš´-ë¬¸ë²•ì„-ê·¸ëŒ€ë¡œ-ë³´ì—¬ì£¼ê³ -ì‹¶ì„-ë•Œ) ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ê³  ì‹¶ì„ ë•Œ ë™ì˜ìƒ ì‚½ì… 123&lt;video controls width=&quot;800&quot;&gt; &lt;source src=&quot;/assets/videos/attention.mp4&quot; type=&quot;video/mp4&quot;&gt;&lt;/video&gt; ê·¸ë¦¼ ë§í¬ ì‚½ì…![image](ì´ë¯¸ì§€ì£¼ì†Œ)ë¡œì»¬ íŒŒì¼ ê²½ë¡œë„ ê°€ëŠ¥í•˜ë‹¤. {: width=â€70%â€ height=â€70%â€}{: .align-center} *ì‚¬ì§„ ì¶œì²˜ : ìš°ë¦¬ì§‘ ê¾¸ë¯¸ ^^ ê·¸ë¦¼ ìì²´ì— ë§í¬ ê±¸ê¸°![image](ì´ë¯¸ì§€ì£¼ì†Œ)](ì´ë™í•˜ë ¤ëŠ” ë§í¬ ì£¼ì†Œ) ì¸ìš©ë¬¸&gt;ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. &gt;&gt; ë‘ê°œ ì“°ë©´ ì¤‘ì²©ëœ ì¸ìš©ë¬¸.ì¤‘ì²©ì‹œí‚¬ë• ì•ì— ìŠ¤í˜ì´ìŠ¤ë°” 2ë²ˆ ! 12&gt; ì´ê±´ ì¸ìš©ë¬¸ì´ì—ìš”. &gt;&gt; ì´ê±´ ì¸ìš©ë¬¸ ì† ì¸ìš©ë¬¸ì´ì—ìš”. ì´ê±´ ì¸ìš©ë¬¸ì´ì—ìš”. ì´ê±´ ì¸ìš©ë¬¸ ì† ì¸ìš©ë¬¸ì´ì—ìš”. &lt;cite&gt; --- íƒœê·¸ì™€ {{: .small}}ë¥¼ í•¨ê»˜ ì¨ì„œ ì¸ìš©ë¬¸ ì¶œì²˜ ë‚¨ê¸°ê¸° 12&lt;cite&gt;Steve Jobs&lt;/cite&gt; --- Apple Worldwide Developers' Conference, 1997{% raw %}{: .small}{% endraw %} Steve Jobs â€” Apple Worldwide Developersâ€™ Conference, 1997{: .small} ë¦¬ìŠ¤íŠ¸unordered list12345678910111213141516171819202122232425- ìˆœì„œê°€ * ì—†ëŠ” + ëª©ë¡ * ìˆœì„œê°€- ì—†ì–´ìš©``` - ìˆœì„œê°€ - ì—†ëŠ” - ëª©ë¡ - ìˆœì„œê°€- ì—†ì–´ìš©### ordered list```html1. ìˆœì„œê°€2. ìˆëŠ” 1. ëª©ë¡ - í•˜ë‚˜ - ë‘˜ 2. ëª©ë¡ - í•˜ë‚˜ - ë‘˜3. ëª©ë¡ ìˆœì„œê°€ ìˆëŠ” ëª©ë¡ í•˜ë‚˜ ë‘˜ ëª©ë¡ í•˜ë‚˜ ë‘˜ ëª©ë¡ check list12- [ ] ì²´í¬ ì•ˆë¨- [X] ì²´í¬ ë¨ ì²´í¬ ì•ˆë¨ ì²´í¬ ë¨ êµ¬ë¶„ì„ ***ì™€ ---ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. 12***--- í…Œì´ë¸”|ì™€ - (3ê°œ ì´ìƒ)ì˜ ì¡°í•©ìœ¼ë¡œ í…Œì´ë¸”ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ì •ë ¬ ì™¼ìª½ ì •ë ¬ |:â€”| ì˜¤ë¥¸ìª½ ì •ë ¬ |â€”:| ê°€ìš´ë° ì •ë ¬ |:â€”:| 12345678910111213141516171819202122232425262728|**ì œëª©**|í‰ì |ê°ìƒí‰||:---:|---:|---||Avatar1|â­â­â­â­â­|ë‚˜ë¹„||Avatar2|â­â­â­â­â­|ë¬¼||ì•„ë°”íƒ€|â­â­â­â­â­|ì•ˆë…•|``` |**ì œëª©**|í‰ì |ê°ìƒí‰||:---:|---:|---||Avatar1|â­â­â­â­â­|ë‚˜ë¹„||Avatar2|â­â­â­â­â­|ë¬¼||ì•„ë°”íƒ€|â­â­â­â­â­|ì•ˆë…•|&lt;br&gt;## í† ê¸€ ë¦¬ìŠ¤íŠ¸ (ì ‘ê¸°/í¼ì¹˜ê¸°)ë§ˆí¬ë‹¤ìš´ì—ì„  ì§€ì›í•˜ì§€ ì•Šê³  HTMLì˜ `details` íƒœê·¸ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. `div markdown=â€1â€` ì€ jekyllì—ì„œ htmlì‚¬ì´ì— markdownì„ ì¸ì‹ í•˜ê¸° ìœ„í•œ ì½”ë“œì´ë‹¤.```html&lt;details&gt;&lt;summary&gt;ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”&lt;/summary&gt;&lt;div markdown=&quot;1&quot;&gt; ìˆ¨ê²¨ì§„ ë‚´ìš©&lt;/div&gt;&lt;/details&gt; ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš” ìˆ¨ê²¨ì§„ ë‚´ìš© ë²„íŠ¼1&lt;a href=&quot;#&quot; class=&quot;btn--success&quot;&gt;Success Button&lt;/a&gt; Success Button 1[Default Button](#){% raw %}{: .btn .btn--primary }{% endraw %} Default Button{: .btn .btn--primary } ë§¨ ìœ„ë¡œ ì´ë™í•˜ê¸°{: .btn .btnâ€“primary }{: .align-right}","link":"/2022/11/19/Blogs_folder/2022-11-19-markdown/"},{"title":"Github commands","text":"Github ì—°ê²° ë§¥ OSì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ gitì´ ì„¤ì¹˜ë˜ì–´ìˆìŠµë‹ˆë‹¤. 123$git --version# ì´ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•˜ë©´ ë²„ì „ì´ ë‚˜ì˜¨ë‹¤ë©´ gitì´ ì„¤ì¹˜ê°€ ë˜ì–´ìˆëŠ” ê²ë‹ˆë‹¤.# git version 2.37.1 (Apple Git-137.1) Githubì´ë‘ ì»´í“¨í„°ë‘ ì—°ë™(ì²˜ìŒ ë“±ë¡í•  ê²½ìš°) ë° ê¸°ë³¸ ëª…ë ¹ì–´123# (ëª…ë ¹ì–´ í™•ì¸(ë©”ë‰´ì–¼ í˜¸ì¶œ))$git --help# ë‚˜ê°€ë ¤ë©´ qëˆ„ë¥´ë©´ ë¨ git config (ì»´í“¨í„°ì— ê¹ƒí—ˆë¸Œ ì•„ì´ë””,ì´ë©”ì¼,í˜ìŠ¤ì›Œë“œ(í† í°)ì„ ë“±ë¡í•˜ëŠ” ëª…ë ¹ì–´)123456$git config --global user.name YOUR_NAME$git config --global user.email YOUR_EMAIL$git config --global user.password YOUR_TOKEN# ìœ ì €,ì´ë©”ì¼,í† í°ì„ ë“±ë¡í•œ ì´í›„ ë“±ë¡ì´ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸(í™”ë©´ ë‚˜ê°€ë ¤ë©´ qëˆ„ë¥´ê¸°)$git config --list git init (ì»´í“¨í„°ì— github repoë¥¼ ì—°ê²°í•˜ëŠ” ëª…ë ¹ì–´)(git cloneìœ¼ë¡œ í•  ê²½ìš° ì´ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  í•„ìš” ì—†ìŒ) ê¹ƒì— ì—°ê²°í•  í´ë”ì— cd ëª…ë ¹ì–´ë¡œ ì´ë™ í›„, í•´ë‹¹ ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œ .gitíŒŒì¼ ìƒì„±(ìˆ¨ê¹€ íŒŒì¼)ë¨ ë™ì‹œì— ê¹ƒëª…ë ¹ì–´ ìˆ˜í–‰í•˜ëŠ” í´ë”ë¡œ ë³€ê²½(iterm2ë¥¼ ì‚¬ìš©í•  ê²½ìš°(ì»¤ìŠ¤í„°ë§ˆì´ì§•) ë¸ŒëŸ°ì¹˜ë„¤ì„ì´ ë‚˜ì˜´) 1234$git init$git remote add origin https://github.com/InhwanCho/Study.git# ê¹ƒì´ë‘ í´ë”ë¥¼ ì—°ê²°# íŒŒì¼ ì²˜ìŒ ì»¤ë°‹í•˜ë ¤ë©´ í‘¸ì‹œ ì•ˆë¨ ì´ê±° ë¨¼ì € í•´ì¤˜ì•¼ í•¨ git clone (ë³´í†µ url.git) git clone ../StudyforGit(repository name) ìƒëŒ€ë°©, í˜¹ì€ ìì‹ ì˜ ê¹ƒì— ì—°ê²°í•˜ì—¬ ë‹¤ìš´ì„ ë°›ìŒ í´ë”ë‚˜ urlì— ì—°ê²° urlì— ë³´í†µ ì—°ê²° 12#ë§¨ ë’¤ì— ë³´í†µ .gitì„ ë¶™ì—¬ì¤˜ì•¼ í•œë‹¤.$git clone https://github.com/InhwanCho/Study.git git status íŒŒì¼ ìˆ˜ì • í›„ ìƒíƒœ í™•ì¸ ì°½.(í™•ì¸ í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ ì´ˆë°˜ì—ëŠ” ë„ì›€ì´ ë§ì´ ë˜ëŠ” ëª…ë ¹ì–´) ìƒëŒ€ë°©ì´ ìˆ˜ì • í–ˆì„ ê²½ìš°ì—ë„ ë„ì›€ì´ ë˜ë‹ˆ ì´ˆë°˜ì— ë§ì´ ì‚¬ìš©í•˜ë„ë¡ í•´ë³´ì. 1$git status git add â€˜filenameâ€™ or . or â€˜-Aâ€™ íŒŒì¼ ìˆ˜ì • í›„ í˜ì´ì§€ì— ë³€ê²½í•  íŒŒì¼ëª… ë“±ë¡. â€˜.â€™ì´ë‚˜ â€˜-Aâ€™ì…ë ¥ ì‹œ í´ë” ì „ì²´ë¥¼ ë“±ë¡í•¨ 12345$git add .$git add -A# ë§Œì•½ í•˜ë‚˜ì”© ë“±ë¡ì„ ì›í•  ê²½ìš°$git add test.text git commit -m â€˜messageâ€™12# addí•œ íŒŒì¼ë“¤ì„ í™ˆí˜ì´ì§€ì— ì˜¬ë¦¼.$git commit -m 'this is a test message' git push123456# commití•œ íŒŒì¼ì„ í™ˆí˜ì´ì§€ì— í™•ì •ìœ¼ë¡œ ì˜¬ë¦¼.$git push# íŒŒì¼ì´ ì²˜ìŒ ìƒì„±ëœ ê²½ìš°(ê¹ƒí—ˆë¸Œ ìì²´ ì—°ë™ ì²˜ìŒí•œ ê²½ìš°)$git push origin master# ìœ„ì˜ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•´ì•¼ í•¨(ì´í›„ì—ëŠ” git pushë§Œ í•˜ì—¬ë„ ì‘ë™) git pull12# í™ˆí˜ì´ì§€ì—ì„œ ìˆ˜ì •ëœ ì •ë³´ë¥¼ ë””ë ‰í† ë¦¬ì™€ ë¹„êµí•´ì„œ ì—…ë°ì´íŠ¸(í˜¼ì ì‘ì—…í• ë•ŒëŠ” ê±°ì˜ ì‚¬ìš© ì•ˆí•¨)$git pull ë³€ê²½ ë¡œê·¸ í™•ì¸(log, diff)12345$git log #ì „ì²´ ë¡œê·¸ ì¶œë ¥$git log --oneline -n 3 #3ê°œë§Œ ì¶œë ¥ì„ ì›í•  ê²½ìš°# íŒŒì¼ ìˆ˜ì • í›„ ë³€ê²½ëœ ë¶€ë¶„ì„ í‘œì‹œí•˜ëŠ” ëª…ë ¹ì–´(ë‚˜ì˜¤ë ¤ë©´ q)$git diff addëœ ëª…ë ¹ ì·¨ì†Œí•˜ê¸°(ì»¤ë°‹ ì „)1$git reset HEAD^ git revert(pushëœ ëª…ë ¹ ì·¨ì†Œí•˜ê¸°)(ë¡œê·¸ ë‚¨ìŒ)123456789#logì—ì„œ ì»¤ë°‹ëœ ë¡œê·¸(ex.abdc0123abdc0123)ë¥¼ ë˜ëŒë¦¬ê¸°$git log --oneline -n 3 #3ê°œì˜ ë¡œê·¸ ì¶œë ¥$git reset --hard abdc0123abdc0123# -&gt; git revert abdc0123abdc0123 --no-edit # -&gt;$git push git reset(pushëœ ëª…ë ¹ ì·¨ì†Œí•˜ê¸°) revertë‘ ìœ ì‚¬í•˜ì§€ë§Œ resetì€ ë¡œê·¸ë¥¼ ë‚¨ê¸°ì§€ ì•Šê¸°ë•Œë¬¸ì— revertê°€ ë³´ë‹¤ ìœ ìš©í•¨ 12345$git reset --hard abdc0123abdc0123 #-&gt;$git reset abdc0123abdc0123 --no-edit#-&gt;$git push revertí•œê²ƒì„ ë‹¤ì‹œ ë˜ëŒë¦¬ê³  ì‹¶ì„ ê²½ìš°12# revertí•œ ë¡œê·¸ë¥¼ ë‹¤ì‹œ revertí•˜ê¸° (1ìœ¼ë¡œ ë¨¸ì§€)$git revert -m 1 abcd0321abcd0321 branch ì‚¬ìš©í•˜ê¸°branch ë¦¬ìŠ¤íŠ¸ í™•ì¸12# í˜„ì¬ ì—°ê²°ëœ ë¸Œë Œì¹˜ë¥¼ í™•ì¸ *ë¡œ í‘œì‹œë¨.$git branch -a branch ìƒì„± ë° ì„ íƒ1234567891011121314# ìƒì„±(ì‘ì—… í›„ add, commitê¹Œì§„ ì‘ì—…ì´ ë™ì¼í•¨) # ë‹¤ë§Œ, pushë¥¼ git push 'branch name'ìœ¼ë¡œ í•´ì•¼í•¨$git branch test_branch_name#git 2.23ë²„ì „ ë¶€í„° git checkoutì„ ëŒ€ì‹ í•˜ì—¬ switchì™€ restoreê°€ ë‚˜ì˜¤ê²Œ ë˜ì—ˆë‹¤.#checkoutì˜ ê¸°ëŠ¥ì´ ë„ˆë¬´ ë§ì•„ ë¶„ë¦¬í•˜ì˜€ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. - checkout: Switch branches or restore working tree files - switch: Switch branches - restore: Restore working tree files# ì„ íƒ$git checkout test_branch_name$git switch test_branch_name$git restore test_branch_name ìƒˆë¡œìš´ branchë¡œ í‘¸ì‰¬í•˜ê¸°12345$git push --set-upstream origin test_branch_name#ë˜ëŠ”$git push -u origin test_branch_name#1íšŒë§Œ í•´ì£¼ë©´ ë‹¤ìŒë¶€í„°ëŠ” ê·¸ëƒ¥ pushë¡œ ì§„í–‰ ê°€ëŠ¥ branch ë¼ë¦¬ í‘¸ì‰¬ëœ í•­ëª© í•©ì¹˜ê¸°12345678#ë‹¤ì‹œ ë©”ì¸ ì—…ìŠ¤íŠ¸ë¦¼ branchë¡œ ì´ë™(ë³´í†µ main)$git checkout main#ë³‘í•©$git merge test_branch_name$git add .$git commit -m 'we have just merged the branch'$git push branch ì‚­ì œ12345# (mergeì•ˆí•˜ê³  í•˜ë©´ ê²½ê³ ëœ¸. ë¬´ì‹œí•´ë„ ë¨)$git branch -d test_branch_name# branchë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì™„ì „íˆ ì œê±°$git push origin --delete test_branch_name","link":"/2022/12/11/Blogs_folder/2022-12-11-Git-command/"},{"title":"Github info","text":"HEADë€? ê¹ƒí—ˆë¸Œë¥¼ ì‚¬ìš©í•˜ë‹¤ë³´ë©´ HEADë¼ëŠ”ê²Œ ìì£¼ ë³´ì…ë‹ˆë‹¤. HEADë€ í•´ë‹¹ branchì˜ ë§ˆì§€ë§‰ commitì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê¹ƒí—ˆë¸Œì— ì˜¬ë¦¬ì§€ ë§ì•„ì•¼ í•  íŒŒì¼ì´ ìˆì„ ê²½ìš° ê¹ƒí—ˆë¸Œë¥¼ ì‚¬ìš©í•˜ë‹¤ë³´ë©´ ê°œì¸ì ìœ¼ë¡œ ì‘ì—… ë˜ëŠ” ë¶ˆí•„ìš”í•œ íŒŒì¼ë“¤ì´ ê¹ƒí—ˆë¸Œ í´ë”ì— ë“¤ì–´ìˆì„ ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì œì–´í•˜ë ¤ë©´ .ignoreíŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. 123456# ë””ë ‰í† ë¦¬ì—ìˆëŠ” íŒŒì¼ ì¤‘ ê¹ƒì— ì˜¬ë¦¬ê³  ì‹¶ì§€ ì•Šì€ íŒŒì¼ì´ í•„ìš”í•  ê²½ìš° ìƒì„± í›„ í¸ì§‘# ê¹ƒí—ˆë¸Œì™€ ì—°ë™ëœ íŒŒì¼ë¡œ cdë¡œ ì´ë™ í›„$touch .gitignore$open .gitignore# ex) .gitignore íŒŒì¼ì— abc.text, *.csv (ì´ëŸ°ì‹ìœ¼ë¡œ ì™€ì¼ë“œì¹´ë“œë¡œ ì„¤ì • ê°€ëŠ¥)# vim/code ê°™ì€ í…ìŠ¤íŠ¸ ì—ë””í„°ë¡œ í¸ì§‘ ì£¼ì˜í•  ì ì€ ì´ë¯¸ stage/repoì— ì˜¬ë¼ê°„ íŒŒì¼ì´ .gitignoreíŒŒì¼ì— ìˆìœ¼ë©´ ì˜¤ë¥˜ê°€ ë‚œë‹¤. 1234# ì´ëŸ° ê²½ìš° íŒŒì¼ì„ ì œê±°í•œ í›„ ì»¤ë°‹í•´ì¤€ë‹¤.$git rm file_name.md$git commit -m 'just deledted file_name.md'$git push","link":"/2022/12/11/Blogs_folder/2022-12-11-Git-info/"},{"title":"Github blog info","text":"ê¹ƒí—ˆë¸Œ í¬ìŠ¤íŒ… ì •ë³´ ì•„ë˜ì™€ ê°™ì€ ì–‘ì‹ì˜ ì •ë³´ë¥¼ ìµœìƒë‹¨ì— ì…ë ¥ì„ í•´ì•¼í•œë‹¤. 1234567891011121314---title: 'Github blog info'categories: - Blogtags: - [Blog] date: 2022-12-30updated: 2022-12-30--- ì˜¤ë¥¸ìª½ì— Contents(ëª©ì°¨)ë¥¼ ì§€ìš°ê³  ì‹¶ìœ¼ë©´ toc : falseì„ ì ê±°ë‚˜, _config.ymlì—ì„œ ì„¤ì •í•˜ë©´ ëª¨ë“  í¬ìŠ¤íŒ…ì— ì ìš©ì´ ëœë‹¤. toc_sticky : trueë¥¼ ì ìš©í•˜ë©´ í˜ì´ì§€(ìŠ¤í¬ë¡¤)ì´ ë„˜ì–´ê°€ë„ í™”ë©´ ì˜¤ë¥¸ìª½ ìƒë‹¨ìª½ì— ê³ ì •ë˜ëŠ” ê¸°ëŠ¥ì´ ì ìš©ëœë‹¤. ë§¨ ë°‘ì˜ Commentë„ ë§ˆì°¬ê°€ì§€ì´ë‹¤. ìµœìƒë‹¨ì— comments : falseë˜ëŠ” _config.ymlì—ì„œ ì„¤ì • íŠ¹ì • í¬ìŠ¤íŠ¸ë¥¼ ë©”ì¸í™”ë©´ì— ê³ ì •ì‹œí‚¤ê³  ì‹¶ìœ¼ë©´ pin : trueë¥¼ ì…ë ¥í•˜ë©´ ëœë‹¤.(ìµœê·¼ë‚ ì§œ ìš°ì„ ) ì´ë¯¸ì§€ ì‚½ì… ì´ë¯¸ì§€ë¥¼ ì‚½ì…í•˜ê¸° ìœ„í•´ì„œëŠ” image: /assets/img_folder/file.jpg ì´ëŸ°ì‹ìœ¼ë¡œ ë„£ëŠ”ë‹¤.(ë°ì´í„°ê°€ ì´ë¯¸ ê·¸ê³³ì— ìˆëŠ” ê²½ìš°) ë˜ëŠ”, ê¹ƒí—ˆë¸Œ issueì— íŒŒì¼ì„ ë“œë ˆê·¸í•˜ë©´ ì£¼ì†Œê°€ ìƒì„±ë˜ëŠ”ë° ê·¸ ì£¼ì†Œë¥¼ ì…ë ¥ì„ í•œë‹¤. {: width=â€™400â€™ class=â€™leftâ€™} ì´ë¯¸ì§€ ì£¼ì†Œ ì˜†ì— ì´ëŸ°ì‹ìœ¼ë¡œ í¬ê¸°, ìœ„ì¹˜ë¥¼ ì„¤ì • ê°€ëŠ¥í•˜ë‹¤.(normal,left,right)","link":"/2022/12/30/Blogs_folder/2022-12-30-blog-info/"},{"title":"Github ë©”ì¸í˜ì´ì§€ README.md ë°°ì§€(badge)ë¡œ ê¾¸ë¯¸ê¸°","text":"ê¹ƒí—ˆë¸Œ ë©”ì¸í˜ì´ì§€ READMEíŒŒì¼ ë…¸ì¶œ ì‹œí‚¤ê¸° ìœ„ì˜ ì‚¬ì§„ì˜ Hi there... ê°€ ì íŒ ë¬¸êµ¬ëŠ” ì œ ê¹ƒí—ˆë¸Œ ì•„ì´ë””(InhwanCho)ì™€ ë™ì¼í•œ ì´ë¦„ì˜ repo(ì €ì¥ì†Œ) InhwanChoREADME.md íŒŒì¼ì…ë‹ˆë‹¤.(ë”ë¸” í´ë¦­ëœ ë¶€ë¶„) ì˜¤ë¥¸ìª½ ìƒë‹¨ì— +ë¥¼ ëˆŒëŸ¬ì„œ New Repositoryë¥¼ í´ë¦­í•´ì„œ ì•„ì´ë””(Owner)ì™€ ë™ì¼í•œ ì´ë¦„ì˜ repoë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì•„ì´ë””ì™€ ë™ì¼í•œ ì´ë¦„ì˜ repoì— ë“¤ì–´ê°€ì„œ README.md íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë©”ì¸ í˜ì´ì§€ë¥¼ ê¾¸ë©°ì¤ë‹ˆë‹¤. ë°°ì§€(badge) ì‚¬ìš© ë°©ë²• ì¼ë‹¨ ìœ„ì˜ ì‚¬ì§„ì˜ README.md íŒŒì¼ì˜ ë°ì´í„°ì…ë‹ˆë‹¤. 123456789101112131415161718### Hi there, I'm Inhwan Cho ğŸ‘‹&lt;h3 align=&quot;center&quot;&gt;ğŸ“š my STACKSğŸ“š&lt;/h3&gt;&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Python-3766AB?style=flat-square&amp;logo=Python&amp;logoColor=white&quot;/&gt;&lt;/a&gt;&amp;nbsp &lt;br&gt; &lt;img src=&quot;https://img.shields.io/badge/TensorFlow-FF6F00?style=flat-square&amp;logo=TensorFlow&amp;logoColor=white&quot;/&gt;&lt;/a&gt;&amp;nbsp &lt;img src=&quot;https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&amp;logo=PyTorch&amp;logoColor=white&quot;/&gt;&lt;/a&gt;&amp;nbsp &lt;img src=&quot;https://img.shields.io/badge/Linux-FCC624?style=flat-square&amp;logo=Linux&amp;logoColor=white&quot;&gt;&lt;/a&gt;&amp;nbsp &lt;br&gt; &lt;img src=&quot;https://img.shields.io/badge/Visual Studio Code-007ACC?style=flat-square&amp;logo=Visual Studio Code&amp;logoColor=white&quot;&gt;&lt;/a&gt;&amp;nbsp &lt;img src=&quot;https://img.shields.io/badge/GitHub-181717?style=flat-square&amp;logo=GitHub&amp;logoColor=white&quot;&gt;&lt;/a&gt;&amp;nbsp &lt;img src=&quot;https://img.shields.io/badge/GitHub Pages-222222?style=flat-square&amp;logo=GitHub Pages&amp;logoColor=white&quot;&gt;&lt;/a&gt;&amp;nbsp &lt;br&gt; &lt;img src=&quot;https://img.shields.io/badge/Google Sheets-34A853?style=flat-square&amp;logo=Google Sheets&amp;logoColor=white&quot;&gt;&lt;/a&gt;&amp;nbsp &lt;/p&gt; ë§¨ìœ„ëŠ” ###ì˜ H3ë¬¸ë²•, ê·¸ ì•„ë˜ëŠ” html ë¬¸ë²•ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ì´ì½˜ ë° ì»¬ëŸ¬ì— ëŒ€í•œ ì •ë³´ëŠ” &lt;simpleicons&gt; ë¥¼ ë“¤ì–´ê°€ì…”ì„œ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ë“¤ì–´ ìŠ¤í…ìŠ¤ì— íŒŒì´ì¬ì„ ì…ë ¥í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ëŒ€ê´„í˜¸ [] ë¶€ë¶„ë§Œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 1https://img.shields.io/badge/[íŒŒì´ì¬ &lt;ì•„ì´ì½˜&gt;]-[ìƒ‰ìƒë„˜ë²„ &lt;#ë¹¼ê³  ì…ë ¥&gt;]?style=flat-square&amp;logo=[íŒŒì´ì¬ &lt;ê¸€ì&gt;]&amp;logoColor=[ê¸€ì ìƒ‰(ë³´í†µ white or black)]","link":"/2023/01/02/Blogs_folder/2023-01-02-gitbadges/"},{"title":"Github page ë§¨ ìœ„(íƒ­) ì•„ì´ì½˜(íŒŒë¹„ì½˜) ë³€ê²½í•˜ê¸°","text":"ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ íŒŒë¹„ì½˜ ë³€ê²½í•˜ê¸° ë³€ê²½ì„ í•˜ê³  ì‹¶ì€ ì•„ì´ì½˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë°›ëŠ”ë‹¤. _config.ymlíŒŒì¼ì˜ favicon ê²½ë¡œë¥¼ ì‚´í´ë³¸ë‹¤. https://favicon.io/ì´ ì‚¬ì´íŠ¸ png-&gt;icoë¥¼ ëˆŒëŸ¬ì„œ convertí•œë‹¤. unzipí•˜ê³  site.webmanifestíŒŒì¼ì„ ì œê±° í•˜ê³  6ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ymlíŒŒì¼ì˜ ê²½ë¡œì—ë‹¤ ì˜®ê²¨ì¤€ë‹¤. ë³€ê²½ë˜ëŠ”ë° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.","link":"/2023/01/03/Blogs_folder/2023-01-03-favicon/"},{"title":"ê¹ƒí—ˆë¸Œë¸”ë¡œê·¸ë¥¼ ë³€ê²½ í›„ ê¸°ì¡´ í˜ì´ì§€ ì”ì¡´ ì‹œ","text":"ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ê¸°ì¡´ í˜ì´ì§€ ì”ì¡´ ì‹œê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ë¥¼ jekyllì—ì„œ hexoë¡œ ë³€ê²½ í›„ë¡œì»¬ ì„œë²„ì—ì„œëŠ” ì˜ ë‚˜ì˜¤ì§€ë§Œ, ë°°í¬í›„ì— ë©”ì¸ í˜ì´ì§€ëŠ” ì¶œë ¥ì´ ì˜ ë˜ëŠ”ë°, About, Archives, Tags, Categoriesê°€ ê¸°ì¡´ì˜ ë¸”ë¡œê·¸ê°€ ì¶œë ¥ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.ê²°ë¡ ì€ ìºì‹œë¥¼ ì§€ìš°ì§€ ì•Šì•„ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤.cssë¥¼ ìˆ˜ì •í•˜ê³  ìƒˆë¡œ ê³ ì¹¨ì„ í•´ë„ ì„œë²„ì—ì„œ ìƒˆë¡œìš´ cssë¥¼ ë°›ì•„ì˜¤ëŠ”ê²ƒì´ ì•„ë‹Œ ìºì‹œì— ì €ì¥ëœ ì´ë¯¸ ìˆëŠ” ìºì‹œ íŒŒì¼ë§Œì„ ê³„ì† ë°›ì•„ì˜¤ë¯€ë¡œ ì´ëŸ° í˜„ìƒì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§¥ì—ì„œëŠ” í•´ë‹¹ í˜ì´ì§€ì—ì„œ Command + Shift + R í˜¹ì€ ìºì‹œ ì‚­ì œë¡œ í•´ê²° ê°€ëŠ¥í•©ë‹ˆë‹¤.","link":"/2023/01/13/Blogs_folder/2023-01-13-blogmoving/"},{"title":"[Github Blog] ë¸”ë¡œê·¸ ìƒì„± ì‹œ ì—ëŸ¬ ëª¨ìŒ","text":"Github.io Blog Errors error : The process '/opt/hostedtoolcache/Ruby/3.1.2/x64/bin/bundle' failed with exit code 16 bundle lock â€“add-platform x86_64-linux &lt;í„°ë¯¸ë„ì— ì…ë ¥ error : --- layout: home # Index page --- (ê¹ƒí—ˆë¸Œ í˜ì´ì§€ Actions) .github/workflows í´ë” -&gt; pages-deploy.ymlíŒŒì¼ ì—´ê¸° -&gt; branchesì—ì„œ ìê¸°ê°€ ì‚¬ìš©í•˜ëŠ” ë¸Œëœì¹˜ë¡œ ë³€ê²½ ê·¸ë˜ë„ ì•ˆë˜ë©´ github -&gt; repo -&gt; setting -&gt; pages -&gt; sourceì—ì„œ GithubActionsë¡œ ë³€ê²½ error : Process completed with exit code 1. ì½”ë“œ 1ê°œê°€ ì˜ëª»ë˜ì—ˆë‹¤ëŠ” ëœ»ì´ë‹¤. ì§ì „ì— commití–ˆë˜ íŒŒì¼ì„ ë‹¤ì‹œ ìˆ˜ì •í•´ë³´ì. ì € ì—ëŸ¬ ìœ„ì— ì•½ê°„ì˜ ì„¤ëª…ì´ ë‚˜ì™€ìˆì„í…ë° ê·¸ê²ƒì„ ìˆ˜ì •í•˜ë©´ ëœë‹¤. error : keychain errors terminalì— $git config â€“global credential.helper osxkeychain ì…ë ¥ ê·¸ë˜ë„ ì•ˆë˜ë©´ ê¹ƒí—ˆë¸Œ -&gt; settings -&gt; developer settings -&gt; Personal Access Token -&gt; Token(Classic) ë°œê¸‰ $git config â€“global user.password ghp_abcabcabcabc (ë°œê¸‰ë°›ì€ í† í° ì…ë ¥) $git config â€“list ì…ë ¥ í›„ ì œëŒ€ë¡œ ì…ë ¥ ë˜ì—ˆëŠ”ì§€ í™•ì¸. ERROR: Invalid first code point of tag name U+BC1C. í¬ìŠ¤íŠ¸.mdíŒŒì¼ì— &lt;html ë¬¸ë²•ì´ ì•„ë‹Œ ì´ëŸ° í•œê¸€ ì…ë ¥ê°’&gt;ì´ ìˆìœ¼ë©´ ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤. 1234567Error: The process '/opt/hostedtoolcache/Ruby/3.2.0/x64/bin/bundle' failed with exit code 5 at ExecState._setResult (/home/runner/work/_actions/ruby/setup-ruby/v1/dist/index.js:5371:25) at ExecState.CheckComplete (/home/runner/work/_actions/ruby/setup-ruby/v1/dist/index.js:5354:18) at ChildProcess.&lt;anonymous&gt; (/home/runner/work/_actions/ruby/setup-ruby/v1/dist/index.js:5248:27) at ChildProcess.emit (node:events:390:28) at maybeClose (node:internal/child_process:1064:16) at Process.ChildProcess._handle.onexit (node:internal/child_process:301:5) ì´ì™€ ê°™ì€ ë©”ì‹œì§€ê°€ ì¶œë ¥ ëœë‹¤ë©´ rubyì˜ ë²„ì „ì— ì˜¤ë¥˜ê°€ ìƒê²¼ì„ í™•ë¥ ì´ ë†’ë‹¤. .pages-delpy.ymlì—ì„œ rubyë²„ì „ì„ 3.1.2ë¡œ ìˆ˜ì •í•˜ë‹ˆ í•´ê²°ë˜ì—ˆë‹¤.","link":"/2022/11/19/Error_fix/2022-11-19-bloging_errors/"},{"title":"No module named &quot;torch&quot;","text":"pytorchì„¤ì¹˜ í›„ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ importì•ˆë  ê²½ìš° mac vantura OSë¥¼ ì‚¬ìš©ì¤‘ì´ë©°, ì•„ë‚˜ì½˜ë‹¤ì˜ ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì‚¬ìš©ì¤‘ì— pipí˜¹ì€ condaë¡œ ì„¤ì¹˜í–ˆì§€ë§Œ(í˜¹ì€ ì˜¤ë¥˜) íŒŒì´í† ì¹˜ ì„¤ì¹˜ í›„ ëª¨ë“ˆì´ ì—†ë‹¤ëŠ” ì—ëŸ¬ê°€ ë‚˜ì˜¤ëŠ” ê²½ìš° í„°ë¯¸ë„ì—ì„œ ê°€ìƒ í™˜ê²½ì„ íŒŒì´ì¬ 3.6ë²„ì „ìœ¼ë¡œ ë³€ê²½ (ì´ë¦„ : env_pytorch) ê·¸ ê°€ìƒ í™˜ê²½ì„ í™œì„±í™” ì‹œí‚¤ê¸° torchvision ì„¤ì¹˜ ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ importí•˜ì—¬ ì‘ë™ í™•ì¸í•´ë³´ê¸° 123conda create -n env_pytorch python=3.6conda activate env_pytorchpip install torchvision 123# ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ importí•˜ì—¬ í™•ì¸import torchimport torchvision ê·¸ë˜ë„ ì•ˆë˜ëŠ” ê²½ìš° ê²½ë¡œ ìˆ˜ì • í•„ìš” &lt;PATH&gt; ì—¬ê¸° í˜ì´ì§€ ëˆŒëŸ¬ì„œ í™•ì¸í•´ë³´ì„¸ìš”.","link":"/2022/12/03/Error_fix/2022-12-03-pytorch-installerror/"},{"title":"VScodeì—ì„œ í•œê¸€ ë²„ë²…ì„ ì˜¤ë¥˜","text":"Visual Studio Codeì—ì„œ í•œê¸€ ì‘ì„± ì‹œ ë²„ë²…ì¼ ê²½ìš°(ë²„í¼ë§)123ë³´ê¸° -&gt; ëª…ë ¹íŒ”ë ˆíŠ¸ (Shift + Command + P) -&gt; í‘œì‹œ ì–¸ì–´ êµ¬ì„± -&gt; 'í•œê¸€' ì„ íƒì»´í“¨í„° ì¬ë¶€íŒ… ì‹œ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ì‹œ 'í•œê¸€' ì„ íƒí•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤. Terminal ì°½ì—ì„œ ê¸€ìê°€ ê¹¨ì§€ê±°ë‚˜ ì‘ê²Œ ë³´ì¼ ê²½ìš°1234567iTerm -&gt; profile -&gt; text ì—ì„œ ì„œì²´ë¥¼ í™•ì¸ &gt; ì œ ê²½ìš°ëŠ” 'SourceCodePro+Powerline+Awesome Regular'ë¡œ ì„¤ì •ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤VScodeì—ì„œ ì„¤ì •ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ terminal.integrated.fontFamilyì„defalt -&gt; &quot;'SourceCodePro+Powerline+Awesome Regular'&quot;ë¡œ ì„¤ì •- í™‘ë”°ì˜´í‘œë¥¼ ì €ëŸ°ì‹ìœ¼ë¡œ 2ë²ˆì„ í•´ì¤˜ì•¼ ì ìš©ì´ ë©ë‹ˆë‹¤!!&quot;terminal.integrated.fontFamily&quot;: &quot;'SourceCodePro+Powerline+Awesome Regular'&quot; #í„°ë¯¸ë„ í°íŠ¸ì— \\'ì‚¬ìš©í•´ì¤˜ì•¼ ì ìš©ë¨","link":"/2022/12/10/Error_fix/2022-12-10-VScode(input_Korean)/"},{"title":"python error logs","text":"íŒŒì´ì¬ error log123AttributeError: Can't get attribute 'Sports_Dataset' on &lt;module '__main__' (built-in)&gt;# íŒŒì´í† ì¹˜ì˜ torch.utils.data.DataLoaderë¥¼ ë¶ˆëŸ¬ì˜¬ë•Œ ì˜µì…˜ì— num_workersì˜ ì˜µì…˜ì„ ipykenelíŒŒì¼ë¡œ ì‹¤í–‰ í•˜ê²Œ ë  ê²½ìš° ì˜¤ë¥˜ê°€ ë‚œë‹¤.# ì½”ë© í™˜ê²½ì—ì„œ ëŒë¦¬ê±°ë‚˜ num_workersì˜µì…˜ì„ ì œê±°í•˜ë©´ ì‹¤í–‰ì€ ëœë‹¤(ëŠë¦¬ë‹¤) 123ValueError: 'a' cannot be empty unless no samples are taken# random.choice(range(train_data.__len__())) ì´ëŸ° ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰ ì‹œ ì˜¤ë¥˜# print(train_data.__len__())í•˜ë©´ 0ê°’ì´ ë‚˜ì˜¬ê²ƒì´ë‹¤. í´ë˜ìŠ¤ ë˜ëŠ” í•¨ìˆ˜ì—ì„œ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•´ë³´ì openCV error log opencvëŠ” ë§¥ì—ì„œ 4.xxë²„ì „ì—ì„œëŠ” trackbarê¸°ëŠ¥ì„ ì‚¬ìš© ì‹œ ì—ëŸ¬ê°€ ë‚˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ë°©ë²•ì„ ì°¾ì•„ë´¤ì§€ë§Œ ì•„ì§ ì˜¤ë¥˜ í•´ê²°ì¤‘ ì¸ë“¯ìœ¼ë¡œ ë³´ì´ë„¤ìš”. ì°¾ì•„ë³¸ ìœ ì¼í•œ í•´ê²°ì±…ì€ ë‹¤ìš´ê·¸ë ˆì´ë“œ (23-01-13ê¸°ì¤€) 123456789# conda í™˜ê²½ ì„¤ì • í›„ì— ì§„í–‰í•˜ì…”ë„ ë©ë‹ˆë‹¤.# opencv ì œê±°python -m pip uninstall opencv-python# pip upgrade(ì´ê±° ì•ˆí•˜ë©´ ì—ëŸ¬ ë‚˜ì˜¬ í™•ë¥  ìˆìŒ)python -m pip install --upgrade pip# opencvë¥¼ ë‹¤ìš´ ê·¸ë ˆì´ë“œí•˜ê¸°python -m pip install opencv-python==3.4.14.51 ì‹¤í–‰í•˜ì—¬ ì˜ ë˜ëŠ”ì§€ í™•ì¸! openCVì˜ findContoursì—ì„œ í•´ë‹¹ ì—ëŸ¬ ë°œìƒ ì‹œ ValueError: too many values to unpack (expected 2) 12#3.ë²„ì „ì—ì„œëŠ” ê²°ê³¼ ê°’ì´ 3ê°œê°€ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì— imagesë¥¼ ë¶™ì—¬ì£¼ë©´ ì—ëŸ¬ê°€ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.images, contours, hierachy = cv2.findContours(image, mode, method)","link":"/2022/12/18/Error_fix/2022-12-18-error-logs/"},{"title":"Dacon code review","text":"ì½”ë“œ ë¦¬ë·°(ë°ì´ì½˜, ì „ì²˜ë¦¬) ë§ˆê°ëœ ëŒ€íšŒì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ ë°›ê³ , ì½”ë“œ ê³µìœ ì—ì„œ ê°„ë‹¨í•˜ê²Œ ì‚´í´ ë³¸ í›„ ìì‹ ì˜ ìŠ¤íƒ€ì¼ì´ ë§ëŠ” ì½”ë“œ(ë„ˆë¬´ ì–´ë µì§€ ì•Šì€ ì½”ë“œ)ë¥¼ ì°¾ìŠµë‹ˆë‹¤. pptíŒŒì¼ë¡œ ê°„ë‹¨í•˜ê²Œ ì½”ë“œë¥¼ ì™œ ì´ëŸ°ì‹(ê³µìœ ëœ ë°©ì‹)ìœ¼ë¡œ ì§°ëŠ”ì§€ ë³´í†µ ì„¤ëª…ì´ ë˜ìˆìŠµë‹ˆë‹¤. pptë°”ë¡œ ì•„ë˜ ì½”ë“œê°€ ê³µìœ ë˜ìˆëŠ”ë° ì˜¤ë¥¸ìª½ì— ë³´ë©´ ë‹¤ìš´ë¡œë“œê°€ ìˆëŠ”ë° í´ë¦­í•˜ì—¬ ë‹¤ìš´ë°›ìŠµë‹ˆë‹¤. jupyternotebookì„ ì´ìš©í•˜ì—¬ í•´ë‹¹ íŒŒì¼ì„ ì—´ì–´ì¤ë‹ˆë‹¤. ì¼ë‹¨ ê°„ë‹¨í•˜ê²Œ ì™œ ì´ëŸ°ì‹ìœ¼ë¡œ ì§°ê³ , ì½”ë“œ ë°©ì‹ì´ ì–´ë–¤ì‹ìœ¼ë¡œ í˜ëŸ¬ê°€ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤. ì²˜ìŒë¶€í„° ëê¹Œì§€ ì½”ë“œë¥¼ ì•ˆë³´ê³  ë¹„ìŠ·í•˜ê²Œ êµ¬ë™ë  ë•Œê¹Œì§€ ë¦¬ë·°ë¥¼ í•©ë‹ˆë‹¤. ë°ì´ì½˜(ì œì£¼ë„ ë„ë¡œ êµí†µëŸ‰ ì˜ˆì¸¡ AI ê²½ì§„ëŒ€íšŒ)1.í•¨ìˆ˜ ì„ ì–¸ì—ì„œ ëª¨ë¥´ëŠ” í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸. ëª¨ë¥´ë©´ êµ¬ê¸€ë§í•˜ì—¬ ì°¾ì•„ë³´ê¸°. 2.csv to parquet(íŒŒì¼“)ì—ì„œ íŒŒì¼“ íŒŒì¼ì„ ì™œ ì‚¬ìš©í•˜ëŠ”ì§€ êµ¬ê¸€ë§ ë° í•¨ìˆ˜ ë‹¤ì‹œ ë§Œë“¤ì–´ë³´ê¸° 123456789101112def csv_to_parquet(csv_path, save_name): df = pd.read_csv(csv_path) df.to_parquet(f'./{save_name}.parquet') del df gc.collect() print(save_name, 'Done.')# ì´ˆê¸° 1íšŒë§Œ ìˆ˜í–‰(csv-&gt;parquet)csv_to_parquet('./train.csv', 'train')csv_to_parquet('./test.csv', 'test')# parquetë¶ˆëŸ¬ì˜¤ê¸°train = pd.read_parquet('./train.parquet')test = pd.read_parquet('./test.parquet') 3.EDAëŠ” ì½”ë“œ ë¦¬ë·° ì „ì— ê°œì¸ì ìœ¼ë¡œ í•´ë³´ê³  ë‚¨ë“¤ì´ ì‚¬ìš©í•œ ë°©ì‹ ë³´ê¸°. 4.ì‹œê³„ì—´ ë°ì´í„°(datetime)ì„ ë¼ë²¨í™” í•  ìˆ˜ ìˆê²Œ ì¶”ê°€ ì—´ ìƒì„±. 1234train['base_date'] = train['base_date'].astype('str') train['year'] = train['base_date'].apply(lambda x: x[:4]).astype('int') train['month'] = train['base_date'].apply(lambda x: x[4:6]).astype('int') train['day'] = train['base_date'].apply(lambda x: x[6:8]).astype('int') 5.ì´ë²ˆ ë°ì´í„°ëŠ” trainë°ì´í„°(21ë…„7ì›”~22ë…„7ì›”)ì™€ testë°ì´í„°(22ë…„8ì›”)ì˜ ë‚ ì§œ ì°¨ì´ê°€ í¬ê¸° ë•Œë¬¸ì— 12test = train.query('month==7 and year==2022 and day&gt;15').reset_index(drop=True)train = train.query('month!=7 or year!=2022 or day&lt;=15').reset_index(drop=True) ì´ëŸ°ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆˆ ê²ƒì„ í™•ì¸ (ì°¸ê³ í•˜ì—¬ ì¶”í›„ì— ë¹„ìŠ·í•œ ë¬¸ì œ ë‚˜ì™€ë„ ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ìƒê°í•´ë³´ê¸°) 6.ë¼ë²¨ ì¸ì½”ë”© í•  ìˆ˜ ìˆëŠ” ì—´ë“¤ì„ í•œ ë²ˆì— ì¸ì½”ë”©í•˜ê¸° 123456789101112str_col = ['day_of_week','start_turn_restricted','end_turn_restricted', 'road_name','road_type','road_rating','start_node_name','end_node_name', 'start_latitude','end_latitude','start_longitude','end_longitude']for i in str_col: le = LabelEncoder() le=le.fit(train[i]) train[i]=le.transform(train[i]) for label in np.unique(test[i]): if label not in le.classes_: le.classes_ = np.append(le.classes_, label) test[i]=le.transform(test[i]) 7.íŒŒìƒ ë³€ìˆ˜ ìƒì„±(Feature Engineering) - ë§¤ìš° ì¤‘ìš” ì œê°€ ë¦¬ë·°í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•œ íŒ€ì€ ë‹¤ìŒê³¼ ê°™ì€ ë³€ìˆ˜ë¥¼ ìƒì„±í–ˆìŒì„ íŒŒì•…. ì£¼ìš” í•­ëª©ë³„ targetì˜ train ë°ì´í„°ì…‹ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ íŒŒìƒë³€ìˆ˜ë¡œ ìƒì„±! [ì‹œê°„, ì œí•œì†ë„]ë³„ target í‰ê· ì€ ë³„ë„ íŒŒìƒë³€ìˆ˜ë¡œ ìƒì„± [ì‹œê°„]ë³„ targe í‰ê· ì— ëŒ€í•œ [ì‹œê°„,ì œí•œì†ë„]ë³„ target í‰ê· ì˜ ë¹„ìœ¨ ì¶”ê°€ íŒŒìƒ ë³€ìˆ˜ëŠ” train ë°ì´í„°ì…‹ ë§Œìœ¼ë¡œ ìƒì„±í•œ ì´í›„, test ë°ì´í„°ì…‹ìœ¼ë¡œ merge train &amp; targetì„ í•©ì¹œ í›„ ë°ì´í„°ë¥¼ êµ¬í•´ì„œ ì–´ë–¤ê²Œ ë” ì¢‹ì€ì§€ íŒŒì•…í•´ë´ë„ ì¢‹ì„ë“¯í•¨ (ì•„ë§ˆ trainì´ ë” ì¢‹ì•„ì„œ trainë§Œ í•œë“¯í•©ë‹ˆë‹¤. ì´ì™€ ê°™ì€ íŒŒìƒ ë³€ìˆ˜ ìƒì„±ì€ ë¬¸ì œë“¤ì„ ë§ì´ í’€ì–´ë³´ê³  ê²½í—˜ì´ ì¶•ì ë˜ì–´ì•¼ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆì„ ë“¯í•©ë‹ˆë‹¤. ì¼ë‹¨, ì œ ê²½ìš°ëŠ” ì´ëŸ¬í•œ ì½”ë“œë“¤ì—ì„œ ì´ëŸ¬í•œ ë³€ìˆ˜ë¥¼ ì–´ë–¤ì‹ìœ¼ë¡œ ì™œ ë§Œë“¤ì—ˆëŠ”ì§€ ë¶„ì„í•´ë³´ê³ , ì¶”í›„ ì ìš©í•  ìˆ˜ ìˆì„ì§€ íŒŒì•…í•˜ëŠ” í¸ì…ë‹ˆë‹¤. 123456789101112names = ['day_of_week', 'base_hour','road_name','start_node_name','end_node_name','maximum_speed_limit','start_latitude','end_latitude','start_longitude','end_longitude']for name in names: print(name) df1 = train.groupby(name).mean().reset_index()[[name,'target']].rename(columns={'target':f'{name}_mean_target'}) train = pd.merge(train,df1,on=name,how='left') test = pd.merge(test,df1,on=name,how='left') df1 = train.groupby(['base_hour','maximum_speed_limit']).mean().reset_index()[[ 'base_hour','maximum_speed_limit','target']].rename(columns={'target':'whs_mean_target'})train = pd.merge(train,df1,on=[ 'base_hour','maximum_speed_limit'],how='left')test = pd.merge(test,df1,on=[ 'base_hour','maximum_speed_limit'],how='left') 8.null ì²˜ë¦¬, ì¹´í…Œê³ ë¦¬(ë¼ë²¨) ì²˜ë¦¬ 123456# null ì²˜ë¦¬ train = train.fillna(0)test = test.fillna(0)# ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì„ ì–¸train[str_col] = train[str_col].astype('category')test[str_col] = test[str_col].astype('category') 9.ì‹œê°„(hour)ì—´ ì²˜ë¦¬ 123456# ì‹œê°„ cos/sin ë³€í™˜ ì¶”ê°€train['cos_time'] = np.cos(2*np.pi*(train['base_hour']/24))train['sin_time'] = np.sin(2*np.pi*(train['base_hour']/24))test['cos_time'] = np.cos(2*np.pi*(test['base_hour']/24))test['sin_time'] = np.sin(2*np.pi*(test['base_hour']/24)) ì—¬ê¸°ê¹Œì§€ ì „ì²˜ë¦¬ ì½”ë“œ ë¦¬ë·°ì˜€ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶œì²˜ : ë°ì´ì½˜_ì½”ë“œê³µìœ ","link":"/2022/11/20/Personal_folder/2022-11-20-dacon-codereview/"},{"title":"Sample_codes","text":"Sample_codesparquet(ë©”ëª¨ë¦¬ ì¤„ì—¬ì¤Œ)12345678910111213import gcdef csv_to_parquet(csv_path, save_name): df = pd.read_csv(csv_path) df.to_parquet(f'./{save_name}.parquet') # df.to_parquet('train.parquet', engine='fastparquet', compression='snappy') del df gc.collect() print(save_name, 'Done.')csv_to_parquet('./train.csv', 'train')train = pd.read_parquet('./train.parquet').drop('road_in_use',axis=1)# from google.colab import files ì½”ë©ì¸ ê²½ìš°# files.download(&quot;train.parquet&quot;) queryí•¨ìˆ˜ (í•„í„°ê±°ëŠ” í•¨ìˆ˜) ì—´ì´ë¦„ ì…ë ¥1train.query('month==7 and year==2022 and day&gt;15') Labelencoding(trainê³¼ testë°ì´í„°ì˜ ê°’ì´ ë‹¤ë¥¼ ê²½ìš°)12345678910for i in str_col: le = LabelEncoder() le=le.fit(train[i]) train[i]=le.transform(train[i]) for label in np.unique(test[i]): if label not in le.classes_: le.classes_ = np.append(le.classes_, label) #np.appendí•˜ë©´ ê°’ì´ ì¶”ê°€ë˜ì–´ ì¶”ê°€ëœ ê°’ì´ ë¼ë²¨í´ë˜ìŠ¤ì— ì¶”ê°€ë˜ì–´ ë¼ë²¨ë§ë˜ëŠ” êµ¬ì¡° test[i]=le.transform(test[i]) global ë³€ìˆ˜ëª… ìƒì„±1globals()['data_{}'.format(i)]","link":"/2022/11/20/Personal_folder/2022-11-20-sample-codes/"},{"title":"JupyterNotebook ì£¼ìš” ë‹¨ì¶•í‚¤","text":"ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì£¼ìš” ë‹¨ì¶•í‚¤ a == ìœ„ì— ì…€ ìƒì„± b == ì•„ë˜ ì…€ ìƒì„± c == ì…€ ë³µì‚¬ x == ì…€ ìë¥´ê¸° v == ì…€ ë¶™ì—¬ë„£ê¸° control + shift + â€˜-â€˜ == ì…€ ë‚˜ëˆ„ê¸° shift + m == ì…€ í•©ì¹˜ê¸° dd == ì…€ ì‚­ì œ y == code ëª¨ë“œ(ì…€) m == markdown ëª¨ë“œ(ì…€) o == ì½”ë“œ ê²°ê³¼ ì ‘ê¸°(ì—´ê¸°) %lgmagic == ì…ë ¥í•˜ë©´ ì…ë ¥ì´ ê°€ëŠ¥í•œ ëª©ë¡ í™•ì¸ ê°€ëŠ¥ % ì…ë ¥ í›„ command ì…ë ¥ ê°€ëŠ¥(ì£¼í”¼í„° í™˜ê²½ ë‚´ë¶€ì—ì„œ í„°ë¯¸ë„ ì‚¬ìš©) ex) %lgmagic, %ls, %pwd, %cd ì´ë¥¼ í™œìš©í•˜ì—¬ import gcë¥¼ í•˜ì§€ ì•Šê³  ì‘ì—…ê°€ëŠ¥ %% ì…ë ¥í•˜ë©´ ì…€ ì „ì²´ command ì…ë ¥ ê°€ëŠ¥ ! ì…ë ¥í•˜ê³  ì…ë ¥í•˜ë©´ command(í„°ë¯¸ë„) ì‚¬ìš©ê°€ëŠ¥ (í„°ë¯¸ë„ê³¼ ì™„ì „ ë™ì¼) ex) !pip3 install pandas ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ ì‰½ê²Œ í˜„ì¬í´ë”(ì£¼í”¼í„°ë…¸íŠ¸ë¶)ìœ¼ë¡œ ì˜®ê¸°ê¸° terminalì„ cdëª…ë ¹ì–´ë¡œ ì£¼í”¼í„°ë…¸íŠ¸ë¶ì˜ í´ë”ë¡œ ì´ë™í•´ë‘”ë‹¤. $mv ~/Dow ê¹Œì§€ ì…ë ¥ í›„ Tapí‚¤ë¥¼ ëˆŒë¥´ê³  ë‹¤ìš´ë°›ì€ íŒŒì¼ì„ íƒ­í‚¤ë¥¼ ì´ìš©í•˜ì—¬ ì…ë ¥í•œë‹¤.-ìˆ˜ì •í•„ìš” ìŠ¤í˜ì´ìŠ¤ë°” í›„ (./)ë¥¼ ì…ë ¥í•œë‹¤. ex) mv ~/Downloads/testfile.text ./ ì´ë ‡ê²Œ ì…ë ¥í•˜ë©´ í•´ë‹¹ íŒŒì¼ì´ í˜„ì¬í´ë”ë¡œ ì˜®ê²¨ì§„ë‹¤.","link":"/2022/11/20/Mac_Fundamental_Concept/2022-11-20-jupyter-command/"},{"title":"Vim ì£¼ìš” ë‹¨ì¶•í‚¤","text":"ê°œìš” ë§¥ë¶/ë¦¬ëˆ…ìŠ¤ì˜ ì—ëŸ¬ë“¤ì„ ê²€ìƒ‰í•˜ë‹¤ë³´ë©´ vim í˜¹ì€ vi ~/.zshrc ê°™ì€ ëª…ë ¹ì–´ë“¤ì„ ì…ë ¥í•˜ë¼ëŠ” ê²Œì‹œê¸€ë“¤ì´ ë§ì´ ìˆìŠµë‹ˆë‹¤. vim/vi/nvimì€ í…ìŠ¤íŠ¸ ì—ë””í„°ë¡œ í…ìŠ¤íŠ¸íŒŒì¼ì„ í•´ë‹¹ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ í¸ì§‘í•˜ê² ë‹¤ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì²˜ìŒ ì‚¬ìš©í•´ë³´ë©´ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ê°ì´ ì•ˆì˜¤ê³  ê·¸ ì „í™”ë©´(ë©”ì¸í™”ë©´)ìœ¼ë¡œ ë‚˜ê°ˆ ìˆ˜ë„ ì—†ìŠµë‹ˆë‹¤. ì£¼ìš” ëª…ë ¹ì–´ë¥¼ í™œìš©í•˜ì—¬ ì´ ì—ë””í„°ë¥¼ ì¡°ê¸ˆ íŒŒì•…í•œë‹¤ë©´ ë³´ë‹¤ ì‰¬ìš´ ê°œë°œì„ í•  ìˆ˜ ìˆì„ê²ë‹ˆë‹¤. commandê¸°ë³¸ì ìœ¼ë¡œ excë²„íŠ¼ì„ ëˆ„ë¥¸ ìƒíƒœì—ì„œ í™œìš©(ê¸°ë³¸ ìƒíƒœ) ì´ë™ h, j, k, l: ì¢Œ,í•˜,ìƒ,ìš° ì»¤ì„œ ì´ë™ - : ì¤„ì˜ ì²˜ìŒ ìœ„ì¹˜ë¡œ ì»¤ì„œ ì´ë™ gg: ë§¨ ìœ„ë¡œ ì»¤ì„œ ì´ë™ [shift + g]: ë§¨ ì•„ë˜ë¡œ ì»¤ì„œ ì´ë™ ë‹¨ì–´ ê²€ìƒ‰ /ëˆ„ë¥´ê³  ê²€ìƒ‰ ex)/conda ì…ë ¥ ì‹œ ì—ë””í„°ì—ì„œ condaí™”ë©´ìœ¼ë¡œ ì»¤ì„œ ì´ë™enterí•œë²ˆ ì…ë ¥ í›„ ë‹¤ìŒ ë‹¨ì–´ ê²€ìƒ‰ ì‹œ enterê°€ ì•„ë‹Œ nì…ë ¥, ì „ìœ¼ë¡œ ê°€ë ¤ë©´ Nì…ë ¥ í˜„ì¬ ë³´ì´ëŠ” í˜ì´ì§€ì—ì„œ ì»¤ì„œ ì´ë™ [shift + h]: í˜„ì¬ ë³´ì´ëŠ” í˜ì´ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§¨ ìœ„ë¡œ ì»¤ì„œ ì´ë™ [shift + m]: í˜„ì¬ ë³´ì´ëŠ” í˜ì´ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ê°„ ë¼ì¸ìœ¼ë¡œ ì»¤ì„œ ì´ë™ [shift + l]: í˜„ì¬ ë³´ì´ëŠ” í˜ì´ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§¨ ì•„ë˜ë¡œ ì»¤ì„œ ì´ë™ ì „ì²´ í˜ì´ì§€ ì´ë™ \\}\\} : ì…ë ¥ ì‹œ í˜ì´ì§€ ë§¨ ì•„ë˜ë¡œ ì´ë™ \\{\\{ : ì…ë ¥ ì‹œ í˜ì´ì§€ ë§¨ ìœ„ë¡œ ì´ë™ (ì°¸ê³ ) ì—­ìŠ¬ë ˆì‹œ ì—†ì´ ì…ë ¥í•´ì•¼í•©ë‹ˆë‹¤. insert ì»¤ë§¨ë“œ i: í˜„ì¬ ì»¤ì„œê°€ ìœ„ì¹˜í•œ ë¬¸ìì˜ ì•ì— Insert í•˜ê¸° I: í˜„ì¬ ì»¤ì„œê°€ ìœ„ì¹˜í•œ ì¤„ ë§¨ ì•ì— Insert í•˜ê¸° a: í˜„ì¬ ì»¤ì„œê°€ ìœ„ì¹˜í•œ ë¬¸ìì˜ ë’¤ì— Insert í•˜ê¸° A: í˜„ì¬ ì»¤ì„œê°€ ìœ„ì¹˜í•œ ì¤„ ë§¨ ë’¤ì— Insert í•˜ê¸° O: í˜„ì¬ ì»¤ì„œê°€ ìœ„ì¹˜í•œ ì¤„ ë°”ë¡œ ìœ—ì¤„ì— Insert í•˜ê¸° o: í˜„ì¬ ì»¤ì„œê°€ ìœ„ì¹˜í•œ ì¤„ ë°”ë¡œ ì•„ë«ì¤„ì— Insert í•˜ê¸° ì‚­ì œ ì»¤ë§¨ë“œ dd : ì»¤ì„œê°€ ìˆëŠ” ì¤„ ì‚­ì œ ì €ì¥ ë° ì¢…ë£Œ ì»¤ë§¨ë“œ excëˆ„ë¥´ê³  : ë¥¼ ì…ë ¥ì‹œ ë§¨ì•„ë˜ì— ì½”ë§¨ë“œ ì…ë ¥ ê°€ëŠ¥ :w ì €ì¥ :wq ì €ì¥ í›„ í…ìŠ¤íŠ¸ì—ë””í„° ì¢…ë£Œ(í„°ë¯¸ë„ë¡œ ì´ë™) :q ì €ì¥ í•˜ì§€ ì•Šê³  ì¢…ë£Œ :wq! ì €ì¥ í›„ í…ìŠ¤íŠ¸ì—ë””í„°ë¥¼ ê°•ì œ ì¢…ë£Œ","link":"/2022/11/20/Mac_Fundamental_Concept/2022-11-20-vim-command/"},{"title":"í„°ë¯¸ë„ì—ì„œ pipìœ¼ë¡œ ì„¤ì¹˜í•œ íŒŒì¼ì´ ì—´ë¦¬ì§€ ì•ŠëŠ” ê²½ìš°","text":"Shell(í„°ë¯¸ë„)ì—ì„œ pipìœ¼ë¡œ ì„¤ì¹˜í•œ íŒŒì¼ì´ ì—´ë¦¬ì§€ ì•ŠëŠ” ê²½ìš° ë¦¬ëˆ…ìŠ¤ì™€ ë§¥ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. 1.ì£¼í”¼í„° ë…¸íŠ¸ë¶(ë©)ì—ì„œ í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰ í•©ë‹ˆë‹¤. 123456import syssys.executable# ì¶œë ¥ ê²°ê³¼ ì˜ˆì‹œ'/opt/homebrew/Cellar/jupyterlab/3.4.8/libexec/bin/python3.10' ì´ ê²°ê³¼ê°€ pip ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜(ì‹¤í–‰) ì‹œì˜ ê²½ë¡œì…ë‹ˆë‹¤. 2.í„°ë¯¸ë„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. 3.í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. 12bashì‚¬ìš©ìë©´ vim ~/.bashrc zshë¼ë©´ zshrc vim ~/.zshrc 4.í‚¤ë³´ë“œ í™”ì‚´í‘œ ì•„ë˜ ë²„íŠ¼ì„ ë§¨ ì•„ë˜ í™”ë©´ì´ ë‚˜ì˜¬ë•Œê¹Œì§€ ë‚´ë¦° í›„ ië¥¼ ëˆ„ë¥´ê³  í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ë¶™ì—¬ì¤ë‹ˆë‹¤. ì•„ë˜ì˜ ëª…ë ¹ì–´ëŠ” ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ë‚˜ì˜¨ ê²½ë¡œë¥¼ PATHë¡œ ì„¤ì •í•˜ëŠ”ê²ë‹ˆë‹¤. 12345export PATH='/opt/homebrew/Cellar/jupyterlab/3.4.8/libexec/bin/python3.10:PATH'ë˜ëŠ”export PATH=/opt/homebrew/Cellar/jupyterlab/3.4.8/libexec/bin/python3.10:$PATH 5.ì‘ì„± í›„:ë¥¼ ì…ë ¥ í›„ wqë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤. vimëª…ë ¹ì–´ë¥¼ í†µí•´ vim text editorë¥¼ ì‚¬ìš©í•˜ì—¬ ê²½ë¡œ ì„¤ì •ì„ í•´ì¤€ê²ë‹ˆë‹¤. vim ì—ë””í„°ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ë””í„°ë¡œ(nano, code ë“±) ìˆ˜ì •í•´ì£¼ì…”ë„ ë¬´ë°©í•©ë‹ˆë‹¤. ì¤‘ë³µ ê²½ë¡œë¥¼ ì œê±°í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰ 1PATH=$(echo -n $PATH | awk -v RS=: '!($0 in a) {a[$0]; printf(&quot;%s%s&quot;, length(a) &gt; 1 ? &quot;:&quot; : &quot;&quot;, $0)}')","link":"/2022/12/07/Mac_Fundamental_Concept/2022-12-07-PATH(shell)/"},{"title":"Terminal ì‚¬ìš© Tips","text":"í„°ë¯¸ë„ ëª…ë ¹ì–´ Tips ë‹¤ìš´ë¡œë“œ(finder)íŒŒì¼ì„ ëˆ„ë¥´ê³  cd ë’¤ë¡œ ë“œë ˆê·¸ë¡œ ì˜®ê²¨ì„œ ì—¬ëŠ”ê²ƒë„ ê°€ëŠ¥(ì¶”í›„ ìŠ¤í¬ë¦°ìƒ·) í™”ë©´ ì„¸ë¡œ ë¶„í•  command + d, ë¶„í•  í•´ì œ command + shift + d ìƒˆë¡œìš´ í„°ë¯¸ë„ command + n ì†ì„± ë³´ê¸° command + i (í™”ë©´ ìƒ‰ìƒ ë° ì •ë³´ í™•ì¸) í„°ë¯¸ë„ íƒ­ ë‹«ê¸° command + w í„°ë¯¸ë„ ëª¨ë“  íƒ­ ë‹«ê¸° command + q ëª¨ë“  íƒ­ ë³´ê¸° ë˜ëŠ” íƒ­ ê°œìš” ì¢…ë£Œ command + shift + \\ â€˜â†‘â€™ í™”ì‚´í‘œ ëˆ„ë¥´ë©´ ì „ì— ì…ë ¥í–ˆë˜ ëª…ë ¹ì–´ ë¶ˆëŸ¬ì˜¤ê¸° ê°€ëŠ¥ ëª‡ ê°œì˜ ë‹¨ì–´ ì…ë ¥ í›„ Tapí‚¤ ëˆ„ë¥´ë©´ ìë™ ì™„ì„± ê¸°ëŠ¥ì´ ìˆ˜í–‰ë˜ì–´ ì‘ì—…ì´ í¸í•´ì§ ex) cd ê°™ì€ ëª…ë ¹ì–´ ë’¤ì— tapí‚¤ ëˆ„ë¥´ë©´ ì„ íƒì§€ì—ì„œ ì„ íƒ ê°€ëŠ¥ control + â€˜uâ€™ &lt; í„°ë¯¸ë„ì— ì“°ê³  ìˆë˜ íƒ€ì´í•‘ ì „ì²´ ì§€ìš°ê¸° . current directory(í˜„ì¬ í´ë”) .. previous directory(ì „ í´ë”) ~ í´ë” ììœ ë¡­ê²Œ ì°¸ì¡°í• ë•Œ ë°”íƒ•í™”ë©´ íŒŒì¼ ì „ì²´ ìˆ¨ê¹€ (ë°°ê²½ ê¹”ë”í•œê±° ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ. ê¸°ë³¸ ë°°ê²½ë§Œ ë‚˜ì˜´) Defaults write com.apple.finder CreateDesktop false &amp;&amp; killall Finder(í•´ì œí•˜ë ¤ë©´ falseì—ì„œ trueë¡œ ë³€ê²½) Control + â€˜aâ€™ == ë§¨ ì™¼ìª½ìœ¼ë¡œ ì»¤ì„œ ì´ë™ Control + â€˜eâ€™ == ë§¨ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì»¤ì„œ ì´ë™","link":"/2022/11/22/Mac_Fundamental_Concept/2022-11-22-termianl-tips/"},{"title":"Terminal ì£¼ìš” ë‹¨ì¶•í‚¤","text":"ë§¥ë¶ terminal ëª…ë ¹ì–´ í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸ pwd/Users/inhwan/ í˜„ì¬ ë””ë ‰í† ë¦¬ íŒŒì¼ë¦¬ìŠ¤íŠ¸ ë³´ê¸° ls, ìˆ¨ê¹€ íŒŒì¼ê¹Œì§€ í™•ì¸ í•  ê²½ìš° ls -la lsLICENSE _config.ymlls -la-rw-râ€“râ€“ 1 inhwan staff 227 11 19 09:40 .editorconfigdrwxr-xr-x 15 inhwan staff 480 11 21 23:02 .git ë””ë ‰í† ë¦¬(í´ë”) ì´ë™ cd cd/Users/inhwan/ &lt;- ìœ¼ë¡œ ì´ë™ë¨(ê¸°ë³¸ ë””ë ‰í† ë¦¬)cd Music~/Music &lt;-ìœ¼ë¡œ í´ë” ì´ë™cd ../Users/inhwan/ &lt;- ì „ í´ë”ë¡œ ì´ë™í•¨ ë””ë ‰í† ë¦¬(í´ë”) ìƒì„± mkdir test_foldertouch test_folder/ &lt;- ìœ„ì™€ ë™ì¼test_folderê°€ í˜„ìœ„ì¹˜(pwd)ì— ìƒì„± íŒŒì¼ ìƒì„± touch test_file.mdtouch test_folder/test_file.txt &lt;- ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ê°€ëŠ¥ ë””ë ‰í† ë¦¬(í´ë”) ë° íŒŒì¼ ì‚­ì œ rmdir test_folder &lt;- ë¹ˆ í´ë”ë§Œ ì‚­ì œ ê°€ëŠ¥rm -R test_folder &lt;- ë¹ˆ í´ë”&amp;íŒŒì¼ ê°•ì œ ì‚­ì œrm -rf test_folder &lt;- ìœ„ì™€ ê°•ì œ ë™ì¼rm test_file.md &lt;- íŒŒì¼ ì‚­ì œ ë””ë ‰í† ë¦¬(í´ë”) ë° íŒŒì¼ ì´ë™ mv test_file.md test_folder/ ë””ë ‰í† ë¦¬(í´ë”) ë° íŒŒì¼ ì´ë¦„ ë³€ê²½ mv test_file.md test_folder/test_rename.mdmv test_folder/ test_folder_rename íŒŒì¼ ì—´ê¸° open test_file.mdopen test_folder/test_rename.md íŒŒì¼ ë³µì‚¬ cp test_file.md new_file.md ëª…ë ¹ì–´ ì…ë ¥ ê¸°ë¡ í™•ì¸ history 2645 ls 2646 cd Music 2647 cd íŒŒì¼ ë‚´ìš© í™•ì¸ cat test_file.md íŒŒì¼ ë‚´ìš© ìˆ˜ì •(í…ìŠ¤íŠ¸ ì—ë””í„°) vim test_file.txtnano test_file.txtì´ê²ƒë“¤ì— ëŒ€í•´ì„œëŠ” ë”°ë¡œ í¬ìŠ¤íŒ…ì„ í•˜ì˜€ìœ¼ë©° ì°¸ê³ .(ìƒê°ë³´ë‹¤ ì´ˆê¸°ì— ì ‘ê·¼ì´ ì‰½ì§€ ì•ŠìŒ) ë””ë ‰í† ë¦¬(í´ë”) ë° íŒŒì¼ ìœ„ì¹˜ ì°¾ê¸° which python/opt/anaconda3/bin/python íŒŒì¼ ìœ„ì¹˜ ì°¾ê¸° find .(í˜„ì¬ ë””ë ‰í† ë¦¬) -type f -name 'test_1.text'ë§Œì•½ ì •í™•í•œ íŒŒì¼ ì´ë¦„ì„ ëª¨ë¥´ë©´ *(ì™€ì¼ë“œì¹´ë“œ) ì‚¬ìš© ê°€ëŠ¥ex)find . -type f -name 'test*' í„°ë¯¸ë„ í™”ë©´ ì´ˆê¸°í™” clearí˜¹ì€ command + 'k' ì…ë ¥ í„°ë¯¸ë„ì—ì„œ ì‘ì„± ì¤‘ì¸ ê¸€ ì§€ìš°ê¸° control + 'U' ì…ë ¥","link":"/2022/11/22/Mac_Fundamental_Concept/2022-11-22-mac-command/"},{"title":"Anaconda ê°€ìƒ í™˜ê²½","text":"í„°ë¯¸ë„ë¡œ ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ ì„¤ì •í•˜ê¸° ê°€ìƒí™˜ê²½ ë¦¬ìŠ¤íŠ¸ í™•ì¸í•˜ê¸° 1conda env list ê°€ìƒí™˜ê²½ ì´ë¦„ â€˜name_of_conda_envâ€™ ì‹¤í–‰ 1conda env activate name_of_conda_env ê°€ìƒí™˜ê²½ ì¢…ë£Œ(ê¸°ë³¸ìœ¼ë¡œ ëŒì•„ì˜´) 1conda env deactivate ê°€ìƒí™˜ê²½ name_of_conda_envì— ì„¤ì¹˜ëœ ëª©ë¡ í™•ì¸ 1conda list -n name_of_conda_env ê°€ìƒí™˜ê²½ ìƒì„± 1234conda create --name name_of_conda_env# íŠ¹ì • ë²„ì „ì˜ í™˜ê²½ ìƒì„±conda create -n name_of_conda_env_3.6 python=3.6 ê°€ìƒí™˜ê²½ ì œê±° 1conda remove --name name_of_conda_env ë§Œì•½ iterm2ë¥¼ ì„¸íŒ…í•´ë’€ìœ¼ë©´ í„°ë¯¸ë„ ì˜¤ë¥¸ìª½ì— ê°€ìƒí™˜ê²½ì´ ì–´ë””ë¡œ ì…‹ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.","link":"/2022/12/10/Mac_Fundamental_Concept/2022-12-10-conda-env/"},{"title":"wget ì‚¬ìš©ë²•","text":"wget ì‚¬ìš©ë²•1234567# ì˜µì…˜ê³¼ urlì˜ ìœ„ì¹˜ëŠ” ë°”ê¿”ì„œ ì‚¬ìš©í•´ë„ ìƒê´€ ì—†ìŒ.$wget [options] [url]# ì˜ˆì‹œ$wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 -O Flickr8k_dataset.zip==$wget -O Flickr8k_dataset.zip https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 wgetì˜ ì˜µì…˜ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì‚¬ì´íŠ¸ ê±´ë„ˆë›°ê¸° --no-check-certificate ì˜µì…˜ì„ ì‚¬ìš© 12$wget --no-check-certificate https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 ì „ì²´ ì›¹ ì‚¬ì´íŠ¸ë¥¼ ë¯¸ëŸ¬ë§í•˜ëŠ” ë°©ë²• -mì˜µì…˜ìœ¼ë¡œ ë¯¸ëŸ¬ë§ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì´ë¥¼ ì´ìš©í•´ ëª¨ë“  ì›¹ì‚¬ì´íŠ¸ì˜ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1$wget -m https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 íŒŒì¼ì˜ ì €ì¥ ì´ë¦„ ì„¤ì •(íŒŒì¼ì„ ë®ì–´ ì”Œì›€) -O ì˜µì…˜ìœ¼ë¡œ ê²°ê³¼ íŒŒì¼ì„ ì§€ì •í•˜ë©´ ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  íŒŒì¼ì— ë®ì–´ì“°ê¸° í•©ë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ ì•ì— ê²½ë¡œë¥¼ ì„¤ì •í•˜ë©´ ê²½ë¡œì— ë°ì´í„°ê°€ ë‹¤ìš´ë°›ì•„ì§‘ë‹ˆë‹¤. 1$wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 -O Flickr8k_dataset.zip ì €ì¥ ìœ„ì¹˜ ì„¤ì • -P ì˜µì…˜ìœ¼ë¡œ ì €ì¥ ìœ„ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë‹¤ë§Œ -Oì˜µì…˜ì— ê²½ë¡œë¥¼ ì„¤ì •í•˜ëŠ”ê²Œ ì¼ë°˜ì ì…ë‹ˆë‹¤. 1$wget -O data/Flickr8k_dataset.zip https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 ì´ì–´ì„œ ë‹¤ìš´ë¡œë“œ ì˜µì…˜ -c ì˜µì…˜ìœ¼ë¡œ ì´ì–´ì„œ ë‹¤ìš´ë¡œë“œê°€ ê°€ëŠ¥í•˜ê²Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ë°›ê¸°ì—ì„œëŠ” íŒŒì¼ì´ë¦„ ë’¤ì— .1ì´ ì¶”ê°€ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ .1ì´ ì´ë¯¸ ìˆìœ¼ë©´ .2ê°€ ì¶”ê°€ë©ë‹ˆë‹¤. 1$wget -c https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1","link":"/2022/12/27/Mac_Fundamental_Concept/2022-12-27-wget/"},{"title":"Mac ì‚¬ìš© Tips","text":"Macì—ì„œ ìœˆë„ìš° í™”ë©´ì„ ì—¬ëŸ¬ ì°½ìœ¼ë¡œ ë„ì–´ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë³´í†µ Command + Tap ì‚¬ìš©í•˜ë©´ ë‹¤ë¥¸ ì°½ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆì§€ë§Œ, ê°™ì€ í”„ë¡œê·¸ë¨ì¼ ê²½ìš° ë¶ˆê°€ëŠ¥í•˜ë‹¤. ì´ ê²½ìš° Command + â‚© Command ë²„íŠ¼ + ìˆ«ì 1 ì™¼ìª½ì˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê°™ì€ í”„ë¡œê·¸ë¨ì˜ ë‹¤ë¥¸ ì°½ì´ ì—´ë¦½ë‹ˆë‹¤.(ë³´í†µ ë“€ì–¼ëª¨ë‹ˆí„° ì‚¬ìš© ì‹œ ë§¤ìš° ìœ ìš©) í„°ë¯¸ë„ì„ ìì£¼ ì‚¬ìš©í•œë‹¤ë©´ Iterm2 ì„¤ì¹˜ë¥¼ ì¶”ì²œ Iterm2ì™€ powerlevel10kê·¸ë¦¬ê³  oh my zshë¥¼ ì„¤ì¹˜í•˜ë©´ ëª…ë ¹ì–´ ì‚¬ìš©ì´ ë¬´ì²™ í¸í•´ì§„ë‹¤.(ê´€ë ¨ ìë£Œ ê²€ìƒ‰í•´ë³´ì„¸ìš”) ìœˆë„ìš°ì˜ delete ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ fn + backspace(ë’¤ë¡œê°€ê¸° ë²„íŠ¼) ë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤. ì œê±°í•œ ì¸í„°ë„·(í¬ë¡¬, ì‚¬íŒŒë¦¬) ì°½ì˜ íƒ­ì„ ë³µêµ¬ command + shift + 't' ì„ ëˆ„ë¥´ë©´ ë©ë‹ˆë‹¤. ê²½ë¡œ ì„¤ì •1234. í˜„ì¬ ë””ë ‰í† ë¦¬.. ë¶€ëª¨ ë””ë ‰í† ë¦¬/ ìµœìƒìœ„ root~ í™ˆ(HOME, ë©”ì¸)","link":"/2022/12/14/Mac_Fundamental_Concept/2022-12-14-Mac-basic/"},{"title":"ì œ PCì˜ ì„¸íŒ…","text":"VScode ì„¤ì • command + ,ëˆ„ë¥´ë©´ Settingìœ¼ë¡œ ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŒ ì œ ì„¸íŒ…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 123456789101112131415161718192021{ &quot;git.autofetch&quot;: true, #ê¹ƒí—ˆë¸Œ ìë™ &quot;workbench.colorTheme&quot;: &quot;One Dark Pro Mix&quot;, #í™”ë©´ ì»¬ëŸ¬ &quot;workbench.iconTheme&quot;: &quot;ayu&quot;, #íƒìƒ‰ê¸° ì•„ì´ì½˜ &quot;workbench.settings.editor&quot;: &quot;json&quot;, #ì„¤ì •ì„ jsonìœ¼ë¡œ ë°”ê¾¸ëŠ” ê¸°ëŠ¥(í˜„ì¬) &quot;workbench.settings.openDefaultSettings&quot;: true, &quot;workbench.settings.useSplitJSON&quot;: true, &quot;editor.fontSize&quot;: 13, &quot;editor.fontWeight&quot;: &quot;normal&quot;, &quot;debug.console.fontSize&quot;: 13, &quot;terminal.integrated.fontSize&quot;: 13, &quot;markdown.preview.fontSize&quot;: 13, &quot;editor.codeActionsOnSave&quot;: { &quot;source.fixAll.markdownlint&quot;: true } &quot;editor.minimap.enabled&quot;: false, #VScode ì˜¤ë¥¸ìª½ ìœ„í¸ì— ë§µì²˜ëŸ¼ ë³´ì´ëŠ” ë¯¸ë‹ˆë§µ ì œê±° &quot;terminal.integrated.fontFamily&quot;: &quot;'SourceCodePro+Powerline+Awesome Regular'&quot;, #í„°ë¯¸ë„ í°íŠ¸ì— \\'ì‚¬ìš©í•´ì¤˜ì•¼ ì ìš©ë¨ &quot;terminal.external.osxExec&quot;: &quot;iTerm.app&quot;, #í„°ë¯¸ë„ -&gt; iTerm &quot;terminal.explorerKind&quot;: &quot;external&quot;, #internalì´ ì•„ë‹ˆë¼ ì™¸ë¶€(iTerm) &quot;terminal.integrated.shell.osx&quot;: '/bin/zsh', #zshë¼ê³  í•´ë„ë¨ Colab ì„¤ì • High Contrast Darkê°€ ê°€ì¥ ë³´ê¸° í¸í•œê±° ê°™ìŠµë‹ˆë‹¤. 12345678910111213{ 'í…Œë§ˆ' : 'Dark', 'í¸ì§‘ê¸° ìƒ‰ìƒ' : 'High Contrast Dark', 'í¸ì§‘ê¸° í‚¤ë°”ì¸ë”©' : 'default', 'ê¸€ê¼´ í¬ê¸°' : 14, 'ì½”ë“œ ëœë”ë§' : 'monospace', 'ì„¸ë¡œ ëˆˆê¸ˆì ì—´' : 80, 'ì½”ë“œ ìë™ì™„ì„±' : false, 'í–‰ë²ˆí˜¸ í‘œì‹œ' : true, 'ë“¤ì—¬ì“°ê¸° ê°€ì´ë“œ' : true, 'ì½”ë“œì…€ ìë™ìœ¼ë¡œ ê´„í˜¸ ë‹«ê¸°' : true, 'enterë¡œ ì œì•ˆ ìˆ˜ë½' : true,} zshrc ê¸°ë¡(ë°±ì—…ìš©) 123456789101112131415161718192021222324252627282930313233343536373839404142434445if [[ -r &quot;${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-${(%):-%n}.zsh&quot; ]]; then source &quot;${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-${(%):-%n}.zsh&quot;fiexport ZSH=&quot;$HOME/.oh-my-zsh&quot;ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;plugins=( git zsh-autosuggestions )source $ZSH/oh-my-zsh.sh[[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh[[ -d ~/.rbenv ]] &amp;&amp; \\ export PATH=${HOME}/.rbenv/bin:${PATH} &amp;&amp; \\ eval &quot;$(rbenv init -)&quot;# Install Ruby Gems to ~/gemsexport GEM_HOME=&quot;$HOME/gems&quot;export PATH=&quot;$HOME/gems/bin:$PATH&quot;export PATH=&quot;$PATH:/Applications/Visual Studio Code.app/Contents/Resources/app/bin&quot;code () { VSCODE_CWD=&quot;$PWD&quot; open -n -b &quot;com.microsoft.VSCode&quot; --args $* ;}export PATH=&quot;/opt/anaconda3/bin:PATH&quot;# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;# !! Contents within this block are managed by 'conda init' !!__conda_setup=&quot;$('/opt/anaconda3/bin/conda' 'shell.zsh' 'hook' 2&gt; /dev/null)&quot;if [ $? -eq 0 ]; then eval &quot;$__conda_setup&quot;else if [ -f &quot;/opt/anaconda3/etc/profile.d/conda.sh&quot; ]; then . &quot;/opt/anaconda3/etc/profile.d/conda.sh&quot; else export PATH=&quot;/opt/anaconda3/bin:$PATH&quot; fifiunset __conda_setup# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;export CONDA_AUTO_ACTIVATE_BASE=false","link":"/2022/12/29/Mac_Fundamental_Concept/2022-12-29-editor-setting/"},{"title":"ë¯¸ë‹ˆí”„ë¡œì íŠ¸ part 2","text":"Classification using Swin Transformer ì´ë²ˆ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ì›¹í¬ë¡¤ë§ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì €ì¥ -&gt; ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(Swin Transformerëª¨ë¸ì„ ì´ìš©í•œ íŒŒì¸ íŠœë‹) -&gt; ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° + êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ &amp; ì‚­ì œ(+ì •ë ¬) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251import torchvisionimport torchfrom PIL import Image, ImageFilterimport osimport numpy as npimport matplotlib.pyplot as pltimport randomfrom torch.utils.data import Dataset, DataLoaderimport torch.nn as nnimport torchvision.transforms as transformsimport cv2import globimport mathfrom einops import rearrange #ì°¨ì› ê´€ë¦¬ ëª¨ë“ˆimport timm # íŒŒì¸íŠœë‹ëª¨ë“ˆfrom tqdm.notebook import tqdm# configurationdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')num_epochs = 10lr = 0.001batch_size = 32num_workers = 4 # ipykenelì—ì„œëŠ” ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ì•¼ë©ë‹ˆë‹¤(ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜)# zipíŒŒì¼(archive) í•´ì œí•˜ê¸°import zipfilezip_file=zipfile.ZipFile('/content/drive/MyDrive/lesson_data/archive.zip')#íŒŒì¼ ì´ë¦„zip_file.extractall(path='/content/data')#ì••ì¶• í•´ì œ ê²½ë¡œ, default(path=None)# í´ë˜ìŠ¤(íƒ€ê²Ÿ) ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°class_names = os.listdir('./data/train/') #í´ë” ì´ë¦„ == í´ë˜ìŠ¤(target) ë„¤ì„class_names.sort()class_len = len(class_names) # Dataset í´ë˜ìŠ¤ ë§Œë“¤ê¸°class Sports_Dataset(Dataset): def __init__(self, data_name): #data_name will be set 'train' or 'valid'(the folder names) self.dataname = data_name #trainíŒŒì¼ ê²½ë¡œë¦¬ìŠ¤íŠ¸ ìƒì„± self.img_path = [] #ê²½ë¡œê°€ .jpg í™•ì¥ìì¸ íŒŒì¼ë“¤ì„ img_pathì— ë¦¬ìŠ¤íŠ¸í™” ì‹œì¼œì¤Œ for name in class_names: self.img_path.append(glob.glob(f'./data/{data_name}/{name}/*jpg')) #2ì°¨ì› ë¦¬ìŠ¤íŠ¸ -&gt; 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ self.img_path = sum(self.img_path, []) #trainíŒŒì¼ì˜ labels ìƒì„± self.labels = [] for path in self.img_path: self.labels.append(class_names.index(path.split('/')[3])) #í…ì„œíƒ€ì…ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ë³€ìˆ˜ ìƒì„± self.img_transpose = transforms.Compose([transforms.ToTensor()]) def __getitem__(self, index): img = Image.open(self.img_path[index]) # swin_base_patch4_window7_224ëª¨ë¸ì´ 224,224ë¡œ íŠ¸ë ˆì´ë‹ ëœ ëª¨ë¸ì´ë¼ì„œ # ì´ë¯¸ì§€ ë³´ê°„ë²•ì„ ì´ìš©í•˜ì—¬ (224,224)ì‚¬ì´ì¦ˆë¡œ ë³€ê²½ if img.size != (224,224): img = img.resize((224,224),Image.Resampling.BILINEAR) # Data augmentation with PIL when only 'train set' if self.dataname == 'train': if random.uniform(0,1) &lt; 0.3 or img.getbands() == 'L': img = img.convert('L').convert('RGB') # Random crop with size (64,64) from 30% if random.uniform(0,1) &lt; 0.3 : img = img.resize((224+64,224+64), Image.Resampling.BILINEAR) x = random.randrange(0,64) y = random.randrange(0,64) img = img.crop((x,y,x+224, y+224)) # Random Gaussian blur from 20% if random.uniform(0,1) &lt; 0.2: img = img.filter(ImageFilter.GaussianBlur(random.uniform(0.5,1.2))) # Random flip from 30% if random.uniform(0,1) &lt; 0.3: img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT) else : img = img.convert('RGB') lbl = self.labels[index] lbl = torch.tensor(lbl) img = self.img_transpose(img) return img, lbl #Sports_Dataset[0] == img, Sports_Dataset[1] == lbl(ë°ì´í„° ì‚¬ìš© ë°©ì‹) def __len__(self): return len(self.img_path)# ì´ë¯¸ì§€ 8ê°œ í™•ì¸ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì‘ë™ ìœ ë¬´ í™•ì¸(ì‹¤í–‰í•˜ì§€ ì•Šì•„ë„ ëª¨ë¸ë§ì—ëŠ” ì§€ì¥ì€ ì—†ìŒ)train_dataset = Sports_Dataset('train')print(train_dataset.__len__())_, ax = plt.subplots(2, 4, figsize=(16,10))for i in range(8): data = train_dataset.__getitem__(random.choice(range(train_dataset.__len__()))) image = data[0].cpu().detach().numpy().transpose(1, 2, 0) * 255 # .cpu() == GPU ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ì ¸ ìˆëŠ” tensorë¥¼ cpu ë©”ëª¨ë¦¬ë¡œ ë³µì‚¬í•˜ëŠ” method # .detach() == Returns a new Tensor # detach,cpu ìˆœì„œëŠ” ë³„ë¡œ ìƒê´€ ì—†ë‹¤. image = image.astype(np.uint32) #uintëŠ” 0ì„í¬í•¨í•œ ì–‘ìˆ˜ë¡œëœ ì •ìˆ˜íƒ€ì… label = data[1] ax[i//4][i-(i//4)*4].imshow(image) ax[i//4][i-(i//4)*4].set_title(class_names[label])# í•™ìŠµëœ ëª¨ë¸ ì¤‘ swin_base_patch4_window7_224ë¥¼ ì‚¬ìš©(íŒŒì¸íŠœë‹)model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)model.head = nn.Sequential(nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(0.3), nn.Linear(512, class_len)) model = model.to(device)criterion = timm.loss.LabelSmoothingCrossEntropy() # this is better than nn.CrossEntropyLosscriterion = criterion.to(device)optimizer = torch.optim.AdamW(model.head.parameters(), lr=lr) # Setting for transfer learning#ë°ì´í„° ì •ì œtrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)val_dataset = Sports_Dataset('valid')val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)#training (ì‹¤í–‰ ì „ì— netí´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±í•´ì£¼ê¸°!)def update_lr(optimizer, lr): for param_group in optimizer.param_groups: param_group['lr'] = lrmodel.train()total_step = len(train_loader)curr_lr = lrbest_score = 0for epoch in range(2): total_loss = 0 for i, (images,labels) in enumerate(tqdm(train_loader)): images = images.to(device) labels = labels.to(device) g_labels = model(images) loss = criterion(g_labels,labels) optimizer.zero_grad() loss.backward() optimizer.step() total_loss += loss.item() if (i+1) % 100 == 0: print(f'{batch_size*(i+1)} / {train_dataset.__len__()}') model.eval() score = 0 for i, (images, labels) in enumerate(valid_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) score += int(torch.max(g_labels, 1)[1][0] == labels[0]) print(f'Epoch : {epoch+1}, Loss : {total_loss/total_step}') avg = score / len(val_dataset) print(f'Accuracy : {avg :.2f}\\n') model.train() if best_score &lt; avg: best_score = avg if not os.path.exists('./nets'): os.mkdir('./nets') torch.save(model.state_dict(), 'nets/SwinTransformer.ckpt') #net í´ë”ë¥¼ ë§Œë“¤ì–´ì•¼í•¨ if (epoch+1) %2 == 0: curr_lr = lr * 0.8 update_lr(optimizer, curr_lr)#ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°model.eval()model.load_state_dict(torch.load('nets/SwinTransformer.ckpt', map_location=device))test_dataset = Sports_Dataset('test')test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)# accuracy í™•ì¸ í•˜ê¸°preds = []gts = []score = 0for i, (images, labels) in enumerate(test_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) pred = torch.max(g_labels, 1)[1][0].item() preds.append(pred) gt = labels[0].item() gts.append(gt) score += int(pred == gt)avg = score / len(val_dataset)print('Accuracy: {:.4f}\\n'.format(avg))#í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€(ëœë¤ 8ê°œ)test_dataset = Sports_data('test')test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)_, ax = plt.subplots(2, 4, figsize=(16,10))for i in range(8): data = test_dataset.__getitem__(np.random.choice(range(test_dataset.__len__()))) image = data[0].cpu().detach().numpy().transpose(1, 2, 0) * 255 image = image.astype(np.uint32) label = data[1] idx = torch.max(model(data[0].unsqueeze(0).to(device)), 1)[1][0].item() ax[i//4][i-(i//4)*4].imshow(image) ax[i//4][i-(i//4)*4].set_title('Predict: {}\\nGT: {}'.format(class_names[idx], class_names[label]))# ë…¹ìƒ‰: perfect score / ë¹¨ê°„ìƒ‰: imperfect score(ì–´ë–¤ ì¢…ëª©ì„ ëª»ë§ì¶”ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸°)for i in range(class_len): score_sum = 0 for j in range(5): score_sum += int(gts[i*5+j] == preds[i*5+j]) if score_sum == 5: print('\\033[92m' + '{}: {} / 5'.format(class_names[i], score_sum)) else: print('\\033[91m' + '{}: {} / 5'.format(class_names[i], score_sum))","link":"/2022/12/17/Portfolio/2022-12-17-%08img-cl-swin/"},{"title":"ë¯¸ë‹ˆí”„ë¡œì íŠ¸ part 3","text":"ì´ë²ˆ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ì›¹í¬ë¡¤ë§ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì €ì¥ -&gt; ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(Swin Transformerëª¨ë¸ì„ ì´ìš©í•œ íŒŒì¸ íŠœë‹) -&gt; ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° + êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ &amp; ì‚­ì œ(+ì •ë ¬) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import torchvisionimport torchfrom PIL import Image, ImageFilterimport osimport numpy as npimport matplotlib.pyplot as pltimport randomfrom torch.utils.data import Dataset, DataLoaderimport torch.nn as nnimport torchvision.transforms as transformsimport cv2import globimport mathfrom einops import rearrange #ì°¨ì› ê´€ë¦¬ ëª¨ë“ˆimport timm # íŒŒì¸íŠœë‹ëª¨ë“ˆfrom tqdm.notebook import tqdm# configurationdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')num_epochs = 10lr = 0.001batch_size = 32num_workers = 4 # ipykenelì—ì„œëŠ” ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ì•¼ë©ë‹ˆë‹¤(ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜)# ë¡œì»¬ í™˜ê²½class_names = os.listdir('./data/train/')class_names = sorted(class_names)class_len = len(class_names)# Dataset í´ë˜ìŠ¤ ë§Œë“¤ê¸°class Sports_Dataset(Dataset): def __init__(self, data_name): #data_name will be set 'train' or 'valid'(the folder names) self.dataname = data_name #trainíŒŒì¼ ê²½ë¡œë¦¬ìŠ¤íŠ¸ ìƒì„± self.img_path = [] #ê²½ë¡œê°€ .jpg í™•ì¥ìì¸ íŒŒì¼ë“¤ì„ img_pathì— ë¦¬ìŠ¤íŠ¸í™” ì‹œì¼œì¤Œ for name in class_names: self.img_path.append(glob.glob(f'./data/{data_name}/{name}/*jpg')) #2ì°¨ì› ë¦¬ìŠ¤íŠ¸ -&gt; 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ self.img_path = sum(self.img_path, []) #trainíŒŒì¼ì˜ labels ìƒì„± self.labels = [] for path in self.img_path: self.labels.append(class_names.index(path.split('/')[3])) #í…ì„œíƒ€ì…ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ë³€ìˆ˜ ìƒì„± self.img_transpose = transforms.Compose([transforms.ToTensor()]) def __getitem__(self, index): img = Image.open(self.img_path[index]) # swin_base_patch4_window7_224ëª¨ë¸ì´ 224,224ë¡œ íŠ¸ë ˆì´ë‹ ëœ ëª¨ë¸ì´ë¼ì„œ # ì´ë¯¸ì§€ ë³´ê°„ë²•ì„ ì´ìš©í•˜ì—¬ (224,224)ì‚¬ì´ì¦ˆë¡œ ë³€ê²½ if img.size != (224,224): img = img.resize((224,224),Image.Resampling.BILINEAR) # Data augmentation with PIL when only 'train set' if self.dataname == 'train': if random.uniform(0,1) &lt; 0.3 or img.getbands() == 'L': img = img.convert('L').convert('RGB') # Random crop with size (64,64) from 30% if random.uniform(0,1) &lt; 0.3 : img = img.resize((224+64,224+64), Image.Resampling.BILINEAR) x = random.randrange(0,64) y = random.randrange(0,64) img = img.crop((x,y,x+224, y+224)) # Random Gaussian blur from 20% if random.uniform(0,1) &lt; 0.2: img = img.filter(ImageFilter.GaussianBlur(random.uniform(0.5,1.2))) # Random flip from 30% if random.uniform(0,1) &lt; 0.3: img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT) # ì™œì¸ì§€ ëª¨ë¥´ê² ì§€ë§Œ êµ¬ê¸€ì´ë¯¸ì§€ ì¤‘ ì»¬ëŸ¬ì¸ë° 1ì±„ë„ì´ ì¡´ì¬í•´ì„œ ë¬´ì¡°ê±´ 3ì±„ë„ë¡œ ë°”ê¿”ì¤˜ì•¼í•©ë‹ˆë‹¤. else : img = img.convert('RGB') lbl = self.labels[index] lbl = torch.tensor(lbl) img = self.img_transpose(img) return img, lbl #Sports_Dataset[0] == img, Sports_Dataset[1] == lbl(ë°ì´í„° ì‚¬ìš© ë°©ì‹) def __len__(self): return len(self.img_path) 12345678910# ëª¨ë¸ ë¡œë“œmodel = timm.create_model('swin_base_patch4_window7_224',pretrained=True)model.head = nn.Sequential( nn.Linear(1024,512), nn.ReLU(), nn.Dropout(0.3), nn.Linear(512,class_len))model = model.to(device) 12345model.eval()model.load_state_dict(torch.load('./nets/SwinTransformer (1).ckpt', map_location=device))test_dataset = Sports_Dataset('test')test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False) 123456789101112131415161718192021#ë¶ˆëŸ¬ì˜¨ ëª¨ë¸(.ckptíŒŒì¼)ì˜ ì„±ëŠ¥ ê²€ì‚¬preds = []gts = []score = 0for i, (images, labels) in enumerate(test_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) pred = torch.max(g_labels, 1)[1][0].item() a = torch.max(g_labels, 1) preds.append(pred) gt = labels[0].item() gts.append(gt) score += int(pred == gt)avg = score / len(test_dataset)print('Accuracy: {:.4f}\\n'.format(avg)) Accuracy: 0.9840 12345test_dataset = Sports_Dataset('base_test')test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)len(test_loader) 12345678910111213141516ori_len = len(test_dataset)_, ax = plt.subplots(2, 4, figsize=(16,10))for i in range(8): data = test_dataset.__getitem__(np.random.choice(range(test_dataset.__len__()))) label = data[1] image = data[0].cpu().detach().numpy().transpose(1, 2, 0) * 255 image = image.astype(np.uint32) label = data[1] idx = torch.max(model(data[0].unsqueeze(0).to(device)), 1)[1][0].item() ax[i//4][i-(i//4)*4].imshow(image) ax[i//4][i-(i//4)*4].set_title('Predict: {}\\nGT: {}'.format(class_names[idx], class_names[label])) ì—¬ê¸°ì„œ ì›ë³¸ê³¼ ì˜ˆìƒì´ ë‹¤ë¥¸ íŒŒì¼ë“¤ì„ ì‚­ì œí•  ê²ë‹ˆë‹¤. 123456789101112131415161718192021222324folder_name = 'base_test'target_folder = 'baseball'test_dataset = Sports_Dataset(folder_name)test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)# ì›ë˜ : baseball, ì˜ˆì¸¡ : chuckwagon racing 13ori_len = len(test_dataset)for i in range(ori_len): try: data = test_dataset.__getitem__(i) label = data[1] idx = torch.max(model(data[0].unsqueeze(0).to(device)), 1)[1][0].item() print(f'ì›ë˜ ì‚¬ì§„ : {class_names[label]}, ì˜ˆì¸¡ : {class_names[idx]}', i) if class_names[label] != class_names[idx]: path = f'data/{folder_name}/{target_folder}/{class_names[label]}_{i}.jpg' os.remove(path) print('\\033[31m'+f'removed file {path}'+'\\033[30m') # if i = : # break except: print('\\033[31m'+f'ê²½ë¡œ {path}ì— {class_names[label]}_{i}.jpg ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤'+'\\033[30m') 1234567891011121314#íŒŒì¼ ì´ë¦„ ì´ˆê¸°í™” ë° ì •ë ¬ !!!!!!!(1íšŒë§Œ ì‹¤í–‰)!!!!!!!!folder_name = 'base_test'target_folder = 'baseball'#í´ë” ê²½ë¡œfolder_path = 'data/base_test/baseball'file_names = os.listdir(folder_path)#íŒŒì¼ ì´ë¦„ ì´ˆê¸°í™” í›„ ì¬ì •ë ¬(1íšŒë§Œ ì‹¤í–‰í•´ì•¼í•¨ ì—¬ëŸ¬ë²ˆ ì‹¤í–‰ ì‹œ ì¤‘ë³µëœ ì´ë¦„ì´ ì‚­ì œë¨)for i, name in enumerate(file_names): newname = f'{folder_path}/{target_folder}_{i}.jpg' print(newname) src = os.path.join(folder_path, name) os.rename(src, newname)","link":"/2022/12/23/Portfolio/2022-12-23-img-delete/"},{"title":"ë¯¸ë‹ˆí”„ë¡œì íŠ¸ part 1","text":"google image save using Chrome driver ì´ë²ˆ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ì›¹í¬ë¡¤ë§ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì €ì¥ -&gt; ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(Swin Transformerëª¨ë¸ì„ ì´ìš©í•œ íŒŒì¸ íŠœë‹) -&gt; ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° + êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ &amp; ì‚­ì œ(+ì •ë ¬) 123456789101112131415161718192021222324252627282930import timeimport urllib.requestfrom urllib.request import urlopen, urlparse, urlunparse, urlretrievefrom selenium import webdriverfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.common.by import Byimport osimport pandas as pdfrom tqdm.notebook import tqdmchrome_path ='../Desktop/chromedriver' #í¬ë¡¬ë“œë¼ì´ë²„ ê²½ë¡œ(ê°ì í™˜ê²½ì— ë§ì¶° ìˆ˜ì •)chrome_options = webdriver.ChromeOptions()chrome_options.add_argument(&quot;lang=ko_KR&quot;) # í•œêµ­ì–´chrome_options.add_argument('window-size=1920x1080') #ìœˆë„ìš° ì°½í¬ê¸°ë¥¼ í‚¤ì›€def selenium_scroll_option(): # ìŠ¤í¬ë¡¤ ë†’ì´ ê°€ì ¸ì˜´ last_height = driver.execute_script('return document.body.scrollHeight') while True: # ëê¹Œì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´ driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') time.sleep(3) # ìŠ¤í¬ë¡¤ ë‹¤ìš´ í›„ ìŠ¤í¬ë¡¤ ë†’ì´ ë‹¤ì‹œ ê°€ì ¸ì˜´ new_height = driver.execute_script('return document.body.scrollHeight') if new_height == last_height: break last_height = new_height 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# í‚¤ì›Œë“œ ê²€ìƒ‰í•˜ê¸°keyword = input(&quot;ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥ : &quot;)image_name = input(&quot;ì €ì¥í•  ì´ë¯¸ì§€(+í´ë”) ì´ë¦„ : &quot;)#í´ë”ê°€ ì—†ìœ¼ë©´ í´ë” ìƒì„±if not os.path.exists(f'./{image_name}'): print(f'create directory ... {image_name}') os.mkdir(f'./{image_name}')driver = webdriver.Chrome(chrome_path)driver.get('http://www.google.co.kr/imghp?hl=ko')browser = driver.find_element(By.CSS_SELECTOR, 'body &gt; div.L3eUgb &gt; div.o3j99.ikrT4e.om7nvf &gt; form &gt; div:nth-child(1) &gt; div.A8SBwf &gt; div.RNNXgb &gt; div &gt; div.a4bIc &gt; input' )browser.click()browser.send_keys(keyword)browser.send_keys(Keys.RETURN)###### ì´ ë¶€ë¶„ì˜ bbí•¨ìˆ˜ ë¶€ë¶„ì€ 'ê²€ìƒ‰ ê²°ê³¼ ë”ë³´ê¸°'ë²„íŠ¼ì„ ëˆ„ë¥´ëŠ” í•¨ìˆ˜ì¸ë° ë²„ì „ë§ˆë‹¤ ì°¨ì´ê°€ ìˆìœ¼ë‹ˆ ìˆ˜ì •í•´ì„œ ì‚¬ìš©í•´ì•¼ë©ë‹ˆë‹¤. ë³¸ì¸ì€ mac/ 4.6.0 ì‚¬ìš©selenium_scroll_option() # ìŠ¤í¬ë¡¤í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë§ì´ í™•ë³´bb = driver.find_element(By.CSS_SELECTOR, '#islmp &gt; div &gt; div &gt; div &gt; div &gt; div.gBPM8 &gt; div.qvfT1 &gt; div.YstHxe &gt; input')bb.click() # ì´ë¯¸ì§€ ë”ë³´ê¸° í´ë¦­selenium_scroll_option()#ì´ë¯¸ì§€ srcìš”ì†Œë¥¼ ë¦¬ìŠ¤íŠ¸ì—…í•´ì„œ ì´ë¯¸ì§€ url ì €ì¥images = driver.find_elements(By.CSS_SELECTOR, &quot;.rg_i.Q4LuWd&quot;) # í´ë˜ìŠ¤ ë„¤ì„ì—ì„œ ê³µë°±ì€ .ì„ ì°ì–´ì¤Œimages_url = []for i in images: if i.get_attribute('src')!= None : images_url.append(i.get_attribute('src')) else : images_url.append(i.get_attribute('data-src'))# driver.close()# ê²¹ì¹˜ëŠ” ì´ë¯¸ì§€ url ì œê±°print(&quot;ì „ì²´ ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ ê°œìˆ˜: {}\\në™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì œê±°í•œ ì´ë¯¸ì§€ ê°œìˆ˜: {}&quot;.format(len(images_url), len(pd.DataFrame(images_url)[0].unique())))images_url=pd.DataFrame(images_url)[0].unique()# ì´ë¯¸ì§€ ì €ì¥# ì €ì¥ë˜ëŠ” ê·œì¹™ì€ folder_name(ê²½ë¡œ)/ì´ë¯¸ì§€ ì´ë¦„(í¬ë¡¤ë§ ì‹œ í´ë” ìƒì„± input ì´ë¦„)_ë²ˆí˜¸.jpgfolder_name = (f'./{image_name}/')for i, url in enumerate(tqdm(images_url), 0): urlretrieve(url, folder_name + image_name + '_' + str(i) + '.jpg')driver.close()","link":"/2022/12/19/Portfolio/2022-12-19-img-webcrawling/"},{"title":"img_Captioning ì½”ë“œ ë¶„í•´ Part 1","text":"ì½”ë“œ ë¦¬ë·° ì´ë¯¸ì§€ ìº¡ì…”ë‹(with attention)ì„ ìœ„í•´ ë¶ˆëŸ¬ì˜¤ê¸°ìš© Class ì •ì˜ pyíŒŒì¼ì…ë‹ˆë‹¤. ì½”ë“œ ì¶œì²˜ : ìºê¸€ ì½”ë“œ ê³µìœ  &lt;kaggle&gt; 1234567891011#ëª¨ë“ˆ importimport osfrom collections import Counterimport numpy as npimport pandas as pdimport spacyimport torchfrom torch.nn.utils.rnn import pad_sequencefrom torch.utils.data import DataLoader,Datasetimport torchvision.transforms as Tfrom PIL import Image Vocabulary í´ë˜ìŠ¤ ì •ì˜ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Vocabulary: #tokenizer(spacyëŠ” ì˜ì–´ì— ìµœì í™”ëœ ëª¨ë¸) spacy_eng = spacy.load(&quot;en_core_web_sm&quot;) def __init__(self,freq_threshold): #ìŠ¤í˜ì…œ í† í°(int -&gt; str(token)) self.itos = {0:&quot;&lt;PAD&gt;&quot;,1:&quot;&lt;SOS&gt;&quot;,2:&quot;&lt;EOS&gt;&quot;,3:&quot;&lt;UNK&gt;&quot;} #string to int tokens #str -&gt; int(ìœ„ì—êº¼ ë‹¤ì‹œ ë³€í™˜, {str : int}í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë°”ê¿ˆ) self.stoi = {v:k for k,v in self.itos.items()} self.freq_threshold = freq_threshold def __len__(self): return len(self.itos) # ì •ì ì¸ ë©”ì†Œë“œ. selfì¸ìë¥¼ ë°›ì§€ ì•Šê³  ë³„ê°œì˜ í•¨ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©í•  ê²½ìš° ì‚¬ìš© @staticmethod def tokenize(text): return [token.text.lower() for token in Vocabulary.spacy_eng.tokenizer(text)] # í† í°í™”ëœ ê°’ì´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì§ # ex) textì— 'this is a goo place'ë¥¼ ë„£ì—ˆë‹¤ë©´ # ['this', 'is', 'a', 'good', 'place'] ì´ëŸ°ì‹ìœ¼ë¡œ ì¶œë ¥ #vocab ìƒì„± í•¨ìˆ˜ def build_vocab(self, sentence_list): frequencies = Counter() #staring index 4(ìŠ¤í˜ì…œí† í°ì´ 0,1,2,3ìœ¼ë¡œ ì§€ì •ë˜ì–´ìˆê¸° ë•Œë¬¸ì— 4ë¶€í„° ì‹œì‘!) idx = 4 for sentence in sentence_list: for word in self.tokenize(sentence): frequencies[word] += 1 #freq_thresholdì´ ë„˜ì–´ê°€ë©´ ê·¸ ë‹¤ìŒ ë²ˆí˜¸ì˜ vocab(idx)ì„ ì¶”ê°€ if frequencies[word] == self.freq_threshold: self.stoi[word] = idx self.itos[idx] = word idx += 1 # ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš©(ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ) def numericalize(self,text): &quot;&quot;&quot; For each word in the text corresponding index token for that word form the vocab built as list &quot;&quot;&quot; tokenized_text = self.tokenize(text) return [ self.stoi[token] if token in self.stoi else self.stoi[&quot;&lt;UNK&gt;&quot;] for token in tokenized_text ] í´ë˜ìŠ¤ê°€ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸ 123456789101112#testing the vicab class v = Vocabulary(freq_threshold=1)v.build_vocab([&quot;This is a good place to find a city&quot;])print(v.stoi) #vocabì´ ë§Œë“¤ì–´ì§{'&lt;PAD&gt;': 0, '&lt;SOS&gt;': 1, '&lt;EOS&gt;': 2, '&lt;UNK&gt;': 3, 'this': 4, 'is': 5, 'a': 6, 'good': 7, 'place': 8, 'to': 9, 'find': 10, 'city': 11}#vocab ì¸ë±ìŠ¤ê°€ ì˜ ë‚˜ì˜¤ëŠ”ì§€ ì¶œë ¥print(v.numericalize(&quot;This is a good place to find a city here!!&quot;))[4, 5, 6, 7, 8, 9, 10, 6, 11, 3, 3, 3] Dataset í´ë˜ìŠ¤ ì •ì˜ 123456789101112131415161718192021222324252627282930313233343536class FlickrDataset(Dataset): def __init__(self,root_dir,caption_file,transform=None,freq_threshold=5): self.root_dir = root_dir self.df = pd.read_csv(caption_file) self.transform = transform #Get image and caption colum from the dataframe self.imgs = self.df[&quot;image&quot;] #íƒ€ì… : ì‹œë¦¬ì¦ˆ self.captions = self.df[&quot;caption&quot;] #íƒ€ì… : ì‹œë¦¬ì¦ˆ #Initialize vocabulary and build vocab self.vocab = Vocabulary(freq_threshold) self.vocab.build_vocab(self.captions.tolist()) #ì‹œë¦¬ì¦ˆ -&gt; ë¦¬ìŠ¤íŠ¸ def __len__(self): return len(self.df) def __getitem__(self,idx): caption = self.captions[idx] img_name = self.imgs[idx] img_location = os.path.join(self.root_dir,img_name) img = Image.open(img_location).convert(&quot;RGB&quot;) #apply the transfromation to the image if self.transform is not None: img = self.transform(img) #numericalize the caption text caption_vec = [] caption_vec += [self.vocab.stoi[&quot;&lt;SOS&gt;&quot;]] #ì‹œì‘ í† í° caption_vec += self.vocab.numericalize(caption) #vocab idx ì˜ˆ) [4, 5, 6, ...] caption_vec += [self.vocab.stoi[&quot;&lt;EOS&gt;&quot;]] #ë í† í° return img, torch.tensor(caption_vec) FlickrDatasetì´ ì‘ë™ì„ ì˜ í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ 123456789101112131415161718192021222324#ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ íŒŒì¸íŠœë‹ìš© (224,224)ë¡œ ë³€ê²½, í…ì„œë¡œ ë³€ê²½transforms = T.Compose([ T.Resize((224,224)), T.ToTensor()])def show_image(inp, title=None): inp = inp.numpy().transpose((1, 2, 0)) plt.imshow(inp) if title is not None: plt.title(title) plt.pause(0.001) # pause a bit so that plots areupdatedimport matplotlib.pyplot as plt#testing the dataset classdataset = FlickrDataset( root_dir = data_location+&quot;/Images&quot;, caption_file = data_location+&quot;/captions.txt&quot;, transform=transforms)img, caps = dataset[3]show_image(img,&quot;Image&quot;)print(&quot;Token:&quot;,caps)print(&quot;Sentence:&quot;, [dataset.vocab.itos[token] for token in caps.tolist()]) batchesê°€ 1ì´ ì•„ë‹Œ ê²½ìš° DataLoaderì˜ collate_fn ì˜µì…˜ì— ë„£ê¸° ìœ„í•´ ìƒì„±ì´ í•„ìš” 123456789101112131415class CapsCollate: def __init__(self,pad_idx,batch_first=False): self.pad_idx = pad_idx self.batch_first = batch_first def __call__(self,batch): imgs = [item[0].unsqueeze(0) for item in batch] imgs = torch.cat(imgs,dim=0) targets = [item[1] for item in batch] targets = pad_sequence(targets, batch_first=self.batch_first, padding_value=self.pad_idx) #batch [0]ì€ img, [1]ì€ target return imgs,targets dataloaderì‘ë™ í™•ì¸(Capscollate) 12345678910111213141516171819202122232425262728293031BATCH_SIZE = 4NUM_WORKER = 1#datasetì€ ì•ì— ë§Œë“  FlickrDataset, íŒ¨ë”© í† í° ì§€ì •(padding_value ì˜µì…˜)pad_idx = dataset.vocab.stoi[&quot;&lt;PAD&gt;&quot;]data_loader = DataLoader( dataset=dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKER, shuffle=True, collate_fn=CapsCollate(pad_idx=pad_idx,batch_first=True))#ë°ì´í„° ë¡œë”ì—ì„œ batchë¡œ ë³´ê¸°ìœ„í•´ iter,nextí•¨ìˆ˜ í˜¸ì¶œdataiter = iter(data_loader)batch = next(dataiter)#ë°°ì¹˜ë¥¼ ë¶„í•´images, captions = batch#ì‹±ê¸€ ë°°ì¹˜ ë‹¨ìœ„ì˜ ì •ë³´ ì¶œë ¥for i in range(BATCH_SIZE): img,cap = images[i],captions[i] caption_label = [dataset.vocab.itos[token] for token in cap.tolist()] print(caption_label) eos_index = caption_label.index('&lt;EOS&gt;') caption_label = caption_label[1:eos_index] caption_label = ' '.join(caption_label) show_image(img,caption_label) plt.show() ì•„ë˜ëŠ” img_captioning_v2ì— ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ í•¨ìˆ˜ 1234567891011121314def get_data_loader(dataset,batch_size,shuffle=False,num_workers=1): pad_idx = dataset.vocab.stoi[&quot;&lt;PAD&gt;&quot;] collate_fn = CapsCollate(pad_idx=pad_idx,batch_first=True) data_loader = DataLoader( dataset=dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=collate_fn ) return data_loader","link":"/2022/12/29/Personal_folder/for_project/2022-12-29-captioning_v1/"},{"title":"ê°œì¸ í”„ë¡œì íŠ¸(í¬íŠ¸í´ë¦¬ì˜¤)","text":"ì´ë¯¸ì§€ í”„ë¡œì íŠ¸ í”„ë¡œì íŠ¸ ê¸°ê°„ : 2022.12.09 ~ 2022.12.23 ì‘ì„±ì, ë°œí‘œì : ì¡°ì¸í™˜ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ í†µí•´ ë¬´ì—‡ì¸ê°€ í™œìš©í•˜ê³  ì‹¶ì–´ì„œ ì‹œì‘í•œ ì£¼ì œì…ë‹ˆë‹¤. ì´ë²ˆ í”„ë¡œì íŠ¸ëŠ” ì´ 3ê°œì˜ íŒŒì¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Part 1. êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ì›¹í¬ë¡¤ë§ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì €ì¥ Part 2. ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(Swin Transformer)ì„ ì´ìš©í•œ íŒŒì¸ íŠœë‹ Part 3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° + êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ =&gt; ì‚­ì œ &amp; ë¦¬ë„¤ì„í•˜ê³  ì¬ì •ë ¬ Part 1. êµ¬ê¸€ ì´ë¯¸ì§€ ì›¹í¬ë¡¤ë§ -&gt; ì´ë¯¸ì§€ ì €ì¥í•˜ëŠ” ì½”ë“œ123456789101112131415161718192021222324252627282930import timeimport urllib.requestfrom urllib.request import urlopen, urlparse, urlunparse, urlretrievefrom selenium import webdriverfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.common.by import Byimport osimport pandas as pdfrom tqdm.notebook import tqdmchrome_path ='../Desktop/chromedriver' #í¬ë¡¬ë“œë¼ì´ë²„ ê²½ë¡œ(ê°ì í™˜ê²½ì— ë§ì¶° ìˆ˜ì •)chrome_options = webdriver.ChromeOptions()chrome_options.add_argument(&quot;lang=ko_KR&quot;) # êµ¬ê¸€.krì´ê¸°ë•Œë¬¸ì— í•œêµ­ì–´ë¡œ ì„¤ì •chrome_options.add_argument('window-size=1920x1080') #ìœˆë„ìš° ì°½í¬ê¸°ë¥¼ í‚¤ì›€def selenium_scroll_option(): # ìŠ¤í¬ë¡¤ ë†’ì´ ê°€ì ¸ì˜´ last_height = driver.execute_script('return document.body.scrollHeight') while True: # ëê¹Œì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´ driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') time.sleep(3) # ìŠ¤í¬ë¡¤ ë‹¤ìš´ í›„ ìŠ¤í¬ë¡¤ ë†’ì´ ë‹¤ì‹œ ê°€ì ¸ì˜´ new_height = driver.execute_script('return document.body.scrollHeight') if new_height == last_height: break last_height = new_height 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# í‚¤ì›Œë“œ ê²€ìƒ‰í•˜ê¸°keyword = input(&quot;ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥ : &quot;)image_name = input(&quot;ì €ì¥í•  ì´ë¯¸ì§€(+í´ë”) ì´ë¦„ : &quot;)#í´ë”ê°€ ì—†ìœ¼ë©´ í´ë” ìƒì„±if not os.path.exists(f'./{image_name}'): print(f'create directory ... {image_name}') os.mkdir(f'./{image_name}')driver = webdriver.Chrome(chrome_path)driver.get('http://www.google.co.kr/imghp?hl=ko')browser = driver.find_element(By.CSS_SELECTOR, 'body &gt; div.L3eUgb &gt; div.o3j99.ikrT4e.om7nvf &gt; form &gt; div:nth-child(1) &gt; div.A8SBwf &gt; div.RNNXgb &gt; div &gt; div.a4bIc &gt; input' )browser.click()browser.send_keys(keyword)browser.send_keys(Keys.RETURN)# ì´ ë¶€ë¶„ì˜ bbí•¨ìˆ˜ ë¶€ë¶„ì€ 'ê²€ìƒ‰ ê²°ê³¼ ë”ë³´ê¸°'ë²„íŠ¼ì„ ëˆ„ë¥´ëŠ” í•¨ìˆ˜ì¸ë°,# ë²„ì „ë§ˆë‹¤ ì°¨ì´ê°€ ìˆìœ¼ë‹ˆ ìˆ˜ì •í•´ì„œ ì‚¬ìš©í•´ì•¼ë©ë‹ˆë‹¤. ë³¸ì¸ì€ mac/ 4.6.0 ì‚¬ìš©selenium_scroll_option() # ìŠ¤í¬ë¡¤í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë§ì´ í™•ë³´bb = driver.find_element(By.CSS_SELECTOR, '#islmp &gt; div &gt; div &gt; div &gt; div &gt; div.gBPM8 &gt; div.qvfT1 &gt; div.YstHxe &gt; input')bb.click() # ì´ë¯¸ì§€ ë”ë³´ê¸° í´ë¦­selenium_scroll_option()#ì´ë¯¸ì§€ srcìš”ì†Œë¥¼ ë¦¬ìŠ¤íŠ¸ì—…í•´ì„œ ì´ë¯¸ì§€ url ì €ì¥images = driver.find_elements(By.CSS_SELECTOR, &quot;.rg_i.Q4LuWd&quot;) # í´ë˜ìŠ¤ ë„¤ì„ì—ì„œ ê³µë°±ì€ .ì„ ì°ì–´ì¤Œimages_url = []for i in images: if i.get_attribute('src')!= None : images_url.append(i.get_attribute('src')) else : images_url.append(i.get_attribute('data-src'))# ê²¹ì¹˜ëŠ” ì´ë¯¸ì§€ url ì œê±°images_url=pd.DataFrame(images_url)[0].unique()# ì´ë¯¸ì§€ ì €ì¥. 700ì¥ ê¸°ì¤€ ì•½ 3~5ë¶„ ì†Œìš”# ì €ì¥ë˜ëŠ” ê·œì¹™ì€ folder_name(ê²½ë¡œ)/ì´ë¯¸ì§€ ì´ë¦„(í¬ë¡¤ë§ ì‹œ í´ë” ìƒì„± input ì´ë¦„)_ë²ˆí˜¸.jpgprint(f'ì „ì²´ ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ ê°œìˆ˜: {len(images_url)}\\n ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì œê±°í•œ ì´ë¯¸ì§€ ê°œìˆ˜: {len(pd.DataFrame(images_url)[0].unique())}\\n *ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤.(ì•½ 3~5ë¶„ ì†Œìš”)')folder_name = (f'./{image_name}/')for i, url in enumerate(tqdm(images_url),0): urlretrieve(url, folder_name + image_name + '_' + str(i) + '.jpg')print('Done')driver.close() Part 2. ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(Swin Transformer)ì„ ì´ìš©í•œ íŒŒì¸ íŠœë‹Swin Transformerë€ ? Swin TransformerëŠ” 2021ë…„ 3ì›”ì— ë§ˆì´í¬ë¡œì†Œí”„íŠ¸(ì•„ì‹œì•„)ì—ì„œ ë°œí‘œí•œ Transformerì´ë‹¤. í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ViTì—ì„œ ëª¨ë“  patchê°€ self attentionì„ í•˜ëŠ” ê²ƒì— ëŒ€í•œ ë‹¨ì ì„ ì§€ì í•˜ë©´ì„œê° patchë¥¼ windowë¡œ ë‚˜ëˆ„ì–´ í•´ë‹¹ ìœˆë„ìš° ì•ˆì—ì„œë§Œ self attentionì„ ìˆ˜í–‰í•˜ê³  ê·¸ ìœˆë„ìš°ë¥¼ í•œë²ˆ shiftí•˜ê³ , ë‹¤ì‹œ self attentionì„ í•˜ëŠ” êµ¬ì¡° ì¼ë°˜ì ì¸ Transformerì™€ ë‹¬ë¦¬ ë§ˆì¹˜ Feature Pyramid Networkê°™ì€ Hierarchical êµ¬ì¡°ë¥¼ ì œì‹œí•˜ë©´ì„œclassificationì€ ë¬¼ë¡  Object Detection, Segmentationì—ì„œ backboneìœ¼ë¡œ ì‚¬ìš©ë˜ì–´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê²Œ ëœë‹¤. Swin Transformer == (shifted windows) Transformer 123456789101112131415161718!pip install pillow==9.1.0 import torchvisionimport torchfrom PIL import Image, ImageFilter #ë²„ì „ ë§ì¶°ì£¼ì„¸ìš” 9.1.0 ì´ìƒimport osimport numpy as npimport matplotlib.pyplot as pltimport randomfrom torch.utils.data import Dataset, DataLoaderimport torch.nn as nnimport torchvision.transforms as transformsimport cv2import globimport mathimport timm # íŒŒì¸íŠœë‹ëª¨ë“ˆfrom timm.loss import LabelSmoothingCrossEntropyfrom tqdm.notebook import tqdm 123456789101112# configurationdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')num_epochs = 10lr = 0.001batch_size = 32num_workers = 2 # ipykenelì—ì„œëŠ” ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ì•¼ë©ë‹ˆë‹¤(ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜)# í´ë˜ìŠ¤(íƒ€ê²Ÿ) ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°class_names = os.listdir('./data/train/') #í´ë” ì´ë¦„ == í´ë˜ìŠ¤(target) ë„¤ì„class_names.sort()class_len = len(class_names) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# Dataset í´ë˜ìŠ¤ ë§Œë“¤ê¸°class Sports_Dataset(Dataset): def __init__(self, data_name): #data_name will be set 'train' or 'valid'(the folder names) self.dataname = data_name #trainíŒŒì¼ ê²½ë¡œë¦¬ìŠ¤íŠ¸ ìƒì„± self.img_path = [] #ê²½ë¡œê°€ .jpg í™•ì¥ìì¸ íŒŒì¼ë“¤ì„ img_pathì— ë¦¬ìŠ¤íŠ¸í™” ì‹œì¼œì¤Œ for name in class_names: self.img_path.append(glob.glob(f'./data/{data_name}/{name}/*jpg')) #2ì°¨ì› ë¦¬ìŠ¤íŠ¸ -&gt; 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ self.img_path = sum(self.img_path, []) #trainíŒŒì¼ì˜ labels ìƒì„± self.labels = [] for path in self.img_path: self.labels.append(class_names.index(path.split('/')[3])) #í…ì„œíƒ€ì…ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ë³€ìˆ˜ ìƒì„± self.img_transpose = transforms.Compose([transforms.ToTensor()]) def __getitem__(self, index): img = Image.open(self.img_path[index]) # swin_base_patch4_window7_224ëª¨ë¸ì´ 224,224ë¡œ íŠ¸ë ˆì´ë‹ ëœ ëª¨ë¸ì´ë¼ì„œ # ì´ë¯¸ì§€ ë³´ê°„ë²•ì„ ì´ìš©í•˜ì—¬ (224,224)ì‚¬ì´ì¦ˆë¡œ ë³€ê²½ if img.size != (224,224): img = img.resize((224,224),Image.Resampling.BILINEAR) # Data augmentation with PIL when only 'train set' if self.dataname == 'train': if random.uniform(0,1) &lt; 0.3 or img.getbands() == 'L': img = img.convert('L').convert('RGB') # Random crop with size (64,64) from 30% if random.uniform(0,1) &lt; 0.3 : img = img.resize((224+64,224+64), Image.Resampling.BILINEAR) x = random.randrange(0,64) y = random.randrange(0,64) img = img.crop((x,y,x+224, y+224)) # Random Gaussian blur from 20% if random.uniform(0,1) &lt; 0.2: img = img.filter(ImageFilter.GaussianBlur(random.uniform(0.5,1.2))) # Random flip from 30% if random.uniform(0,1) &lt; 0.3: img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT) # ì™œì¸ì§€ ëª¨ë¥´ê² ì§€ë§Œ êµ¬ê¸€ì´ë¯¸ì§€ ì¤‘ ì»¬ëŸ¬ì¸ë° 1ì±„ë„ì´ ì¡´ì¬í•´ì„œ ë¬´ì¡°ê±´ 3ì±„ë„ë¡œ ë°”ê¿”ì¤˜ì•¼í•©ë‹ˆë‹¤. else : img = img.convert('RGB') lbl = self.labels[index] lbl = torch.tensor(lbl) img = self.img_transpose(img) return img, lbl #Sports_Dataset[0] == img, Sports_Dataset[1] == lbl(ë°ì´í„° ì‚¬ìš© ë°©ì‹) def __len__(self): return len(self.img_path) 1234567891011121314151617181920# ì´ë¯¸ì§€ 8ê°œ í™•ì¸ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì‘ë™ ìœ ë¬´ í™•ì¸(ì‹¤í–‰í•˜ì§€ ì•Šì•„ë„ ëª¨ë¸ë§ì—ëŠ” ì§€ì¥ì€ ì—†ìŒ)train_dataset = Sports_Dataset('train')print(train_dataset.__len__())_, ax = plt.subplots(2, 4, figsize=(16,10))for i in range(8): data = train_dataset.__getitem__(random.choice(range(train_dataset.__len__()))) image = data[0].cpu().detach().numpy().transpose(1, 2, 0) * 255 # .cpu() == GPU ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ì ¸ ìˆëŠ” tensorë¥¼ cpu ë©”ëª¨ë¦¬ë¡œ ë³µì‚¬í•˜ëŠ” method # .detach() == Returns a new Tensor # detach,cpu ìˆœì„œëŠ” ë³„ë¡œ ìƒê´€ ì—†ë‹¤. image = image.astype(np.uint32) #uintëŠ” 0ì„í¬í•¨í•œ ì–‘ìˆ˜ë¡œëœ ì •ìˆ˜íƒ€ì… label = data[1] ax[i//4][i-(i//4)*4].imshow(image) ax[i//4][i-(i//4)*4].set_title(class_names[label]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# í•™ìŠµëœ ëª¨ë¸ ì¤‘ swin_base_patch4_window7_224ë¥¼ ì‚¬ìš©(íŒŒì¸íŠœë‹)model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)model.head = nn.Sequential(nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(0.3), nn.Linear(512, class_len)) model = model.to(device)criterion = timm.loss.LabelSmoothingCrossEntropy() # this is better than nn.CrossEntropyLosscriterion = criterion.to(device)optimizer = torch.optim.AdamW(model.head.parameters(), lr=lr) # Setting for transfer learning#ë°ì´í„° ì •ì œtrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)val_dataset = Sports_Dataset('valid')val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)#training def update_lr(optimizer, lr): for param_group in optimizer.param_groups: param_group['lr'] = lrmodel.train()total_step = len(train_loader)curr_lr = lrbest_score = 0for epoch in range(2): total_loss = 0 for i, (images,labels) in enumerate(tqdm(train_loader)): images = images.to(device) labels = labels.to(device) g_labels = model(images) loss = criterion(g_labels,labels) optimizer.zero_grad() loss.backward() optimizer.step() total_loss += loss.item() if (i+1) % 100 == 0: print(f'{batch_size*(i+1)} / {train_dataset.__len__()}') model.eval() score = 0 for i, (images, labels) in enumerate(valid_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) score += int(torch.max(g_labels, 1)[1][0] == labels[0]) print(f'Epoch : {epoch+1}, Loss : {total_loss/total_step}') avg = score / len(val_dataset) print(f'Accuracy : {avg :.2f}\\n') model.train() if best_score &lt; avg: best_score = avg if not os.path.exists('./nets'): os.mkdir('./nets') torch.save(model.state_dict(), 'nets/SwinTransformer.ckpt') if (epoch+1) %2 == 0: curr_lr = lr * 0.8 update_lr(optimizer, curr_lr)#ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°model.eval()model.load_state_dict(torch.load('nets/SwinTransformer.ckpt', map_location=device))test_dataset = Sports_Dataset('test')test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)# accuracy í™•ì¸ í•˜ê¸°preds = []gts = []score = 0for i, (images, labels) in enumerate(test_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) pred = torch.max(g_labels, 1)[1][0].item() preds.append(pred) gt = labels[0].item() gts.append(gt) score += int(pred == gt)avg = score / len(val_dataset)print('Accuracy: {:.4f}\\n'.format(avg)) 12345678910111213141516171819#í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€(ëœë¤ 8ê°œ)test_dataset = Sports_Dataset('test')test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)_, ax = plt.subplots(2, 4, figsize=(16,10))for i in range(8): data = test_dataset.__getitem__(np.random.choice(range(test_dataset.__len__()))) image = data[0].cpu().detach().numpy().transpose(1, 2, 0) * 255 image = image.astype(np.uint32) label = data[1] idx = torch.max(model(data[0].unsqueeze(0).to(device)), 1)[1][0].item() ax[i//4][i-(i//4)*4].imshow(image) ax[i//4][i-(i//4)*4].set_title('Predict: {}\\nGT: {}'.format(class_names[idx], class_names[label])) 123456789# ë…¹ìƒ‰: perfect score / ë¹¨ê°„ìƒ‰: imperfect score(ì–´ë–¤ ì¢…ëª©ì„ ëª»ë§ì¶”ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸°)for i in range(class_len): score_sum = 0 for j in range(5): score_sum += int(gts[i*5+j] == preds[i*5+j]) if score_sum == 5: print('\\033[92m' + '{}: {} / 5'.format(class_names[i], score_sum)) else: print('\\033[91m' + '{}: {} / 5'.format(class_names[i], score_sum)) Part 3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° + êµ¬ê¸€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ &amp; ì‚­ì œ &amp; ë¦¬ë„¤ì„1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import torchvisionimport torchfrom PIL import Image, ImageFilterimport osimport numpy as npimport matplotlib.pyplot as pltimport randomfrom torch.utils.data import Dataset, DataLoaderimport torch.nn as nnimport torchvision.transforms as transformsimport cv2import globimport mathfrom einops import rearrange #ì°¨ì› ê´€ë¦¬ ëª¨ë“ˆimport timm # íŒŒì¸íŠœë‹ëª¨ë“ˆfrom tqdm.notebook import tqdm# configurationdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')num_epochs = 10lr = 0.001batch_size = 32num_workers = 4 # ipykenelì—ì„œëŠ” ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ì•¼ë©ë‹ˆë‹¤(ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜)# ë¡œì»¬ í™˜ê²½class_names = os.listdir('./data/train/')class_names = sorted(class_names)class_len = len(class_names)# Dataset í´ë˜ìŠ¤ ë§Œë“¤ê¸°class Sports_Dataset(Dataset): def __init__(self, data_name): #data_name will be set 'train' or 'valid'(the folder names) self.dataname = data_name #trainíŒŒì¼ ê²½ë¡œë¦¬ìŠ¤íŠ¸ ìƒì„± self.img_path = [] #ê²½ë¡œê°€ .jpg í™•ì¥ìì¸ íŒŒì¼ë“¤ì„ img_pathì— ë¦¬ìŠ¤íŠ¸í™” ì‹œì¼œì¤Œ for name in class_names: self.img_path.append(glob.glob(f'./data/{data_name}/{name}/*jpg')) #2ì°¨ì› ë¦¬ìŠ¤íŠ¸ -&gt; 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ self.img_path = sum(self.img_path, []) #trainíŒŒì¼ì˜ labels ìƒì„± self.labels = [] for path in self.img_path: self.labels.append(class_names.index(path.split('/')[3])) #í…ì„œíƒ€ì…ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ë³€ìˆ˜ ìƒì„± self.img_transpose = transforms.Compose([transforms.ToTensor()]) def __getitem__(self, index): img = Image.open(self.img_path[index]) # swin_base_patch4_window7_224ëª¨ë¸ì´ 224,224ë¡œ íŠ¸ë ˆì´ë‹ ëœ ëª¨ë¸ì´ë¼ì„œ # ì´ë¯¸ì§€ ë³´ê°„ë²•ì„ ì´ìš©í•˜ì—¬ (224,224)ì‚¬ì´ì¦ˆë¡œ ë³€ê²½ if img.size != (224,224): img = img.resize((224,224),Image.Resampling.BILINEAR) # Data augmentation with PIL when only 'train set' if self.dataname == 'train': if random.uniform(0,1) &lt; 0.3 or img.getbands() == 'L': img = img.convert('L').convert('RGB') # Random crop with size (64,64) from 30% if random.uniform(0,1) &lt; 0.3 : img = img.resize((224+64,224+64), Image.Resampling.BILINEAR) x = random.randrange(0,64) y = random.randrange(0,64) img = img.crop((x,y,x+224, y+224)) # Random Gaussian blur from 20% if random.uniform(0,1) &lt; 0.2: img = img.filter(ImageFilter.GaussianBlur(random.uniform(0.5,1.2))) # Random flip from 30% if random.uniform(0,1) &lt; 0.3: img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT) # ì™œì¸ì§€ ëª¨ë¥´ê² ì§€ë§Œ êµ¬ê¸€ì´ë¯¸ì§€ ì¤‘ ì»¬ëŸ¬ì¸ë° 1ì±„ë„ì´ ì¡´ì¬í•´ì„œ ë¬´ì¡°ê±´ 3ì±„ë„ë¡œ ë°”ê¿”ì¤˜ì•¼í•©ë‹ˆë‹¤. else : img = img.convert('RGB') lbl = self.labels[index] lbl = torch.tensor(lbl) img = self.img_transpose(img) return img, lbl #Sports_Dataset[0] == img, Sports_Dataset[1] == lbl(ë°ì´í„° ì‚¬ìš© ë°©ì‹) def __len__(self): return len(self.img_path) 12345678910# ëª¨ë¸ ë¡œë“œmodel = timm.create_model('swin_base_patch4_window7_224',pretrained=True)model.head = nn.Sequential( nn.Linear(1024,512), nn.ReLU(), nn.Dropout(0.3), nn.Linear(512,class_len))model = model.to(device) 12345model.eval()model.load_state_dict(torch.load('./nets/SwinTransformer (1).ckpt', map_location=device))test_dataset = Sports_Dataset('test')test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False) 123456789101112131415161718192021#ë¶ˆëŸ¬ì˜¨ ëª¨ë¸(.ckptíŒŒì¼)ì˜ ì„±ëŠ¥ ê²€ì‚¬preds = []gts = []score = 0for i, (images, labels) in enumerate(test_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) pred = torch.max(g_labels, 1)[1][0].item() a = torch.max(g_labels, 1) preds.append(pred) gt = labels[0].item() gts.append(gt) score += int(pred == gt)avg = score / len(test_dataset)print('Accuracy: {:.4f}\\n'.format(avg)) Accuracy: 0.9840 12345test_dataset = Sports_Dataset('base_test')test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)len(test_loader) 12345678910111213141516ori_len = len(test_dataset)_, ax = plt.subplots(2, 4, figsize=(16,10))for i in range(8): data = test_dataset.__getitem__(np.random.choice(range(test_dataset.__len__()))) label = data[1] image = data[0].cpu().detach().numpy().transpose(1, 2, 0) * 255 image = image.astype(np.uint32) label = data[1] idx = torch.max(model(data[0].unsqueeze(0).to(device)), 1)[1][0].item() ax[i//4][i-(i//4)*4].imshow(image) ax[i//4][i-(i//4)*4].set_title('Predict: {}\\nGT: {}'.format(class_names[idx], class_names[label])) ì—¬ê¸°ì„œ ì›ë³¸ê³¼ ì˜ˆìƒì´ ë‹¤ë¥¸ íŒŒì¼ë“¤ì„ ì‚­ì œí•  ê²ë‹ˆë‹¤. 123456789101112131415161718192021222324folder_name = 'base_test'target_folder = 'baseball'test_dataset = Sports_Dataset(folder_name)test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)# ì›ë˜ : baseball, ì˜ˆì¸¡ : chuckwagon racing 13ori_len = len(test_dataset)for i in range(ori_len): try: data = test_dataset.__getitem__(i) label = data[1] idx = torch.max(model(data[0].unsqueeze(0).to(device)), 1)[1][0].item() print(f'ì›ë˜ ì‚¬ì§„ : {class_names[label]}, ì˜ˆì¸¡ : {class_names[idx]}', i) if class_names[label] != class_names[idx]: path = f'data/{folder_name}/{target_folder}/{class_names[label]}_{i}.jpg' os.remove(path) print('\\033[31m'+f'removed file {path}'+'\\033[30m') # if i = : # break except: print('\\033[31m'+f'ê²½ë¡œ {path}ì— {class_names[label]}_{i}.jpg ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤'+'\\033[30m') 1234567891011121314#íŒŒì¼ ì´ë¦„ ì´ˆê¸°í™” ë° ì •ë ¬ !!!!!!!(1íšŒë§Œ ì‹¤í–‰)!!!!!!!!folder_name = 'base_test'target_folder = 'baseball'#í´ë” ê²½ë¡œfolder_path = 'data/base_test/baseball'file_names = os.listdir(folder_path)#íŒŒì¼ ì´ë¦„ ì´ˆê¸°í™” í›„ ì¬ì •ë ¬(1íšŒë§Œ ì‹¤í–‰í•´ì•¼í•¨ ì—¬ëŸ¬ë²ˆ ì‹¤í–‰ ì‹œ ì¤‘ë³µëœ ì´ë¦„ì´ ì‚­ì œë¨)for i, name in enumerate(file_names): newname = f'{folder_path}/{target_folder}_{i}.jpg' print(newname) src = os.path.join(folder_path, name) os.rename(src, newname) ê·¸ë™ì•ˆ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ë§Œ í•´ë³´ê³  ì´ë¥¼ ì´ìš©í•´ì„œ ë‹¤ë¥¸ ê²ƒì„ í•˜ëŠ” ì‘ì—…ì€ í•œ ì ì´ ì—†ì—ˆëŠ”ë°, ì´ë²ˆ í”„ë¡œì íŠ¸ ë•Œ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‹œë„í•´ ë³´ë©° íŒŒì´í† ì¹˜ë¥¼ ë‹¤ë£¨ëŠ” ë¶€ë¶„, OSë¥¼ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„ ë“± ë‹¤ì–‘í•œ ì‚¬ìš© ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤. ì´ë²ˆ í”„ë¡œì íŠ¸ë¥¼ í•˜ë©´ì„œ ê°€ì¥ ë‚œë„ê°€ ë†’ì•˜ë˜ ì‘ì—…ì€ êµ¬ê¸€ì—ì„œ ë‹¤ìš´ë°›ì€ ì´ë¯¸ì§€ë“¤ì„ ì˜ˆì¸¡ê°’ì— ë§ê²Œ ë‹¤ì‹œ í˜•ì‹ì„ ë§ì¶”ê³  ë‹¤ë£¨ëŠ” ë¶€ë¶„ì´ì—ˆìŠµë‹ˆë‹¤.","link":"/2022/12/23/Portfolio/2022-12-23-img-project/"},{"title":"ê³¼ì ì í•©(Overfitting)ì„ ë§‰ëŠ” ë°©ë²•","text":"ê³¼ì í•©ì„ ë§‰ëŠ” ë°©ë²•1.ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ê¸° ë§Œì•½, ë°ì´í„°ì˜ ì–‘ì´ ì ì„ ê²½ìš°ì—ëŠ” ì˜ë„ì ìœ¼ë¡œ ê¸°ì¡´ì˜ ë°ì´í„°ë¥¼ ì¡°ê¸ˆì”© ë³€í˜•í•˜ê³  ì¶”ê°€í•˜ì—¬ ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ê¸°ë„ í•˜ëŠ”ë° ì´ë¥¼ ë°ì´í„° ì¦ì‹ ë˜ëŠ” ì¦ê°•(Data Augmentation)ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ ê²½ìš°ì—ëŠ” ë°ì´í„° ì¦ì‹ì´ ë§ì´ ì‚¬ìš©ë˜ëŠ”ë° ì´ë¯¸ì§€ë¥¼ ëŒë¦¬ê±°ë‚˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ê³ , ì¼ë¶€ë¶„ì„ ìˆ˜ì •í•˜ëŠ” ë“±ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¦ì‹ì‹œí‚µë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ê²½ìš°ì—ëŠ” ë°ì´í„°ë¥¼ ì¦ê°•í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë²ˆì—­ í›„ ì¬ë²ˆì—­ì„ í†µí•´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ì—­ë²ˆì—­(Back Translation) ë“±ì˜ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. 2.ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ì¤„ì´ê¸° 3.ê°€ì¤‘ì¹˜ ê·œì œ(Regularization) ì ìš©í•˜ê¸° 4.ë“œë¡­ì•„ì›ƒ(Dropout) 123456789101112131415#ì˜ˆì‹œfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dropout, Densemax_words = 10000num_classes = 46model = Sequential()model.add(Dense(256, input_shape=(max_words,), activation='relu'))model.add(Dropout(0.5)) # ë“œë¡­ì•„ì›ƒ ì¶”ê°€. ë¹„ìœ¨ì€ 50% &lt;- ì—¬ê¸°ì„œ ë“œë¡­ì•„ì›ƒ 50%ë§Œ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸(ëœë¤ìœ¼ë¡œ)model.add(Dense(128, activation='relu'))model.add(Dropout(0.5)) # ë“œë¡­ì•„ì›ƒ ì¶”ê°€. ë¹„ìœ¨ì€ 50%model.add(Dense(num_classes, activation='softmax'))# ì½”ë“œ ì¶œì²˜ : ìœ„í‚¤ë…ìŠ¤(wikidocs) pad_sequences ì‚¬ìš©í•˜ëŠ” ì´ìœ  ìƒ˜í”Œì˜ ê¸¸ì´ê°€ ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆëŠ”ë°, ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ë ¤ë©´ ëª¨ë“  ìƒ˜í”Œì˜ ê¸¸ì´ë¥¼ í†µì¼í•´ì£¼ëŠ” í•¨ìˆ˜ maxlen = ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ì„œ ì •ê·œí™” í•  ê¸¸ì´ padding = â€˜postâ€™ë¡œ ì…ë ¥ ì‹œ ë’¤ì—ê»˜ ì˜ë¦¼, ë³´í†µ â€˜postâ€™ë¥¼ ì‚¬ìš©í•¨ 1234567891011121314from tensorflow.keras.preprocessing.sequence import pad_sequencespad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='pre') #ê²°ê³¼array([[1, 2, 3], [4, 5, 6], [0, 7, 8]], dtype=int32)pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], maxlen=3, padding='post')#ê²°ê³¼array([[1, 2, 3], [4, 5, 6], [7, 8, 0]], dtype=int32)","link":"/2022/12/01/Study_folder/DL(Deep_Learning)/2022-12-01-Overfitting/"},{"title":"img_Captioning ì½”ë“œ ë¶„í•´ Part 2","text":"ì´ë¯¸ì§€ ìº¡ì…”ë‹(with attention) í˜„ì¬ ì‘ì—…ì¤‘ì¸ íŒŒì¼ì…ë‹ˆë‹¤. ë°ì´í„°ëŠ” ìºê¸€ì˜ Flickr8kë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ì½”ë“œ ì¶œì²˜ : &lt;kaggle&gt; custom íŒŒì¼(data_loader.py)ëŠ” Part 1ì— ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‹¤ìš´, ì••ì¶• í•´ì œ ë‹¤ìš´ë°›ê³  ì••ì¶•ì„ í•´ì œí•˜ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤.(ë”°ë¡œ êµ¬í•´ì„œ í¸ì§‘í•¨) 123456789101112# íŒŒì¼ ë‹¤ìš´!wget -O Flickr8k_dataset.zip https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXVy7_7pF5FIsPp6WfXXfWgBNfUKx8N1VrTisN8FbGYG9w?download=1 -q# ì••ì¶• í•´ì œimport zipfilezipfile.ZipFile('Flickr8k_dataset.zip').extractall(path ='/content/dataset')# ë¡œì¼€ì´ì…˜ ì§€ì •data_location = './dataset'# ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ë„ ê°€ëŠ¥(magic ëª…ë ¹ì–´)# !unzip -q Flickr8k_dataset.zip -d ./dataset 123456789101112#importsimport numpy as npimport torchimport torchvision.transforms as Timport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport torchvision.models as modelsfrom torch.utils.data import DataLoader,Dataset#custom imports (Part 1 ì°¸ê³ )from data_loader import FlickrDataset,get_data_loader 1234567891011121314151617181920#show the tensor imageimport matplotlib.pyplot as pltdef show_image(img, title=None): &quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot; #unnormalize img[0] = img[0] * 0.229 img[1] = img[1] * 0.224 img[2] = img[2] * 0.225 img[0] += 0.485 img[1] += 0.456 img[2] += 0.406 img = img.numpy().transpose((1, 2, 0)) plt.imshow(img) if title is not None: plt.title(title) plt.pause(0.001) â€œAll pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224â€ ì´ íŠ¹ì • ìˆ˜ì¹˜ë“¤ì€ pretrainingì— ì‚¬ìš©ëœ ëª¨ë¸ë“¤ì˜ ImageNet ë°ì´í„°ì…‹ì˜ í•™ìŠµ ì‹œì— ì–»ì–´ë‚¸ ê°’ì´ê³ , ImageNet ë°ì´í„°ì…‹ì€ ì§ˆ ì¢‹ì€ ì´ë¯¸ì§€ë“¤ì„ ë‹¤ëŸ‰ í¬í•¨í•˜ê³  ìˆê¸°ì— ì´ëŸ° ë°ì´í„°ì…‹ì—ì„œ ì–»ì–´ë‚¸ ê°’ì´ë¼ë©´ ì–´ë–¤ ì´ë¯¸ì§€ ë°ì´í„° ì…‹ì—ì„œë„ ì˜ ì‘ë™í•  ê²ƒì´ë¼ëŠ” ê°€ì •í•˜ì— ì´ ê°’ë“¤ì„ ê¸°ë³¸ ê°’ìœ¼ë¡œ ì„¸íŒ…í•´ ë†“ì€ ê²ƒì´ë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738#ë°ì´í„°ì…‹, ë°ì´í„°ë¡œë” ë§Œë“¤ê¸° (part1 íŒŒì¼ ì°¸ê³ í•˜ì„¸ìš”)data_location = './dataset'# BATCH_SIZE = 256BATCH_SIZE = 6NUM_WORKER = 1 # ì‘ì—… í™˜ê²½ì— ë”°ë¼ ìˆ˜ì •#transformstransforms = T.Compose([ T.Resize(226), T.RandomCrop(224), T.ToTensor(), T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])#datasetdataset = FlickrDataset( root_dir = data_location+&quot;/Images&quot;, caption_file = data_location+&quot;/captions.txt&quot;, transform=transforms)#writing the dataloaderdata_loader = get_data_loader( dataset=dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKER, shuffle=True, batch_first=True)#vocab_sizevocab_size = len(dataset.vocab)print(vocab_size)# 2994device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) ì „ì²´ì  ëª¨ë¸ì€ seq2seq ëª¨ë¸ì…ë‹ˆë‹¤. encoderëŠ” resnet50(CNN)ì„ ì‚¬ìš©í•˜ê³ , ë””ì½”ë”ì—ëŠ” ë°”ë‹¤ë‚˜ìš° ì–´í…ì…˜ì„ ì‚¬ìš©(RNN(LSTM)) 12345678910111213141516171819202122class EncoderCNN(nn.Module): def __init__(self): super(EncoderCNN, self).__init__() resnet = models.resnet50(pretrained=True) # ì‹ ê²½ë§ì˜ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ê³ ì •í•©ë‹ˆë‹¤(íŒŒì¸ íŠœë‹ ì‹œ ë³´í†µ ì‚¬ìš©) for param in resnet.parameters(): param.requires_grad_(False) modules = list(resnet.children())[:-2] #ë§ˆì§€ë§‰ í•™ìŠµëœ 2ê°œì˜ ì¸µì€ ì‚¬ìš©í•˜ì§€ ì•Šê² ë‹¤ self.resnet = nn.Sequential(*modules) def forward(self, images): features = self.resnet(images) #(batch_size,2048,7,7) features = features.permute(0, 2, 3, 1) # ì°¨ì› ë³€ê²½ #(batch_size,7,7,2048) features = features.view(features.size(0), -1, features.size(-1)) #(batch_size,49,2048) return features ë¯¸ì„¸ì¡°ì •(finetuning)ì„ í•˜ëŠ” ê³¼ì •ì—ì„œ, ìƒˆë¡œìš´ ì •ë‹µ(label)ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ ëª¨ë¸ì˜ ëŒ€ë¶€ë¶„ì„ ê³ ì •í•œ ë’¤ ì¼ë°˜ì ìœ¼ë¡œ ë¶„ë¥˜ ê³„ì¸µ(classifier layer)ë§Œ ë³€ê²½í•©ë‹ˆë‹¤.ë˜í•œ ìº¡ì…”ë‹(captioning)ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë§ˆì§€ë§‰ í•™ìŠµëœ 2ê°œì˜ ì¸µ(layer)ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë””ì½”ë” ëª¨ë¸ì„ ì •ì˜í•˜ê¸° ì „ì— ëª¨ë¸ì„ ì–´ë–»ê²Œ ìŒ“ì„ì§€ ë³´ë©´ ì´í•´ê°€ ì˜ ë ê²ë‹ˆë‹¤ ë³€ìˆ˜ê°’ìœ¼ë¡œ vocab_size=2994, embedding=300, attention_dim=256, encoder_dim=2048, decoder_dim=512ì´ ì…ë ¥ë©ë‹ˆë‹¤. ëª¨ë¸ì€ í¬ê²Œë³´ë©´ embedding, attention, ë‚˜ë¨¸ì§€ ëª¨ë¸ë“¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. 1234567891011121314151617(decoder): DecoderRNN( (embedding): Embedding(2994, 300) (attention): Attention( (W): Linear(in_features=512, out_features=256, bias=True) (U): Linear(in_features=2048, out_features=256, bias=True) (A): Linear(in_features=256, out_features=1, bias=True) ) (init_h): Linear(in_features=2048, out_features=512, bias=True) (init_c): Linear(in_features=2048, out_features=512, bias=True) (lstm_cell): LSTMCell(2348, 512) (f_beta): Linear(in_features=512, out_features=2048, bias=True) (fcn): Linear(in_features=512, out_features=2994, bias=True) (drop): Dropout(p=0.3, inplace=False) ) ê·¸ëŸ¼ ì½”ë“œë¥¼ ë³´ë©´ì„œ í•´ì„í•´ ë´…ì‹œë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738394041424344# ë””ì½”ë”ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì–´í…ì…˜ì…ë‹ˆë‹¤.# Bahdanau Attentionclass Attention(nn.Module): def __init__(self, encoder_dim,decoder_dim,attention_dim): super(Attention, self).__init__() self.attention_dim = attention_dim self.U = nn.Linear(encoder_dim,attention_dim) self.W = nn.Linear(decoder_dim,attention_dim) self.A = nn.Linear(attention_dim,1) def forward(self, features, hidden_state): u_hs = self.U(features) #@@@ì¸ì½”ë”ì˜ ì€ë‹‰ìƒíƒœ?(query?) #(batch_size,num_layers,attention_dim) w_ah = self.W(hidden_state) #@@@ë””ì½”ë”ì˜ ì€ë‹‰ìƒíƒœ?(key?í˜¹ì€ value?) #(batch_size,attention_dim) combined_states = torch.tanh(u_hs + w_ah.unsqueeze(1)) #(batch_size,num_layers,attemtion_dim) # w_ahì—ë§Œ unsqueeze(1)í•˜ëŠ” ì´ìœ ëŠ” num_layersê°€ 1ì´ê³  u_hsì™€ ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ attention_scores = self.A(combined_states) #(batch_size,num_layers,1) attention_scores = attention_scores.squeeze(2) #(batch_size,num_layers) #ì–´í…ì…˜ ê°’ alpha = F.softmax(attention_scores,dim=1) #(batch_size,num_layers) attention_weights = features * alpha.unsqueeze(2) #(batch_size,num_layers,features_dim) #featuresì™€ ì—°ì‚°ì„ ìœ„í•´ ì°¨ì›ì„ ë§ì¶°ì¤Œ attention_weights = attention_weights.sum(dim=1) #(batch_size,num_layers) return alpha,attention_weights 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#Attention Decoderclass DecoderRNN(nn.Module): def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3): super().__init__() #save the model param self.vocab_size = vocab_size self.attention_dim = attention_dim self.decoder_dim = decoder_dim self.embedding = nn.Embedding(vocab_size,embed_size) self.attention = Attention(encoder_dim,decoder_dim,attention_dim) self.init_h = nn.Linear(encoder_dim, decoder_dim) #hidden self.init_c = nn.Linear(encoder_dim, decoder_dim) #cell self.lstm_cell = nn.LSTMCell(embed_size+encoder_dim,decoder_dim,bias=True) self.f_beta = nn.Linear(decoder_dim, encoder_dim) self.fcn = nn.Linear(decoder_dim,vocab_size) self.drop = nn.Dropout(drop_prob) def forward(self, features, captions): #vectorize the caption embeds = self.embedding(captions) # Initialize LSTM state h, c = self.init_hidden_state(features) # (batch_size, decoder_dim) #@@@ self.init_hidden_stateëŠ” initì— ì •ì˜ ì•ˆë˜ìˆëŠ”ë° ì–´ë–¤ì‹ìœ¼ë¡œ ì‘ë™ë  ìˆ˜ ìˆëŠ”ê±´ì§€? #get the seq length to iterate seq_length = len(captions[0])-1 #Exclude the last one batch_size = captions.size(0) num_features = features.size(1) preds = torch.zeros(batch_size, seq_length, self.vocab_size).to(device) alphas = torch.zeros(batch_size, seq_length,num_features).to(device) for s in range(seq_length): alpha,context = self.attention(features, h) lstm_input = torch.cat((embeds[:, s], context), dim=1) h, c = self.lstm_cell(lstm_input, (h, c)) output = self.fcn(self.drop(h)) preds[:,s] = output alphas[:,s] = alpha return preds, alphas def generate_caption(self,features,max_len=20,vocab=None): # Inference part # Given the image features generate the captions batch_size = features.size(0) h, c = self.init_hidden_state(features) # (batch_size, decoder_dim) alphas = [] #starting input word = torch.tensor(vocab.stoi['&lt;SOS&gt;']).view(1,-1).to(device) embeds = self.embedding(word) captions = [] for i in range(max_len): alpha,context = self.attention(features, h) #store the apla score alphas.append(alpha.cpu().detach().numpy()) lstm_input = torch.cat((embeds[:, 0], context), dim=1) h, c = self.lstm_cell(lstm_input, (h, c)) output = self.fcn(self.drop(h)) output = output.view(batch_size,-1) #select the word with most val predicted_word_idx = output.argmax(dim=1) #save the generated word captions.append(predicted_word_idx.item()) #end if &lt;EOS detected&gt; if vocab.itos[predicted_word_idx.item()] == &quot;&lt;EOS&gt;&quot;: break #send generated word as the next caption embeds = self.embedding(predicted_word_idx.unsqueeze(0)) #covert the vocab idx to words and return sentence return [vocab.itos[idx] for idx in captions],alphas def init_hidden_state(self, encoder_out): mean_encoder_out = encoder_out.mean(dim=1) h = self.init_h(mean_encoder_out) # (batch_size, decoder_dim) c = self.init_c(mean_encoder_out) return h, c 12345678910111213141516class EncoderDecoder(nn.Module): def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3): super().__init__() self.encoder = EncoderCNN() self.decoder = DecoderRNN( embed_size=embed_size, vocab_size = len(dataset.vocab), attention_dim=attention_dim, encoder_dim=encoder_dim, decoder_dim=decoder_dim ) def forward(self, images, captions): features = self.encoder(images) outputs = self.decoder(features, captions) return outputs 1234567#Hyperparamsembed_size=300vocab_size = len(dataset.vocab)attention_dim=256encoder_dim=2048decoder_dim=512learning_rate = 3e-4 1234567891011#init modelmodel = EncoderDecoder( embed_size=300, vocab_size = len(dataset.vocab), attention_dim=256, encoder_dim=2048, decoder_dim=512).to(device)criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi[&quot;&lt;PAD&gt;&quot;])optimizer = optim.Adam(model.parameters(), lr=learning_rate) 12345678910111213#helper function to save the modeldef save_model(model,num_epochs): model_state = { 'num_epochs':num_epochs, 'embed_size':embed_size, 'vocab_size':len(dataset.vocab), 'attention_dim':attention_dim, 'encoder_dim':encoder_dim, 'decoder_dim':decoder_dim, 'state_dict':model.state_dict() } torch.save(model_state,'attention_model_state.pth') Training Job from above configs 1234567891011121314151617181920212223242526272829303132333435363738394041num_epochs = 25print_every = 100for epoch in range(1,num_epochs+1): for idx, (image, captions) in enumerate(iter(data_loader)): image,captions = image.to(device), captions.to(device) # Zero the gradients. optimizer.zero_grad() # Feed forward outputs,attentions = model(image, captions) # Calculate the batch loss. targets = captions[:,1:] loss = criterion(outputs.view(-1, vocab_size), targets.reshape(-1)) # Backward pass. loss.backward() # Update the parameters in the optimizer. optimizer.step() if (idx+1)%print_every == 0: print(&quot;Epoch: {} loss: {:.5f}&quot;.format(epoch,loss.item())) #generate the caption model.eval() with torch.no_grad(): dataiter = iter(data_loader) img,_ = next(dataiter) features = model.encoder(img[0:1].to(device)) caps,alphas = model.decoder.generate_caption(features,vocab=dataset.vocab) caption = ' '.join(caps) show_image(img[0],title=caption) model.train() #save the latest model save_model(model,epoch) Visualizing the attentions123456789101112131415161718192021222324252627282930313233343536373839#generate captiondef get_caps_from(features_tensors): #generate the caption model.eval() with torch.no_grad(): features = model.encoder(features_tensors.to(device)) caps,alphas = model.decoder.generate_caption(features,vocab=dataset.vocab) caption = ' '.join(caps) show_image(features_tensors[0],title=caption) return caps,alphas#Show attentiondef plot_attention(img, result, attention_plot): #untransform img[0] = img[0] * 0.229 img[1] = img[1] * 0.224 img[2] = img[2] * 0.225 img[0] += 0.485 img[1] += 0.456 img[2] += 0.406 img = img.numpy().transpose((1, 2, 0)) temp_image = img fig = plt.figure(figsize=(15, 15)) len_result = len(result) for l in range(len_result): temp_att = attention_plot[l].reshape(7,7) ax = fig.add_subplot(len_result//2,len_result//2, l+1) ax.set_title(result[l]) img = ax.imshow(temp_image) ax.imshow(temp_att, cmap='gray', alpha=0.7, extent=img.get_extent()) plt.tight_layout() plt.show() 123456789#show any 1dataiter = iter(data_loader)images,_ = next(dataiter)img = images[0].detach().clone()img1 = images[0].detach().clone()caps,alphas = get_caps_from(img.unsqueeze(0))plot_attention(img1, caps, alphas)","link":"/2022/12/30/Personal_folder/for_project/2022-12-29-captioning_v2/"},{"title":"Keras ì†ì‹¤(loss) í•¨ìˆ˜ ì¢…ë¥˜","text":"ì†ì‹¤ í•¨ìˆ˜ ì†ì‹¤ í•¨ìˆ˜ë€?ì†ì‹¤ í•¨ìˆ˜ëŠ” ê°’ì„ ì˜ˆì¸¡í•˜ë ¤í•  ë•Œ ë°ì´í„°ì—ëŒ€í•œ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œì˜ ê°’ì„ ë¹„êµí•˜ëŠ” í•¨ìˆ˜ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ë•Œ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™” ì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ì´ë‹¤.ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì˜¬ë¦¬ê¸° ìœ„í•´ loss í•¨ìˆ˜ë¥¼ ì„ì˜ì ìœ¼ë¡œ ë³€í˜•í•  ìˆ˜ ìˆë‹¤. ë”¥ëŸ¬ë‹ì—ì„œ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ê°€ì§€ ë§ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ë¹„ìš© í•¨ìˆ˜(cost function) = ì†ì‹¤ í•¨ìˆ˜(loss function) = ì˜¤ì°¨ í•¨ìˆ˜(error function) = ëª©ì  í•¨ìˆ˜(objective function) Mean_Squared_error ì˜ˆì¸¡í•œ ê°’ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ í‰ê·  ì œê³± ì˜¤ì°¨ë¥¼ ì •ì˜í•œë‹¤. ê³µì‹ì´ ë§¤ìš° ê°„ë‹¨í•˜ë©°, ì°¨ê°€ ì»¤ì§ˆìˆ˜ë¡ ì œê³± ì—°ì‚°ìœ¼ë¡œ ì¸í•´ì„œ ê°’ì´ ë”ìš± ëšœë ·í•´ì§„ë‹¤.ê·¸ë¦¬ê³  ì œê³±ìœ¼ë¡œ ì¸í•´ì„œ ì˜¤ì°¨ê°€ ì–‘ìˆ˜ì´ë“  ìŒìˆ˜ì´ë“  ëˆ„ì  ê°’ì„ ì¦ê°€ì‹œí‚¨ë‹¤. 123from sklearn.metrics import mean_squared_errorMSE = mean_squared_error(y, y_pred) RMSE(Root Mean Squared error) Mean_Squared_errorì— Rootë¥¼ ì”Œìš´ ê°’ìœ¼ë¡œ ì™œê³¡ì„ ì¤„ì—¬ì¤€ë‹¤. 1234from sklearn.metrics import mean_squared_errorRMSE = mean_squared_error(y, y_pred)**0.5RMSE = mean_squared_error(y, y_pred, squared=False) RMSLE(Root mean squared Logarithmic error) ì¤‘ê°„ì— ë¡œê·¸ë¥¼ ì·¨í•´ì„œ í¸ì°¨ë¥¼ êµ¬í•¨ 1234from sklearn.metrics import mean_squared_log_errorMSLE = mean_squared_log_error(y, y_pred)RMSLE = mean_squared_log_error(y, y_pred)**0.5 Binary Crossentropy ì´ì§„ ë¶„ë¥˜(0ë˜ëŠ” 1ë¶„ë¥˜)ë¥¼ í•  ê²½ìš° ì‚¬ìš©. sparse_categorical_crossentropy vs categorical_crossentropy ëª¨ë‘ ë‹¤ì¤‘ ë¶„ë¥˜ ì†ì‹¤ í•¨ìˆ˜ì´ë‹¤. categorical_crossentropyëŠ” ë‹¤ì¤‘ ë¶„ë¥˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ one_hot_encoding í´ë˜ìŠ¤ì´ë‹¤ sparse_categorical_crossentropyëŠ” int_type í´ë˜ìŠ¤ì´ë‹¤. ê²°ë¡ ì ìœ¼ë¡œ, ì›í•«ë°±í„°ì¸ ê²½ìš° categorical_crossentropyintì¸ ê²½ìš°ì—ëŠ” sparse_categorical_crossentropyë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤.","link":"/2022/12/20/Study_folder/DL(Deep_Learning)/2022-12-20-loss/"},{"title":"ìŠ¤ì¼€ì¼ë§(Scaling)","text":"ì°¨ì›ì¶•ì†Œ (ë¹„ì§€ë„ í•™ìŠµ) ì¤‘ ìŠ¤ì¼€ì¼ë§ì„ í•˜ëŠ” ì´ìœ ì°¨ì› ì¶•ì†Œë¥¼ í•˜ëŠ” ì´ìœ  ê³ ì°¨ì› ë°ì´í„°(columns)ì˜ ì˜ë¯¸ì  íŠ¹ì„± -&gt; ìµœëŒ€í•œ ìœ ì§€ -&gt; ì €ì°¨ì› ì¶•ì†Œ í‘œí˜„shapeì´ M x N í–‰ë ¬ì—ì„œ(ë°ì´í„°í”„ë ˆì„) PCAë¥¼ ì´ìš©í•˜ì—¬ Nì°¨ì› -&gt; (Në³´ë‹¤ ì‘ì€)ì°¨ì› ì°¨ì›ì˜ ì €ì£¼ë¥¼ í”¼í•˜ê¸° ìœ„í•´ : outfittingì„ í”¼í•˜ê¸° ìœ„í•´ ë³€ìˆ˜ê°„ ì²™ë„ê°€ ë‹¤ë¦„ -&gt; ë¹„êµê°€ ë¶ˆê°€ëŠ¥, ëª¨ìˆ˜ì˜ ì™œê³¡ -&gt; ë³€ìˆ˜ì˜ í‘œì¤€í™” ì‘ì—…ì´ í•„ìš”(í‘œì¤€ ì •ê·œë¶„í¬ë¡œ í‘œì¤€í™” ë“±) ë°ì´í„° ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œëŠ” StandardScale, MinmaxScale, RobustScale, log1p ë“±ì´ ìˆë‹¤. ìŠ¤ì¼€ì¼ë§ ì˜ˆì‹œ1.í‘œì¤€í™”(StandardScaling) 123456789101112131415# í‘œì¤€í™” ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.import numpy as npimport scipy.stats as ssfrom sklearn.preprocessing import StandardScalerdata = np.random.randint(30, size=(6,5))# (data - mean)/std ì•„ë˜ 3ê°€ì§€ ë°©ë²• ëª¨ë‘ ë™ì¼í•œ ê²°ê³¼ê°’ì„ ë‚˜íƒ€ëƒ„(data-np.mean(data, axis=0))/np.std(data,axis=0)== ss.zscore(data) ==StandardScaler().fit_transform(data) # ê²°ê³¼ê°’array([[-1.2265705 , 0.67625223, 0.90236202, 1.28902742, -0.9166985 ], [-1.2265705 , -0.13525045, -1.44108561, -0.60505369, -0.9166985 ], [-0.19967427, -1.4877549 , -1.36027707, 1.28902742, -0.64168895], [ 1.51181945, 1.21725401, 0.82155348, -1.39425415, 1.74172714], [ 0.48492322, 0.81150267, 0.49831932, 0.02630668, -0.1833397 ], [ 0.65607259, -1.08200356, 0.57912786, -0.60505369, 0.9166985 ]]) 2.RobustScaler í‘œì¤€í™”(ì´ìƒì¹˜ê°€ ì ë‹¤ëŠ” ê°€ì •ì—ì„œ ìˆ˜í–‰), but ë§Œì•½ ì´ìƒì¹˜ê°€ ë§ë‹¤ë©´? ì´ìƒì¹˜ë¥¼ ì œê±°í›„ì— í‘œì¤€í™” í‰ê·  ëŒ€ì‹  ëœ ë¯¼ê°í•œ ì¤‘ìœ„ìˆ˜, í‘œì¤€í¸ì°¨ ëŒ€ì‹  IQR(data - mean)/std =&gt; (data - median)/IQR == RobustScaler 1234567891011# (data - median)/IQR == RobustScaler ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ê³  meanëŒ€ì‹  medianê°’ì„ ë¹¼ì¤Œ# ê·¸ë˜í”„ ê·¸ë ¤ë³´ë©´ í‘œì¤€í™”ë³´ë‹¤ ì´ì˜ê²Œ ë‚˜ì˜´from sklearn.preprocessing import RobustScalerRobustScaler().fit_transform(data) # ê²°ê³¼ê°’array([[-1.2265705 , 0.67625223, 0.90236202, 1.28902742, -0.9166985 ], [-1.2265705 , -0.13525045, -1.44108561, -0.60505369, -0.9166985 ], [-0.19967427, -1.4877549 , -1.36027707, 1.28902742, -0.64168895], [ 1.51181945, 1.21725401, 0.82155348, -1.39425415, 1.74172714], [ 0.48492322, 0.81150267, 0.49831932, 0.02630668, -0.1833397 ], [ 0.65607259, -1.08200356, 0.57912786, -0.60505369, 0.9166985 ]]) 3.MinMaxScaler 123456789from sklearn.preprocessing import MinMaxScaler, minmax_scaleMinMaxScaler().fit_transform(data)minmax_scale(data, axis=0) #ìœ„ì™€ ë™ì¼array([[0. , 0.8 , 1. , 1. , 0. ], [0. , 0.5 , 0. , 0.29411765, 0. ], [0.375 , 0. , 0.03448276, 1. , 0.10344828], [1. , 1. , 0.96551724, 0. , 1. ], [0.625 , 0.85 , 0.82758621, 0.52941176, 0.27586207], [0.6875 , 0.15 , 0.86206897, 0.29411765, 0.68965517]]) 4.log1p ê·¸ëƒ¥ logê°€ ì•„ë‹Œ 1pë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” 0ì— ê°€ê¹Œìš´ ì•„ì£¼ ì‘ì€ ì–‘ìˆ˜ì˜ ê²½ìš° (ex. 0.00001) ìŒì˜ ë¬´í•œëŒ€ì— ê°€ê¹Œì›Œì§€ê²Œ ëœë‹¤. ì¦‰ -infê°€ ë‚˜ì˜¤ê²Œë˜ê¸°ì— 1ì„ ë”í•œ log1pë¥¼ ì‚¬ìš©í•œë‹¤ 123import numpy as npdf = np.log1p(df)np.log1p(data)","link":"/2022/11/21/Study_folder/ML(Machin_Learning)/2022-11-21-Scaling/"},{"title":"ì¸ì½”ë”(Encorder) - pd.get_dummies","text":"get_dummies OneHotEncoderì™€ ë™ì¼í•˜ë©° í¸í•œ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. 1234567891011121314151617181920212223# ì˜ˆì‹œ ë°ì´í„°df = pd.DataFrame({'C1': np.random.randn(20),'C2': ['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a','b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']})C1 C20 0.839674 a1 -0.514992 a2 -2.072183 a3 -1.664719 a4 0.881287 a5 -1.151537 a6 0.768122 a7 0.942399 a8 0.384411 a9 -1.072716 a10 0.216321 b11 -0.018060 b12 -0.297903 b13 1.430495 b14 -0.258497 b15 0.509483 b16 0.526239 b17 1.305845 b18 -0.900900 b19 -0.463382 b 123456789101112131415161718192021222324# C2ì—´ ë”ë¯¸í™”pd.get_dummies(df,columns=['C2'],prefix='word') C1 word_a word_b0 0.303355 1 01 0.320274 1 02 -1.192643 1 03 -0.582344 1 04 1.233197 1 05 0.053738 1 06 -0.761975 1 07 -0.702154 1 08 0.949892 1 09 1.346181 1 010 1.883862 0 111 -0.766519 0 112 -0.417308 0 113 -0.674398 0 114 0.589356 0 115 -1.489583 0 116 0.077735 0 117 0.479897 0 118 1.244302 0 119 -2.331532 0 1","link":"/2022/11/21/Study_folder/ML(Machin_Learning)/2022-11-21-get_dummies/"},{"title":"callbacks - EarlyStopping, ModelCheckpoint","text":"1234567891011121314from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint# earlystopping == ë”ì´ìƒ ê°œì„ ì´ ì•ˆë  ê²½ìš° ìŠ¤íƒ‘í•˜ëŠ” ê¸°ëŠ¥.# ê´€ì‹¬ ê°€ì§€ëŠ” ë³€ìˆ˜ monitor = 'ë³€ìˆ˜'# ì—°ì†í•´ì„œ 4ë²ˆì˜ ë³€í™”ê¹Œì§€ëŠ” ì°¸ëŠ”ë‹¤(ê³„ì† ì§„í–‰í•œë‹¤) patience = 4es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)# ëª¨ë¸ ì„ì‹œ ì €ì¥ modelcheckpointmc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)# ì½œë°±(callback) : ì‹œìŠ¤í…œì´ ì–´ë–¤ ìƒí™©ì´ ë˜ì—ˆì„ë•Œ ì‹œìŠ¤í…œì— ì˜í•´ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])history = model.fit(X_train, y_train, batch_size=128, epochs=2, callbacks=[es, mc], validation_data=(X_test, y_test))","link":"/2022/12/01/Study_folder/DL(Deep_Learning)/2022-12-03-callbacks/"},{"title":"ì¸ì½”ë”(Encorder) - OneHotEncoder","text":"OneHotEncoder ì‚¬ìš©í•˜ëŠ” ì´ìœ  : ì¼ë‹¨ object typeì€ ë¨¸ì‹ ëŸ¬ë‹ fitì„ í•  ìˆ˜ ì—†ê³ , ì¹´í…Œê³ ë¦¬í™”ë¥¼ í•˜ì—¬ fittingì„ ì •í™•í•˜ê²Œ í•˜ê¸° ìœ„í•¨ì´ë‹¤. ë°©ë²•ì—ëŠ” OneHotEncoder, get_dummies ë“±ì´ ìˆë‹¤. 1OneHotEncoder().fit_transform(data3['column1','column2']) 1234567891011OneHotEncoder : ë²”ì£¼í˜• ë³€ìˆ˜ -&gt; ì´í•­ ë³€ìˆ˜ex) ì„±ì  columnì— ['a','b','c','d'] ì´ë ‡ê²Œ ìˆë‹¤ë©´ OneHotEncoder ì ìš©ì‹œ ì•„ë˜ì™€ê°™ì´ ë³€ê²½í•  ìˆ˜ ìˆë‹¤. 0 1 2 3 4(colums) --------- a 1 0 0 0 0 b 0 1 0 0 0 c 0 0 1 0 0 d 0 0 0 1 0 f 0 0 0 0 1 123456789101112# ì˜ˆë¥¼ ë“¤ì–´ data3ì„ OneHotEncoderë¡œ ëŒë¦¬ê²Œ ë˜ë©´,# ex) ì„±ë³„ : male(0), female(1)# ì—°ë ¹ëŒ€ : 20ëŒ€(0), 30ëŒ€(1), 40ëŒ€(1)# ì„±ì  : a(0), b(1), c(2), d(3), f(4) =&gt;# ì„±ë³„ ë°ì´í„°2, ì—°ë ¹ëŒ€:3, ì„±ì  :5data3 = np.array([ [0, 0, 0],#ë‚¨ì, 20ëŒ€, a(ì„±ì ) [0, 2, 4],#ë‚¨ì, 40ëŒ€, f [1, 1, 1],#ì—¬ì, 30ëŒ€, b [1, 0, 3] #ì—¬ì, 20ëŒ€, c]) 1234567OneHotEncoder().fit_transform(data3).toarray()# ì„±ë³„(1ìë¦¬), ì—°ë ¹ëŒ€(3), ì„±ì (5) col &gt;[ì„±ë³„, ì—° ë ¹ ëŒ€ , ì„± ì  ~~~~~~~~]array([[1., 0., 1., 0., 0., 1., 0., 0., 0.], [1., 0., 0., 0., 1., 0., 0., 0., 1.], [0., 1., 0., 1., 0., 0., 1., 0., 0.], [0., 1., 1., 0., 0., 0., 0., 1., 0.]]) ì¸ì½”ë”©ëœ ê°’ë“¤ì„ í™•ì¸í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 12345fitted_data3 = OneHotEncoder().fit(data3)fitted_data3.n_features_in_# ê²°ê³¼ê°’ì€ &quot;3&quot;ì´ ì¶œë ¥ (ì„±ë³„,ì—°ë ¹ëŒ€,ì„±ì )fitted_data3.categories_# ê²°ê³¼ê°’ì€ [array([0, 1]), array([0, 1, 2]), array([0, 1, 3, 4])]","link":"/2022/11/21/Study_folder/ML(Machin_Learning)/2022-11-21-OneHotEncoder/"},{"title":"globals(), eval()","text":"globas() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ  forë¬¸ì„ ëŒë¦¬ê¸° ì „ì— í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ë©´ 1~2ê°œ ì •ë„ëŠ” ê·¸ëƒ¥ ë§Œë“¤ë©´ ë˜ì§€ë§Œ ì—¬ëŸ¬ê°œì˜ í•¨ìˆ˜ë¥¼ ëª…ëª…í•  ê²½ìš° ìƒê°ë³´ë‹¤ ë³´ê¸°ì— ì•ˆì¢‹ê³  ë°˜ë³µ ì‘ì—…ì´ ë  ìˆ˜ ìˆê¸°ì— globals() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. 1234567# ì˜ˆë¥¼ ë“¤ì–´ item_1 ~ item5 ê¹Œì§€ í•¨ìˆ˜ë¥¼ ë§Œë“ ë‹¤ê³  ê°€ì •í•´ë³´ì# globals()ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì§€ì €ë¶„í•˜ê²Œ ë³´ì¸ë‹¤.item_1 = []item_2 = []item_3 = []item_4 = []item_5 = [] 123# ì•„ë˜ì™€ ê°™ì´ 2ì¤„ì´ë©´, ì—¬ëŸ¬ê°œì˜ í•¨ìˆ˜ë¥¼ ìƒì„± ê°€ëŠ¥í•˜ë‹¤.for i in range(1,6): globals()[f'items_{i}'] = [] eval() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ  evalí•¨ìˆ˜ëŠ” ' ' &lt;-ì´ëŸ¬í•œ í™‘ë”°ìŒí‘œë¡œ ë¬¶ì¸ê²ƒì—ì„œ í™‘ë”°ìŒí‘œë¥¼ ì œê±°í•´ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤. forë¬¸ì—ì„œ ê·œì¹™ì„±ì´ ìˆëŠ” í•¨ìˆ˜ë¥¼ í˜¸ì¶œ(ì¶”ì¶œ)í•  ê²½ìš° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ê²Œ ë¬´ìŠ¨ë§ì¸ì§€ ì´í•´ê°€ ì˜ ì•ˆê°ˆ ìˆ˜ ìˆì–´ì„œ ì˜ˆì‹œë¥¼ ë³´ì—¬ì£¼ê² ìŠµë‹ˆë‹¤. 123456789item_1 = ['ê°€','ë‚˜','ë‹¤']item_2 = ['ë¼','ë§ˆ','ë°”']# evalì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ìš°for i in range(1,3): print(f'item_{i}')#ì¶œë ¥ ê²°ê³¼item_1item_2 1234567# evalì„ ì‚¬ìš©í•œ ê²½ìš°for i in range(1,3): print(eval(f'item_{i}'))#ì¶œë ¥ ê²°ê³¼['ê°€', 'ë‚˜', 'ë‹¤']['ë¼', 'ë§ˆ', 'ë°”'] globals()ì™€ eval()ì„ ê°™ì´ ì‚¬ìš©ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤1234567891011# ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡œìš´ ë³€ìˆ˜ëª…(í•¨ìˆ˜)ì— ì…ë ¥ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.test_1 = [1,2,3]test_2 = [4,5,6]for i in range(1,3): globals()[f'items_{i}'] = eval(f'test_{i}')print(items_1)print(items_2)# ì¶œë ¥ ê²°ê³¼[1, 2, 3][4, 5, 6]","link":"/2022/11/23/Study_folder/Basic_study/2022-11-23-globals(),eval()/"},{"title":"pickle()-íŒŒì¼,ë¦¬ìŠ¤íŠ¸ ì €ì¥","text":"pickle íŒŒì´ì¬ì—ì„œ ì‘ì—…ì¤‘ì´ë˜ ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬ ë“±ì„ ì €ì¥í•´ì„œ ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œ ì—´ê³  ì‹¶ì„ ê²½ìš° í”¼í´ íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ì €ì¥, ë¶ˆëŸ¬ì˜¤ê¸°ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. with open(íŒŒì¼ ì´ë¦„, íŒŒì¼ ëª¨ë“œ) as f: # &lt;- fë¼ëŠ” ì´ë¦„ì˜ íŒŒì¼ë¡œ íŒŒì¼ ì´ë¦„, ëª¨ë“œë¥¼ ì—°ë‹¤ëŠ” ì˜ë¯¸. 12345678import picklelist_save = [1, 2, 3, 4]# í”¼í´ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ê²ë‹ˆë‹¤. íŒŒì¼ ëª…ì€ &quot;list_ex.pkl&quot;ë¡œ ì €ì¥# í¸ì§‘ ê°€ëŠ¥í•˜ê²Œ 'wb'with open(&quot;list_ex.pkl&quot;,&quot;wb&quot;) as f: pickle.dump(list_save, f) 12345678# ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤import picklewith open(&quot;list_save.pkl&quot;,&quot;rb&quot;) as f: list_load = pickle.load(f)print(list_load)# [1, 2, 3, 4] íŒŒì¼ ëª¨ë“œ ì„¤ëª…(ë³´í†µ wb,rbë¥¼ ë§ì´ ì‚¬ìš©)) |file_mode|ê¸°ëŠ¥|ì„¤ëª…||â€™râ€™|ì½ê¸° ì „ìš©|íŒŒì¼ì„ ì½ì–´ì˜¤ëŠ” ê¸°ëŠ¥ì´ë©°, íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬||â€™wâ€™|ì“°ê¸° ì „ìš©|íŒŒì¼ì´ ìˆìœ¼ë©´ ë‚´ìš©ì„ ë®ì–´ ì”€||â€™aâ€™|ì¶”ê°€|íŒŒì¼ì´ ì—†ìœ¼ë©´ íŒŒì¼ì„ ìƒì„±||â€™bâ€™|ë°”ì´ë„ˆë¦¬ ëª¨ë“œ|íŒŒì¼ì˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì½ê³ , ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©| joblibìœ¼ë¡œ ì €ì¥, ë¶ˆëŸ¬ì˜¤ê¸°1234567#joblibìœ¼ë¡œ dumpí•˜ì—¬ í”¼í´ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê¸°.import joblibjoblib.dump((x_train, x_test, y_train, y_test), 'review.pkl')# ë¶ˆëŸ¬ì˜¤ê¸°x_train, x_test, y_train, y_test = joblib.load('review.pkl')","link":"/2022/11/30/Study_folder/Basic_study/2022-11-30-save-list(pickle)/"},{"title":"íŒŒì´ì¬ì—ì„œ ZipFile ì—´ê¸°","text":"from zipfile import ZipFileë¡œ ì••ì¶• í•´ì œí•˜ì§€ ì•Šê³  ì‚¬ìš©í•˜ê¸°1234567891011121314151617181920from zipfile import ZipFileimport pandas as pd# zipíŒŒì¼ ì—´ê¸°(ì••ì¶• í•´ì œí•˜ì§€ì•Šê³  ì‚¬ìš©)z = ZipFile('sentiment labelled sentences.zip')# ì–´ë–¤ ë¦¬ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸z.namelist()# ì¶œë ¥ ê²°ê³¼# ['sentiment labelled sentences/amazon_cells_labelled.txt']# zipíŒŒì¼ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ ì½ì–´ì˜´.# í¸ì§‘ ì‘ì—… ì‹œ ì•„ë˜ì™€ ê°™ì´ `pd.read_csv` ê°™ì€ í•¨ìˆ˜ë¡œ ë³€ê²½(ì˜®ê²¨)í•˜ì—¬ ì‚¬ìš©data = z.open('sentiment labelled sentences/amazon_cells_labelled.txt')df = pd.read_csv(data, sep=&quot;\\t&quot;, header=None)# ìì„¸í•œ ì •ë³´ í™•ì¸zip_info = my_zip.getinfo('sentiment labelled sentences/amazon_cells_labelled.txt') print(zip_info.filename) #íŒŒì¼ ì´ë¦„print(zip_info.file_size)#íŒŒì¼ ì‚¬ì´ì¦ˆprint(zip_info.date_time)#ì‘ì„±ì¼ zipíŒŒì¼ì„ ê²½ë¡œì— ì‹¤ì œë¡œ ì••ì¶• í•´ì œí•˜ê¸°1234!unzip test.zip# -dì˜µì…˜ìœ¼ë¡œ ê²½ë¡œ ì§€ì • ê°€ëŠ¥(í´ë” ìë™ ìƒì„±)%unzip test.zip -d test_folder/ 1234567891011121314from zipfile import ZipFile#íŠ¹ì • íŒŒì¼ë§Œ ì••ì¶• í•´ì œí•  ê²½ìš° ì‚¬ìš©(ë¦¬ìŠ¤íŠ¸ forë¬¸ì´ë¼ ì‹œê°„ì´ ê½¤ ê±¸ë¦¼)directory = './' #í˜„ì¬ ê²½ë¡œwith ZipFile('TeamA_name2.zip') as f : x = [f.extract(file, directory) for file in f.namelist() if file.endswith('jpg')] #íŠ¹ì • í™•ì¥ìë§Œ ì••ì¶• í•´ì œí•˜ê¸°(endwith('jpg'))#xëŠ” ì•„ë¬´ ë³€ìˆ˜ë‚˜ ì¤˜ë„ ë©ë‹ˆë‹¤.# ì „ì²´ ì••ì¶• í•´ì œë¥¼ ì›í•˜ëŠ” ê²½ìš°(ì—„ì²­ ë¹ ë¦„)import zipfilezip_file=zipfile.ZipFile('TeamA_name2.zip')#íŒŒì¼ ì´ë¦„zip_file.extractall(path='/content/temtem')#ì••ì¶• í•´ì œ ê²½ë¡œ, default(path=None) ì™¸ë¶€ ê²½ë¡œë¥¼ í†µí•´ zipíŒŒì¼ì„ ë‹¤ìš´ ë°›ê³  ì••ì¶• í•´ì œí•˜ê¸°(ì¼€ë¼ìŠ¤ ë°ì´í„°ì…‹ì— ì €ì¥)123456789101112131415161718192021222324252627282930313233## Download the movielens data from website urlimport tensorflow.keras as kerasfrom zipfile import ZipFilefrom pathlib import Pathimport os#zipíŒŒì¼ì´ ìˆëŠ” urlzipped_url = ( 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip')#zip_filezipped_file = keras.utils.get_file( 'zipped_dataset.zip', zipped_url, extract=True)keras_path = Path(zipped_file).parents[0] #ì „ì˜ ê²½ë¡œ ì„¤ì •print('datasets path:', keras_path) #ë°ì´í„°ë“¤ì´ ì¼€ë¼ìŠ¤ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.# datasets path: /root/.keras/datasetsprint(os.listdir(keras_path))#['ml-latest-small', 'zipped_dataset.zip']movielens_dir = keras_path / os.listdir(keras_path)[0] #keras_pathì˜ íŒŒì¼ ëª©ë¡ ì¤‘ ì²«ë²ˆì§¸ ëª©ë¡ì„ ì„ì˜ë¡œ ì§€ì •#ëŸ°íƒ€ì„ 1íšŒë§Œ ì‚¬ìš© ê°€ëŠ¥if not movielens_dir.exists(): with ZipFile(zipped_file, &quot;r&quot;) as zip: zip.extractall(path=keras_path) #ì••ì¶• í•´ì œprint(os.listdir(movielens_dir))#['tags.csv', 'movies.csv', 'README.txt', 'links.csv', 'ratings.csv']","link":"/2022/12/03/Study_folder/Basic_study/2022-12-03-ZipFile/"},{"title":"Class(í´ë˜ìŠ¤, í´ë˜ìŠ¤ ìƒì†)","text":"í´ë˜ìŠ¤(Class) í´ë˜ìŠ¤ : í´ë˜ìŠ¤ëŠ” ë°ì´í„°ì™€ ê¸°ëŠ¥ì„ í•¨ê»˜ ë¬¶ëŠ” ë°©ë²• ì¸ìŠ¤í„´ìŠ¤ : í´ë˜ìŠ¤ë¡œ ì •ì˜ëœ ê°ì²´ë¥¼ í”„ë¡œê·¸ë¨ ìƒì—ì„œ ì´ìš©í•  ìˆ˜ ìˆê²Œ ë§Œë“  ë³€ìˆ˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í´ë˜ìŠ¤ë¥¼ ë¨¼ì € ë§Œë“¤ì–´ì•¼ í•¨ í´ë˜ìŠ¤ì˜ í•¨ìˆ˜ : ë©”ì†Œë“œ &lt; í´ë˜ìŠ¤ ë‚´ë¶€ì˜ í•¨ìˆ˜ í´ë˜ìŠ¤ì˜ ëª…ëª…ì€ ë§¨ ì•ìëŠ” ëŒ€ë¶„ìë¥¼ ì“°ëŠ”ê²Œ ì¼ë°˜ì ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì œ ì…ë‹ˆë‹¤. ì˜ˆì‹œ1 - í´ë˜ìŠ¤ ìƒì„±12345678910111213141516171819202122232425262728293031323334class Charicters : # í´ë˜ìŠ¤ì˜ ìƒì„±ì # def __init__ ì€ ì´ì™€ ìœ ì‚¬í•œ í˜•ì‹ì„ ë”°ë¼ì•¼ í•¨ def __init__(self, name, hobby): self.name = name #í´ë˜ìŠ¤ì˜ ë§´ë²„ self.hobby = hobby #í´ë˜ìŠ¤ì˜ ë§´ë²„ #í´ë˜ìŠ¤ì˜ ë©”ì†Œë“œ def xxx(self): print(f'ì´ë¦„ : {self.name}, ì·¨ë¯¸ : {self.hobby}') #setter ë©”ì†Œë“œ def set_hobby(self, hobby): self.hobby = hobby #í´ë˜ìŠ¤ ê³„ìŠ¹ì„ ìœ„í•œ í•¨ìˆ˜(ë°‘ì˜ ì˜ˆì‹œìš©) def nice(self): print('nice to meet you')a = Characters('ì¡°ì¸í™˜', 'í´ë¼ì´ë°')a.xxx()# ì¶œë ¥ ê²°ê³¼# ì´ë¦„ : ì¡°ì¸í™˜, ì·¨ë¯¸ : í´ë¼ì´ë°a.hobby# ì¶œë ¥ ê²°ê³¼# í´ë¼ì´ë°a = Characters('ì¡°ì¸í™˜', 'í´ë¼ì´ë°')a.set_hobby('ì‚°ì±…')a.xxx()# ì¶œë ¥ ê²°ê³¼# ì´ë¦„ : ì¡°ì¸í™˜, ì·¨ë¯¸ : ì‚°ì±… ì˜ˆì‹œ 2 - í´ë˜ìŠ¤ ìƒì† - ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„±(pytorch) ë¶€ëª¨ì™€ ìì‹ ê´€ê³„ê°€ ì¡´ì¬ ë¶€ëª¨ í´ë˜ìŠ¤ : ê¸°ì¡´ì˜ í´ë˜ìŠ¤ ìì‹ í´ë˜ìŠ¤ : ë¶€ëª¨ í´ë˜ìŠ¤ë¥¼ ìƒì† ë°›ì€ í´ë˜ìŠ¤ 12345678910111213141516#í´ë˜ìŠ¤ì—ì„œ í´ë ˆìŠ¤ë¥¼ ë§Œë“œëŠ”ê²ƒì„ í´ë˜ìŠ¤ ìƒì†ì´ë¼ê³  í•©ë‹ˆë‹¤.class Baby(Characters) : def hansome(self): #super()ë¥¼ ì‚¬ìš©í•˜ë©´ ë¶€ëª¨ í´ë˜ìŠ¤ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. super().nice() def hobi_is(self): print(f'{self.name}ì˜ ì·¨ë¯¸ëŠ” {self.hobby}ì…ë‹ˆë‹¤')b = Baby('ì¡°ì¸í™˜','í´ë¼ì´ë°')b.nice()#nice to meet youb.hobi_is()# ì¡°ì¸í™˜ì˜ ì·¨ë¯¸ëŠ” í´ë¼ì´ë°ì…ë‹ˆë‹¤ ì˜ˆì‹œ 3 - í´ë˜ìŠ¤ ìƒì† - ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„±(pytorch)123456789101112131415161718192021222324252627282930313233343536import torchimport torch.nn as nn#NeuralNetì´ë¼ëŠ” í´ë˜ìŠ¤ë¥¼ ë§Œë“¬(nn.Moduleì„ ìƒì†)class NeuralNet(nn.Module): def __init__(self): # torch.nn.Moduleì˜ NeuralNetì„ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ # (from nn import NeuralNet)ë¥¼ ìˆ˜í–‰ super(NeuralNet, self).__init__() #Conv2dë¥¼ 2ë²ˆ, Linearë¥¼ 2ë²ˆ ì‹¤í–‰í•œë‹¤ëŠ” ì˜ë¯¸ self.conv1 = nn.Conv2d(1,8,2) self.conv2 = nn.Conv2d(8,10,3) self.fc1 = nn.Linear(10*5*5,60) self.fc2 = nn.Linear(60,10) def forward(self,x): x = F.max_pool2d(F.relu(self.conv1(x)), 2) x = F.max_pool2d(F.relu(self.conv2(x)), 2) #LinearëŠ” flattení•œ ë°ì´í„°ë§Œ ì‚¬ìš© ê°€ëŠ¥í•´ì„œ ë°ì´í„° í¸ì§‘ x = x.view(-1,self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = self.fc2(x) return x def num_flat_features(self, x): size = x.size()[1:] num_features = 1 for s in size: num_features *= s return num_featuresnet = NeuralNet()print(net)","link":"/2022/11/30/Study_folder/Basic_study/2022-11-30-Class/"},{"title":"Portfolio(ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ 1)","text":"ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ 1 ë¬¸ì œ123456789101112131415161718192021222324252627282930313233343536373839404142431. tmdb_5000_movies ë°ì´í„° ì…‹ ë¶„ì„1) ì˜ˆì‚°ê³¼ ì¥ë¥´ ê´€ê³„?2) í‚¤ì›Œë“œë¡œ ë§ì´ ì‚¬ìš©ëœ ë‹¨ì–´ëŠ”? 3) ì¥ë¥´ì™€ í‚¤ì›Œë“œ ê´€ê³„ëŠ”?4) í‰ê·  í‰ì ê³¼ ì¥ë¥´ ì‚¬ì´ì˜ ê´€ê³„?5) ì—°ë„ë³„ë¡œ ë§ì´ ì œì‘ëœ ì˜í™” ì¥ë¥´ëŠ”?6) ì¸ê¸°ë„ì™€ ì˜ˆì‚° ê´€ê³„ëŠ”?7) ì˜í™” run timeê³¼ ì¸ê¸°ë„ ì‚¬ì´ì— ê´€ê³„ê°€ ìˆì„ê¹Œ?2. tmdb_5000_movies ë°ì´í„° ê¸°ë°˜ ì¶”ì²œì‹œìŠ¤í…œ ì œì‘â€‹3. dataset ë°ì´í„° ë¶„ì„ ë° ì—°ê´€ ê·œì¹™ ìƒì„±1) dataset íŒŒì¼ ë¶„ì„2) ì—°ë„ë³„ ë§ì´ / ì ê²Œ íŒ”ë¦° ì•„ì´í…œì€?3) member id ì— ë”°ë¥¸ êµ¬ë§¤ ì—°(ì›”, ìš”ì¼)ë„, ì•„ì´í…œ ë¶„ì„- ë¬´ìŠ¨ ìš”ì¼ì— ì™€ì„œ êµ¬ë§¤ë¥¼ ë§ì´ í–ˆì„ê¹Œ?4) ì—°ê´€ ê·œì¹™ ìƒì„±5) ì—°ê´€ ê·œì¹™ì— ë”°ë¥¸ vip memberì—ê²Œ ì–´ë–¤ ìƒí’ˆì„ ì¶”ì²œí• ê¹Œ?-vipëŠ” ë§¤ì¶œíšŸìˆ˜ê°€ ê°€ì¥ ë§ì€ ìƒìœ„ 100ëª… â€‹4. ì™€ì¸ì˜ í™”í•™ ì¡°ì„±ì„ ì‚¬ìš©í•˜ì—¬ ì™€ì¸ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ë°ì´í„°ì´ë‹¤. load_wine() ëª…ë ¹ìœ¼ë¡œ ë¡œë“œí•˜ë©° ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì™€ì¸ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤.from sklearn.datasets import load_wine 1,2ë²ˆ ë¬¸ì œ1234import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sns 123t_df = pd.read_csv('../Downloads/tmdb_5000_movies.csv')g_df = pd.read_csv('../Downloads/Groceries_dataset.csv')pd.options.display.max_columns=50 123t_df.drop(columns=['homepage','tagline','status'],inplace=True)t_df.dropna(inplace=True)t_df.reset_index(drop=True,inplace=True) 1234567# json ì—´ì„ nameë§Œ ì¶”ì¶œí•˜ì—¬ ì „ì²˜ë¦¬, keywordsëŠ” ê³µë°±ì´ ìœ ì˜ë¯¸í•œ ë‹¨ìœ„ì´ë¯€ë¡œ ë”°ë¡œ ì²˜ë¦¬json_col = ['genres','production_companies','production_countries','spoken_languages']for i in json_col: t_df[i] = t_df[i].apply(lambda x : eval(x)) t_df[i] = t_df[i].apply(lambda x : [d['name'] for d in x]).apply(lambda x : ' '.join(x))t_df['keywords'] = t_df['keywords'].apply(lambda x : eval(x))t_df['keywords'] = t_df['keywords'].apply(lambda x : [d['name'] for d in x]).apply(lambda x : ','.join(x)) 123456# 1) ì˜ˆì‚°ê³¼ ì¥ë¥´ ê´€ê³„?t_df['budget_cat'] = pd.qcut(t_df['budget'],5,duplicates='drop')t_df.pivot_table(index='budget_cat',columns='genres',aggfunc='count')# ì›¨ìŠ¤í„´í’ì€ ì €ì˜ˆì‚°ì´ ë§ê³ , ì–´ë“œë²¤ì³ìª½ì€ ê³ ì˜ˆì‚°ì´ ë§ë‹¤. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } budget ... vote_count genres Action Action Adventure Action Adventure Animation Comedy Family Action Adventure Animation Comedy Family Fantasy Romance Action Adventure Animation Comedy Family Fantasy Science Fiction Action Adventure Animation Comedy Science Fiction Action Adventure Animation Family Action Adventure Animation Family Fantasy Action Adventure Animation Fantasy Science Fiction Action Adventure Animation Science Fiction Thriller Action Adventure Comedy Action Adventure Comedy Crime Action Adventure Comedy Crime Drama Action Adventure Comedy Crime Mystery Thriller Action Adventure Comedy Crime Romance Thriller Action Adventure Comedy Crime Thriller Action Adventure Comedy Drama Family Music Romance Action Adventure Comedy Drama Foreign Action Adventure Comedy Drama Mystery Action Adventure Comedy Drama Science Fiction Thriller Action Adventure Comedy Family Action Adventure Comedy Family Fantasy Action Adventure Comedy Family Fantasy Science Fiction Action Adventure Comedy Family Science Fiction ... War War Action War Action Adventure Drama Thriller War Action Drama History Thriller War Adventure Drama Romance War Comedy Drama War Crime Drama Mystery Romance Thriller War Drama War Drama Action War Drama History War Drama History Action War Drama History Action Romance War Drama Romance War History Action Adventure Drama Romance War History Drama War Western Western Western Action Drama History Western Adventure Western Animation Adventure Comedy Family Western Comedy Western Drama Western Drama Adventure Thriller Western History Western History War budget_cat (-0.001, 7500000.0] 27 6 1 0 1 0 1 0 0 1 0 3 1 1 0 0 0 0 1 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 2 0 2 0 0 1 0 0 1 15 1 0 0 1 0 0 0 0 (7500000.0, 22000000.0] 0 3 0 0 0 0 0 0 0 0 0 4 2 0 0 0 0 1 0 0 1 0 0 1 0 ... 1 0 0 0 0 1 0 2 0 0 0 1 0 0 1 0 2 0 0 0 0 2 0 1 0 (22000000.0, 50000000.0] 0 7 0 0 0 1 0 0 0 0 1 5 0 0 0 0 0 0 0 0 0 2 0 0 1 ... 0 0 0 1 2 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 (50000000.0, 380000000.0] 0 5 7 2 0 0 0 1 1 0 0 8 0 0 1 1 3 0 0 1 0 1 1 1 0 ... 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 4 rows Ã— 18800 columns 123456789101112# 2) í‚¤ì›Œë“œë¡œ ë§ì´ ì‚¬ìš©ëœ ë‹¨ì–´ëŠ”? t_df.keywordsfrom collections import Countera = []for i in range(len(t_df['keywords'])): a.append(t_df['keywords'][i])a = ''.join(a)words = a.split(',')counter = Counter(words)print(counter.most_common(5))# ('independent film', 192), ('murder', 172), ('violence', 146), ('dystopia', 120), ('duringcreditsstinger', 116) [('independent film', 192), ('murder', 172), ('violence', 146), ('dystopia', 120), ('duringcreditsstinger', 116)] 12345678910111213141516171819202122232425262728293031# 3) ì¥ë¥´ì™€ í‚¤ì›Œë“œ ê´€ê³„ëŠ”?&quot;&quot;&quot;1) Tf(Term Frequency)í•˜ë‚˜ì˜ ë¬¸ì„œ(ë¬¸ì¥)ì—ì„œ íŠ¹ì • ë‹¨ì–´ê°€ ë“±ì¥í•˜ëŠ” íšŸìˆ˜2) Idf(Inverse Document Frequency)Df(Document Frequency)ëŠ” ë¬¸ì„œ ë¹ˆë„. íŠ¹ì • ë‹¨ì–´ê°€ ëª‡ ê°œì˜ ë¬¸ì„œ(ë¬¸ì¥)ì—ì„œ ë“±ì¥í•˜ëŠ”ì§€ë¥¼ ìˆ˜ì¹˜í™” í•œ ê²ƒ. ê·¸ê²ƒì˜ ì—­ìˆ˜ê°€ idfë‹¤.ë³´í†µ ê·¸ëƒ¥ ì—­ìˆ˜ë¥¼ ì·¨í•˜ê¸° ë³´ë‹¤ëŠ” ì•„ë˜ì²˜ëŸ¼ ìˆ˜ì‹í™”í•œë‹¤. ì—­ìˆ˜ ê°œë…ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ”, ì ì€ ë¬¸ì„œ(ë¬¸ì¥)ì— ë“±ì¥í• ìˆ˜ë¡ í° ìˆ«ìê°€ ë˜ê²Œí•˜ê³  ë°˜ëŒ€ë¡œ ë§ì€ ë¬¸ì„œ(ë¬¸ì¥)ì— ë“±ì¥í• ìˆ˜ë¡ ìˆ«ìë¥¼ ì‘ì•„ì§€ê²Œ í•¨ìœ¼ë¡œì¨ì—¬ëŸ¬ ë¬¸ì„œ(ë¬¸ì¥)ì— ì˜ë¯¸ ì—†ì´ ì‚¬ìš©ë˜ëŠ” ë‹¨ì–´ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ì„œë‹¤.&quot;&quot;&quot;from sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.metrics.pairwise import cosine_similaritytfidf_vector = TfidfVectorizer()#ì¥ë¥´ì™€ í‚¤ì›Œë“œë¥¼ ë°±í„°í™”tfidf_matrix = tfidf_vector.fit_transform(t_df['genres']+ ' ' + t_df['keywords']).toarray()#ë²¡í„°í™”ë˜ê¸° ì „ ì´ë¦„ë“¤ì„ ì¶”ì¶œtfidf_matrix_feature = tfidf_vector.get_feature_names_out()#ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸°tfidf_matrix = pd.DataFrame(tfidf_matrix, columns=tfidf_matrix_feature, index = t_df.title)#ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ìœ ì‚¬ ê´€ê³„ íŒŒì•…cosine_sim = cosine_similarity(tfidf_matrix)cosine_sim_df = pd.DataFrame(cosine_sim, index = t_df.title, columns = t_df.title)cosine_sim_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title Avatar Pirates of the Caribbean: At World's End Spectre The Dark Knight Rises John Carter Spider-Man 3 Tangled Avengers: Age of Ultron Harry Potter and the Half-Blood Prince Batman v Superman: Dawn of Justice Superman Returns Quantum of Solace Pirates of the Caribbean: Dead Man's Chest The Lone Ranger Man of Steel The Chronicles of Narnia: Prince Caspian The Avengers Pirates of the Caribbean: On Stranger Tides Men in Black 3 The Hobbit: The Battle of the Five Armies The Amazing Spider-Man Robin Hood The Hobbit: The Desolation of Smaug The Golden Compass King Kong ... Rampage Slacker Dutch Kills Dry Spell Flywheel Backmask The Puffy Chair Stories of Our Lives Breaking Upwards All Superheroes Must Die Pink Flamingos Clean The Circle Tin Can Man Cure On The Downlow Sanctuary: Quite a Conundrum Bang Primer Cavite El Mariachi Newlyweds Signed, Sealed, Delivered Shanghai Calling My Date with Drew title Avatar 1.000000 0.033911 0.017435 0.004221 0.248501 0.035139 0.024894 0.059988 0.023661 0.022763 0.043666 0.022542 0.022596 0.010072 0.088634 0.043253 0.077686 0.102427 0.143133 0.092661 0.021569 0.029362 0.045073 0.022733 0.013829 ... 0.010297 0.008659 0.000000 0.061893 0.000000 0.000000 0.023269 0.000000 0.031020 0.074724 0.030946 0.000000 0.000000 0.0 0.000000 0.012150 0.000000 0.000000 0.048523 0.000000 0.006793 0.056478 0.026349 0.0 0.0 Pirates of the Caribbean: At World's End 0.033911 1.000000 0.021037 0.034132 0.012511 0.111809 0.011378 0.017092 0.044458 0.027466 0.029152 0.027200 0.474144 0.012153 0.029551 0.068232 0.038306 0.208616 0.008180 0.028966 0.037160 0.029612 0.030120 0.027430 0.142986 ... 0.012424 0.000000 0.000000 0.000000 0.015401 0.000000 0.000000 0.000000 0.000000 0.000000 0.018194 0.038199 0.000000 0.0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.008197 0.000000 0.021293 0.0 0.0 Spectre 0.017435 0.021037 1.000000 0.078061 0.070146 0.060568 0.030749 0.111236 0.017189 0.057658 0.103059 0.549934 0.022014 0.018065 0.062035 0.076458 0.062227 0.023734 0.012160 0.023387 0.021013 0.024623 0.018135 0.096466 0.024804 ... 0.045032 0.000000 0.097970 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.012025 0.000000 0.000000 0.0 0.070458 0.000000 0.000000 0.000000 0.000000 0.000000 0.123730 0.000000 0.000000 0.0 0.0 The Dark Knight Rises 0.004221 0.034132 0.078061 1.000000 0.004502 0.051288 0.024913 0.062652 0.000000 0.180473 0.109040 0.109994 0.005329 0.004373 0.150406 0.023430 0.059022 0.005746 0.065193 0.005662 0.082179 0.005961 0.000000 0.000000 0.012210 ... 0.061043 0.079586 0.186559 0.000000 0.007272 0.019680 0.020162 0.094137 0.000000 0.120491 0.013621 0.010274 0.027136 0.0 0.019153 0.004788 0.032963 0.010261 0.093245 0.023555 0.033142 0.000000 0.007541 0.0 0.0 John Carter 0.248501 0.012511 0.070146 0.004502 1.000000 0.012965 0.049956 0.088164 0.010223 0.034291 0.154023 0.024046 0.013092 0.032782 0.151277 0.060955 0.105641 0.073203 0.119286 0.063651 0.012497 0.031320 0.078151 0.057371 0.014752 ... 0.010983 0.009237 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.079708 0.000000 0.000000 0.000000 0.0 0.034295 0.012961 0.000000 0.000000 0.051759 0.000000 0.007246 0.000000 0.000000 0.0 0.0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... El Mariachi 0.006793 0.008197 0.123730 0.033142 0.007246 0.008494 0.000000 0.009899 0.000000 0.008641 0.009172 0.053005 0.008578 0.007039 0.009297 0.000000 0.009326 0.009248 0.011084 0.009113 0.008188 0.009594 0.000000 0.000000 0.009665 ... 0.056640 0.000000 0.146807 0.000000 0.000000 0.031677 0.000000 0.000000 0.000000 0.032542 0.010962 0.000000 0.000000 0.0 0.019168 0.000000 0.053056 0.000000 0.009552 0.037913 1.000000 0.000000 0.000000 0.0 0.0 Newlyweds 0.056478 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.053283 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.051092 0.000000 0.332759 0.000000 0.000000 0.411991 0.000000 0.549240 0.000000 0.036634 0.000000 0.000000 0.0 0.000000 0.000000 0.275376 0.000000 0.000000 0.000000 0.000000 1.000000 0.154088 0.0 0.0 Signed, Sealed, Delivered 0.026349 0.021293 0.000000 0.007541 0.000000 0.022065 0.000000 0.064265 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.060542 0.000000 0.008210 0.000000 0.000000 0.000000 0.000000 0.000000 0.005281 ... 0.009198 0.007873 0.033924 0.051274 0.006188 0.000000 0.080640 0.080105 0.084631 0.000000 0.005645 0.008742 0.023091 0.0 0.042630 0.004074 0.042432 0.008732 0.005635 0.000000 0.000000 0.154088 1.000000 0.0 0.0 Shanghai Calling 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.0 0.0 My Date with Drew 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.132800 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.044517 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.0 1.0 4799 rows Ã— 4799 columns 1234567891011121314151617181920#4) í‰ê·  í‰ì ê³¼ ì¥ë¥´ ì‚¬ì´ì˜ ê´€ê³„?tfidf_vector = TfidfVectorizer()#ì¥ë¥´ë¥¼ ë°±í„°í™”tfidf_matrix = tfidf_vector.fit_transform(t_df['genres']).toarray()#ë²¡í„°í™”ë˜ê¸° ì „ ì´ë¦„ë“¤ì„ ì¶”ì¶œtfidf_matrix_feature = tfidf_vector.get_feature_names_out()#ìœ ì‚¬ë„ ê°’ì´ ì•„ë‹Œ ì´ì§„í™”tfidf_matrix = pd.DataFrame(tfidf_matrix, columns=tfidf_matrix_feature)tfidf_matrix = tfidf_matrix.applymap(lambda x : 0 if x == 0 else 1)# í‰ì ì„ ë²”ì£¼í™” (í‰ì  5ê°€ ê°€ì¥ ë†’ìŒ)t_df['cat_voteav'] = pd.qcut(t_df['vote_average'],5,labels=[1,2,3,4,5])tfidf_matrix['vote_average'] = t_df['cat_voteav']tfidf_matrix.groupby('vote_average').sum()# í˜¸ëŸ¬*ì½”ë¯¸ë””ê°€ í‰ì ì´ ë‚®ê³ , ìŒì•…&amp;ì—­ì‚¬&amp;ë“œë¼ë§ˆê°€ í‰ì ì´ ë†’ì€ ê²½í–¥ì´ ìˆë‹¤. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } action adventure animation comedy crime documentary drama family fantasy fiction foreign history horror movie music mystery romance science thriller tv war western vote_average 1 266 149 31 427 95 19 273 122 99 137 7 10 203 4 22 59 152 137 288 4 7 15 2 291 203 54 458 146 9 416 124 109 122 3 21 130 1 32 70 207 122 309 1 19 12 3 279 162 45 397 190 13 503 102 83 104 5 44 95 1 39 102 192 104 321 1 29 13 4 173 144 51 267 139 24 578 92 67 98 13 54 55 1 50 55 200 98 200 1 36 16 5 145 132 53 173 126 43 526 73 66 74 6 68 36 1 42 62 143 74 156 1 53 26 123456789# 5) ì—°ë„ë³„ë¡œ ë§ì´ ì œì‘ëœ ì˜í™” ì¥ë¥´ëŠ”?# í‰ì ì„ ë²”ì£¼í™” (í‰ì  5ê°€ ê°€ì¥ ë†’ìŒ)t_df['cat_year'] = pd.qcut(t_df['vote_average'],10,labels=range(1,11))tfidf_matrix['cat_year'] = t_df['cat_year']tfidf_matrix.groupby('cat_year').sum(numeric_only=True)#ì•¡ì…˜ì€ ìµœê·¼ì— ì¤„ì–´ë“œëŠ” ê²½í–¥ì´ ìˆìŒ.#ë“œë¼ë§ˆëŠ” ëŠ˜ì–´ë‚˜ëŠ” ê²½í–¥ì´ ìˆìŒ. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } action adventure animation comedy crime documentary drama family fantasy fiction foreign history horror movie music mystery romance science thriller tv war western cat_year 1 135 69 12 203 45 14 136 61 42 76 2 2 114 2 12 29 69 76 145 2 3 10 2 131 80 19 224 50 5 137 61 57 61 5 8 89 2 10 30 83 61 143 2 4 5 3 127 79 24 205 59 5 156 56 44 59 1 4 56 0 17 27 83 59 136 0 3 5 4 164 124 30 253 87 4 260 68 65 63 2 17 74 1 15 43 124 63 173 1 16 7 5 117 68 10 154 85 3 187 37 26 43 4 13 44 1 18 43 81 43 136 1 13 4 6 162 94 35 243 105 10 316 65 57 61 1 31 51 0 21 59 111 61 185 0 16 9 7 95 72 28 130 59 7 231 41 33 52 4 27 32 0 24 27 87 52 95 0 17 8 8 78 72 23 137 80 17 347 51 34 46 9 27 23 1 26 28 113 46 105 1 19 8 9 74 59 18 88 59 17 235 24 26 31 2 31 19 0 23 32 68 31 85 0 21 10 10 71 73 35 85 67 26 291 49 40 43 4 37 17 1 19 30 75 43 71 1 32 16 12345# 6) ì¸ê¸°ë„ì™€ ì˜ˆì‚° ê´€ê³„ëŠ”?t_df.pivot_table(index = t_df['cat_voteav'], columns='budget_cat',aggfunc='count')['budget']#í‰ì  5ê°€ ë†’ì€ê±°ì„.#í‰ì ì´ ë†’ë‹¤ê³  ì˜ˆì‚°ì´ ë†’ì€ ì˜í™”ì´ì§€ëŠ” ì•Šì§€ë§Œ, í‰ì ì´ ë‚®ìœ¼ë©´ ì €ì˜ˆì‚° ì˜í™”ì¼ í™•ë¥ ì€ ë†’ë‹¤. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } budget_cat (-0.001, 7500000.0] (7500000.0, 22000000.0] (22000000.0, 50000000.0] (50000000.0, 380000000.0] cat_voteav 1 508 174 177 138 2 352 212 250 234 3 345 217 249 214 4 375 202 188 157 5 341 180 139 147 123456# 7) ì˜í™” run timeê³¼ ì¸ê¸°ë„ ì‚¬ì´ì— ê´€ê³„ê°€ ìˆì„ê¹Œ?t_df['cat_runtime'] = pd.qcut(t_df['runtime'],5,labels=range(1,6))t_df.pivot_table(index = t_df['cat_runtime'], columns='cat_voteav',aggfunc='count')['budget']# í™•ì‹¤íˆ ëŸ°íƒ€ì„ì´ ê¸¸ë©´ ê¸¸ ìˆ˜ë¡ í‰ì ì´ ë†’ì€ ê²½í–¥ì´ ìˆë‹¤. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cat_voteav 1 2 3 4 5 cat_runtime 1 389 229 156 111 87 2 278 241 202 158 87 3 195 248 240 169 123 4 90 217 238 245 167 5 45 113 189 239 343 1234567891011121314def genre_recommendations(df , mat, items): a = mat.loc[df].sort_values(ascending=False)[1:21] scale_score = pd.DataFrame(a) scale_score = scale_score.reset_index() for i in range(20): scale_score.loc[i,['score']] = (items[items['title'] == a.index[i]]['vote_average']).values #ìŠ¤ì¼€ì¼ë§ scale_score['total_score'] = scale_score.iloc[:,1]+(scale_score.iloc[:,2]/0.8) return scale_score.sort_values(by='total_score',ascending=False)[:10]# ì¶”ì²œ ì‹œìŠ¤í…œ ì˜ˆì‹œ - Avatarì™€ ìœ ì‚¬í•œ ì˜í™” 10ê°œ ì¶”ì²œgenre_recommendations('Avatar',cosine_sim_df,t_df).reset_index(drop=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title Avatar score total_score 0 Alien 0.377950 7.9 10.252950 1 Aliens 0.427672 7.7 10.052672 2 Star Trek Into Darkness 0.420840 7.4 9.670840 3 Gravity 0.417716 7.3 9.542716 4 Treasure Planet 0.320138 7.2 9.320138 5 Stargate: The Ark of Truth 0.315874 6.9 8.940874 6 Spaceballs 0.329561 6.7 8.704561 7 Starship Troopers 0.298873 6.7 8.673873 8 Silent Running 0.410423 6.3 8.285423 9 Space Dogs 0.391469 6.3 8.266469 3ë²ˆ ë¬¸ì œ123456789101112131415# #3. dataset ë°ì´í„° ë¶„ì„ ë° ì—°ê´€ ê·œì¹™ ìƒì„±# 1) dataset íŒŒì¼ ë¶„ì„# 2) ì—°ë„ë³„ ë§ì´ / ì ê²Œ íŒ”ë¦° ì•„ì´í…œì€?# 3) member id ì— ë”°ë¥¸ êµ¬ë§¤ ì—°(ì›”, ìš”ì¼)ë„, ì•„ì´í…œ ë¶„ì„# - ë¬´ìŠ¨ ìš”ì¼ì— ì™€ì„œ êµ¬ë§¤ë¥¼ ë§ì´ í–ˆì„ê¹Œ?# 4) ì—°ê´€ ê·œì¹™ ìƒì„±# 5) ì—°ê´€ ê·œì¹™ì— ë”°ë¥¸ vip memberì—ê²Œ ì–´ë–¤ ìƒí’ˆì„ ì¶”ì²œí• ê¹Œ?# -vipëŠ” ë§¤ì¶œíšŸìˆ˜ê°€ ê°€ì¥ ë§ì€ ìƒìœ„ 100ëª… 12#Dateì—´ì„ datetimeìœ¼ë¡œ ë³€ê²½g_df['Date'] = pd.to_datetime(g_df['Date'],format='%d-%m-%Y' ) 12# na.nanë°ì´í„° ì—†ìŒg_df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 38765 entries, 0 to 38764 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Member_number 38765 non-null int64 1 Date 38765 non-null datetime64[ns] 2 itemDescription 38765 non-null object dtypes: datetime64[ns](1), int64(1), object(1) memory usage: 908.7+ KB 1234# 2) ì—°ë„ë³„ ë§ì´ / ì ê²Œ íŒ”ë¦° ì•„ì´í…œì€?g_df['year'] = g_df['Date'].dt.yeara = g_df.pivot_table(index='year',columns='itemDescription',aggfunc='count')['Date']a.max(axis=1) year 2014 1038.0 2015 1464.0 dtype: float64 123a#Whole milkê°€ ì—°ë„ë³„ë¡œ ê°€ì¥ ë†’ê³ ,#bags, toilet cleaner ê°€ì¥ ì ë‹¤ .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } itemDescription Instant food products UHT-milk abrasive cleaner artif. sweetener baby cosmetics bags baking powder bathroom cleaner beef berries beverages bottled beer bottled water brandy brown bread butter butter milk cake bar candles candy canned beer canned fish canned fruit canned vegetables cat food ... sparkling wine specialty bar specialty cheese specialty chocolate specialty fat specialty vegetables spices spread cheese sugar sweet spreads syrup tea tidbits toilet cleaner tropical fruit turkey vinegar waffles whipped/sour cream whisky white bread white wine whole milk yogurt zwieback year 2014 37.0 160.0 12.0 13.0 1.0 1.0 67.0 11.0 177.0 128.0 109.0 319.0 504.0 17.0 323.0 273.0 126.0 54.0 34.0 136.0 266.0 70.0 8.0 49.0 109.0 ... 25.0 110.0 37.0 125.0 20.0 10.0 23.0 48.0 155.0 34.0 13.0 19.0 12.0 5.0 364.0 27.0 29.0 166.0 365.0 3.0 213.0 82.0 1038.0 640.0 24.0 2015 23.0 163.0 10.0 16.0 2.0 3.0 55.0 6.0 339.0 199.0 142.0 368.0 429.0 21.0 248.0 261.0 137.0 39.0 32.0 83.0 451.0 46.0 13.0 33.0 68.0 ... 21.0 100.0 35.0 115.0 9.0 1.0 17.0 52.0 110.0 35.0 8.0 8.0 10.0 NaN 668.0 53.0 22.0 114.0 297.0 5.0 149.0 94.0 1464.0 694.0 36.0 2 rows Ã— 167 columns 12345#3g_df['weekday'] = g_df['Date'].dt.weekday#0ì´ ì›”ìš”ì¼ 6ì´ ì¼ìš”ì¼g_df['month'] = g_df['Date'].dt.monthg_df.groupby('Member_number').sum(numeric_only=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year weekday month Member_number 1000 26192 43 76 1001 24175 35 51 1002 16116 46 36 1003 16114 24 30 1004 42296 27 150 ... ... ... ... 4996 20150 24 90 4997 12088 36 50 4998 4030 4 20 4999 32236 58 62 5000 14101 27 34 3898 rows Ã— 3 columns 1g_df_dummies = pd.get_dummies(g_df,columns=['weekday','month']) 1234g_df_dummies.groupby('Member_number').sum(numeric_only=True).iloc[:,1:].sum()#0ì´ ì›”ìš”ì¼ 6ì´ ì¼ìš”ì¼#ìš”ì¼ì€ ìƒê´€ ì—†ì´ êµ¬ë§¤ëŸ‰ì€ ë¹„ìŠ·í•˜ë‹¤.#ì›”ë„ í¬ê²Œ ì°¨ì´ê°€ ë‚˜ëŠ” í¸ì€ ì•„ë‹ˆë‹¤. weekday_0 5382 weekday_1 5558 weekday_2 5562 weekday_3 5620 weekday_4 5562 weekday_5 5551 weekday_6 5530 month_1 3324 month_2 2997 month_3 3133 month_4 3260 month_5 3408 month_6 3264 month_7 3300 month_8 3496 month_9 3059 month_10 3261 month_11 3254 month_12 3009 dtype: int64 1# 4,5 123456# ë§¤ì¶œíšŸìˆ˜ ìƒìœ„ 100ëª…ì—ê²Œ vipíƒ€ì´í‹€ ë¶€ì—¬b = g_df.groupby('Member_number')['itemDescription'].size().sort_values(ascending=False)[:100]g_df['vip']= g_df['Member_number'].apply(lambda x : 1 if x in b.index else 0)#vipvip = g_df[g_df['vip']==1] /var/folders/pr/27tft1vj6396wqnj02ngz5p80000gn/T/ipykernel_28378/1060107556.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`. b = g_df.groupby('Member_number')['itemDescription'].size().sort_values(ascending=False)[:100] 12345678910111213141516171819202122232425262728293031323334353637383940from mlxtend.preprocessing import TransactionEncoderfrom mlxtend.frequent_patterns import apriori, association_rules#vipë“¤ì´ êµ¬ë§¤í•œ ìƒí’ˆì„ ê·¸ë£¹í™”(ì¥ë°”êµ¬ë‹ˆí™”)vip['itemDescription'] = vip['itemDescription'].apply(lambda x : x+',')vip_item = vip.groupby('Member_number')['itemDescription'].sum().to_list()items = [0 for x in range(len(vip_item))]for i in range(len(vip_item)): items[i] = vip_item[i].split(',')# TransactionEncoder(ì•„ì´í…œ ë”ë¯¸í™”)te = TransactionEncoder()te_result = te.fit(items).transform(items)df = pd.DataFrame(te_result, columns=te.columns_ ,dtype='int')# aprioriapr_result = apriori(df, min_support=0.09, use_colnames=True)lift_based = association_rules(apr_result, metric='lift', min_threshold=3)# # #liftì™€ confidenceë¥¼ ì†Œìˆ˜ì  1,2ìë¦¬ê¹Œì§€ë§Œ ì¶œë ¥ -&gt; ì •ë ¬lift_based['lift'] = lift_based['lift'].apply(lambda x : f'{x:.1f}')lift_based['confidence'] = lift_based['confidence'].apply(lambda x : f'{x:.2f}')#frozenset -&gt; objectë¡œ ë³€ê²½ (ì˜ëª»ëœ ê³µë°±ê°’ì„ ì œê±°í•˜ê¸° ìœ„í•´)lift_based['antecedents'] = lift_based['antecedents'].apply(lambda x: ', '.join(list(x))).str.replace(' ','')lift_based['consequents'] = lift_based['consequents'].apply(lambda x: ', '.join(list(x))).str.replace(' ','')# , ì œê±°lift_based['antecedents'] = lift_based['antecedents'].apply(lambda x : x if x[0] != ',' else x[1:])lift_based['consequents'] = lift_based['consequents'].apply(lambda x : x if x[0] != ',' else x[1:])#liftì™€ confidenceë¡œ ì •ë ¬lift_sort = lift_based.sort_values(by = ['lift','confidence'], ascending=False)# yogurt,tropicalfruit,rolls/buns &amp; wholemilk,othervegetables,cannedbeer# ì´ê²ƒë“¤ì€ ì—¬ê¸° ìƒì  VIPì˜ ì—°ê´€ì„±ì´ ê°€ì¥ ë†’ì€ ë¬¼í’ˆë“¤ì´ë‹¤. ì´ ë“¤ì˜ ë™ì„ ì„ ì‚´ì§ ë©€ì°ì´ ë„ì–´ë‘ê³  # ê·¸ ì‚¬ì´ì— ì´ë²¤íŠ¸ ìƒí’ˆë“¤ì„ íŒë§¤í•˜ë©´ ë‹¤ë¥¸ ìƒí’ˆë“¤ì˜ ë§¤ì¶œë„ ëŠ˜ ê²ƒ ê°™ë‹¤.lift_sort /var/folders/pr/27tft1vj6396wqnj02ngz5p80000gn/T/ipykernel_28378/1298349058.py:6: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy vip['itemDescription'] = vip['itemDescription'].apply(lambda x : x+',') /opt/homebrew/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type warnings.warn( .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } antecedents consequents antecedent support consequent support support confidence lift leverage conviction 8 yogurt,tropicalfruit,rolls/buns othervegetables,cannedbeer,wholemilk 0.11 0.21 0.09 0.82 3.9 0.0669 4.345000 14 yogurt,tropicalfruit,rolls/buns othervegetables,cannedbeer,wholemilk 0.11 0.21 0.09 0.82 3.9 0.0669 4.345000 20 yogurt,tropicalfruit,rolls/buns othervegetables,cannedbeer,wholemilk 0.11 0.21 0.09 0.82 3.9 0.0669 4.345000 9 othervegetables,cannedbeer,wholemilk yogurt,tropicalfruit,rolls/buns 0.21 0.11 0.09 0.43 3.9 0.0669 1.557500 15 othervegetables,cannedbeer,wholemilk yogurt,tropicalfruit,rolls/buns 0.21 0.11 0.09 0.43 3.9 0.0669 1.557500 21 othervegetables,cannedbeer,wholemilk yogurt,tropicalfruit,rolls/buns 0.21 0.11 0.09 0.43 3.9 0.0669 1.557500 6 yogurt,rolls/buns,tropicalfruit,wholemilk othervegetables,cannedbeer 0.10 0.25 0.09 0.90 3.6 0.0650 7.500000 12 tropicalfruit,wholemilk,yogurt,rolls/buns othervegetables,cannedbeer 0.10 0.25 0.09 0.90 3.6 0.0650 7.500000 17 yogurt,rolls/buns,tropicalfruit,wholemilk othervegetables,cannedbeer 0.10 0.25 0.09 0.90 3.6 0.0650 7.500000 11 othervegetables,cannedbeer yogurt,rolls/buns,tropicalfruit,wholemilk 0.25 0.10 0.09 0.36 3.6 0.0650 1.406250 18 othervegetables,cannedbeer yogurt,rolls/buns,tropicalfruit,wholemilk 0.25 0.10 0.09 0.36 3.6 0.0650 1.406250 23 othervegetables,cannedbeer tropicalfruit,wholemilk,yogurt,rolls/buns 0.25 0.10 0.09 0.36 3.6 0.0650 1.406250 0 yogurt,tropicalfruit,rolls/buns othervegetables,cannedbeer 0.11 0.25 0.09 0.82 3.3 0.0625 4.125000 2 yogurt,tropicalfruit,rolls/buns othervegetables,cannedbeer 0.11 0.25 0.09 0.82 3.3 0.0625 4.125000 4 yogurt,tropicalfruit,rolls/buns othervegetables,cannedbeer 0.11 0.25 0.09 0.82 3.3 0.0625 4.125000 1 othervegetables,cannedbeer yogurt,tropicalfruit,rolls/buns 0.25 0.11 0.09 0.36 3.3 0.0625 1.390625 3 othervegetables,cannedbeer yogurt,tropicalfruit,rolls/buns 0.25 0.11 0.09 0.36 3.3 0.0625 1.390625 5 othervegetables,cannedbeer yogurt,tropicalfruit,rolls/buns 0.25 0.11 0.09 0.36 3.3 0.0625 1.390625 10 yogurt,cannedbeer,othervegetables rolls/buns,tropicalfruit,wholemilk 0.13 0.22 0.09 0.69 3.1 0.0614 2.535000 16 yogurt,cannedbeer,othervegetables rolls/buns,tropicalfruit,wholemilk 0.13 0.22 0.09 0.69 3.1 0.0614 2.535000 22 yogurt,cannedbeer,othervegetables rolls/buns,tropicalfruit,wholemilk 0.13 0.22 0.09 0.69 3.1 0.0614 2.535000 7 rolls/buns,tropicalfruit,wholemilk yogurt,cannedbeer,othervegetables 0.22 0.13 0.09 0.41 3.1 0.0614 1.472308 13 rolls/buns,tropicalfruit,wholemilk yogurt,cannedbeer,othervegetables 0.22 0.13 0.09 0.41 3.1 0.0614 1.472308 19 rolls/buns,tropicalfruit,wholemilk yogurt,cannedbeer,othervegetables 0.22 0.13 0.09 0.41 3.1 0.0614 1.472308 4ë²ˆ ë¬¸ì œ1234567891011121314151617181920212223242526272829303132333435363738394041# 4. ì™€ì¸ì˜ í™”í•™ ì¡°ì„±ì„ ì‚¬ìš©í•˜ì—¬ ì™€ì¸ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ë°ì´í„°ì´ë‹¤. load_wine() ëª…ë ¹ìœ¼ë¡œ ë¡œë“œí•˜ë©° ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆë‹¤. # ì™€ì¸ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤.from sklearn.datasets import load_winefrom sklearn.preprocessing import StandardScalerfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Densefrom tensorflow.keras import optimizersfrom sklearn.model_selection import train_test_splitwine = load_wine()w_df = wine.dataw_target = wine.target#í‘œì¤€í™”scaler = StandardScaler()w_df = scaler.fit_transform(w_df)xtrain , xtest, ytrain, ytest = train_test_split(w_df,w_target,test_size= 0.3)#í…ŒìŠ¤íŠ¸ê°€ ê°’ì´ 3ì¢…ë¥˜ë¼ ì¹´í…Œê³ ë¦¬í™”í•˜ê¸°ytrain = to_categorical(ytrain)ytest = to_categorical(ytest)model=Sequential()model.add(Dense(3, input_dim=13, activation='softmax'))model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])hist = model.fit(xtrain, ytrain, epochs=300, batch_size=1, validation_data=(xtest, ytest))epochs = range(1, len(hist.history['accuracy']) + 1)plt.plot(epochs, hist.history['loss'])plt.plot(epochs, hist.history['val_loss'])plt.title('model loss')plt.ylabel('loss')plt.xlabel('epoch')plt.legend(['train', 'val'], loc='upper left')plt.show()# accuracy: 1.0000","link":"/2022/11/27/Study_folder/Basic_study/2022-11-27-mini-project-first/"},{"title":"ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´ iter","text":"iterator for ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•  ë•Œ rangeë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ for ë°˜ë³µë¬¸ì„ ì„¤ëª…í•  ë•Œ for i in range(100):ì€ 0ë¶€í„° 99ê¹Œì§€ ì—°ì†ëœ ìˆ«ìë¥¼ ë§Œë“¤ì–´ ë‚´ëŠ”ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, ì‚¬ì‹¤ì€ ìˆ«ìë¥¼ ëª¨ë‘ ë§Œë“¤ì–´ ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ 0ë¶€í„° 99ê¹Œì§€ ê°’ì„ ì°¨ë¡€ëŒ€ë¡œ êº¼ë‚¼ ìˆ˜ ìˆëŠ” ì´í„°ë ˆì´í„°ë¥¼ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ì´í›„ ë°˜ë³µí•  ë•Œë§ˆë‹¤ ì´í„°ë ˆì´í„°ì—ì„œ ìˆ«ìë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ë°˜ë³µí•©ë‹ˆë‹¤. 12345678910list_iter= [1, 2, 3]list_iter = [1, 2, 3].__iter__()list_iter.__next__()#ì¶œë ¥ê°’ : 1list_iter.__next__()#ì¶œë ¥ê°’ : 2list_iter.__next__()#ì¶œë ¥ê°’ : 3list_iter.__next__()#error Traceback (most recent call last) &lt; ë‹¤ìŒ ê°’ì´ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í˜¸ì¶œ ì—ëŸ¬ ì•„ë˜ì™€ ê°™ì€ íŒŒì´í† ì¹˜ ìš©ë²•ì—ì„œë„ ë˜‘ê°™ì€ ì˜ë¯¸ë¡œ ì‚¬ìš©ëœ ê²ƒì…ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ iter()ëŠ” iteratorë¥¼ ë°˜í™˜í•˜ëŠ” iris_loaderì—ì„œ iter() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. next() ê·¸ëŸ° ë‹¤ìŒ í•´ë‹¹ ë°˜ë³µìì—ì„œ next() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì²« ë²ˆì§¸ ë°˜ë³µì„ ê°€ì ¸ì˜µë‹ˆë‹¤. next()ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ë°˜ë³µìì˜ ë‘ ë²ˆì§¸ í•­ëª© ë“±ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1images, labels = next(iter(train_loader))","link":"/2022/12/12/Study_folder/Basic_study/2022-12-12-iter/"},{"title":"íŒŒì´ì¬ì—ì„œ OSëª¨ë“ˆë¡œ ê²½ë¡œ&#x2F;í´ë” ìƒì„±","text":"í˜„ì¬ íŒŒì¼ì´ ì‹¤í–‰ë˜ê³ ìˆëŠ” ê²½ë¡œë¥¼ íŒŒì•…í•˜ëŠ” í•¨ìˆ˜1234567891011import osos.getcwd()# ë˜ëŠ” ì‰˜ëª…ë ¹ì–´ë¡œ íŒŒì•… ê°€ëŠ¥#ìœˆë„ìš°ì—ì„œ í™•ì¸í•  ê²½ìš°!cwd %cwd #ë§¥ì—ì„œëŠ”!pwd%pwd í´ë”ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜123456789101112import osos.mkdir('folder_name')#ë§Œì•½ ë‹¤ì¤‘ í´ë”(í´ë”ì˜ í´ë”)ë¥¼ ìƒì„±í•  ê²½ìš°os.makedirs('./folder_name/folder_name/')#ë˜ëŠ” ì‰˜ëª…ë ¹ì–´ë¡œ ìƒì„± ê°€ëŠ¥!mkdir folder_name%mkdir folder_name!mkdir folder_name/folder_name%mkdir folder_name/folder_name ì‘ìš©í•˜ì—¬ í´ë”ê°€ ì—†ìœ¼ë©´ í´ë” ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ìƒì„±12345import osPATH = './folder/folder/' if not os.path.exists(PATH): os.makedirs(PATH) íŒŒì¼ ì‹¤í–‰ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ê¸°12345678import osPATH = './folder/folder/' os.chdir(PATH)#ë˜ëŠ” ì‰˜ ëª…ë ¹ì–´ë¡œ!cd folder/folder/%cd folder/folder/ ê²½ë¡œì— íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í™•ì¸1234567891011import os#í˜„ì¬ ê²½ë¡œos.listdir()#í•´ë‹¹ ê²½ë¡œPATH = './folder/folder/' os.listdir(PATH)#ë˜ëŠ” ì‰˜ ëª…ë ¹ì–´ë¡œ!ls%ls folder/folder/ íŒŒì¼/í´ë” ì‚­ì œ123456789101112import os#íŒŒì¼ ì‚­ì œos.remove('./folder/test_file.txt')#í´ë” ì‚­ì œ(ë¹ˆ í´ë”ë§Œ ì‚­ì œ ê°€ëŠ¥)os.rmdir('./folder/test_folder')#í´ë”(ë¹ˆ í´ë”ê°€ ì•„ë‹Œ í´ë”) ì‚­ì œë¥¼ ì›í•  ì‹œimport shutilshutil.rmtree('./folder/test_folder')#ë³µêµ¬ê°€ ì•ˆë˜ë‹ˆ ì‹ ì¤‘í•˜ê²Œ ì‹¤í–‰í•˜ì„¸ìš” íŒŒì¼ ì¡´ì¬ ìœ ë¬´ í™•ì¸123import osos.path.exists('./folder/test_file.txt')# True ê²½ë¡œ ì¡°ì‘ ë° íŒŒì¼ ì´ë¦„ ë³€ê²½1234567#ê²½ë¡œ ìƒì„±import osprint('ì¶œë ¥ ê²°ê³¼ :' + ' join(): ' + os.path.join('test_folder', 'test_file.txt'))# ì¶œë ¥ ê²°ê³¼ : 'join(): test_folder/test_file.txt'os.rename(a,b) #a-&gt;b#ì´ë¥¼ í™œìš©í•˜ì—¬ í´ë” ë‚´ì˜ íŒŒì¼ë“¤ì˜ ì´ë¦„ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ë° í´ë” ì´ë™1234import shutil#ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ê°€ ë‚˜ë©°, íŒŒì¼ ì´ë¦„ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ì—¬ë„ ê¸°ì¡´ì˜ íŒŒì¼ì€ ì—†ì–´ì§€ê³  ìƒˆë¡œìš´ íŒŒì¼ì´ ìƒì„±ëœ ì±„ ì˜®ê²¨ì§‘ë‹ˆë‹¤(ë¦¬ëˆ…ìŠ¤ì˜ mvë‘ ìœ ì‚¬)shutil.move('./test_folder/test.txt','./test_folder/test_folder2/test2.txt')","link":"/2022/12/12/Study_folder/Basic_study/2022-12-12-os_module/"},{"title":"Magic Command","text":"ë§¤ì§ ëª…ë ¹ì–´(magic command) Magic commandëŠ” IPython kernelì—ì„œ ì œê³µë˜ëŠ” ëª…ë ¹ì–´ì´ë‹¤. ì£¼í”¼í„° ë…¸íŠ¸ë¶, ë©, ê·¸ë¦¬ê³  ì½”ë© í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. Magic commandëŠ” ëª…ë ¹í”„ë¡¬í”„íŠ¸(í„°ë¯¸ë„)ì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´ì™€ ê±°ì˜ ìœ ì‚¬í•©ë‹ˆë‹¤ %lgmagic ì…ë ¥ ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë¥¼ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Magic commandëŠ” %, %% í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. %ëŠ” Line magicìœ¼ë¡œ ë¶€ë¥´ë©° í•œ ì¤„ ì•ˆì—ì„œ ëª…ë ¹ì–´ ì‹¤í–‰ì´ ì‹œì‘ë˜ê³  ì¢…ë£Œëœë‹¤. 1234%ls#ìœ„ì˜ lsëª…ë ¹ì–´ì™€ ë³„ê°œë¡œ ì•„ë˜ì˜ ì…€ ì‹¤í–‰ì´ ë¨.print('hi')print(3+5) %%ëŠ” Cell magicìœ¼ë¡œ ë¶€ë¥´ë©° ë…¸íŠ¸ë¶ì˜ Cellì•ˆì—ì„œ ëª…ë ¹ì–´ ì‹¤í–‰ì´ ì‹œì‘ë˜ê³  ì¢…ë£Œëœë‹¤. (ì…€ ì „ì²´ê°€ í”„ë¡¬í”„íŠ¸ ëª…ë ¹ì–´ë¥¼ ê³„ì† ì‹¤í–‰í•œë‹¤ëŠ” ì˜ë¯¸) ì•„ë˜ëŠ” ì…€ ì „ì²´ê°€ ëª…ë ¹í”„ë¡¬í”„íŠ¸í™” ë˜ì–´ í™•ì¥ì .py íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ì˜ˆì‹œ 123456789%%writefile sample.pydef mul(a,b): return a*bdef main(): print(mul(3*6))if __name__ == '__main__': main() pwd, mkdir, cd, history, mv, write, load ë“± ì‚¬ìš© ê°€ëŠ¥í•˜ë©° ê¸°ëŠ¥ì€ ë¦¬ëˆ…ìŠ¤ë‚˜ ìœˆë„ìš°ì™€ ë™ì¼í•©ë‹ˆë‹¤. ê²½ë¡œ ì„¤ì • í‚¤ì›Œë“œ1234. í˜„ì¬ ë””ë ‰í† ë¦¬.. ë¶€ëª¨ ë””ë ‰í† ë¦¬(ì „ í´ë”)/ ìµœìƒìœ„ root~ í™ˆ(HOME, ë©”ì¸) 12# ì´ëŸ°ì‹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.(ì „ì˜ ì „ í´ë”ì˜ test_folerì˜ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í™•ì¸)!ls ../../test_folder","link":"/2022/12/14/Study_folder/Basic_study/2022-12-14-magic-command/"},{"title":"glob.glob()","text":"í´ë”ì˜ ëª¨ë“  ëª©ë¡ globsëŠ” ë¦¬ëˆ…ìŠ¤ ìš´ì˜ì²´ì œì˜ ëª…ë ¹ì–´ ì¸ìë¡œ, íŒŒì´ì¬ì—ì„œë„ import globí•˜ì—¬ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŒŒì¼ì„ ê²€ìƒ‰í•˜ëŠ” ëª…ë ¹ì–´ë¡œ ì˜ ì‚¬ìš©í•˜ë©´ íŒŒì¼ ê´€ë¦¬ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. 1234567891011121314151617181920212223242526#íŒŒì¼ ëª©ë¡folder : file1.txt, file2.txt, file101.txt, file102.txt, file_a.txt, file_b.txt, file1.jpg, file2.jpgfolder/sub_folder : subfile1.txt, subfile2.txtfolder/sub_folder/sub/sub2 : sub2.txtimport glob# '*'ëŠ” ì„ì˜ ê¸¸ì´ì˜ ëª¨ë“  ë¬¸ìì—´ì„ ì˜ë¯¸í•œë‹¤.output = glob.glob('folder/*.txt')print(output)['folder/file1.txt', 'folder/file102.txt', 'folder/file2.txt', 'folder/file_a.txt', 'folder/file_b.txt']# '?'ëŠ” í•œìë¦¬ì˜ ë¬¸ìë¥¼ ì˜ë¯¸í•œë‹¤. file_a.txt ê°™ì€ íŒŒì¼ë“¤ì€ ê²€ìƒ‰í•˜ì§€ ëª»í•¨output = glob.glob('folder/file?.*')print(output)['folder/file1.bmp', 'folder/file1.txt', 'folder/file2.bmp', 'folder/file2.txt', 'folder/file_a.txt', 'folder/file_b.txt']# '**'ì€ í•­ëª©ì„ ì „ì²´ ì°¾ì•„ì¤ë‹ˆë‹¤.(ë””ë ‰í† ë¦¬ ì´ë¦„ê¹Œì§€ ê°€ëŠ¥)output = glob.glob('folder/**xt')print(output)['folder/file1.txt', 'folder/file102.txt', 'folder/file2.txt', 'folder/file_a.txt', 'folder/file_b.txt', 'folder/file12.txt]# '[]'ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì‚¬ìš©ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.output = glob.glob('folder/file[0-9]*.txt')print(output)['folder/file1.txt', 'folder/file102.txt', 'folder/file2.txt']","link":"/2022/12/15/Study_folder/Basic_study/2022-12-15-glob/"},{"title":"íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°(ë”í•˜ê¸°)","text":"ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸° (a+b)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# ë‹¨ìˆœ ë”í•˜ê¸°a = [1,2,3]b = [4,3,2]print(a + b)# [1, 2, 3, 4, 3, 2]#extend ì‚¬ìš©í•˜ê¸° - ë¦¬ìŠ¤íŠ¸ a ì— bë¥¼ ì—°ê²° í•©ë‹ˆë‹¤. a ë¦¬ìŠ¤íŠ¸ê°€ ë³€ê²½ë¨.(ë‹¨ìˆœ ë”í•˜ê¸°)a = [4, 3, 2]b = [1, 2, 3]print(a.extend(b))# [1, 2, 3, 4, 3, 2]# '+' ì—°ì‚°ì´ë‘ ê°’ì´ ê°™ìŒ#append ì‚¬ìš©í•˜ê¸° - ë¦¬ìŠ¤íŠ¸ ë’¤ì— ê°’ì„ ì¶”ê°€í•˜ê¸°a = [1,2,3]b = [4,3,2]print(a.append(b))[1, 2, 3, [4, 3, 2]]# 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ -&gt; (2-1)ì°¨ì› ë¦¬ìŠ¤íŠ¸ (ì°¨ì›ì„ 1ë‹¨ê³„ë§Œ ë‚®ì¶°ì¤ë‹ˆë‹¤)a = [['a','b'],['c','d'],[1,2]]a = sum(a, [])print(a)# ['a', 'b', 'c', 'd', 1, 2]# ë§Œì•½ 3ì°¨ì›ë¦¬ìŠ¤íŠ¸ -&gt; 1ì°¨ì›ë¦¬ìŠ¤íŠ¸ë¥¼ ì›í•  ê²½ìš°a = [[['a','b'],['c','d'],[1,2]]]a = sum(a, [])a = sum(a, [])print(a)# ['a', 'b', 'c', 'd', 1, 2]#ë§Œì•½ ë¶€ë¶„ì ìœ¼ë¡œ 2ì°¨ì›ë¦¬ìŠ¤íŠ¸ì˜ ê°’ì„ ê°€ì§€ê³  ìˆë‹¤ë©´import itertoolslist1 = ['1', '2', '3', ['4', '3', '2']]list2 = list(itertools.chain.from_iterable(list1))print(list2)#['1', '2', '3', '4', '3', '2']list1 = ['1', '2', '3', ['4', '3', '2']]list2 = list(itertools.chain(*list1))print(list2)#['1', '2', '3', '4', '3', '2']","link":"/2022/12/17/Study_folder/Basic_study/2022-12-17-list-sum/"},{"title":"ì´ìŠ¤ì¼€ì´í”„ ì‹œí€€ìŠ¤(escape sequence) í”„ë¦°íŠ¸ë¬¸ì— ìƒ‰ìƒ ì…íˆê¸°","text":"íŒŒì´ì¬ í”„ë¦°íŠ¸ë¬¸(print)ì— ìƒ‰ìƒ ì…íˆê¸° BRIGHT_BLACK = â€˜\\033[90mâ€™ BRIGHT_RED = â€˜\\033[91mâ€™ BRIGHT_GREEN = â€˜\\033[92mâ€™ BRIGHT_YELLOW = â€˜\\033[93mâ€™ BRIGHT_BLUE = â€˜\\033[94mâ€™ BRIGHT_MAGENTA = â€˜\\033[95mâ€™ BRIGHT_CYAN = â€˜\\033[96mâ€™ BRIGHT_WHITE = â€˜\\033[97mâ€™ BRIGHT_END = â€˜\\033[0mâ€™ Black = â€˜\\033[30mâ€™ Red = â€˜\\033[31mâ€™ Green = â€˜\\033[32mâ€™ Yellow = â€˜\\033[33mâ€™ Blue = â€˜\\033[34mâ€™ Magenta = â€˜\\033[35mâ€™ Cyan = â€˜\\033[36mâ€™ White = â€˜\\033[37mâ€™ 123456# ì´ëŸ°ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.print('\\033[93m' + 'ì•ˆë…•í•˜ì„¸ìš”') # ë…¸ë€ìƒ‰ì˜ 'ì•ˆë…•í•˜ì„¸ìš”' ê¸€ìê°€ ì¶œë ¥print('\\033[92m' + 'ì•ˆë…•í•˜ì„¸ìš”') # ë…¹ìƒ‰ì˜ 'ì•ˆë…•í•˜ì„¸ìš”' ê¸€ìê°€ ì¶œë ¥print('\\033[31m' + 'ì•ˆë…•' + '\\033[95m' + 'í•˜ì„¸ìš”') # ë¹¨ê°„ìƒ‰ì˜ 'ì•ˆë…•'ê³¼ 'ë³´ë¼ìƒ‰'ì˜ í•˜ì„¸ìš” ê¸€ìê°€ ì¶œë ¥","link":"/2022/12/18/Study_folder/Basic_study/2022-12-19-escape-sequence/"},{"title":"Pillow(from PIL import Image)","text":"PIL ì´ë¯¸ì§€ ê¸°ë³¸ì  ì‚¬ìš©ë²•123456789101112#ì—´ê¸° ë°©ë²•1img = Image.open('test_file.jpg') img.show()#ì—´ê¸° ë°©ë²•2from PIL import Imagewith Image.open(&quot;test_file.jpg&quot;) as im: im.show()#ì •ë³´ í™•ì¸(ê°€ë¡œ, ì„¸ë¡œ, ì‚¬ì´ì¦ˆ)img.width, img.height, img.size#ì‚¬ì´ì¦ˆ ë³€ê²½image.resize((w, h)) Thumbnail íŒŒì¼ ìƒì„±í•˜ê¸°123456789101112131415from PIL import Imageimport glob, ossize = 128, 128#í˜„ì¬ í´ë”ì—ì„œ jpgíŒŒì¼ë“¤ì„ ì¸ë„¤ì¼ë¡œ ë§Œë“¬for infile in glob.glob(&quot;*.jpg&quot;): file, ext = os.path.splitext(infile) im = Image.open(infile) im.thumbnail(size) im.save(file + &quot;.thumbnail&quot;, &quot;JPEG&quot;)#ì´ë¯¸ì§€ ì—´ê¸° img = Image.open('test_file.thumbnail') img.show() ì´ë¯¸ì§€ ê²¹ì¹˜ê¸°(ì‚¬ì´ì¦ˆê°€ ê°™ì•„ì•¼í•¨)12345# ì´ë¯¸ì§€ í•©ì„±1(ê²¹ì¹˜ê¸°)Image.alpha_composite(img_1, img_2)# ì´ë¯¸ì§€ í•©ì„±2(í¬ë¯¸í•˜ê²Œ ë§Œë“¤ì–´ì„œ ê²¹ì¹˜ê¸° - ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„±)Image.blend(img_1, img_2, .1) ì´ë¯¸ì§€ ì¦ì‹1234567891011121314151617181920212223242526272829# ì´ë¯¸ì§€ ìë¥´ê¸° : íŠ¹ì • ì˜ì—­ì„ ì˜¤ë ¤ë‚¸ ì‚¬ë³¸ì„ ë§Œë“ ë‹¤. boxëŠ” (left, upper, right, lower)ë¡œ êµ¬ì„±ëœ íŠœí”Œì´ë‹¤.Image.crop(box=None)# ex) Image.crop((x, y, x+64, y+64)) #íŠœí”Œí˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì•¼ë¨!# ì´ë¯¸ì§€ ë¶™ì—¬ë„£ê¸°# ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì´ë¯¸ì§€ ë‚´ íŠ¹ì • ì˜ì—­ì´ë‚˜ ìœ„ì¹˜ì— ë¶™ì—¬ë„£ëŠ”ë‹¤. maskë¥¼ ì¨ì„œ ë¶™ì´ëŠ” ì´ë¯¸ì§€ì— ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•  ìˆ˜ ìˆë‹¤. ë§ˆìŠ¤í¬ëŠ” ì´ë¯¸ì§€ ì™¸ì— íˆ¬ëª…ë„ê°’ì„ ì¤„ ìˆ˜ ìˆë‹¤.image.paste(im, box=None, mask=None) # ì´ë¯¸ì§€ íšŒì „í•˜ê¸°# ì£¼ì–´ì§„ ê°ë„ë§Œí¼ ì´ë¯¸ì§€ë¥¼ íšŒì „í•œë‹¤. ê°ë„ëŠ” ë„(degree)ë¡œ ì£¼ì–´ì§„ë‹¤.image.rorate(angle, resample=0, expand=0, center=None, translate=None) #ì´ë¯¸ì§€ íšŒì „image.transpose(Image.FL) #ì¢Œìš° ë°˜ì „image.transpose(Image.FLIP_TOP_BOTTOM) #ìƒí•˜ ë°˜ì „image.transpose(Image.ROTATE_90) #90ë„ íšŒì „# ì´ë¯¸ì§€ ë³€í˜•í•˜ê¸°image.transform(size, method, data=None, resample=0, fill=1, fillcolor=None)# ì´ë¯¸ì§€ í•„í„°(í•„í„°ëŠ” ImageFilter ëª¨ë“ˆì— ì •ì˜ë˜ì–´ ìˆë‹¤.)from PIL import Image, ImageDraw, ImageFont, ImageFilterimg = Image.open('cat_img.jpg').resize((300,300))d = ImageDraw.Draw(img)d.text((40, 10), 'this is BLUR', fill=&quot;Red&quot;) #ìœ„ì¹˜ ì¢Œí‘œëŠ” íŠœí”Œ íƒ€ì…ìœ¼ë¡œ ì…ë ¥img = img.filter(ImageFilter.BLUR)img.save('BLUR.jpg','jpeg')img.show() ì´ë¯¸ì§€ í•„í„° ì¢…ë¥˜ ImageFilter ì‚¬ì§„ BLUR CONTOUR DETAIL EDGE_ENHANCE EMBOSS FIND_EDGES SHARPEN SMOOTH ì´ë¯¸ì§€ í¸ì§‘ ì‹œ í•„ìš”í•œ í•¨ìˆ˜ë“¤12345678910111213# ë°´ë“œ ì–»ê¸°from PIL import Imageim = Image.open(&quot;hopper.jpg&quot;)print(im.getbands()) # Returns ('R', 'G', 'B')# ë°”ìš´ë”© ë°•ìŠ¤ ì–»ê¸°# ì´ë¯¸ì§€ì—ì„œ 0ì´ì•„ë‹Œ ì˜ì—­ì˜ ë²”ìœ„ë¥¼ êµ¬í•¨im = Image.open(&quot;hopper.jpg&quot;)print(im.getbbox())# Returns four coordinates in the format (left, upper, right, lower)# ì±„ë„ ì–»ê¸°Image.getchannel(channel) ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ì‚½ì…1234567from PIL import Image, ImageDraw, ImageFontim = Image.open('cat_img.jpg').resize((150,150))ft = ImageFont.truetype('Pantherdam Signature Italic.ttf', size=20) #í°íŠ¸ ì‚¬ìš©ì‹œ íŒŒì¼ ì§€ì •d = ImageDraw.Draw(im)d.text((10, 10), 'text any text', font=ft, fill=&quot;#ff3&quot;) #ìœ„ì¹˜ ì¢Œí‘œëŠ” íŠœí”Œ íƒ€ì…ìœ¼ë¡œ ì…ë ¥im.show()","link":"/2022/12/18/Study_folder/Basic_study/2022-12-18-Pillow/"},{"title":"í¬ë§¤íŒ…(fomatting)","text":"ì†Œìˆ˜ì  ìë¦¬ìˆ˜ ë‚˜íƒ€ë‚´ëŠ” í¬ë§¤íŒ…12345678910# fomatí•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ì´ 3ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í‘œí˜„ í•  ìˆ˜ ìˆìœ¼ë©° ê²°ê³¼ëŠ” ë™ì¼í•©ë‹ˆë‹¤.# ì‹¤ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ .(ì ) ì•ì— ì •ë ¬í•  ê¸¸ì´ë¥¼ ì§€ì •í•˜ê³ , ì  ë’¤ì— ì†Œìˆ˜ì  ì´í•˜ ìë¦¿ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.num = 12.1print(f'ì†Œìˆ˜ ì²«ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°: {num:.1f} , ë‘ë²ˆì§¸ ìë¦¬ê¹Œì§€: {num:.2f}')# ì†Œìˆ˜ ì²«ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°: 12.1 , ë‘ë²ˆì§¸ ìë¦¬ê¹Œì§€: 12.10print(('ì†Œìˆ˜ ì²«ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°: {0:.1f} , ë‘ë²ˆì§¸ ìë¦¬ê¹Œì§€: {1:.2f}').format(num,num))# ì†Œìˆ˜ ì²«ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°: 12.1 , ë‘ë²ˆì§¸ ìë¦¬ê¹Œì§€: 12.10print('ì†Œìˆ˜ ì²«ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°: %.1f , ë‘ë²ˆì§¸ ìë¦¬ê¹Œì§€: %.2f' %(num,num))# ì†Œìˆ˜ ì²«ë²ˆì§¸ ìë¦¬ê¹Œì§€ í‘œê¸°: 12.1 , ë‘ë²ˆì§¸ ìë¦¬ê¹Œì§€: 12.10 ìë¦¬ìˆ˜ë¥¼ ê³ ì •í•œ ì±„ë¡œ ì¶œë ¥í•˜ëŠ” í¬ë§¤íŒ…1234567891011121314151617181920# ìë¦¬ìˆ˜ë¥¼ ê³ ì •í•œ ì±„ë¡œ ì¶œë ¥ì„ ì›í•˜ëŠ” ê²½ìš°'%10d' % 222f'{222:10d}''{0:10d}'.format(int(222))' 222'# ìë¦¬ìˆ˜ë¥¼ ê³ ì • + ì™¼ìª½ ì •ë ¬(ë¬¸ìì—´ë§Œ ê°€ëŠ¥)num = '222'f'{num:10s}'# '222 ''%-10s' % '222'# '222 '# ì™¼ìª½ ì •ë ¬ì— '&lt;' ê¸°í˜¸, ì˜¤ë¥¸ìª½ ì •ë ¬ì— '&gt;'ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.num = '222'f'{num:&lt;10s}'num = '222'# '222 'f'{num:&gt;10s}'# ' 222' ìë¦¬ìˆ˜ë¥¼ ê³ ì •í•œ ì±„ ê³µë°±(ë³´í†µ ìˆ«ì â€˜0â€™ìœ¼ë¡œ) ì±„ìš°ê¸°12345678910111213'{0:08.2f}'.format(22.33)# '00022.33'# ì¤‘ìš” !!! ì™¼ìª½ì— ë¬¸ì ì±„ìš°ê³  0ìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì¹¸ ì±„ìš°ê¸°(ì´8ì¹¸)num = '222'f'{num:0&lt;8s}''22200000'# ì˜¤ë¥¸ìª½ì— ë¬¸ì ì±„ìš°ê³  0ìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì¹¸ ì±„ìš°ê¸°(ì´8ì¹¸)num = '222'f'{num:0&gt;8s}''00000222' 3ìë¦¬ ë‹¨ìœ„ë§ˆë‹¤ â€˜,â€™ìˆëŠ” ìˆ«ìë¡œ í‘œí˜„í•˜ê¸°123'{0:,}'.format(1234567890)# '1,234,567,890'","link":"/2022/12/22/Study_folder/Basic_study/2022-12-22-fomatting/"},{"title":"íŒŒì´ì¬ ì—ëŸ¬ ìƒì„± ë° ì²˜ë¦¬ ë°©ë²•(assert, raise, try)","text":"Assert ì‚¬ìš© ë°©ë²• ì˜ˆì™¸ ì²˜ë¦¬(try, raise)í•¨ìˆ˜ì™€ ë‹¬ë¦¬ assertëŠ” ê°€ì • ì„¤ëª…ë¬¸ ì…ë‹ˆë‹¤. ì¦‰, ì–´ë–¤ ì¡°ê±´ì´ Trueë©´ passë˜ê³ , ì•„ë‹ˆë©´ Error(ì˜¤ë¥˜)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë°©ë²•ì€ ê°„ë‹¨í•©ë‹ˆë‹¤. assert (ê°€ì •ë²•), 'ì—ëŸ¬ ë©”ì‹œì§€ ì‘ì„±'ì´ë ‡ê²Œ ì‘ì„±í•˜ê¸°ë©´ ë©ë‹ˆë‹¤. 12345678emd = 256heads =8head_dim = emd // headsassert (head_dim * heads == emd), 'embed size needs to be div by heads'print('hello')# ì‹¤í–‰í•˜ë©´ (head_dim * heads == emd)ì´ True ë•Œë¬¸ì— ì•„ë¬´ ì¶œë ¥ ê²°ê³¼ê°€ ì—†ë‹¤.hello 1234567891011# ì•ì˜ ê°’ì´ Falseë¼ë©´assert (head_dim * heads == emd + 1), 'embed size needs to be div by heads'print('hello') 3 head_dim = emd // heads 4 ----&gt; 5 assert (head_dim * heads == emd + 1), 'embed size needs to be div by heads' 6 AssertionError: embed size needs to be div by heads# ìœ„ì™€ ê°™ì€ AssertionErrorê°€ ìƒì„±ëœë‹¤. Raise ì‚¬ìš© ë°©ë²• ì¼ë¶€ëŸ¬ ì—ëŸ¬ë¥¼ ë°œìƒì‹œì¼œì•¼ ë˜ëŠ” ê²½ìš°ê°€ ìˆëŠ”ë°, ì´ë•Œ ì‚¬ìš©í•˜ëŠ”ê²Œ assertì™€ raise raiseëŠ” assertì™€ ë‹¬ë¦¬ ì‹¤í–‰ë§Œ ë˜ë©´ ì—ëŸ¬ê°€ ìƒì„±ë©ë‹ˆë‹¤. 1234567891011# Exceptionìœ¼ë¡œ ë¬¸êµ¬ë¥¼ ì‘ì„±í•´ë„ ë˜ê³  ì•ˆí•´ë„ ë©ë‹ˆë‹¤(ì˜µì…˜)raise Exception('hi')print('hello')# ê²°ê³¼-ì—ëŸ¬----&gt; 1 raise Exception('ì•„ë¬´ ì—ëŸ¬ ë¬¸êµ¬') 2 3 print('hello')Exception: ì•„ë¬´ ì—ëŸ¬ ë¬¸êµ¬ 12345678910# ë³´í†µ ì´ëŸ°ì‹ìœ¼ë¡œ ì¡°ê±´ë¬¸ê³¼ ê°™ì´ ì‚¬ìš©í•©ë‹ˆë‹¤b = 1a = [1,2,3]if b not in a: raise Exception('aì— ì—†ëŠ” ê°’ì´ë¼ì„œ ì—ëŸ¬ ë°œìƒ ì‹œí‚¬ê²Œìš”.')print('hello')# ì¶œë ¥ ê²°ê³¼hello 123456789101112131415b = 5a = [1,2,3]if b not in a: raise Exception('aì— ì—†ëŠ” ê°’ì´ë¼ì„œ ì—ëŸ¬ ë°œìƒ ì‹œí‚¬ê²Œìš”.')print('hello')# ì¶œë ¥ ê²°ê³¼ 4 if b not in a:----&gt; 5 raise Exception('aì— ì—†ëŠ” ê°’ì´ë¼ì„œ ì—ëŸ¬ ë°œìƒ ì‹œí‚¬ê²Œìš”.') 6 7 print('hello')Exception: aì— ì—†ëŠ” ê°’ì´ë¼ì„œ ì—ëŸ¬ ë°œìƒ ì‹œí‚¬ê²Œìš”. Try, Except ì‚¬ìš© ë°©ë²• tryëŠ” ì—ëŸ¬ê°€ ë°œìƒí•˜ë”ë¼ë„ ê·¸ëƒ¥ ì‘ì—…ì„ ì§„í–‰í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ì„ ë•Œ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. exceptë’¤ ì— ë°œìƒë˜ëŠ” [ì—ëŸ¬ ì´ë¦„] ê·¸ ë’¤ì— ì²˜ë¦¬ë¥¼ ì–´ë–»ê²Œ í• ì§€ ì‚¬ìš© ì—ëŸ¬ê°€ ë‚˜ì™€ë„ ê·¸ëƒ¥ passë¥¼ ì›í•˜ë©´ pass ì…ë ¥ ì˜ˆì‹œë¥¼ ë³´ë©´ ë°”ë¡œ ì´í•´ë˜ì‹¤ ê²ë‹ˆë‹¤. 123456789101112131415161718192021222324# ìˆ«ì 2ê°œë¥¼ ë‚˜ëˆŒë•Œ ë‚˜ì˜¤ëŠ” ì—ëŸ¬ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.try: a, b = map(int,input('ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : ').split()) print(a / b)except ZeroDivisionError: # ìˆ«ìë¥¼ 0ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ë•Œ ì‹¤í–‰ë¨ print('ìˆ«ìë¥¼ 0ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')except ValueError as a: # inputê°’ì„ ì œëŒ€ë¡œ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ì‹¤í–‰ print('ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤', a) passprint('hi')# ê²°ê³¼ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : 3 13.0hi# ê²°ê³¼(zerodivision)ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : 3 0ìˆ«ìë¥¼ 0ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.# ê²°ê³¼(valueeroor)ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : 3abdì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤ invalid literal for int() with base 10: '3abd'hi ë§Œì•½ ì–´ë–¤ ì—ëŸ¬ì¸ì§€ ëª¨ë¥´ëŠ” ê²½ìš° í…ŒìŠ¤íŠ¸ë¥¼í•˜ì—¬ ì—ëŸ¬ë¥¼ í™•ì¸í•œë‹¤. 123456789101112131415a, b = map(int,input('ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : ').split())print(a / b)# '3 0'ì„ ì…ë ¥í•  ê²½ìš° 'ZeroDivisionError'&lt;ipython-input-65-a03c397788a2&gt; in &lt;module&gt; 1 a, b = map(int,input('ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : ').split())----&gt; 2 print(a / b)ZeroDivisionError: division by zero# '3abd'ì„ ì…ë ¥í•  ê²½ìš° 'ValueError'----&gt; 1 a, b = map(int,input('ìˆ«ì 2ê°œë¥¼ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš” : ').split()) 2 print(a / b)ValueError: invalid literal for int() with base 10: '3abd'","link":"/2023/01/05/Study_folder/Basic_study/2023-01-05-assert/"},{"title":"Einsum (Einstein Summation)","text":"einsum ì°¸ê³  : &lt;Aladdin youtube&gt; Einsumì€ Einstein Summation Conventionìœ¼ë¡œ ì—°ì‚°ì„ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì—°ì‚°ì„ í†µí•´ ë‚´ì (Dot products), ì™¸ì (Outer porducts), ì „ì¹˜(Transpose), í–‰ë ¬ê³±(Matmul) ë“±ì„ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë©°, í˜•íƒœ(dim, shape)ì„ ê´€ë¦¬í•  ë•Œ ë§¤ìš° ìœ ìš©í•˜ë‹¤. einsumì€ numpy, torch, tensorflowì—ì„œ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤.ex) numpy.einsum(), torch.einsum(), tensorflow.einsum() ê°„ë‹¨í•˜ê²Œ ì•„ë˜ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.(ì°¨ì› í‘œí˜„ìœ¼ë¡œ ijk... ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.) a,b ì¤‘ ê°™ì€ ì°¨ì›ì´ë¼ë©´ ë™ì¼í•œ ì•ŒíŒŒë²³ìœ¼ë¡œ ì…ë ¥í•´ì£¼ê¸°. einsumì˜ í†µìƒì ì¸ ì‚¬ìš©ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. torchì¸ a.shape==(2,3,4),b.shape(3,4,1)ê°€ ìˆë‹¤ë©´,torch.einsum(â€˜ijk , jka -&gt; jkiâ€™ , [a,b])ê²°ê³¼ëŠ” [3,4,2] ë¼ëŠ” ì‹ìœ¼ë¡œ ë‚˜ì˜µë‹ˆë‹¤. ìˆ˜í•™ì ìœ¼ë¡œ í‘œí˜„í•˜ìë©´ ë„ˆë¬´ ë³µì¡í•´ì§€ë‹ˆ ì˜ˆì‹œë¥¼ í†µí•´ ê°„ë‹¨í•œ ì‚¬ìš© ë°©ë²•ì„ ìµí˜€ë´…ì‹œë‹¤. ì˜ˆì‹œ123456789101112# MATRIX TRANSPOSEimport torcha = torch.arange(6).reshape(2, 3)print(a)torch.einsum('ij-&gt;ji', [a])tensor([[0, 1, 2], [3, 4, 5]])tensor([[0, 3], [1, 4], [2, 5]]) 12345# SUMa = torch.arange(6).reshape(2, 3)torch.einsum('ij-&gt;', [a])tensor(15) # 6! 123456789# COLUMN SUMa = torch.arange(6).reshape(2, 3)print(a)torch.einsum('ij-&gt;j', [a])tensor([[0, 1, 2], [3, 4, 5]])# 0+3 , 1+4, 2+5tensor([3, 5, 7]) 12345678910# ROW SUMa = torch.arange(6).reshape(2, 3)print(a)torch.einsum('ij-&gt;i', [a])tensor([[0, 1, 2], #0+1+2-&gt;3 [3, 4, 5]]) #3+4+5-&gt;12tensor([ 3, 12]) 123456789101112# MATRIX-VECTOR MULTIPLICATIONa = torch.arange(6).reshape(2, 3)b = torch.arange(3)torch.einsum('ik,k-&gt;i', [a, b])tensor([ 5, 14])# í–‰ë ¬ê³±ê³¼ ê°’ì´ ë™ì¼np.matmul(a,b) tensor([ 5, 14]) 12345678# MATRIX-MATRIX MULTIPLICATIONa = torch.arange(6).reshape(2, 3)b = torch.arange(15).reshape(3, 5)torch.einsum('ik,kj-&gt;ij', [a, b])tensor([[ 25, 28, 31, 34, 37], [ 70, 82, 94, 106, 118]]) 1234567# DOT PRODUCT(vector)a = torch.arange(3)b = torch.arange(3,6) # [3, 4, 5]torch.einsum('i,i-&gt;', [a, b])tensor(14) 1234567# DOT PRODUCT(matrix)a = torch.arange(6).reshape(2, 3)b = torch.arange(6,12).reshape(2, 3)torch.einsum('ij,ij-&gt;', [a, b])tensor(145) 12345# HADAMARD PRODUCTa = torch.arange(6).reshape(2, 3)b = torch.arange(6,12).reshape(2, 3)torch.einsum('ij,ij-&gt;ij', [a, b]) 1234567891011121314# OUTER PRODUCTa = torch.arange(3)b = torch.arange(3,7) #[3, 4, 5, 6]c = torch.einsum('i,j-&gt;ij', [a, b])print(a.shape,b.shape,c.shape)ctorch.Size([3]) torch.Size([4]) torch.Size([3, 4])tensor([[ 0, 0, 0, 0], [ 3, 4, 5, 6], [ 6, 8, 10, 12]])","link":"/2023/01/05/Study_folder/Basic_study/2023-01-05-einsum/"},{"title":"ìì—°ì–´ ì²˜ë¦¬ NLP(Natural Language Processing)","text":"NLPë€ ìì—°ì–´ ì²˜ë¦¬(Natural Language Processing)í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬í† í°í™” : ì½”í¼ìŠ¤ë¡œë¶€í„° í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…, nltk, konlpyë¥¼ ì‚¬ìš©í† í° : ì²˜ë¦¬í•˜ëŠ” ë‹¨ìœ„(ë‹¨ì–´, ë¬¸ì, ë¬¸ì¥, ë¬¸ë‹¨). ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì–´ ë‹¨ìœ„ë¡œ í† í°í™” ì‘ì—…ì„ ì‹¤í–‰ì˜ì–´ì™€ ë‹¬ë¦¬ í•œêµ­ì–´ëŠ” ì¡°ì‚¬ë¥¼ ë¶„ë¦¬í•´ì•¼ í•¨ í˜•íƒœì†Œ : ê°€ì¥ ì‘ì€ ë§ì˜ ë‹¨ìœ„(ìë¦½ í˜•íƒœì†Œ, ì˜ì¡´ í˜•íƒœì†Œê°€ ìˆìŒ) ìë¦½ í˜•íƒœì†Œ : ì¡°ì‚¬, ì–´ë¯¸ì™€ ìƒê´€ì—†ì´ ìë¦½í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥(ìì²´ê°€ ë‹¨ì–´ê°€ ë¨) ì˜ì¡´ í˜•íƒœì†Œ : ë‹¤ë¥¸ í˜•íƒœì†Œì™€ ê²°í•©í•´ì„œ ì‚¬ìš©(ì ‘ì‚¬, ì–´ë¯¸, ì¡°ì‚¬, ì–´ê°„) ë¬¸ì¥ : ê¸¸ë™ì´ê°€ ì½”ë”©ì„ í•©ë‹ˆë‹¤ í† í°í™”(ë„ì–´ì“°ê¸°) : [ê¸¸ë™ì´ê°€, ì½”ë”©ì„, í•©ë‹ˆë‹¤] ìë¦½ í˜•íƒœì†Œ : ê¸¸ë™ì´, ì½”ë”© ì˜ì¡´ í˜•íƒœì†Œ : â€˜-ê°€â€™, â€˜ì„â€™, â€˜-í•©â€™, â€˜-ë‹ˆâ€™, â€˜-ë‹¤â€™ í˜„ì¬ëŠ” í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ëŠ” ì˜ì¡´ í˜•íƒœì†Œë¥¼ ë²„ë¦¬ê³  ìˆëŠ”ë°, ì´ë¥¼ ì‚´ë ¤ì•¼ ë³´ë‹¤ ì •í™•í•œ ì •ë³´ë¥¼ íšë“ ê°€ëŠ¥","link":"/2022/11/22/Study_folder/NLP(Natural_Language_Processing)/2022-11-22-NLP/"},{"title":"BERT íŒŒì¸íŠœë‹(Fine Tunning) ì„¤ëª…","text":"Bert êµ¬ì¡° Fine Tunning(íŒŒì¸íŠœë‹)ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ê¸°ì¡´ì˜ í•™ìŠµë˜ê¸° ì „ì˜ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë°”ê¿” ì¤„ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì¦‰ íŒŒì¸íŠœë‹ì„ ìœ„í•´ì„œëŠ” Bertë°©ì‹ì˜ ë°ì´í„° ì •ì œê°€ í•„ìš”í•©ë‹ˆë‹¤. BertëŠ” ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ 3ê°€ì§€ì˜ ì…ë ¥ ì„ë² ë”©(Token, Segment, Position ì„ë² ë”©)ì˜ í•©ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ í•™ìŠµëœ ëª¨ë¸ì…ë‹ˆë‹¤. Token Embeddings Word Piece ì„ë² ë”© ë°©ì‹ ì‚¬ìš© ìì£¼ ë“±ì¥í•˜ë©´ì„œ ê°€ì¥ ê¸´ ê¸¸ì´ì˜ sub-wordë¥¼ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¡œ ìƒì„± ì¦‰, ìì£¼ ë“±ì¥í•˜ëŠ” sub-wordì€ ê·¸ ìì²´ê°€ ë‹¨ìœ„ê°€ ë˜ê³ , ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´(rare word)ëŠ” sub-wordë¡œ ìª¼ê°œì§ ê¸°ì¡´ ì›Œë“œ ì„ë² ë”© ë°©ë²•ì€ Out-of-vocabulary (OOV) ë¬¸ì œê°€ ì¡´ì¬í•˜ë©°, í¬ê·€ ë‹¨ì–´, ì´ë¦„, ìˆ«ìë‚˜ ë‹¨ì–´ì¥ì— ì—†ëŠ” ë‹¨ì–´ì— ëŒ€í•œ í•™ìŠµ, ë²ˆì—­ì— ì–´ë ¤ì›€ì´ ìˆìŒ Word Piece ì„ë² ë”©ì€ ëª¨ë“  ì–¸ì–´ì— ì ìš© ê°€ëŠ¥í•˜ë©°, sub-word ë‹¨ìœ„ë¡œ ë‹¨ì–´ë¥¼ ë¶„ì ˆí•˜ë¯€ë¡œ OOV ì²˜ë¦¬ì— íš¨ê³¼ì ì´ê³  ì •í™•ë„ ìƒìŠ¹íš¨ê³¼ë„ ìˆìŒ Sentence Embeddings BERTëŠ” ë‘ ê°œì˜ ë¬¸ì¥ì„ ë¬¸ì¥ êµ¬ë¶„ì([SEP],ìŠ¤í˜ì…œ í† í°)ì™€ í•¨ê»˜ ê²°í•© í•œêµ­ì–´ëŠ” ë³´í†µ í‰ê·  20 subwordë¡œ êµ¬ì„±ë˜ê³  99%ê°€ 60 subwordë¥¼ ë„˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì…ë ¥ ê¸¸ì´ë¥¼ ë‘ ë¬¸ì¥ì´ í•©ì³ 128(max_len)ìœ¼ë¡œ ì„¤ì • í•´ë„ ì¶©ë¶„í•©ë‹ˆë‹¤ ê°„í˜¹ ê¸´ ë¬¸ì¥ì´ ìˆìœ¼ë¯€ë¡œ ìš°ì„  ì…ë ¥ ê¸¸ì´ 128ë¡œ ì œí•œí•˜ê³  í•™ìŠµí•œ í›„, 128ë³´ë‹¤ ê¸´ ì…ë ¥ë“¤ì„ ëª¨ì•„ ë§ˆì§€ë§‰ì— ë”°ë¡œ ì¶”ê°€ í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš© Position Embedding BERTëŠ” Transformer ëª¨ë¸ì„ ì°©ìš© ê·¸ ì¤‘ Self-Attention ëª¨ë¸ì„ ì‚¬ìš© Self-Attentionì€ ì…ë ¥ì˜ ìœ„ì¹˜ì— ëŒ€í•´ ê³ ë ¤í•˜ì§€ ëª»í•˜ë¯€ë¡œ ì…ë ¥ í† í°ì˜ ìœ„ì¹˜ ì •ë³´ê°€ í•„ìš”(position embeddingí•„ìš”ì„±) Position encodingì€ ë‹¨ìˆœí•˜ê²Œ Token ìˆœì„œëŒ€ë¡œ 0, 1, 2, â€¦ì™€ ê°™ì´ ìˆœì„œëŒ€ë¡œ ì¸ì½”ë”© Fine Tunningì˜ 2ê°€ì§€ ëŒ€í‘œì ì¸ ë°©ë²• BERTëŠ” ìœ„ì—ì„œ ì†Œê°œí•œ 3ê°€ì§€ì˜ ì…ë ¥ ì„ë² ë”©(Token, Segment, Position ì„ë² ë”©)ì„ ì·¨í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì„ë² ë”© ê°’ìœ¼ë¡œ ìƒì„± ì„ë² ë”©ì˜ í•©ì— Layer Normalizationê³¼ Dropoutì„ ì ìš©í•˜ì—¬ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© MLM(Masked Language Model) ì…ë ¥ ë¬¸ì¥ì—ì„œ ì„ì˜ë¡œ Tokenì„ ë§ˆìŠ¤í‚¹(masking), ê·¸ Tokenì„ ë§ì¶”ëŠ” ë°©ì‹ì¸ MLM í•™ìŠµ ì§„í–‰ ë¬¸ì¥ì˜ ë¹ˆì¹¸ ì±„ìš°ê¸° ë¬¸ì œë¥¼ í•™ìŠµ ìƒì„± ëª¨ë¸ ê³„ì—´ì€(ì˜ˆë¥¼ ë“¤ì–´ GPT) ì…ë ¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ MLMì€ ë¬¸ì¥ ë‚´ ëœë¤í•œ ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹ í•˜ê³  ì´ë¥¼ ì˜ˆì¸¡ ì…ë ¥ì˜ 15% ë‹¨ì–´ë¥¼ [MASK] Tokenìœ¼ë¡œ ë°”ê¿”ì£¼ì–´ ë§ˆìŠ¤í‚¹ ì´ ë•Œ 80%ëŠ” [MASK]ë¡œ ë°”ê¿”ì£¼ì§€ë§Œ, ë‚˜ë¨¸ì§€ 10%ëŠ” ë‹¤ë¥¸ ëœë¤ ë‹¨ì–´ë¡œ, ë˜ ë‚¨ì€ 10%ëŠ” ë°”ê¾¸ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë‘  ì´ëŠ” íŠœë‹ ì‹œ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ì„ ë•ë„ë¡ ë§ˆìŠ¤í‚¹ì— ë…¸ì´ì¦ˆë¥¼ ì„ìŒ NSP(Next Sentence Prediction) NSPëŠ” ë‘ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ë°”ë¡œ ë‹¤ìŒì— ì˜¤ëŠ” ë¬¸ì¥ì¸ì§€ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ ë‘ ë¬¸ì¥ ê°„ ê´€ë ¨ì´ ê³ ë ¤ë˜ì–´ì•¼ í•˜ëŠ” NLIì™€ QAì˜ íŒŒì¸íŠœë‹ì„ ìœ„í•´ ë‘ ë¬¸ì¥ì´ ì—°ê´€ì´ ìˆëŠ”ì§€ë¥¼ ë§ì¶”ë„ë¡ í•™ìŠµ ìœ„ì—ì„œ ì„¤ëª…í•œ MLMê³¼ ë™ì‹œì— NSPë„ ì ìš©ëœ ë¬¸ì¥ë“¤ ì²« ë²ˆì§¸ ë¬¸ì¥ê³¼ ë‘ ë²ˆì§¸ ë¬¸ì¥ì€ [SEP]ë¡œ êµ¬ë¶„(ìŠ¤í˜ì…œ í† í°) ë‘ ë¬¸ì¥ì´ ì‹¤ì œë¡œ ì—°ì†í•˜ëŠ”ì§€ëŠ” 50% ë¹„ìœ¨ë¡œ ì°¸ì¸ ë¬¸ì¥ê³¼, 50%ì˜ ëœë¤í•˜ê²Œ ì¶”ì¶œëœ ìƒê´€ ì—†ëŠ” ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„± ì´ í•™ìŠµì„ í†µí•´ ë¬¸ë§¥ê³¼ ìˆœì„œë¥¼ í•™ìŠµ ê°€ëŠ¥ ì•„ë˜ ê·¸ë¦¼ì€ NSPì˜ ì…ë ¥ ì˜ˆì‹œ ì°¸ê³  ìë£Œ[ebbn] : https://ebbnflow.tistory.com/151[NLP-kr] : https://github.com/NLP-kr/tensorflow-ml-nlp-tf2[ì´ìˆ˜í•œì»´í“¨í„°ì—°êµ¬ì†Œ] : https://www.youtube.com/watch?v=LEtLfx1dS7Q[ìœ„í‚¤ë…ìŠ¤] : https://wikidocs.net/156998","link":"/2022/12/10/Study_folder/NLP(Natural_Language_Processing)/2022-12-10-BERT_fine_intro/"},{"title":"KoGPT2 íŒŒì¸íŠœë‹í•˜ì—¬ ì±—ë´‡ ìƒì„±","text":"KoGPT2 íŒŒì¸ íŠœë‹ì„ ì‚¬ìš©í•œ ì±—ë´‡ ë§Œë“¤ê¸° ì „ì²˜ë¦¬ëŠ” ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜(from AIí—ˆë¸Œ)ì˜ Q,Aë¶€ë¶„ë§Œ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163#Thinkbig_KoGPT2_fine_tunningimport numpy as npimport pandas as pdimport torchfrom torch.utils.data import DataLoader, Datasetfrom transformers import PreTrainedTokenizerFast, GPT2LMHeadModelimport refrom tqdm import tqdm# ìŠ¤í˜ì…œ í† í°U_TKN = '&lt;usr&gt;' #Qusetioní† í°S_TKN = '&lt;sys&gt;' #Answerí† í°BOS = '&lt;/s&gt;'#ë¬¸ì¥ì˜ ì‹œì‘ í† í° #ì‹œì‘ê³¼ ëì„ êµ¬ë¶„í•˜ê¸° ë•Œë¬¸ì— bos,eosí† í°ì˜ ê°’ì„ ë™ì¼ ì‹œ í•´ë„ ìƒê´€ì—†ë‹¤.EOS = '&lt;/s&gt;'#ë¬¸ì¥ì˜ ë í† í°MASK = '&lt;unused0&gt;'#ë§ˆìŠ¤í¬ í† í°SENT = '&lt;unused1&gt;'#ë¬¸ì¥ í† í°(Qì™€ Aí† í° ì‚¬ì´ì— ë„£ì–´ì„œ êµ¬ë¶„)PAD = '&lt;pad&gt;' #íŒ¨ë“œ í† í°# #hugging_faceì˜ KoGPT2(ì´ë¯¸ í•™ìŠµëœ ë°ì´í„°)ë¥¼ ê°€ì ¸ì˜´koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2', bos_token=BOS, eos_token=EOS, unk_token='&lt;unk&gt;', pad_token=PAD, mask_token=MASK)model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')# íŒŒë¼ë¯¸í„°, í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ë¡œìŠ¤, ì˜µí‹°ë§ˆì´ì €(ì•„ë‹´)epoch = 2Sneg = -1e18learning_rate = 3e-5criterion = torch.nn.CrossEntropyLoss(reduction='none')optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)# ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°df = pd.read_csv('../../ChatbotData.csv')df.head()#ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìƒì†class ChatbotDataset(Dataset): # ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ë¶€ë¶„ def __init__(self, chats, max_len=64): self._data = chats self.max_len = max_len self.q_token = U_TKN self.a_token = S_TKN self.sent_token = SENT self.eos = EOS self.pad = PAD self.mask = MASK self.tokenizer = koGPT2_TOKENIZER def __len__(self): return len(self._data) #Q,Aë§Œ ì‚¬ìš©í•˜ì—¬ íŒŒì¸íŠœë‹ì„ ìœ„í•œ í† í°í™”(ì¸ë±ìŠ¤(idx)ì— í•´ë‹¹í•˜ëŠ” ì…ì¶œë ¥ ë°ì´í„° ë°˜í™˜) def __getitem__(self, idx): turn = self._data.iloc[idx] q = turn['Q'] # ì§ˆë¬¸ì„ ê°€ì ¸ì˜¨ë‹¤. q = re.sub(r'([?.!,])', r' ', q) # íŠ¹ìˆ˜ê¸°í˜¸ ìƒëµ(ì´ê±° ì•ˆí•˜ë©´ ê²°ê³¼ê°€ ì´ìƒí•˜ê²Œ ë‚˜ì˜¬ ë•Œê°€ ë§ìŒ) a = turn['A'] # ë‹µë³€ì„ ê°€ì ¸ì˜¨ë‹¤. a = re.sub(r'([?.!,])', r' ', a) q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token) q_len = len(q_toked) a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos) a_len = len(a_toked) #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´(64)ë³´ë‹¤ í¬ë©´ if q_len &gt; self.max_len: a_len = self.max_len - q_len #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´ if a_len &lt;= 0: #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´ q_toked = q_toked[-(int(self.max_len / 2)) :] #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ q_len = len(q_toked) a_len = self.max_len - q_len #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´ a_toked = a_toked[:a_len] a_len = len(a_toked) #ì§ˆë¬¸ì˜ ê¸¸ì´ + ë‹µë³€ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´ if q_len + a_len &gt; self.max_len: a_len = self.max_len - q_len #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´ if a_len &lt;= 0: #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´ q_toked = q_toked[-(int(self.max_len / 2)) :] #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ q_len = len(q_toked) a_len = self.max_len - q_len #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´ a_toked = a_toked[:a_len] a_len = len(a_toked) # ë‹µë³€ labels = [mask, mask, ...., mask, ..., &lt;bos&gt;,..ë‹µë³€.. &lt;eos&gt;, &lt;pad&gt;....] labels = [self.mask] * q_len + a_toked[1:] # mask = ì§ˆë¬¸ê¸¸ì´ 0 + ë‹µë³€ê¸¸ì´ 1 + ë‚˜ë¨¸ì§€ 0 mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len) # ë‹µë³€ labelsì„ index ë¡œ ë§Œë“ ë‹¤. labels_ids = self.tokenizer.convert_tokens_to_ids(labels) # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING while len(labels_ids) &lt; self.max_len: labels_ids += [self.tokenizer.pad_token_id] # ì§ˆë¬¸ + ë‹µë³€ì„ index ë¡œ ë§Œë“ ë‹¤. token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked) # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING while len(token_ids) &lt; self.max_len: token_ids += [self.tokenizer.pad_token_id] #ì§ˆë¬¸+ë‹µë³€, ë§ˆìŠ¤í¬, ë‹µë³€ return (token_ids, np.array(mask), labels_ids)# batchesê°€ 1ì´ ì•„ë‹Œ ê²½ìš° ì´ëŸ°ì‹ìœ¼ë¡œ ì„¸íŒ…í•˜ì—¬ DataLoaderì˜ collate_fnì— ë„£ì–´ì¤€ë‹¤.def collate_batch(batch): data = [item[0] for item in batch] mask = [item[1] for item in batch] label = [item[2] for item in batch] return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)df=df[['Q','A']]# df = df.iloc[:100,:] #í…ŒìŠ¤íŠ¸ ì‹œ ë°ì´í„°ë¥¼ ì§§ê²Œ ë§Œë“¤ì–´ì„œ êµ¬ë™ì—¬ë¶€ í™•ì¸device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')print(f'GPU ì‚¬ìš© ê°€ëŠ¥í•œê°€ìš” ? : {torch.cuda.is_available()}') train_set = ChatbotDataset(df, max_len=64) #ìœˆë„ìš° í™˜ê²½ì—ì„œëŠ” num_workers ëŠ” ë¬´ì¡°ê±´ 0ìœ¼ë¡œ ì§€ì •train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch)model.to(device)model.train()# ê°€ì¤‘ì¹˜ ê°™ì€ê±° ì—†ì´ í•™ìŠµprint ('í•™ìŠµ ì‹œì‘')for epoch in range(epoch): for batch_idx, samples in enumerate(tqdm(train_dataloader)): optimizer.zero_grad() #Pytorchì—ì„œëŠ” gradientsê°’ë“¤ì„ ì¶”í›„ì— backwardë¥¼ í•´ì¤„ë•Œ ê³„ì† ë”í•´ì£¼ê¸° ë•Œë¬¸ token_ids, mask, label = samples out = model(token_ids) out = out.logits #Returns a new tensor with the logit of the elements of input mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2) mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out)) loss = criterion(mask_out.transpose(2, 1), label) # í‰ê·  loss ë§Œë“¤ê¸° avg_loss[0] / avg_loss[1] &lt;- loss ì •ê·œí™” avg_loss = loss.sum() / mask.sum() avg_loss.backward() # í•™ìŠµ ë optimizer.step()#ê²½ì‚¬í•˜ê°•ë²•(gradient descent)print ('í•™ìŠµ ì¢…ë£Œ')### ì±—ë´‡ ì‹¤í–‰ 'quit' ì…ë ¥ ì‹œ ì¢…ë£Œwith torch.no_grad(): #requires_grad=False ìƒíƒœê°€ ë˜ì–´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•„ê»´ì¤Œ print('ì±—ë´‡ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤. ì¢…ë£Œë¥¼ ì›í•˜ë©´ \\&quot;quit\\&quot;ì„ ì…ë ¥í•´ì£¼ì„¸ìš”') print(' ') while True : q = input('ë‚˜ &gt; ').strip() if q == 'quit': break a = '' while True: input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(U_TKN + q + SENT + S_TKN + a)).unsqueeze(dim=0) pred = model(input_ids) pred = pred.logits #ë§ˆì§€ë§‰ dimì˜ ìµœëŒ€ê°’ ì¸ë±ìŠ¤ gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1] if gen == EOS: break a += gen.replace('â–', ' ') print('Chatbot &gt; {}'.format(a.strip()))","link":"/2022/12/10/Study_folder/NLP(Natural_Language_Processing)/2022-12-10-KoGPT2_chatbot/"},{"title":"SBERT(Sentence BERT)ë¥¼ í™œìš©í•œ ì±—ë´‡ ìƒì„±","text":"SBERT SBERTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ BERTì˜ ë¬¸ì¥ ì„ë² ë”©ì˜ ì„±ëŠ¥ì„ ìš°ìˆ˜í•˜ê²Œ ê°œì„ ì‹œí‚¨ ëª¨ë¸ì…ë‹ˆë‹¤. SBERTëŠ” ìœ„ì—ì„œ ì–¸ê¸‰í•œ BERTì˜ ë¬¸ì¥ ì„ë² ë”©ì„ ì‘ìš©í•˜ì—¬ BERTë¥¼ íŒŒì¸ íŠœë‹í•©ë‹ˆë‹¤. ë¬¸ì¥ ìŒ ë¶„ë¥˜ íƒœìŠ¤í¬ë¡œ íŒŒì¸ íŠœë‹ SBERTë¥¼ í•™ìŠµí•˜ëŠ” ì²«ë²ˆì§¸ ë°©ë²•ì€ ë¬¸ì¥ ìŒ ë¶„ë¥˜ íƒœìŠ¤í¬. ëŒ€í‘œì ìœ¼ë¡œëŠ” NLI(Natural Language Inferencing) ë¬¸ì œë¥¼ í‘¸ëŠ” ê²ƒì…ë‹ˆë‹¤. NLIëŠ” ë‘ ê°œì˜ ë¬¸ì¥ì´ ì£¼ì–´ì§€ë©´ ìˆ˜ë°˜(entailment) ê´€ê³„ì¸ì§€, ëª¨ìˆœ(contradiction) ê´€ê³„ì¸ì§€, ì¤‘ë¦½(neutral) ê´€ê³„ì¸ì§€ë¥¼ ë§ì¶”ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ë¬¸ì¥ ìŒ íšŒê·€ íƒœìŠ¤í¬ë¡œ íŒŒì¸ íŠœë‹ SBERTë¥¼ í•™ìŠµí•˜ëŠ” ë‘ë²ˆì§¸ ë°©ë²•ì€ ë¬¸ì¥ ìŒìœ¼ë¡œ íšŒê·€ ë¬¸ì œë¥¼ í‘¸ëŠ” ê²ƒìœ¼ë¡œ ëŒ€í‘œì ìœ¼ë¡œ STS(Semantic Textual Similarity) ë¬¸ì œë¥¼ í‘¸ëŠ” ê²½ìš°ì…ë‹ˆë‹¤. STSë€ ë‘ ê°œì˜ ë¬¸ì¥ìœ¼ë¡œë¶€í„° ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ ë§í•©ë‹ˆë‹¤. SBERTì˜ ì„ë² ë”©ì„ ì‚¬ìš©í•œ ì±—ë´‡ë§Œë“¤ê¸° SBERTì—ì„œ ì„ë² ë”© ë¶€ë¶„ë§Œ ì‚¬ìš©(STS) dfì˜ ì„ë² ë”© ê°’ê³¼ ì§ˆë¬¸ì˜ ì„ë² ë”©ê°’ ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ êµ¬í•˜ì—¬ ë‹µì„ í•˜ëŠ” êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ. streamlitì„ ì‚¬ìš©í•˜ì—¬(ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜) ì±—ë´‡ ìƒì„± ì „ì²˜ë¦¬ëŠ” ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜(from AIí—ˆë¸Œ)ì—ì„œ Q,Aë¶€ë¶„ë§Œ ê°€ì ¸ì™€ì„œ ì‚¬ìš© 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#Thinkbig_chatbot SBERT(sentence_transformers)import streamlit as stfrom streamlit_chat import message# streamlit_chatì€ python 3.8ë²„ì „ ì´ìƒì—ì„œë§Œ ì œëŒ€ë¡œ ë™ì‘import pandas as pdfrom sentence_transformers import SentenceTransformerfrom sklearn.metrics.pairwise import cosine_similarityimport jsonimport osfrom typing import Literal, Optional, Unionimport streamlit.components.v1 as components@st.cache(allow_output_mutation=True)# cache : ëª¨ë¸ì„ ì—¬ëŸ¬ë²ˆ ë¶€ë¥´ì§€ ì•Šê³  í•œë²ˆë§Œ ë¶ˆëŸ¬ì˜¤ëŠ” ì—­í• # Streamlitì˜ ìºì‹œ ì£¼ì„ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ í‘œì‹œí•˜ë©´ í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œë§ˆë‹¤ ë‹¤ìŒ ì„¸ ê°€ì§€ë¥¼ í™•ì¸í•´ì•¼ í•œë‹¤ê³  Streamlitì— ì•Œë¦°ë‹¤.def cached_model(): model = SentenceTransformer('jhgan/ko-sroberta-multitask') return model# ëª¨ë¸ì€ ë¯¸ë¦¬ í•™ìŠµëœ SentenceTransformerì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©# SentenceTransformerëŠ” ìµœì‹  ë¬¸ì¥, í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì„ë² ë”©ì„ ìœ„í•œ python í”„ë ˆì„ì›Œí¬# ì´ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ 100ê°œ ì´ìƒì˜ ì–¸ì–´ì— ëŒ€í•œ ë¬¸ì¥/í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ê³„ì‚°# ê·¸ëŸ° ë‹¤ìŒ ì´ëŸ¬í•œ ì„ë² ë”©ì„ ì˜ˆë¥¼ ë“¤ì–´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ë¹„êµí•˜ì—¬ ìœ ì‚¬í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë¬¸ì¥ì„ ì°¾ëŠ”ë‹¤.# wellness_dataset_final.csv : aií—ˆë¸Œì˜ ê°ì„±ëŒ€í™” ë°ì´í„°ì™€ ì±—ë´‡ ë°ì´í„°ë¥¼ ë³‘í•©í•œ í›„ ì „ì²˜ë¦¬í•œ ë°ì´í„°@st.cache(allow_output_mutation=True)def get_dataset(): df = pd.read_csv('wellness_dataset_final.csv') # ì„ë² ë”©ëœ ë°ì´í„°ì…‹ ë¡œë“œ df['embedding'] = df['embedding'].apply(json.loads) # ì„ë² ë”© return df# streamlitì— ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ ë¡œë“œmodel = cached_model()df = get_dataset()# í™”ë©´ì— í‘œì‹œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ì¶œë ¥st.title('ìì—°ì–´ì²˜ë¦¬ í”„ë¡œì íŠ¸') # ì œëª©st.header('ì‹¬ë¦¬ìƒë‹´ ì±—ë´‡') # í—¤ë”# st.subheader(&quot;ì„œë¸Œí—¤ë”&quot;)# st.text(&quot;í…ìŠ¤íŠ¸&quot;)st.markdown(&quot;â¤ï¸chatbot_think_big&quot;) # ë§ˆí¬ë‹¤ìš´#st.subheader(&quot;&quot;)st.markdown(&quot;&quot;&quot; ğŸ™‚ ìì—°ì–´ì²˜ë¦¬ 1ì°¨ íŒ€í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. &quot;&quot;&quot; &quot;&quot;&quot; ğŸ’œ SentenceTransformerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ ì„ë² ë”©í•˜ê³  ì´ë¥¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ í•¨ê»˜ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ì„ ì±„íƒí•©ë‹ˆë‹¤. &quot;&quot;&quot;)# ì™¼ìª½ sidebar ë¶€ë¶„st.sidebar.header(&quot;NLP PROJECT&quot;)st.sidebar.subheader(&quot;TEAM : Think_Big&quot;)st.sidebar.subheader(&quot;íŒ€ì›&quot;)st.sidebar.text(&quot;ì¡°ì¸í™˜(íŒ€ì¥)&quot;)st.sidebar.text(&quot;ê¹€ì˜ì§„&quot;)st.sidebar.text(&quot;ìµœì˜ˆì€&quot;)st.sidebar.text(&quot;ë°±ì„œìœ¤&quot;)# session_state : ê° ì‚¬ìš©ì ì„¸ì…˜ì— ëŒ€í•´ ì¬ì‹¤í–‰ ê°„ì— ë³€ìˆ˜ë¥¼ ê³µìœ í•˜ê³  ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ìœ ì§€# ì±—ë´‡ì´ ëŒ€í™”í•œ ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” generated session_stateë¥¼ ë§Œë“ ë‹¤if 'generated' not in st.session_state: st.session_state['generated'] = []# ìœ ì €ê°€ ëŒ€í™”í•œ ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” past session_stateë¥¼ ë§Œë“ ë‹¤if 'past' not in st.session_state: st.session_state['past'] = []## session_stateë¥¼ ì‚¬ìš©í•˜ë©´ streamlitì´ ìë™ìœ¼ë¡œ ì¬ì‹¤í–‰ë˜ë„ ì´ˆê¸°í™”ê°€ ë˜ì§€ ì•Šë„ë¡ í•œë‹¤.# formì„ ë§Œë“¤ì–´ì„œ ìœ ì €ì˜ ì…ë ¥ë°•ìŠ¤ì™€ ì „ì†¡ ë²„íŠ¼ì„ ë§Œë“ ë‹¤with st.form('form', clear_on_submit=True): # clear_on_submit=True : ì „ì†¡ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í…ìŠ¤íŠ¸ ë°•ìŠ¤ê°€ ìë™ìœ¼ë¡œ ì§€ì›Œì§„ë‹¤. user_input = st.text_input('ë‹¹ì‹ : ', '') submitted = st.form_submit_button('ì „ì†¡')# ìœ ì €ì˜ inputì— ì§ˆë¬¸ì´ ì…ë ¥ë˜ë©´ ì¸ì½”ë”©í•˜ì—¬ ë²¡í„°í™”í•œë‹¤if submitted and user_input: embedding = model.encode(user_input) # ìœ ì €ì˜ ì§ˆë¬¸ê³¼ ë°ì´í„°ì˜ ì§ˆë¬¸ë“¤ì„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ë¹„êµí•œ í›„, # ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë‹µë³€ì„ ì¶œë ¥ df['distance'] = df['embedding'].map(lambda x: cosine_similarity([embedding], [x]).squeeze()) answer = df.loc[df['distance'].idxmax()] # ìœ ì €ì˜ ì§ˆë¬¸ì„ pastì— ì €ì¥ st.session_state.past.append(user_input) # ì±—ë´‡ì˜ ë‹µë³€ì„ generatedì— ì €ì¥ st.session_state.generated.append(answer['A'])# ìœ ì €ì˜ ì§ˆë¬¸ê³¼ ì±—ë´‡ì˜ ë‹µë³€ì„ ë©”ì„¸ì§€ì°½ì— ì¶œë ¥í•˜ë„ë¡ í•˜ëŠ” êµ¬ë¬¸for i in range(len(st.session_state['past'])): message(st.session_state['past'][i], is_user=True, key=str(i) + '_user') if len(st.session_state['generated']) &gt; i: message(st.session_state['generated'][i], key=str(i) + '_bot')","link":"/2022/12/10/Study_folder/NLP(Natural_Language_Processing)/2022-12-10-SBERT-chatbot/"},{"title":"ìì—°ì–´ ì „ì²˜ë¦¬ ì¸ì½”ë”©, íŒ¨ë”©","text":"ìì—°ì–´ VOCABULARY ë§Œë“¤ê¸° ìì—°ì–´ ì²˜ë¦¬ì—ì„œëŠ” í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ì—¬ëŸ¬ê°€ì§€ ê¸°ë²•ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬í•œ ê¸°ë²•ë“¤ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì²« ë‹¨ê³„ë¡œ ê° ë‹¨ì–´ë¥¼ ê³ ìœ í•œ ì •ìˆ˜ì— ë§µí•‘(mapping)ì‹œí‚¤ëŠ” ì „ì²˜ë¦¬ ì‘ì—…ì…ë‹ˆë‹¤. Vocabì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ì„œëŠ” íŠ¹ì • ë‹¨ì–´ê°€ ë§ì´ ìˆì–´ì•¼(ì œê±°í•´ì•¼í•  í•„ìš”ì„±ì´ ìˆìŒ) ë³´ì—¬ ì¤„ ìˆ˜ ìˆê¸°ì— ì—¬ëŸ¬ ë¬¸ì¥, ë‹¨ì–´ë¥¼ ì‚¬ìš© 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import nltkfrom nltk.tokenize import sent_tokenizefrom nltk.tokenize import word_tokenizefrom nltk.corpus import stopwordstext = 'This is a good place. I want to go climbing right now. I dont know where this place is'# ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒ¨í‚¤ì§€ ë‹¤ìš´ë°›ê¸°(í•œêµ­ì–´ëŠ” ë‹¤ë¥¸ íŒ¨í‚¤ì§€ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤)nltk.download('punkt')nltk.download('stopwords')# ë¬¸ì¥ ë‚˜ëˆ„ê¸°(í…ìŠ¤íŠ¸ ë°ì´í„° -&gt; ë¬¸ì¥ ë‹¨ìœ„ë¡œ í† í°í™”)sentences = sent_tokenize(text)print(sentences)# ë‹¨ì–´ í† í°í™”(ë¬¸ì¥ ë‹¨ìœ„ -&gt; í† í°(ë‹¨ì–´)ë‹¨ìœ„ í† í°í™”)word_tokenize(sentences[0])# ì¶œë ¥ ê²°ê³¼# ['This is a good place.', 'I want to go climbing right now.', 'I dont know where this place is']## ['This', 'is', 'a', 'good', 'place', '.']# ë‹¨ì–´ ì‚¬ì „ ë§Œë“¤ê¸°vocab = {}preprocessed_sentences = []stop_words = set(stopwords.words('english'))for sentence in sentences: tokenized_sentence = word_tokenize(sentence) result = [] for word in tokenized_sentence: word = word.lower() if word not in stop_words : # ë‹¨ì–´ í† í°í™” ëœ ê²°ê³¼ì— ëŒ€í•´ì„œ ë¶ˆìš©ì–´ë¥¼ ì œê±°í•œë‹¤.(ë³´í†µ ë”°ë¡œ ì¶”ê°€ë¡œ ë‹¨ì–´ì¥ ë§Œë“¤ì–´ì„œ ì¶”ê°€ë¡œ ì œê±°) if len(word) &gt; 2: result.append(word) if word not in vocab: vocab[word] = 0 vocab[word] += 1 preprocessed_sentences.append(result) print(preprocessed_sentences)# [['good', 'place'], ['want', 'climbing', 'right'], ['dont', 'know', 'place']]print('VOCAB :',vocab)# VOCAB : {'good': 1, 'place': 2, 'want': 1, 'climbing': 1, 'right': 1, 'dont': 1, 'know': 1}# ì´ì œ ë¹ˆë„ìˆ˜ ë³„ë¡œ ì¸ì½”ë”©ì„ í•˜ëŠ”ë° Counter í•¨ìˆ˜ë¥¼ ë§ì´ ì´ìš©í•©ë‹ˆë‹¤.from collections import Counterall_words_list = sum(preprocessed_sentences, []) # 2ì°¨ì›ë¦¬ìŠ¤íŠ¸ -&gt; 1ì°¨ì›ë¦¬ìŠ¤íŠ¸vocab = Counter(all_words_list)print(vocab)# Counter({'place': 2, 'good': 1, 'want': 1, 'climbing': 1, 'right': 1, 'dont': 1, 'know': 1}) íŒ¨ë”©ì²˜ë¦¬ í•˜ê¸°(Padding) ì»´í“¨í„°ëŠ” ê¸¸ì´ê°€ ì „ë¶€ ë™ì¼í•œ ë¬¸ì„œë“¤ì— ëŒ€í•´ í•˜ë‚˜ì˜ í–‰ë ¬ë¡œ ë³´ê³ , í•œêº¼ë²ˆì— ë¬¶ì–´ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ë³‘ë ¬ ì—°ì‚°ì„ ìœ„í•´ì„œ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ í†µì¼ ì‹œì¼œì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì´í† ì¹˜ì˜ from torch.nn.utils.rnn import pad_sequence ë˜ëŠ” ì¼€ë¼ìŠ¤ì˜ from tensorflow.keras.preprocessing.sequence import pad_sequencesë¥¼ ì´ìš©í•˜ì—¬ íŒ¨ë”©í•˜ë©´ ë©ë‹ˆë‹¤. 12345678910111213141516171819202122232425print(preprocessed_sentences)# [['good', 'place'], ['want', 'climbing', 'right'], ['dont', 'know', 'place']]from tensorflow.keras.preprocessing.sequence import pad_sequencesfrom tensorflow.keras.preprocessing.text import Tokenizer# í† í¬ë‚˜ì´ì €tokenizer = Tokenizer()tokenizer.fit_on_texts(preprocessed_sentences)encoded = tokenizer.texts_to_sequences(preprocessed_sentences)print(encoded)[[2, 1], [3, 4, 5], [6, 7, 1]]padded = pad_sequences(encoded)print(padded) #ê¸°ë³¸ ì˜µì…˜ìœ¼ë¡œ íŒ¨ë”©# array([[2, 1, 0],# [3, 4, 5],# [6, 7, 1]], dtype=int32)padded = pad_sequences(encoded, padding='post') #paddingì˜ ê¸°ë³¸ ì˜µì…˜ì´ 'post'ì´ê³  ë’¤ì— 0ì„ ë¶™ì¸ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. padded# array([[2, 1, 0, 0, 0],# [3, 4, 5, 0, 0],# [6, 7, 1, 0, 0]], dtype=int32) í•œêµ­ì–´ ì²˜ë¦¬ëŠ” nltkê°€ ì•„ë‹Œ ë³´í†µ ë‹¤ë¥¸ íŒ¨í‚¤ì§€ë¥¼ konlyê°™ì€ í•œêµ­ì–´ìš© ë²„ì „ì„ ë”°ë¡œ ë‹¤ìš´ë°›ì•„ì„œ ì‚¬ìš©í•¨ 1234567891011import konlpyfrom konlpy.tag import Mecab###################mecab = Mecab()sentence = 'ì•ˆë…•í•˜ì„¸ìš” í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ ì…ë‹ˆë‹¤.'temp_X = mecab.morphs(sentence)temp_X# ì¶œë ¥ ê²°ê³¼['ì•ˆë…•', 'í•˜', 'ì„¸ìš”', 'í…ŒìŠ¤íŠ¸', 'ìš©', 'í…ìŠ¤íŠ¸', 'ì…ë‹ˆë‹¤', '.']","link":"/2022/12/30/Study_folder/NLP(Natural_Language_Processing)/2022-12-30-int-encoding/"},{"title":"Seq to Seq &amp; Attention &amp; Transformer","text":"ê¸°ê³„ ë²ˆì—­ ëª¨ë¸ì˜ ë°œì „ ì°¸ê³  : &lt;ìœ„í‚¤ ë…ìŠ¤&gt; ì°¸ê³  : &lt;Jay Almmar ìë£Œ&gt; GPT : Transformerì˜ ë””ì½”ë” ì•„í‚¤í…ì³ë¥¼ í™œìš© BERT : Transformerì˜ ì¸ì½”ë” ì•„í‚¤í…ì³ë¥¼ í™œìš© Seq2Seq2(ì‹œí€€ìŠ¤ íˆ¬ ì‹œí€€ìŠ¤) - `[ì¸ì½”ë” - ì»¨í…ìŠ¤íŠ¸ë°±í„° - ë””ì½”ë”]`ë¡œ ì´ë£¨ì–´ì ¸ ìˆê³  - seq2seqëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë” ì•„í‚¤í…ì²˜ì˜ ë‚´ë¶€ëŠ” ì‚¬ì‹¤ `ë‘ ê°œì˜ RNN êµ¬ì¡°`ë¡œ ì´ë£¨ì–´ì§„ ëª¨ë¸ - ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤(Sequence-to-Sequence, seq2seq)ëŠ” ì±—ë´‡ê³¼ ê¸°ê³„ ë²ˆì—­ì—ì„œ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. - ëŒ€ëµì ì¸ êµ¬ì¡°ëŠ” `ì…ë ¥ ì‹œí€€ìŠ¤`(ì§ˆë¬¸)ì™€ `ì¶œë ¥ ì‹œí€€ìŠ¤`(ëŒ€ë‹µ)ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ì€ ë’¤ì— ë§ˆì§€ë§‰ì— ì´ ëª¨ë“  ë‹¨ì–´ ì •ë³´ë“¤ì„ ì••ì¶•í•´ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë§Œë“­ë‹ˆë‹¤. ì´ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°(context vector)ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.(ì´ëŠ” ê³ ì •ëœ í¬ê¸°ë¼ì„œ í•œê³„ì ì´ ì¡´ì¬) ì…ë ¥ ë¬¸ì¥ì˜ ì •ë³´ê°€ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œ ëª¨ë‘ ì••ì¶•ë˜ë©´ ë²¡í„°ë¥¼ ë””ì½”ë”ë¡œ ì „ì†¡í•©ë‹ˆë‹¤. ë””ì½”ë”ëŠ” ë²ˆì—­ëœ ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. ì•„ë˜ ë™ì˜ìƒì„ ë³´ì‹œë©´ ì‰½ê²Œ ì´í•´ë  ê²ƒì…ë‹ˆë‹¤(10ì´ˆ) seq2seqì˜ í•œê³„ì  í•­ìƒ ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ì—(ì»¨í…ìŠ¤íŠ¸ ë²¡í„°) ëª¨ë“  ì •ë³´ë¥¼ ì €ì¥í•˜ê¸° ë•Œë¬¸ì— bottle neckí˜„ìƒì´ ë°œìƒí•˜ì—¬ ì •ë³´ ì†ì‹¤ì´ ë°œìƒí•œë‹¤. ì…ë ¥ì˜ ê¸¸ì´ê°€ ê¸¸ì–´ì§€ë©´ ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œê°€ ë°œìƒí•œë‹¤.(context vectorë¥¼ ê¸°ì¤€ìœ¼ë¡œ Encoder, Decoderê°€ ì™„ì „íˆ ë¶„ë¦¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì…ì¶œë ¥ì˜ ì—°ê´€ ê´€ê³„ê°€ ë„ˆë¬´ ë–¨ì–´ì ¸ ìˆì–´ì„œ ì—­ì „íŒŒ ì‹œ ê¸°ìš¸ê¸° ì†Œì‹¤ ë°œìƒ) ì–´í…ì…˜ ëª¨ë¸(Attention) seq2seqì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ëª¨ë¸ì´ Attention ëª¨ë¸ì´ë‹¤. ì–´í…ì…˜ì€ ì¤‘ìš”í•œ ë¶€ë¶„ì— ë” attention(ì§‘ì¤‘)í•˜ìëŠ” ìš”ì§€ë¡œ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì´ë©°, ê°„ë‹¨íˆ ë§í•´ì„œ ì¸ì½”ë”©ì˜ ëª¨ë“  ì€ë‹‰ì¸µì˜ ì •ë³´ë¥¼ ë””ì½”ë”ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ë‹¤.(Encoderì˜ hidden stateë¥¼ Decoderì—ì„œë„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•) ë‹¨ì–´ì— ê°€ì¤‘ì¹˜ë¥¼ ì£¼ëŠ” ë ˆì´ì–´ê°€ ì¶”ê°€ë¨(seq2seqì— ì–´í…ì…˜ ë ˆì´ì–´ê°€ ì¶”ê°€ë¨) ì•„ë˜ì˜ ë™ì˜ìƒ(10ì´ˆ)ì€ seq2seqì— attentionì„ ì¶”ê°€í•œ ë™ì˜ìƒì…ë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸(transformer) ì•ì˜ ì–´í…ì…˜ì„ RNNì˜ ë³´ì • ìš©ë„ê°€ ì•„ë‹Œ ì–´í…ì…˜ë§Œìœ¼ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ë§Œë“  ëª¨ë¸ì´ íŠ¸ë ŒìŠ¤í¬ë¨¸!(ì´ ëª¨ë¸ì´ ë“±ì¥í•˜ê³  ìì—°ì–´ ë¶„ì•¼ì˜ ìƒíƒœê³„ê°€ ë³€í–ˆìŠµë‹ˆë‹¤) ì¸ì½”ë”ì™€ ë””ì½”ë”ë¼ëŠ” ë‹¨ìœ„ê°€ ì—¬ëŸ¬ ê°œë¡œ êµ¬ì„±ë˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì—ì„œëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°œìˆ˜ë¥¼ ê°ê° 6ê°œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ë””ì½”ë”ëŠ” seq2seq êµ¬ì¡°ì²˜ëŸ¼ ì‹œì‘ í† í° ë¶€í„° ì¢…ë£Œ í† í° ê¹Œì§€ ì—°ì‚°ì„ ì§„í–‰í•©ë‹ˆë‹¤. ì´ëŠ” RNNì€ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ ì—¬ì „íˆ ì¸ì½”ë”-ë””ì½”ë”ì˜ êµ¬ì¡°ëŠ” ìœ ì§€ë˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í•˜ì§€ë§Œ íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ë‹¨ì–´ ì…ë ¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ë°›ëŠ” ë°©ì‹ì´ ì•„ë‹ˆë¯€ë¡œ ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì•Œë ¤ì¤„ í•„ìš”ê°€ ìˆëŠ”ë° ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ì„œ ê° ë‹¨ì–´ì˜ ì„ë² ë”© ë²¡í„°ì— ìœ„ì¹˜ ì •ë³´ë“¤ì„ ë”í•˜ì—¬ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ë°, ì´ë¥¼ í¬ì§€ì…”ë„ ì¸ì½”ë”©(positional encoding)ì´ë¼ê³  í•©ë‹ˆë‹¤. ì¸ì½”ë”ëŠ” ì´ ë ˆì´ì–´ ê°œìˆ˜ ë§Œí¼ì˜ ì¸µ ì—°ì‚°ì„ ìˆœì°¨ì ìœ¼ë¡œ í•œ í›„ì— ë§ˆì§€ë§‰ ì¸µì˜ ì¸ì½”ë”ì˜ ì¶œë ¥ì„ ë””ì½”ë”ì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤. ì¸ì½”ë” ì—°ì‚°ì´ ëë‚¬ìœ¼ë©´ ë””ì½”ë” ì—°ì‚°ì´ ì‹œì‘ë˜ì–´ ë””ì½”ë” ë˜í•œ ë§Œí¼ì˜ ì—°ì‚°ì„ í•˜ëŠ”ë°, ì´ë•Œë§ˆë‹¤ ì¸ì½”ë”ê°€ ë³´ë‚¸ ì¶œë ¥ì„ ê° ë””ì½”ë” ì¸µ ì—°ì‚°ì— ì‚¬ìš©í•©ë‹ˆë‹¤. ë””ì½”ë”ë„ ì¸ì½”ë”ì™€ ë™ì¼í•˜ê²Œ ì„ë² ë”© ì¸µê³¼ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ ê±°ì¹œ í›„ì˜ ë¬¸ì¥ í–‰ë ¬ì´ ì…ë ¥ë©ë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë”ì—ì„œëŠ” í˜„ì¬ ì‹œì ì˜ ì˜ˆì¸¡ì—ì„œ ë¯¸ë˜ì— ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì°¸ê³ í•˜ì§€ ëª»í•˜ë„ë¡ ë£©-ì–´í—¤ë“œ ë§ˆìŠ¤í¬(look-ahead mask)ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤.","link":"/2022/12/31/Study_folder/NLP(Natural_Language_Processing)/2022-12-31-nlp-model-history/"},{"title":"SBERT(Sentence BERT) ê°œë…","text":"SBERT(Sentence + BERT) Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks(2019)ì˜ ë…¼ë¬¸ì—ì„œ ì²˜ìŒ ë“±ì¥í•˜ì˜€ë‹¤.ê¸°ì¡´ì˜ BERTëŠ” í•™ìŠµì‹œê°„ì´ ë„ˆë¬´ ë§ì´ ê±¸ë¦¬ëŠ” ë‹¨ì ì„ ë³´ì™„í•œ ëª¨ë¸ Sentence-BERT ëŠ” word embedding modelì´ë‹¤. ì›Œë“œì„ë² ë”©ì´ë€ í…ìŠ¤íŠ¸ ë¶„ì„ì„ ìœ„í•œ ë‹¨ì–´ í‘œí˜„ì— ì‚¬ìš©ë˜ëŠ” ìš©ì–´ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ ë²¡í„° ê³µê°„ì—ì„œ ë” ê°€ê¹Œìš´ ë‹¨ì–´ê°€ ì˜ë¯¸ê°€ ìœ ì‚¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë„ë¡ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì¸ì½”ë”©í•˜ëŠ” ì‹¤ìˆ˜ ê°’ ë²¡í„°ì˜ í˜•íƒœì…ë‹ˆë‹¤. SBERTì˜ ë°ì´í„°ëŠ” 2ê°€ì§€ ì¢…ë¥˜ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. STS(Semantic Textual Similarity) NLI(Natural Language Inference) STS ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ ë¬¸ì¥ê°„ similarity(ì˜ë¯¸ì  ìœ ì‚¬ì„±)ì˜ ì •ë„ë¥¼ í‰ê°€í•˜ê³  ë¶„ë¥˜ ë³´í†µ 0(ê´€ë ¨ ì—†ìŒ)ì—ì„œ 5.0(ê±°ì˜ ìœ ì‚¬)ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë¶„ë¥˜ NLI(Natural Language Inference) ë‘ ë¬¸ì¥(premise, hypothesis)ì„ ì…ë ¥ ë°›ì•„ ë‘ ê´€ê³„ë¥¼ entailment(positive), contradiction(negative), neutralë¡œ ë¶„ë¥˜ a : ë‚˜ëŠ” í•™ì›ì— ê°„ë‹¤(anchor)b : ë‚˜ëŠ” ë²„ìŠ¤ë¥¼ íƒ€ê³  í•™ì›ì— ê°„ë‹¤(entailment)c : ë‚˜ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™ì„ í•œë‹¤(contradiction) í•™ìŠµ :ë‘ ë¬¸ì¥(s1, s2)ì´ ì´ˆê¸°í™” ëœ siamese network(ìƒ´ ë„¤íŠ¸ì›Œí¬)ë¡œ ì…ë ¥ë‘ ì…ë ¥ ë¬¸ì¥ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ê°’(e1, e2)ì„ ì¶”ì¶œë‘ ì„ë² ë”© ë²¡í„°(e1, e2)ì— ëŒ€í•´ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°ë§Œì•½ ë‘ ì…ë ¥ ë¬¸ì¥ì´ ê°™ì€ classë¼ë©´ ê±°ë¦¬ê°€ ê°€ê¹Œì›Œì§€ë„ë¡, ë‹¤ë¥¸ classë¼ë©´ ê±°ë¦¬ê°€ ë©€ì–´ì§€ë„ë¡ weightì„ ì¡°ì ˆí•˜ë©° í•™ìŠµ SBERTì—ì„œëŠ” cost functionìœ¼ë¡œ triplet lossì„ ì‚¬ìš© ==&gt; ì•µì»¤ ë¬¸ì¥ê³¼ ë™ì¼(ë‹¤ë¥¸) í´ë˜ìŠ¤ ë¬¸ì¥ ê±°ë¦¬ softmaxë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  -&gt; MNR loss(triplet lossì™€ ìœ ì‚¬) ì‚¬ìš© SBERT - finetuningí•˜ê¸° ìœ„í•œ ê°œìš” NLI dataset(ë¬¸ì¥ê³¼ì˜ ê´€ê³„ë„), ë¬¸ì¥ê³¼ì˜ ìœ ì‚¬ë„(ê±°ë¦¬) ë‘ ê°€ì§€ê°€ í•„ìš”í•˜ë‹¤. triplet êµ¬ì¡°ë¡œ(ì—¥ì»¤, Positive ë¬¸ì¥, Negative ë¬¸ì¥) NLI ë°ì´í„°ì…‹ì„ êµ¬ì„±í•œë‹¤. ì˜ˆë¥¼ ë“¤ë©´ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ì´ë‹¤.(a,b,c) a : ë‚˜ëŠ” í•™ì›ì— ê°„ë‹¤(anchor) b : ë‚˜ëŠ” ë²„ìŠ¤ë¥¼ íƒ€ê³  í•™ì›ì— ê°„ë‹¤(entailment) c : ë‚˜ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™ì„ í•œë‹¤(contradiction) pretrained BERTëª¨ë¸ë¡œ NLI ë°ì´í„°ë¥¼ ë¬¸ì¥ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ MNR loss(MultipleNegativesRankingLoss) í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ NLI ë°ì´í„°ë¥¼ íŒŒì¸íŠœë‹","link":"/2023/01/04/Study_folder/NLP(Natural_Language_Processing)/2023-01-04-SBERT-nli/"},{"title":"Attention íŒŒì•…í•˜ê¸°","text":"ì°¸ê³  ìë£Œ : &lt;ê¹€ì§„ì†”ë‹˜ ë¸”ë¡œê·¸&gt; ì°¸ê³  ì˜ìƒ : &lt;Aladdin youtube&gt; ì–´í…ì…˜ ëª¨ë¸ seq2seqì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ëª¨ë¸ì´ Attention ëª¨ë¸ì´ë‹¤. ì–´í…ì…˜ì€ ì¤‘ìš”í•œ ë¶€ë¶„ì— ë” ì§‘ì¤‘ì„ í•˜ìëŠ” ìš”ì§€ë¡œ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì´ë©°, ê°„ë‹¨íˆ ë§í•´ì„œ ì¸ì½”ë”©ì˜ ëª¨ë“  ì€ë‹‰ì¸µì˜ ì •ë³´ë¥¼ ë””ì½”ë”ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¨ì–´ì— ê°€ì¤‘ì¹˜ë¥¼ ì£¼ëŠ” ë ˆì´ì–´ê°€ ì¶”ê°€ë¨(seq2seqì— ì–´í…ì…˜ ë ˆì´ì–´ê°€ ì¶”ê°€ë¨) ë§ˆìŠ¤í¬(Mask)ë€? Masking ë¼ëŠ” ì˜ë¯¸ëŠ” ê°€ë¦°ë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤. ë””ì½”ë”(Decoder)ì—ì„œì˜ Self-Attention Layer ëŠ” ë°˜ë“œì‹œ ìê¸° ìì‹  ë³´ë‹¤ ì•ìª½ì— í¬ì§€ì…˜ì— í•´ë‹¹í•˜ëŠ” í† í°ë“¤ì˜ ì–´í…ì…˜ ìŠ¤ì½”ì–´ë§Œ ë³¼ìˆ˜ìˆë‹¤. ì•„ì›ƒí’‹ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë’¤ì— ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ì€ ë³¼ ìˆ˜ ì—†ë‹¤. (transformerë„ ê°™ìŒ) Maskingì„ ìˆ˜í•™ì ìœ¼ë¡œ êµ¬í˜„í•  ë•ŒëŠ” Score ê°’ì„ -inf (ë§ˆì´ë„ˆìŠ¤ ë¬´í•œëŒ€) ê°’ìœ¼ë¡œ í‘œê¸°í•¨ìœ¼ë¡œì¨ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.(ê°’ì„ êµ¬í•˜ê³  ì´ë¥¼ -inf ê°’ìœ¼ë¡œ ë³€ê²½) MLM(Masked Language Model) MLMì€ ë§ˆìŠ¤í¬ê°€ ë¬´ì—‡ì¸ì§€ ëª…ë£Œí•˜ê²Œ ì•Œë ¤ì£¼ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ì…ë ¥ ë¬¸ì¥ì—ì„œ ì„ì˜ë¡œ Tokenì„ ë§ˆìŠ¤í‚¹(masking), ê·¸ Tokenì„ ë§ì¶”ëŠ” ë°©ì‹ì¸ MLM í•™ìŠµ ì§„í–‰ ë¬¸ì¥ì˜ ë¹ˆì¹¸ ì±„ìš°ê¸° ë¬¸ì œë¥¼ í•™ìŠµ ìƒì„± ëª¨ë¸ ê³„ì—´ì€(ì˜ˆë¥¼ ë“¤ì–´ GPT) ì…ë ¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ MLMì€ ë¬¸ì¥ ë‚´ ëœë¤í•œ ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹ í•˜ê³  ì´ë¥¼ ì˜ˆì¸¡ ì…ë ¥ì˜ 15% ë‹¨ì–´ë¥¼ [MASK] Tokenìœ¼ë¡œ ë°”ê¿”ì£¼ì–´ ë§ˆìŠ¤í‚¹ ì´ ë•Œ 80%ëŠ” [MASK]ë¡œ ë°”ê¿”ì£¼ì§€ë§Œ, ë‚˜ë¨¸ì§€ 10%ëŠ” ë‹¤ë¥¸ ëœë¤ ë‹¨ì–´ë¡œ, ë˜ ë‚¨ì€ 10%ëŠ” ë°”ê¾¸ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë‘  ì´ëŠ” íŠœë‹ ì‹œ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ì„ ë•ë„ë¡ ë§ˆìŠ¤í‚¹ì— ë…¸ì´ì¦ˆë¥¼ ì„ìŒ Scaled Dot Product Attention(í”íˆ ì–´í…ì…˜ìœ¼ë¡œ ì•Œë ¤ì§„ Attention) ì…ë ¥ê°’ì€ Q(query), K(key), V(value) ê·¸ë¦¬ê³  attention maskë¡œ êµ¬ì„± ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì…ë ¥ê°’ ì¤‘ K, VëŠ” ê°™ì€ ê°’ ì´ì–´ì•¼ í•©ë‹ˆë‹¤. Qê¹Œì§€ K, Vì™€ ë™ì¼í•œ ê²½ìš°ëŠ” self attentionì´ë¼ í•©ë‹ˆë‹¤. Query : ì°¾ê³ ì í•˜ëŠ” ëŒ€ìƒ Key : ì €ì¥ëœ ë°ì´í„°ë¥¼ ì°¾ê³ ì í•  ë•Œ ì°¸ì¡°í•˜ëŠ” ê°’ Value : ì €ì¥ë˜ëŠ” ë°ì´í„° 1234567# dictionary êµ¬ì¡°ë¥¼ ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤{ 'key1' : 'value1', 'key2' : 'value2'}# queryì˜ ê°’ìœ¼ë¡œëŠ” 'key1' ë˜ëŠ” 'key2'ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.# ì´ë•Œ queryì™€ ê°™ì€ keyê°’ì„ ì„ íƒí•  ì§€ ë˜ëŠ” ê°€ì¥ ìœ ì‚¬í•œ keyê°’ì„ ì„ íƒí•  ì§€ëŠ” ë¬¸ì œì— ë”°ë¼ ë‹¬ë¼ì§€ê²Œ ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ì ì€ Qì™€ Keyê°’ë“¤ì´ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ê³„ì‚°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¦‰, (softmaxë¥¼ ì ìš©í•˜ì—¬ ì´ í•©ì´ 1ì¸) Keyê°’ë“¤ê³¼ Valueì˜ ê°’ì„ ê³±í•œ í›„ ëª¨ë‘ ë”í•˜ë©´ Attention valueê°€ ë˜ëŠ” ì›ë¦¬ì…ë‹ˆë‹¤. QueryëŠ” Decoderì˜ ì€ë‹‰ì¸µ(hidden state)ê°€ ë©ë‹ˆë‹¤. Attentionì—ì„œëŠ” Encoderì˜ hidden stateë¥¼ Keyì™€ Valueë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.(ì•ì„œ ë§í•œ self attention) ì¦‰, Keyì™€ ValueëŠ” ê°™ê³  ë‹¨ì–´ì˜ ê°¯ìˆ˜ ë§Œí¼ Key ê°’ì„ ê°€ì§‘ë‹ˆë‹¤. ì›-ë…¼ë¬¸ì—ì„œ CompareëŠ” Fully Connected ë°©ì‹ì˜ ì—°ì‚°ì„ ì´ìš©í•˜ì˜€ê³  Aggregateì˜ ê²½ìš° ëª¨ë“  key-valueì— ëŒ€í•˜ì—¬ ë²¡í„°ì˜ element-wise multiplication ì—°ì‚°ì„ í•œ í›„ element-wise sumì„ í•˜ì—¬ Attention Valueë¥¼ ìƒì„±í•©ë‹ˆë‹¤.ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. $$ \\text{Compare}(q, k_{j}) = q \\cdot k_{j} = q^{T}k_{j} $$$$ \\text{Aggregate}(c, V) = \\sum_{j} c_{j}v_{j} $$ ìš”ì•½ ì•„ë˜ ê·¸ë¦¼ë“¤ë¡œ ìš”ì•½ì„ í•˜ê² ìŠµë‹ˆë‹¤. Encoderì˜ hidden stateëŠ” (Key, Value)ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë¦¼ì—ì„œ hëŠ” Keyì™€ Valueë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. Decoderì˜ hidden stateëŠ” Queryë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. Decoderì—ì„œ së¼ëŠ” Queryê°€ ì…ë ¥ë˜ê³  ê·¸ Queryì™€ ëª¨ë“  key ê°’ì¸ h (ì•„ë˜ ê·¸ë¦¼ì—ì„œëŠ” $$ h_{0}, h_{1}, h_{2} $$)ì™€ Comparison ì—°ì‚°ì„ í†µí•˜ì—¬ ìœ ì‚¬ë„ë¥¼ êµ¬í•©ë‹ˆë‹¤. ê°’ì€ softmaxë¥¼ ê±°ì¹˜ê¸° ë•Œë¬¸ì— í™•ë¥  ê°’ì²˜ëŸ¼ ì´ í•©ì´ 1ì´ ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ Valueì— í•´ë‹¹í•˜ëŠ” hì™€ ìœ ì‚¬ë„ë¥¼ ê³±í•˜ê³  ê²°ê³¼ë“¤ì„ í•©í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ a ë¼ëŠ” Attenen valueë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. $$ c_{i} = \\text{softmax}(s_{i}^{T}h_{j}) $$$$ a_{i} = \\sum_{j}c_{i}h_{j} $$ ê·¸ë¦¬ê³  Decoderì˜ ì€ë‹‰ì¸µì€ RNN(ë˜ëŠ” LSTM)ì—ì„œ ì—°ì‚°í•˜ì—¬ $$ s_{i} $$ â†’ $$ s_{i+1} $$ë¡œ ë§Œë“­ë‹ˆë‹¤. ê·¸ í›„ $$ a_{i} $$ì™€ $$ s_{i+1} $$ì„ í•©í•˜ê³  ($$ v_{i} = [s_{i}; a_{i-1}] $$) í•˜ì—¬ $$ v_{i+1} $$ì„ ë§Œë“­ë‹ˆë‹¤. ì´ ê°’ì„ FC layerì™€ Softmaxë¥¼ ê±°ì³ì„œ ìµœì¢… ì¶œë ¥ì¸ $$ y_{i} $$ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. attentionì—ì„œ Query, Key, Valueë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë°”ë‹¤ë‚˜ìš° ì–´í…ì…˜ vs Dot_Product_Attention ì»¨í…ìŠ¤íŠ¸ ë²¡í„°(context vector) ë°”ë‹¤ë‚˜ìš°: ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ êµ¬í•  ë•Œ ì´ì „ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœë¥¼ ì‚¬ìš©í•œë‹¤.Dot_Product_Attention: ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ êµ¬í•  ë•Œ í˜„ì¬ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ stë¥¼ ì‚¬ìš©í•œë‹¤. ì¶œë ¥ ë°”ë‹¤ë‚˜ìš°: í˜„ì¬ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœë¡œë¶€í„° ì¶œë ¥ì´ ë‚˜ì˜¨ë‹¤.Dot_Product_Attention: í˜„ì¬ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœëŠ” RNNì˜ ì€ë‹‰ ìƒíƒœ ì—­í• ë§Œ í•˜ê³ , ìƒˆë¡œìš´ ë²¡í„°ë¥¼ ì‚¬ìš©í•œë‹¤. ê³„ì‚° ì†ë„ ë°”ë‹¤ë‚˜ìš°: ë””ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœë¥¼ êµ¬í•  ë•Œ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ê°€ ì‚¬ìš©ë˜ë¯€ë¡œ RNNì˜ ì¬ê·€ ì—°ì‚°ì´ ìˆ˜í–‰ë  ë•Œ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ê°€ êµ¬í•´ì§ˆ ë•Œê¹Œì§€ ê¸°ë‹¤ë ¤ì•¼ í•œë‹¤. ê³„ì‚°ì´ ëŠë¦¼Dot_Product_Attention: ê³„ì‚°ì´ ë¹ ë¦„ ì¸ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœ ì‚¬ìš© ë°”ë‹¤ë‚˜ìš°: ì¸ì½”ë”ì˜ ëª¨ë“  ì€ë‹‰ ìƒíƒœì˜ ë²¡í„°ë¥¼ ë³¸ë‹¤.Dot_Product_Attention: íŠ¹ì • í•˜ì´í¼íŒŒë¼ë¯¸í„° Dì— ëŒ€í•´ (2D+1)ê°œì˜ ë¶€ë¶„ì§‘í•© ë²¡í„°ë§Œ ë³¸ë‹¤. ì…€í”„ ì–´í…ì…˜ì´ë€? ê°™ì€ ë¬¸ì¥ ë‚´ì˜ ë‘ token ì‚¬ì´ì˜ Attentionì„ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì€, Self-Attentionì´ë¼ê³  ë¶€ë¥¸ë‹¤. Q, K, V í˜•íƒœê°€ ë™ì¼ ë°˜ë©´, ì„œë¡œ ë‹¤ë¥¸ ë‘ ë¬¸ì¥ì— ê°ê° ì¡´ì¬í•˜ëŠ” ë‘ token ì‚¬ì´ì˜ Attentionì„ ê³„ì‚°í•˜ëŠ” ê²ƒì„ Cross-Attentionì´ë¼ê³  ë¶€ë¥¸ë‹¤.","link":"/2023/01/05/Study_folder/NLP(Natural_Language_Processing)/2023-01-05-attention/"},{"title":"Attention ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°","text":"ìŠ¤ì¼€ì¼ë“œ ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜ ì°¸ì¡° : &lt;ìœ„í‚¤ë…ìŠ¤&gt; ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜(dot-product attention)ì—ì„œ ìŠ¤ì¼€ì¼ë§í•˜ëŠ” ê²ƒì„ ì¶”ê°€í•˜ë©´ ìŠ¤ì¼€ì¼ë“œ ë‹·-í”„ë¡œë•íŠ¸ ì–´í…ì…˜(Scaled dot-product Attention)ì´ë¼ê³  í•©ë‹ˆë‹¤ scaled_dot_product_attentionì„ tensorflowë¡œ êµ¬í˜„, ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. 12345678910111213141516171819202122232425def scaled_dot_product_attention(query, key, value, mask): # query í¬ê¸° : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads) # key í¬ê¸° : (batch_size, num_heads, keyì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads) # value í¬ê¸° : (batch_size, num_heads, valueì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads) # padding_mask : (batch_size, 1, 1, keyì˜ ë¬¸ì¥ ê¸¸ì´) # Qì™€ Kì˜ ê³±. ì–´í…ì…˜ ìŠ¤ì½”ì–´ í–‰ë ¬. matmul_qk = tf.matmul(query, key, transpose_b=True) # ìŠ¤ì¼€ì¼ë§ depth = tf.cast(tf.shape(key)[-1], tf.float32) logits = matmul_qk / tf.math.sqrt(depth) # ë§ˆìŠ¤í‚¹, ë§¤ìš° ì‘ì€ ê°’ì´ë¯€ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ì— ì˜í•´ 0ì´ ëœë‹¤. if mask is not None: logits += (mask * -1e9) # ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” ë§ˆì§€ë§‰ ì°¨ì›ì¸ keyì˜ ë¬¸ì¥ ê¸¸ì´ ë°©í–¥ìœ¼ë¡œ ìˆ˜í–‰(axis=-1) # attention weight : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, keyì˜ ë¬¸ì¥ ê¸¸ì´) attention_weights = tf.nn.softmax(logits, axis=-1) # output : (batch_size, num_heads, queryì˜ ë¬¸ì¥ ê¸¸ì´, d_model/num_heads) output = tf.matmul(attention_weights, value) return output, attention_weights í…ŒìŠ¤íŠ¸ temp_qì˜ ê°’ [0, 10, 0]ì€ Keyì— í•´ë‹¹í•˜ëŠ” temp_kì˜ ë‘ë²ˆì§¸ ê°’ [0, 10, 0]ê³¼ ì¼ì¹˜í•˜ê²Œ ì„¤ì • 1234567891011121314import tensorflow as tfimport numpy as np# ì„ì˜ì˜ Query, Key, Valueì¸ Q, K, V í–‰ë ¬ ìƒì„±np.set_printoptions(suppress=True) #ì˜µì…˜ ë„£ì–´ì¤˜ì•¼ ë³´ê¸° í¸í•¨(ì†Œìˆ˜ì  ë°˜ì˜¬ë¦¼)temp_k = tf.constant([[10,0,0], [0,10,0], [0,0,10], [0,0,10]], dtype=tf.float32) # (4, 3)temp_v = tf.constant([[1,0], [10,0], [100,5], [1000,6]], dtype=tf.float32) # (4, 2)temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32) # (1, 3) #transpose_b ì–´í…ì…˜ ë¶„í¬ëŠ” [0, 1, 0, 0]ì˜ ê°’ì„ ê°€ì§€ë©° Valueì˜ ë‘ë²ˆì§¸ ê°’ì¸ [10, 0]ì´ ì¶œë ¥ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 12345678# í•¨ìˆ˜ ì‹¤í–‰temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)print(temp_attn) # ì–´í…ì…˜ ë¶„í¬(ì–´í…ì…˜ ê°€ì¤‘ì¹˜ì˜ ë‚˜ì—´)# tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)print(temp_out) # ì–´í…ì…˜ ê°’# tf.Tensor([[10. 0.]], shape=(1, 2), dtype=float32)","link":"/2023/01/08/Study_folder/NLP(Natural_Language_Processing)/2023-01-08-attention-imp/"},{"title":"OpenCV ê¸°ì´ˆ","text":"OpenCV ì´ë¯¸ì§€ í™•ì¸123456789import cv2# imreadë¡œ ì´ë¯¸ì§€ ì½ì–´ì˜¤ê¸°img = cv2.imread('cat_img.jpg')# imshow('ì´ë¯¸ì§€ í‘œì‹œ ì´ë¦„',ì´ë¯¸ì§€íŒŒì¼)ì…ë ¥cv2.imshow('output',img)waitKey(0) #(0ì„ ë„£ìœ¼ë©´ == ê³„ì† ë”œë ˆì´ - ëŒ€ê¸°í•˜ë¼ëŠ” ì˜ë¯¸) imshowì˜ ì• â€˜outputâ€™ì´ë¦„ìœ¼ë¡œ img íŒŒì¼ì´ ì¶œë ¥ë©ë‹ˆë‹¤. ì‚¬ì§„, ì˜ìƒì„ ë„ë ¤ë©´ í‚¤ë³´ë“œ që¥¼ ëˆ„ë¥´ì‹œë©´ ë©ë‹ˆë‹¤. ë‚´ì¥ ì¹´ë©”ë¼(ì›¹ìº ) ì‹¤í–‰12345678910111213141516import cv2# ì›¹ìº cap = cv2.VideoCapture(0) #ë…¸íŠ¸ë¶ì€ 0ë²ˆì´ ê¸°ë³¸ ë‚´ì¥ ì›¹ìº cap.set(3,640) #id_nubmer, widthcap.set(4,480) #id_number, heightcap.set(10,100) #id_number,bright# ì›¹ìº ì€ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ê³„ì† ì¶œë ¥ë˜ê¸° ë•Œë¬¸ì— ì¼ë°˜ì ìœ¼ë¡œ whileë¬¸ìœ¼ë¡œ ì‹¤í–‰í•œë‹¤.# í‚¤ë³´ë“œ 'q'ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì‹¤í–‰ì´ ì¢…ë£Œë©ë‹ˆë‹¤.# successëŠ” Ture,Falseì´ê³ , imgëŠ” í”„ë ˆì„ ë‹¨ìœ„ì˜ ì´ë¯¸ì§€ë¡œ ì €ì¥ë˜ëŠ” í˜•íƒœì´ë‹¤.while True: success, img = cap.read() cv2.imshow('video_mp4', img) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break ì‹¤í–‰ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥1234import cv2loaded_img = cv2.imread('cat_img.jpg')cv2.imwrite('folder/folder1/img.jpg',loaded_img)","link":"/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-cv2/"},{"title":"OpenCV ì´ë¯¸ì§€ ë³€í™˜","text":"Grayscale, GaussianBlur1234567891011121314import cv2img = cv2.imread('cat_img.jpg')# ì»¬ëŸ¬ -&gt; í‘ë°±ìœ¼ë¡œ ë³€í™˜imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)# ksize == kernel sizeì´ë¯€ë¡œ í™€ìˆ˜ë§Œ ì‚¬ìš© ê°€ëŠ¥, sigmaXëŠ” ë¸”ëŸ¬ ì •ë„ë¼ê³  ìƒê°í•˜ë©´ í¸í•˜ë©°,# ë³´í†µ -3~3ì‚¬ì´ì˜ ê°’ì„ ì‚¬ìš©imgBlur = cv2.GaussianBlur(imgGray, ksize=(7,7),sigmaX=3)cv2.imshow('output',imgGray)cv2.imshow('output2',imgBlur)cv2.waitKey(0) ê²°ê³¼ imgGray ê²°ê³¼ imgBlur Canny, Dialation1234567891011121314151617import cv2img = cv2.imread('cat_img.jpg')imgCanny = cv2.Canny(img,100,100)kernel = np.ones((5,5), np.uint8)# iterationsì— ë†’ì€ ìˆ˜ë¥¼ ë„£ìœ¼ë©´ ìœ¤ê³½ì„ ì´ ë” ì»¤ì§‘ë‹ˆë‹¤.imgDialation = cv2.dilate(imgCanny, kernel=kernel,iterations=1)imgEroded = cv2.erode(imgDialation, kernel=kernel, iterations=1)cv2.imshow('output3',imgCanny)cv2.imshow('output4',imgDialation)cv2.imshow('output5',imgEroded)cv2.waitKey(0) ê²°ê³¼ imgCanny ê²°ê³¼ imgDialation ê²°ê³¼ imgEroded","link":"/2023/01/11/Study_folder/OpneCV/2023-01-11-img_change/"},{"title":"OpenCVì— ê´€í•œ ì •ë³´","text":"OpenCV openCVë¥¼ ì£¼í”¼í„° í™˜ê²½ì—ì„œ ì‹¤í–‰ ì‹œ ë™ì˜ìƒì´ë‚˜ ì‚¬ì§„ì˜ (x)ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì£¼í”¼í„°ê°€ ë¨¹í†µì´ ë  ë•Œê°€ ë§ë‹¤. í‚¤ë³´ë“œ â€˜qâ€™ë¥¼ ëˆŒëŸ¬ì„œ ë„ëŠ”ê±¸ ê¶Œì¥í•œë‹¤. ë§¥ë¶ ì£¼í”¼í„° í™˜ê²½ì—ì„œëŠ” (x)ë²„íŠ¼ì´ ì—†ì–´ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ë©´ êº¼ì§€ê¸°ëŠ” í•œë‹¤.(í„°ë¯¸ë„ì„ ì¢…ë£Œí•´ë„ êº¼ì§) ë‹¤ë§Œ, íŒŒì´ì°¸ì´ë‚˜ VScodeë¥¼ í™œìš©í•´ .pyíŒŒì¼ì„ ì¸í„°í”„ë¦¬í„°ë¡œ ì‹¤í–‰í•˜ê¸°ë¥¼ ê¶Œì¥í•œë‹¤. 12345cv2.destroyAllWindows()cv2.waitKey(1)cv2.waitKey(1)cv2.waitKey(1)cv2.waitKey(1) ì¸í„°í”„ë¦¬í„°ë¡œ ì‹¤í–‰ ì‹œ ê²½ë¡œ ì„¤ì •í•˜ê¸° ì¸í„°í”„ë¦¬í„° í™˜ê²½(í„°ë¯¸ë„í™˜ê²½)ì—ì„œ ì‹¤í–‰ ì‹œ ì£¼í”¼í„°ì˜ ì‹¤í–‰ ê²½ë¡œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì¤˜ì•¼ ì˜¤ë¥˜ê°€ ì•ˆë‚˜ì˜¨ë‹¤. VScodeì—ì„œ ê²½ë¡œë¥¼ í™•ì¸, ìˆ˜ì •í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ë¨¼ì €, ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œë„ ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ê³  ì‹¤í–‰ì„ í•œë‹¤. ê·¸ ë‹¤ìŒ py íŒŒì¼ì—ì—ë„ ê°™ì€ ì…ë ¥ì„ í•˜ê³  ì €ì¥ &amp; ì‹¤í–‰ì„ í•œë‹¤. 123456import sysprint(sys.executable)# ì¶œë ¥ ê²°ê³¼# '/opt/anaconda3/bin/python' VScodeì˜ ê²½ìš°ëŠ” ëª…ë ¹ íŒ”ë ˆíŠ¸ë¥¼ ì—´ê³  (Shift + command + P) Python: Select Interpreterì„ ê²€ìƒ‰ &amp; ëˆ„ë¥¸ë‹¤. ì œ ê²½ìš°ëŠ” /opt/anaconda3/bin/python ì•ì˜ ì¶œë ¥ ê²°ê³¼(ì£¼í”¼í„°)ì— ë™ì¼í•œ ê²°ê³¼ë¥¼ ì„ íƒí•œë‹¤. ì‹¤í–‰í•´ì„œ ì˜ ë˜ëŠ”ì§€ í™•ì¸í•œë‹¤.","link":"/2023/01/11/Study_folder/OpneCV/2023-01-11-basic-tip-cv2/"},{"title":"OpenCV shape ë³€í™˜","text":"openCV ì‚¬ì§„ ì‚¬ì´ì¦ˆ ë³€í™˜ openCVì—ì„œ ì¢Œí‘œëŠ” ì•„ë˜ ì‚¬ì§„ì²˜ëŸ¼ í‘œí˜„ ë©ë‹ˆë‹¤. Resize12345678910111213141516import cv2img = cv2.imread('lena.png')print(img.shape)#(512,512,3)imgResize = cv2.resize(img,(200,150))print(imgResize.shape)#(200,150,3)cv2.imshow('origin',img)cv2.imshow('resize',imgResize)cv2.waitKey(0) Crop12345678910111213141516171819import cv2img = cv2.imread('lena.png')print(img.shape)#(512,512,3)imgResize = cv2.resize(img,(500,400))print(imgResize.shape)#(500,400,3)# cvì—ì„œ cropì€ [width, hight]ì…ë‹ˆë‹¤imgCropped = img[0:200,200:400]cv2.imshow('resize',imgResize)cv2.imshow('cropped',imgCropped)cv2.waitKey(0) Drawing ì˜ì—­ ë§Œë“¤ê¸° 123456789101112import cv2#0ê°’ì€ blackìœ¼ë¡œ í‘œí˜„ë¨img = np.zeros((512,512,3), np.uint8)# íŒŒë€ìƒ‰ ì˜ì—­ì„ ê·¸ë¦¼img[200:300, 100:500] = 255,0,0 #BGR(Blue, Green, Red)cv2.imshow('image1', img)cv2.waitKey(0) line, rectangle ê·¸ë¦¬ê¸° 1234567img = np.zeros((512,512,3), np.uint8)#start_point, end_point, color, thicknesscv2.line(img,(0,0),(300,300),color=(0,0,255),thickness=3)cv2.imshow('image1', img)cv2.waitKey(0) 1234cv2.rectangle(img,(50,50),(500,200),(0,255,0),3)cv2.imshow('image1', img)cv2.waitKey(0) 1234cv2.circle(img,(200,200), 30, (255,20,50),thickness=3)cv2.imshow('image1', img)cv2.waitKey(0) 12345cv2.putText(img, 'THIS IS Text', (50,300),fontFace=cv2.FONT_HERSHEY_COMPLEX,fontScale=1,color=(255,0,0),thickness=5)cv2.imshow('image1', img)cv2.waitKey(0)","link":"/2023/01/11/Study_folder/OpneCV/2023-01-11-shape/"},{"title":"OpenCV ì½”ë©ì—ì„œ ì›¹ìº  ì‚¬ìš©í•˜ê¸°","text":"Javascriptë¥¼ ì´ìš©í•˜ì—¬ ì½”ë©ì—ì„œ ì›¹ìº ì„ ì¼œëŠ” ë°©ë²•ì…ë‹ˆë‹¤ filenameì€ photo.jpgë¡œ ì €ì¥ ë˜ëŠ”ë° ë³€ê²½í•´ì„œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. jsë¡œ í•¨ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from IPython.display import display, Javascriptfrom google.colab.output import eval_jsfrom base64 import b64decodedef take_photo(filename='photo.jpg', quality=0.8): #javascript ì‘ì„± ì‹œì‘ js = Javascript(''' async function takePhoto(quality) { //div(ê³µê°„) ìƒì„± const div = document.createElement('div'); //button ìƒì„± const capture = document.createElement('button'); capture.textContent = 'Capture'; div.appendChild(capture); //video ìƒì„± const video = document.createElement('video'); //ë¹„ë””ì˜¤ ëª¨ì–‘ ë„¤ëª¨ë„¤ëª¨ video.style.display = 'block'; //ì¹´ë©”ë¼(ì›¹ìº ) ë¶ˆëŸ¬ì˜¤ê¸° const stream = await navigator.mediaDevices.getUserMedia({video: true}); //div ë°‘ì— child ê³µê°„ ì¶”ê°€ document.body.appendChild(div); //ê³µê°„ì— video ë„£ê¸° div.appendChild(video); //videoì™€ ì›¹ìº  ì—°ê²° video.srcObject = stream; //await -&gt; ë¹„ë™ê¸°ì‹ ì²˜ë¦¬ (threadì™€ ê´€ë ¨)(asyncì™€ ì„¸íŠ¸) await video.play(); // Resize the output to fit the video element. google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true); // Wait for Capture to be clicked. await new Promise((resolve) =&gt; capture.onclick = resolve); //canvas ìƒì„± const canvas = document.createElement('canvas'); //í¬ê¸° ë§ì¶”ê¸° canvas.width = video.videoWidth; canvas.height = video.videoHeight; //ì´ë¯¸ì§€ ê·¸ë¦¬ê¸° canvas.getContext('2d').drawImage(video, 0, 0); //ë¹„ë””ì˜¤ ë„ê¸° stream.getVideoTracks()[0].stop(); //div ì‚­ì œ div.remove(); // íŒŒì¼ ì£¼ì†Œ ë°˜í™˜ return canvas.toDataURL('image/jpeg', quality); } ''') display(js) data = eval_js('takePhoto({})'.format(quality)) #ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë°ì´í„°ë¥¼ ì €ì¥í• ë•Œ base64ë¡œ ì €ì¥ binary = b64decode(data.split(',')[1]) with open(filename, 'wb') as f: f.write(binary) return filename ì‹¤í–‰ ì½”ë“œì…ë‹ˆë‹¤. 1234567891011from IPython.display import Imagetry: filename = take_photo() print('Saved to {}'.format(filename)) # Show the image which was just taken. display(Image(filename))except Exception as err: # Errors will be thrown if the user does not have a webcam or if they do not # grant the page permission to access it. print(str(err)) ì‹¤í–‰ ê²°ê³¼ ì…ë‹ˆë‹¤.(capture buttonì„ ëˆ„ë¥´ë©´ ì‹¤í–‰ ì¢…ë£Œ)","link":"/2023/01/15/Study_folder/OpneCV/2023-01-15-webcam-in-colab/"},{"title":"Pytorch Dataset í´ë˜ìŠ¤(ìƒì†) íŒŒì•…í•˜ê¸°!!","text":"BERT_Dataset ë°ì´í„°ë¥¼ ì •ì œí•˜ì˜€ë‹¤ë©´, ê° ë°ì´í„°ê°€ KoBERT ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” í˜•íƒœê°€ ë˜ë„ë¡ í† í°í™”, ì •ìˆ˜ ì¸ì½”ë”©, íŒ¨ë”© ë“±ì„ í•´ì£¼ì–´ì•¼ í•œë‹¤. ì•„ë˜ëŠ” ê·¸ë¥¼ ìˆ˜í–‰í•  í´ë˜ìŠ¤ì´ë‹¤. Datasetì„ ìƒì† ë°›ëŠ” í´ë˜ìŠ¤ì˜ êµ¬ì„± ì‚¬ìš©ì ì •ì˜ Dataset í´ë˜ìŠ¤ëŠ” ë°˜ë“œì‹œ 3ê°œ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤: 1.__init__,2.__len__,3.__getitem__ __init__ í•¨ìˆ˜ëŠ” Dataset ê°ì²´ê°€ ìƒì„±(instantiate)ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤. __len__ í•¨ìˆ˜ëŠ” ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.len()í•¨ìˆ˜ë¥¼ ì‚¬ìš© ì‹œ ë°˜í™˜ê°’ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤. __getitem__ í•¨ìˆ˜ëŠ” í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤ì— ì ‘ê·¼í•  ë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œ(í•¨ìˆ˜)ì´ë‹¤.ì‰½ê²Œ í‘œí˜„í•˜ë©´ ìŠ¬ë¼ì´ì‹±ì„ êµ¬í˜„í•˜ë ¤ë©´ í•„ìš”í•œ ê²ƒì€ __getitem__ë¼ëŠ” ë©”ì†Œë“œ! 1234567891011121314151617181920212223242526272829303132333435363738from torch.utils.data import Datasetimport gluonnlp as nlpclass BERT_Dataset(Dataset): # __init__ í•¨ìˆ˜ëŠ” Dataset ê°ì²´ê°€ ìƒì„±(instantiate)ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤. # ì—¬ê¸°ì„œëŠ” dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair)ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. # í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê²Œë˜ë©´ nlp.data.BERTSentenceTransformì„ í•˜ê³ , sentencesì™€ labelsì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ê²Œ ë©ë‹ˆë‹¤. def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair): transform = nlp.data.BERTSentenceTransform( bert_tokenizer, max_seq_length = max_len, pad = pad, pair = pair) self.sentences = [transform([i[sent_idx]]) for i in dataset] self.labels = [np.int32(i[label_idx]) for i in dataset] # ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ê³¼ ë¼ë²¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤. returnì— ìŠ¬ë¼ì´ì‹± &quot;[]&quot;ì´ í•„ìš”í•¨. def __getitem__(self, i): return (self.sentences[i] + (self.labels[i], )) # __len__ í•¨ìˆ˜ëŠ” ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸” ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. def __len__(self): return (len(self.labels))#######################################################################ì‚¬ìš©í•˜ê¸°tokenizer = get_tokenizer()token = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)# ì´ëŸ°ì‹ìœ¼ë¡œ ë§Œë“  í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.data_train = BERTDataset(dataset = train_set_data, sent_idx = 0, label_idx = 1, bert_tokenizer = token, max_len = 64, pad = True, pair = False)# ì•„ë‹ˆë©´ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ '=' ê¸°í˜¸ë¥¼ ë¹¼ê³  ì‚¬ìš©í•˜ì…”ë„ ê²°ê³¼ëŠ” ê°™ìŠµë‹ˆë‹¤.data_train = BERTDataset(train_set_data, 0, 1, token, max_len, True, False) ì½”ë“œ ë¶„í•´í•˜ì—¬ ì›ë¦¬ íŒŒì•…í•˜ê¸°1234567891011121314151617181920212223242526272829303132from kobert.utils import get_tokenizerimport gluonnlp as nlptokenizer = get_tokenizer()bertmodel, vocab = get_pytorch_kobert_model()token = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)data_train = BERTDataset(dataset = train_set_data, sent_idx = 0, label_idx = 1, bert_tokenizer = token, max_len = 64, pad = True, pair = False)# dataë¥¼ ë¦¬ìŠ¤íŠ¸[0]ì—ëŠ” ë¬¸ì¥ì„ ë„£ê³ , ë¦¬ìŠ¤íŠ¸[1]ì—ëŠ” ê°ì •(labels)ìœ¼ë¡œ ë„£ì–´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤Œ.train_set_data = [[i, str(j)] for i, j in zip(train_set['data'], train_set['label'])]print(train_set_data[0])# ì¶œë ¥ ê²°ê³¼ =&gt; ['í°ì•„ë“¤ì´ ê²°í˜¼í•˜ëŠ”ë° ì§‘ì„ ì‚¬ë‹¬ë¼ê³  í•´ì„œ í™”ê°€ ë‚˜.', '4']print(data_train[0])# ì¶œë ¥ ê²°ê³¼ =&gt;(array([ 2, 4688, 6797, 5940, 950, 7795, 4384, 7088, 2573, 5794, 5439, 5007, 5112, 5330, 1370, 517, 54, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), array(18, dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 4)# arrayì˜ ì²« ë²ˆì§¸ëŠ” íŒ¨ë”©ëœ ì‹œí€€ìŠ¤, ë‘ ë²ˆì§¸ëŠ” ê¸¸ì´ì™€ íƒ€ì…ì— ëŒ€í•œ ë‚´ìš©, ì„¸ ë²ˆì¬ëŠ” ì–´í…ì…˜ ë§ˆìŠ¤í¬ ì‹œí€€ìŠ¤ì´ë‹¤. ì•„ë˜ëŠ” from kobert.pytorch_kobert import get_pytorch_kobert_modelì˜ get_kobert_modelí•¨ìˆ˜ í˜•ì‹ì…ë‹ˆë‹¤. bertmodel, vocab = get_pytorch_kobert_model()ì„ ì‹¤í–‰ ì‹œ ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤ë©´ !pip install sentencepiece==0.1.91 !pip install transformers==4.8.2ë²„ì „ì„ ë§ì¶°ì£¼ë©´ í•´ê²°ì´ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. 123456789def get_kobert_model(model_path, vocab_file, ctx=&quot;cpu&quot;): bertmodel = BertModel.from_pretrained(model_path) device = torch.device(ctx) bertmodel.to(device) bertmodel.eval() vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(vocab_file, padding_token='[PAD]') return bertmodel, vocab_b_obj KoBERT í•¨ìˆ˜ ì¶œì²˜&lt;KoBERT&gt;","link":"/2022/12/02/Study_folder/Pytorch/2022-12-02-pytorch-Dataset(class)/"},{"title":"Pytorch nn.Module í´ë˜ìŠ¤(ìƒì†) íŒŒì•…í•˜ê¸°!!","text":"Pytorchì—ì„œ í´ë˜ìŠ¤ë¡œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° íŒŒì´í† ì¹˜ì—ì„œ ëŒ€ë¶€ë¶„ ëª¨ë¸ì„ ìƒì„±í•  ë•Œ í´ë˜ìŠ¤(Class)ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œëŠ” nn.Moduleí´ë˜ìŠ¤ì˜ BERTClassifierë¥¼ ìƒì† ë°›ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. __init__()ì—ì„œ ëª¨ë¸ì˜ êµ¬ì¡°ì™€ ë™ì‘ì„ ì •ì˜í•˜ëŠ” ìƒì„±ìë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ëŠ” íŒŒì´ì¬ì—ì„œ ê°ì²´ê°€ ê°–ëŠ” ì†ì„±ê°’ì„ ì´ˆê¸°í™”í•˜ëŠ” ì—­í• ë¡œ, ê°ì²´ê°€ ìƒì„±ë  ë•Œ ìë™ìœ¼í˜¸ í˜¸ì¶œë©ë‹ˆë‹¤. super() í•¨ìˆ˜ë¥¼ ë¶€ë¥´ë©´ ì—¬ê¸°ì„œ ë§Œë“  í´ë˜ìŠ¤ëŠ” nn.Module í´ë˜ìŠ¤ì˜ ì†ì„±ë“¤ì„ ê°€ì§€ê³  ì´ˆê¸°í™” ë©ë‹ˆë‹¤. foward() í•¨ìˆ˜ëŠ” ëª¨ë¸ì´ í•™ìŠµë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ì„œ forward ì—°ì‚°ì„ ì§„í–‰ì‹œí‚¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ì´ forward() í•¨ìˆ˜ëŠ” model ê°ì²´ë¥¼ ë°ì´í„°ì™€ í•¨ê»˜ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ ì‹¤í–‰ì´ë©ë‹ˆë‹¤. nn.Moduleí´ë˜ìŠ¤ì—ì„œ ê·¸ë ‡ê²Œ ë§Œë“¤ì–´ì¡Œê¸°ì— ê·¸ë ‡ìŠµë‹ˆë‹¤. 123456789101112131415# ê°„ë‹¨í•œ ì˜ˆì‹œfrom torch import nnimport torch.nn.functional as Fclass MultiLinear(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(3, 1) # input_dim=3, output_dim=1. def forward(self, x): return self.linear(x)######model = MultiLinear()optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) nb_epochs = 200# ... KoBERT ë¶„ë¥˜ê¸° í´ë˜ìŠ¤ë¡œ ìƒì„± ì–´í…ì…˜ ë§ˆìŠ¤í¬(attention mask)ëŠ” BERTê°€ ì–´í…ì…˜ ì—°ì‚°ì„ í•  ë•Œ, ë¶ˆí•„ìš”í•˜ê²Œ íŒ¨ë”© í† í°ì— ëŒ€í•´ì„œ ì–´í…ì…˜ì„ í•˜ì§€ ì•Šë„ë¡ ì‹¤ì œ ë‹¨ì–´ì™€ íŒ¨ë”© í† í°ì„ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ì•Œë ¤ì£¼ëŠ” ì…ë ¥ì…ë‹ˆë‹¤. 0ê³¼ 1ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ìˆëŠ”ë°, ìˆ«ì 0ì€ í•´ë‹¹ í† í°ì€ íŒ¨ë”© í† í°ì´ë¯€ë¡œ ë§ˆìŠ¤í‚¹ì„ í•œë‹¤ëŠ” ì˜ë¯¸ì´ê³  ìˆ«ì 1ì€ í•´ë‹¹ í† í°ì€ ì‹¤ì œ ë‹¨ì–´ì´ë¯€ë¡œ ë§ˆìŠ¤í‚¹ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. 12345678910111213141516171819202122232425262728293031323334353637383940414243from torch import nn#KoBERT í•™ìŠµëª¨ë¸ ìƒì„±class KoBERTClassifier(nn.Module): ## nn.Module í´ë˜ìŠ¤ë¥¼ ìƒì† def __init__(self, bert, #bertëª¨ë¸ hidden_size = 768, #íˆë“ ì‚¬ì´ì¦ˆ num_classes=6, #í´ë˜ìŠ¤ ìˆ˜ dr_rate=None): #dropout super(BERTClassifier, self).__init__() #superí•¨ìˆ˜ ìƒì„± ì‹œ selfê°€ ë’¤ì— ì™€ì•¼í•œë‹¤. self.bert = bert self.dr_rate = dr_rate #inputsize, outputsizeì˜ Linearmodel ë§Œë“œëŠ” í•¨ìˆ˜ self.classifier = nn.Linear(hidden_size , num_classes) #dropoutì˜µì…˜ì„ ì‚¬ìš©í•œë‹¤ë©´ ì•„ë˜ í•¨ìˆ˜ ìƒì„± if dr_rate: self.dropout = nn.Dropout(p=dr_rate) #ì–´í…ì…˜ë§ˆìŠ¤í¬ ìƒì„±ì„ ìœ„í•œ í•¨ìˆ˜ def gen_attention_mask(self, token_ids, valid_length): attention_mask = torch.zeros_like(token_ids) for i, v in enumerate(valid_length): attention_mask[i][:v] = 1 return attention_mask.float() def forward(self, token_ids, valid_length, segment_ids): #ì–´í…ì…˜ë§ˆìŠ¤í¬ ìƒì„± attention_mask = self.gen_attention_mask(token_ids, valid_length) _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device)) #dropoutì˜µì…˜ì„ ì‚¬ìš©í•œë‹¤ë©´ ì•„ë˜ í•¨ìˆ˜ ìƒì„± if self.dr_rate: out = self.dropout(pooler) return self.classifier(out)######## ì‚¬ìš© ì˜ˆì‹œ ########bertmodel, vocab = get_pytorch_kobert_model()model = KoBERTClassifier(bertmodel, dr_rate=0.5).to(device) ì½”ë“œ ë¶„í•´í•˜ì—¬ ì›ë¦¬ íŒŒì•…í•˜ê¸°1234567torch.nn.Linear(in_features,out_features,bias = True, device = None,dtype = None)train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)# train_dataloaderì˜ ë¦¬ìŠ¤íŠ¸ëŠ”# [[token_ids], [valid_length], [segment_ids], [label]] ì˜ ìˆœì„œë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.# for i ,(token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader): ì´ëŸ°ì‹ìœ¼ë¡œ ì‚¬ìš©.","link":"/2022/12/03/Study_folder/Pytorch/2022-12-03-nn.Module(class)/"},{"title":"Pytorch Dataloader","text":"Dataloader ì‚¬ìš©í•˜ëŠ” ë°©ë²• ëª¨ë“  Dataset ìœ¼ë¡œë¶€í„° DataLoader ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyTorchì˜ DataLoader ëŠ” ë°°ì¹˜ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. DataLoaderë€ Datasetì„ batchê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œ ë¯¸ë‹ˆë°°ì¹˜ í˜•íƒœë¡œ ë§Œë“¤ì–´ì„œ ìš°ë¦¬ê°€ ì‹¤ì œë¡œ í•™ìŠµí•  ë•Œ ì´ìš©í•  ìˆ˜ ìˆê²Œ í˜•íƒœë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê¸°ëŠ¥ì„ í•©ë‹ˆë‹¤. DataLoaderë¥¼ í†µí•´ Datasetì˜ ì „ì²´ ë°ì´í„°ê°€ batch sizeë¡œ sliceë˜ì–´ ê³µê¸‰ë©ë‹ˆë‹¤. datasetì„ inputìœ¼ë¡œ ë„£ì–´ì£¼ë©´ ì—¬ëŸ¬ ì˜µì…˜(ë°ì´í„° ë¬¶ê¸°, ì„ê¸°, ì•Œì•„ì„œ ë³‘ë ¬ì²˜ë¦¬)ì„ í†µí•´ batchë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. DataLoaderëŠ” iterator í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ì— ì ‘ê·¼ í•˜ë„ë¡ í•˜ë©° batch_sizeë‚˜ shuffle ìœ ë¬´ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. ì¼ë°˜ì ì¸ ì‚¬ìš© ë°©ë²•123456789101112from torch.utils.data import Dataloaderdataloader1 = Dataloader( dataset, batch_size = 1, shuffle = True,)dataloader2 = DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None) batch_sizeëŠ” ì¼ë°˜ì ìœ¼ë¡œ 2ì˜ ë°°ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.(ì»´í“¨í„°ì˜ ì—°ì‚°ë•Œë¬¸ì— 2ì˜ ë°°ìˆ˜ë¡œ í•´ì•¼ ì†ë„ê°€ ë¹ ë¦„) shuffle ì€ Epoch ë§ˆë‹¤ ë°ì´í„°ì…‹ì„ ì„ì–´, ë°ì´í„°ê°€ í•™ìŠµë˜ëŠ” ìˆœì„œë¥¼ ë°”ê¾¸ëŠ” ê¸°ëŠ¥ì„ ë§í•©ë‹ˆë‹¤. num_workerëŠ” ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” í”„ë¡œì„¸ì„œì˜ ìˆ˜ì…ë‹ˆë‹¤. PC(íŠ¹íˆ ìœˆë„ìš°)ì—ì„œëŠ” default=0ë¡œ ì„¤ì •í•´ì•¼ ì˜¤ë¥˜ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤. collate_fn í•¨ìˆ˜ëŠ” DataLoader ë¡œë¶€í„° ìƒì„±ëœ ìƒ˜í”Œ ë°°ì¹˜ë¡œ ë™ì‘í•©ë‹ˆë‹¤. collate_fn ì˜ ì…ë ¥ì€ DataLoader ì— ë°°ì¹˜ í¬ê¸°(batch size)ê°€ ìˆëŠ” ë°°ì¹˜(batch) ë°ì´í„°ì´ë©°, collate_fn ì€ ì´ë¥¼ ë¯¸ë¦¬ ì„ ì–¸ëœ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì— ë”°ë¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.(ì•„ë˜ì˜ ì˜ˆì‹œ) 12345678910# batchesê°€ 1ì´ ì•„ë‹Œ ê²½ìš° ì´ëŸ°ì‹ìœ¼ë¡œ ì„¸íŒ…í•˜ì—¬ DataLoaderì˜ collate_fnì— ë„£ì–´ì¤€ë‹¤.# ì‚¬ìš©ì ì •ì˜ collate_fn() í•¨ìˆ˜ëŠ” ê°€ë³€ ê¸¸ì´ ë°°ì¹˜ë¥¼ ì±„ìš°ëŠ” ë° ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.def collate_batch(batch): data = [item[0] for item in batch] mask = [item[1] for item in batch] label = [item[2] for item in batch] return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch)","link":"/2022/12/10/Study_folder/Pytorch/2022-12-10-Dataloader/"},{"title":"ë§¥ë¶(Mac OS) ì‚¬ìš©ìì˜ Pytorch GPUë¥¼ ì‚¬ìš©ë²•","text":"GPUì‚¬ìš© ì¼ë‹¨ ì•„ë˜ì˜ ì‚¬ì§„ì„ ë³´ë©´ ì•„ì‹œê² ì§€ë§Œ, í˜„ì¬ íŒŒì´í† ì¹˜ëŠ” ë§¥OSì— CUDAê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. mpsë¡œ GPUë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ì–´ ì¤€ ë‹¤ìŒ(í•„ìˆ˜ëŠ” ì•„ë‹˜) 123456#ìƒì„±conda create --name name_of_conda_env#ì‹¤í–‰conda activate name_of_conda_env#ë§Œì•½ ê°€ìƒí™˜ê²½ìœ¼ë¡œ ëŒì•„ê°€ê³  ì‹¶ë‹¤ë©´conda deactivate ë¨¼ì €, pytorch í™ˆí˜ì´ì§€ ë¡œ ë“¤ì–´ê°€ì„œ https://pytorch.org/ conda ...ìœ¼ë¡œ ì…ë ¥ëœ ì¹¸ì˜ ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•˜ì—¬ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•´ ì„¤ì¹˜í•©ë‹ˆë‹¤. í™•ì¸ ë° ì‚¬ìš© ë°©ë²•12345678910import torch#ì—¬ê¸°ì„œ 'cuda'ê°€ ì•„ë‹Œ 'mps'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')print (f'PyTorch version:{torch.__version__}') # 1.12.1 ì´ìƒprint(f'MPS ì¥ì¹˜ë¥¼ ì§€ì›í•˜ë„ë¡ build ë˜ì—ˆëŠ”ì§€: {torch.backends.mps.is_built()}') # True ì—¬ì•¼ í•©ë‹ˆë‹¤.print(f'MPS ì¥ì¹˜ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€: {torch.backends.mps.is_available()}') # True ì—¬ì•¼ í•©ë‹ˆë‹¤.!python -c 'import platform;print(platform.platform())'model.to(device) ë˜ëŠ” 12mps_device = torch.device('mps')model.to(mps_device)","link":"/2022/12/10/Study_folder/Pytorch/2022-12-10-pytorch-GPU/"},{"title":"íŒŒì´í† ì¹˜ë¡œ nnëª¨ë“ˆì˜ CNNì‚¬ìš©í•˜ê¸°","text":"íŒŒì´í† ì¹˜ë¡œ CNN ëª¨ë¸ ìƒì„±(fasion_mnist data)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115from torch.utils.data import Dataset, DataLoaderimport torchvision.transforms as transformsfrom torchvision import datasetsimport torch.nn as nnimport torch.nn.functional as Fimport torchimport torch.optim as optim#ToTensor() - ë°ì´í„°ë¥¼ tensorë¡œ ë°”ê¿”ì¤€ë‹¤.#Normalize(mean, std, inplace=False) - ì •ê·œí™”í•œë‹¤.# Fasion-mnist ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°transform = transforms.Compose([transforms.ToTensor()])trainset = datasets.FashionMNIST(root='/content', train=True, download=True, transform = transform)testset = datasets.FashionMNIST(root='/content', train=False, download=True, transform = transform)#ë°ì´í„°ë¡œë”ë¡œ ë°ì´í„° ì •ì œtrain_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)test_loader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)#ë°˜ë³µë¬¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ iterë¡œ ë§Œë“¤ê¸°images, labels = next(iter(train_loader))images.shape, labels.shape #(torch.Size([64, 1, 28, 28]), torch.Size([64]))#nn.Module í´ë˜ìŠ¤ ìƒì†(CNN ëª¨ë¸ ë§Œë“¤ê¸°)class FashionCNN(nn.Module): def __init__(self): super(FashionCNN, self).__init__() # ImgIn shape=(1, 28, 28, 1) # Conv -&gt; (1, 28, 28, 32) # Pool -&gt; (1, 14, 14, 32) self.layer1 = nn.Sequential( nn.Conv2d(1,32,3, padding=1), #paddingì„ í•˜ì—¬ ì´ë¯¸ì§€ í¬ê¸° ì†ì‹¤ì´ ì—†ìŒ nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2,2) ) # ImgIn shape=(1, 14, 14, 1) # Conv -&gt; (1, 12, 12, 64) # Pool -&gt; (1, 6, 6, 64) self.layer2 = nn.Sequential( nn.Conv2d(32,64,3), #paddingì˜µì…˜ì´ ì—†ì–´ì„œ ì´ë¯¸ì§€ í¬ê¸°ê°€ -2ë˜ì—ˆìŒ(kenel size=3ì´ê¸°ë•Œë¬¸ì—) nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2) ) self.fc1 = nn.Linear(64*6*6, 600) #layer2ì¶œë ¥ì´ 64, ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ 6*6ì´ê¸° ë•Œë¬¸ì— 1ì°¨ì›ìœ¼ë¡œ í‘œí˜„í•˜ë©´ 64*6*6 self.drop = nn.Dropout2d(0.25) self.fc2 = nn.Linear(600, 120) self.fc3 = nn.Linear(120, 10) def forward(self, x): out = self.layer1(x) out = self.layer2(out) out = out.view(out.size(0), -1) #64*6*6(1ì°¨ì›ìœ¼ë¡œ ë³€ê²½) out = self.fc1(out) out = self.drop(out) out = self.fc2(out) out = self.fc3(out) return outmodel = FashionCNN()#ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜criterion = nn.CrossEntropyLoss()optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)#í•™ìŠµ (20epochs)for epoch in range(20): running_loss = 0.0 for i, data in enumerate(train_loader, 0): inputs , labels = data optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() #item() == tensorì— ì €ì¥ëœ ê°’ë§Œ ê°€ì ¸ì˜´(í…ì„œì—ì„œ ê°’ë§Œ ê°€ì ¸ì˜´) if i % 100 == 99: print('Epoch : {}, Iter : {}, Loss : {}'.format(epoch+1,i+1, running_loss/2000)) runngin_loss = 0.0#í‰ê°€correct = 0total = 0with torch.no_grad(): for data in test_loader: images, labels = data outputs = model(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item()print(100 * correct / total)#90.69#ì €ì¥PATH = './fashion_mnist.pth'torch.save(model.state_dict(), PATH)#ë¶ˆëŸ¬ì˜¤ê¸°model = FashionCNN()model.load_state_dict(torch.load(PATH))","link":"/2022/12/12/Study_folder/Pytorch/2022-12-12-nn(CNN)/"},{"title":"íŒŒì´í† ì¹˜ ì´ë¯¸ì§€ ì¦ì‹ ë°©ë²• ì°¨ì´","text":"torchvisionì˜ transformsì™€ albumentationì˜ ì°¨ì´ì  ë³´í†µ torchvisionì˜ transformsì—ì„œëŠ” Normalizeë¥¼ ì‚¬ìš©í•  ë•Œ ë°ì´í„°ë¥¼ min_max scale(0~1)ë¡œ ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ToTensorë¥¼ ë¨¼ì € ì‚¬ìš©í•œ í›„ì— Normalizeë¥¼ ì ìš©í•˜ëŠ”ë° albumentationì˜ NormalizeëŠ” scalingê³¼ normalizeë¥¼ ë™ì‹œì— ì²˜ë¦¬í•œë‹¤ëŠ” ì°¨ì´ì ì´ ìˆë‹¤. albumentationsì—ì„œëŠ” ToTensor ëŒ€ì‹  ToTensorV2ë¥¼ ì‚¬ìš©í•˜ëŠ”ë° ToTesorV2ëŠ” ToTensorì™€ ë§ˆì°¬ê°€ì§€ë¡œ tensorí˜•ë³€í™˜, channel dimensionì„ ì²«ë²ˆì§¸ ì°¨ì›ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ì—­í• ì€ í•˜ì§€ë§Œ min_max scalingì€ í•˜ì§€ ì•ŠëŠ”ë‹¤. (ì¶”ê°€ë¡œ ìë£Œí˜• ë¬¸ì œ ë•Œë¬¸ì— albumentationsì—ì„œ ToTensorV2ë¥¼ Normalize ë³´ë‹¤ ì•ì—ì„œ ì‚¬ìš©í•˜ë©´ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤.)","link":"/2022/12/15/Study_folder/Pytorch/2022-12-15-dif-tran-alb/"},{"title":"íŒŒì´í† ì¹˜ ì°¨ì› ë³€ê²½(reshape,view,permute) ë¹„êµ","text":"3ê°€ì§€ í•¨ìˆ˜ì˜ ê³µí†µì  reshape, view, permuteëŠ” ëª¨ë‘ í…ì„œì˜ í˜•íƒœ(ì°¨ì›ì„ ë°”ê¾¸ëŠ”) ê¸°ëŠ¥ì´ë‹¤. viewì™€ reshape viewë¡œ ë°˜í™˜ëœ tensorëŠ” ì›ë³¸ tensorì™€ ê¸°ë°˜ì´ ë˜ëŠ” dataë¥¼ ê³µìœ í•œë‹¤. ë§Œì•½ ë°˜í™˜ëœ tensorì˜ ê°’ì´ ë³€ê²½ëœë‹¤ë©´, viewedë˜ëŠ” tensorì—ì„œ í•´ë‹¹í•˜ëŠ” ê°’ì´ ë³€ê²½ëœë‹¤. viewì™€ reshapeì€ ì—°ì‚° ìì²´ëŠ” ê°™ê³  ê¸°ì¡´ tensorê°€ ë³€ê²½ë˜ëƒ ë˜ì§€ ì•ŠëŠ”ì§€ì˜ ì°¨ì´ê°€ ìˆë‹¤.(contiguous) viewëŠ” ë¶™ì–´ìˆëŠ” ì°¨ì› ë–¼ì–´ë‚¼ ë•Œ ì‚¬ìš©í•˜ë©´ ìš©ì´í•˜ë‹¤. [A*2, B, C] -&gt; [A, 2, B, C] viewëŠ” contiguousí•œ í•¨ìˆ˜ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. reshapeì€ contiguous í•˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ì—ì„œë„ ì‘ë™í•œë‹¤. permute(input, dims) permuteì˜ parametersì—ëŠ” input=tensor, dims = indexê°’ì„ ì…ë ¥í•œë‹¤. numpyì˜ transposeëŠ” ë‘ ê°œì˜ ì°¨ì›ì„ ë§êµí™˜í•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ permute()ëŠ” ëª¨ë“  ì°¨ì›ë“¤ì„ ë³€ê²½í•  ìˆ˜ ìˆë‹¤. 12345678910111213141516171819x = torch.randn(2, 3, 5)print(x)# tensor([[[ 0.5676, 0.4593, -0.2802, -1.9395, -1.2933],# [-0.6459, -1.0244, -0.3164, 1.5379, 0.9390],# [-0.2366, -1.4711, -0.6014, -0.4424, 0.1915]],# [[-1.3794, -0.4103, 0.1862, 0.2172, 0.3282],# [-1.9206, 1.1295, -0.4130, -0.5630, 0.9670],# [-1.0632, 0.7054, 0.4358, -0.4522, -0.3983]]])print(x.size())# torch.Size([2, 3, 5])torch.permute(x, (2, 0, 1)).size() #== x.permute(2, 0, 1)# torch.Size([5, 2, 3])# transposeëŠ” ë‘ ê°œì˜ ì°¨ì›ì„ ë§êµí™˜x.tranpose(0, 3) # 0ê³¼ 3ì˜ ì°¨ì›ì„ ë³€ê²½(êµí™˜) contiguousë€ ì‚¬ì „ì  ì˜ë¯¸ëŠ” â€˜ì ‘ì´‰í•˜ëŠ”â€™ ì´ë‹¤. contiguous ë€ matrix ì˜ ëˆˆì— ë³´ì´ëŠ” í˜•íƒœ(shape) ê³¼ ì‹¤ì œ matrix ì˜ ê° ë°ì´í„°ê°€ ì €ì¥ëœ ìœ„ì¹˜ê°€ ê°™ì€ì§€ì˜ ì—¬ë¶€ì´ë‹¤. unsqueeze, squeeze batchê°€ 1ì¼ ë•Œ batchì°¨ì›ë„ ì—†ì• ë²„ë¦´ ìˆ˜ ìˆê¸°ë•Œë¬¸ì— ì´ ê²½ìš°ë¥¼ ìœ ì˜í•´ì„œ ì‚¬ìš©í•´ì•¼í•œë‹¤. 1ì°¨ì›ì„ ìƒì„± ë° ì œê±°ë¥¼ í•  ê²½ìš° unsqueeze, squeezeí•¨ìˆ˜ê°€ í¸í•˜ë‹¤. Summary view : tensor ì— ì €ì¥ëœ ë°ì´í„°ì˜ ë¬¼ë¦¬ì  ìœ„ì¹˜ ìˆœì„œì™€ index ìˆœì„œê°€ ì¼ì¹˜í•  ë•Œ (contiguous) shapeì„ ì¬êµ¬ì„±í•œë‹¤. ì´ ë•Œë¬¸ì— í•­ìƒ contiguous í•˜ë‹¤ëŠ” ì„±ì§ˆì´ ë³´ìœ ëœë‹¤. reshape : ìˆœì„œê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ shapeì„ ì¬êµ¬ì„±í•œ ì´í›„ì— ê°•ì œë¡œ ì¼ì¹˜ì‹œí‚¨ë‹¤. ì´ ë•Œë¬¸ì— í•­ìƒ contiguous í•˜ë‹¤ëŠ” ì„±ì§ˆì´ ë³´ìœ ëœë‹¤. transpose : tensor ì˜ index ìˆœì„œëŠ” ê°™ë‹¤ëŠ” ë³´ì¥ì´ ì—†ìœ¼ë¯€ë¡œ í•­ìƒ contiguous í•˜ì§€ ì•Šë‹¤. permute : contiguous í•˜ì§€ ì•Šë‹¤. transposeì™€ permuteëŠ” transpose.contiguous()ì´ëŸ°ì‹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. einsum : ì—¬ëŸ¬ ì—°ì‚°ì„ í†µí•´ ì°¨ì› ê´€ë¦¬ë¥¼ ì‰½ê²Œ í•  ìˆ˜ ìˆë‹¤.","link":"/2023/01/02/Study_folder/Pytorch/2023-01-02-dim-shape/"},{"title":"íŒŒì´í† ì¹˜ í•¨ìˆ˜","text":"ones(),zeros()123456789101112131415161718import torchtorch.zeros(4,4)# tensor([[0., 0., 0., 0.],# [0., 0., 0., 0.],# [0., 0., 0., 0.],# [0., 0., 0., 0.]])tensor = torch.ones(4, 4)# tensor([[1., 1., 1., 1.],# [1., 1., 1., 1.],# [1., 1., 1., 1.],# [1., 1., 1., 1.]])#ìŠ¬ë¼ì´ì‹±ë„ ê°€ëŠ¥tensor[:,1] = 0print(tensor)tensor([[1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.]]) cat() íŒë‹¤ìŠ¤ì˜ concat()í•¨ìˆ˜ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤˜ì•¼í•œë‹¤. 123456789tensor = torch.ones(4, 4)tensor[:,1] = 0con_tensor = torch.cat([tensor, tensor, tensor], dim=1)print(con_tensor)# tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],# [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],# [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],# [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]]) argmax() ìµœëŒ€ê°’ì˜ indexë¥¼ ì°¾ì•„ì£¼ëŠ” í•¨ìˆ˜ 12345678910111213141516171819202122import torch# dim ì˜µì…˜ì´ ì—†ì„ ê²½ìš°(default)a = torch.randn(3,3)argmax = torch.argmax(a)print(a)print(argmax)# tensor([[-0.0626, -1.4816, -0.6745],# [-0.8330, 0.2181, 0.5294],# [ 0.3596, -0.5217, 0.0292]])# tensor(5)#dim optionì„ ì¤„ ê²½ìš°a = torch.randn(3, 3)argmax_dim_0 = torch.argmax(a, dim = 0)print(a)print(argmax_dim_0)# tensor([[ 2.1830, 0.1679, -0.7654],# [-0.4077, 0.1342, -0.3766],# [-0.9798, 1.2932, -0.4124]])# tensor([0, 2, 1]) max() ìµœëŒ€ê°’ì„ ì¶œë ¥í•´ì£¼ëŠ” í•¨ìˆ˜ 12345678a = torch.randn(3,3)justmax = torch.max(a)print(a)print(argmax)# tensor([[ 2.1830, 0.1679, -0.7654],# [-0.4077, 0.1342, -0.3766],# [-0.9798, 1.2932, -0.4124]])# tensor(2.1830) item() item()ì€ ê°’ë§Œì„ ê°€ì ¸ì˜¤ê³  ì‹¶ì„ ê²½ìš° ì‚¬ìš©í•œë‹¤.(scalarsì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥) 12345678tensor = torch.ones(4, 4)agg = tensor.sum()agg_item = agg.item()print(agg,agg_item, type(agg_item))# tensor(16.) # 16.0 # &lt;class 'float'&gt; eval() eval()ì€ ë³´í†µ evaluation ê³¼ì • ì „ì— ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ì´ë‹¤. eval() í•¨ìˆ˜ëŠ” evaluation ê³¼ì •ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” layerë“¤ì„ ì•Œì•„ì„œ off ì‹œí‚¤ë„ë¡ í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. evaluation/validation ê³¼ì •ì—ì„  ë³´í†µ model.eval()ê³¼ torch.no_grad()ë¥¼ í•¨ê»˜ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤. 12345678910model.eval()score = 0for i, (images, labels) in enumerate(val_loader): images = images.to(device) labels = labels.to(device) g_labels = model(images) score += int(torch.max(g_labels, 1)[1][0] == labels[0]) numpy.clip() -CVì—ì„œ ìì£¼ ì‚¬ìš©ë¨1234567numpy.clip(array, min, max) array ë‚´ì˜ ê°’ë“¤ì— ëŒ€í•´ì„œ min ê°’ ë³´ë‹¤ ì‘ì€ ê°’ë“¤ì„ minê°’ìœ¼ë¡œ ë°”ê¿”ì£¼ê³  max ê°’ ë³´ë‹¤ í° ê°’ë“¤ì„ maxê°’ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜.","link":"/2022/12/19/Study_folder/Pytorch/2022-12-19-methods-of-torch/"},{"title":"Squeeze, Unsqueeze","text":"squeeze squeezeì™€ unsqueezeëŠ” 1ì¸ ì°¨ì›ì„ ì œê±°, ìƒì„±í• ë•Œ ë§¤ìš° ìœ ìš©í•œ í•¨ìˆ˜ì´ë‹¤. squeezeëŠ” ì°¨ì›ì´ 1ì¸ ì°¨ì›ì„ ì œê±°í•´ì¤€ë‹¤.(defaultê°’) ì°¨ì›ì„ ì„¤ì •í•´ì£¼ë©´ ê·¸ ì°¨ì›ë§Œ ì œê±°í•œë‹¤.(1ì¸ ì°¨ì›ë§Œ ì œê±°ë˜ë‹ˆ ì°¸ê³ ) 123456789101112131415import torchx = torch.rand(3, 20, 1, 1)print(x.shape)# torch.Size([3, 20, 1, 1])x = x.squeeze()print(x.shape)# torch.Size([3, 20])x = torch.squeeze(x, 1)print(x.shape)# torch.Size([3, 20]) unsqueeze unsqueezeëŠ” ì°¨ì›ì´ 1ì¸ ì°¨ì›ì„ ìƒì„±í•´ì¤€ë‹¤. 12345678910111213141516171819202122232425262728x = torch.rand(3, 20, 30, 40)print(x.shape)# torch.Size([3, 20, 30, 40])x = x.unsqueeze(dim=1)print(x.shape)# torch.Size([3, 1, 20, 30, 40])x = torch.rand(3, 20, 30, 40)print(x.shape)# torch.Size([3, 20, 30, 40])x = torch.unsqueeze(x,1)print(x.shape)# torch.Size([3, 1, 20, 30, 40])x = torch.rand(3, 20, 30, 40)print(x.shape)# torch.Size([3, 20, 30, 40])x = x.unsqueeze(dim = 0)print(x.shape)# torch.Size([1, 3, 20, 30, 40])","link":"/2023/01/06/Study_folder/Pytorch/2023-01-06-squeeze/"},{"title":"íŒŒì´í† ì¹˜ ê¸°ë³¸ ì •ë³´ë“¤","text":"íŒŒì´í† ì¹˜ ê¸°ë³¸ í•¨ìˆ˜ë“¤ torch.autograd ìë™ ë¯¸ë¶„ì„ ìœ„í•œ í•¨ìˆ˜ë“¤ì´ í¬í•¨ë˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. torch.nn ì‹ ê²½ë§ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡°ë‚˜ ë ˆì´ì–´ ë“±ì´ ì •ì˜ë˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.RNN, LSTMê³¼ ê°™ì€ ë ˆì´ì–´, ReLUì™€ ê°™ì€ í™œì„±í™” í•¨ìˆ˜, MSELossì™€ ê°™ì€ ì†ì‹¤ í•¨ìˆ˜ë“¤ì´ ìˆìŠµë‹ˆë‹¤. torch.optim í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent, SGD)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ íŒŒë¼ë¯¸í„° ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì´ êµ¬í˜„ë˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. torch.utils.data Dataset, Dataloaderë“±ì˜ í•¨ìˆ˜ê°€ ë‚´ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. torch.onnx ONNX(Open Neural Network Exchange)ì˜ í¬ë§·ìœ¼ë¡œ ëª¨ë¸ì„ ìµìŠ¤í¬íŠ¸(export)í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ONNXëŠ” í…ì„œí”Œë¡œê°™ì€ ë‹¤ë¥¸ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ê°„ì˜ êµë¥˜ì— í•„ìš”í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤. íŒŒì´í† ì¹˜ ì •ë³´ë“¤ optimizer.zero_grad()ê°€ í•„ìš”í•œ ì´ìœ  íŒŒì´í† ì¹˜ëŠ” ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸°ë¥¼ ì´ì „ì— ê³„ì‚°ëœ ê¸°ìš¸ê¸° ê°’ì— ëˆ„ì ì‹œí‚¤ëŠ” íŠ¹ì§•ì´ ìˆì–´ì„œ ê°’ì„ ì´ˆê¸°í™” ì‹œì¼œì¤„ í•„ìš”ê°€ ìˆìŒ backward()ëŠ” ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜","link":"/2022/12/30/Study_folder/Pytorch/2022-12-30-torch-basic/"},{"title":"ë²”ì£¼í™”(ì¹´í…Œê³ ë¦¬í™”) - pd.cut(), pd.qcut()","text":"cut, qcutì€ ìˆ˜ì¹˜í˜• ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬í™” í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. pd.cut() pd.cut()ì€ êµ¬ê°„(bin, ë‚˜ëˆ„ëŠ” ê°œìˆ˜)ì„ íŠ¹ì • ë²”ìœ„ë¡œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤. 1234567891011121314151617181920df = pd.DataFrame({'Age' : range(1,100,7)})df['Age_category'] = pd.cut(df['Age'],bins=[0,10,70,100],labels=['young','medium','older']) df# ì¶œë ¥ ê²°ê³¼ Age Age_category0 1 young1 8 young2 15 medium3 22 medium4 29 medium5 36 medium6 43 medium7 50 medium8 57 medium9 64 medium10 71 older11 78 older12 85 older13 92 older14 99 older pd.qcut() qcutì€ cutê³¼ ë‹¬ë¦¬ êµ¬ê°„ ì„¤ì •ì„ ì •í™•íˆ ë‚˜ëˆŒ ê²½ìš° ì‚¬ìš©ë˜ì–´ ì„ì˜ì˜ ê³„ì‚°ì´ í•„ìš” ì—†ë‹¤. ì•„ë˜ì™€ ê°™ì€ ê²½ìš° ë¼ë²¨ì´ youngì€ df[â€˜Ageâ€™].quantile(0.33)ì´í•˜ì˜ ê°’ì´ê³  mediumì€ 0.33 ~ 0.66ì´ë©°, olderëŠ” df[â€˜Ageâ€™].quantile(0.66)ì˜ ê°’ì´ binì´ë‹¤. 12345678910111213141516171819202122df = pd.DataFrame({'Age' : range(1,100,7)})df['Age_category'] = pd.qcut(df['Age'],3,labels=['young','medium','older']) df# ë§Œì•½,duplicatesì˜¤ë¥˜ê°€ ë‚˜ì˜¨ë‹¤ë©´ duplicates='drop'ì„ ì¶”ê°€ ì˜µì…˜ì— ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.# ì¶œë ¥ ê²°ê³¼ Age Age_category0 1 young1 8 young2 15 young3 22 young4 29 young5 36 medium6 43 medium7 50 medium8 57 medium9 64 medium10 71 older11 78 older12 85 older13 92 older14 99 older","link":"/2022/11/25/Study_folder/Pandas,%20Numpy/2022-11-25-cut()-qcut()/"},{"title":"torch.tril","text":"torch.tril torch.tril(input, diagonal=0, *, out=None) í–‰ë ¬ì˜ ì•„ë˜ìª½ ì‚¼ê°í˜• ë¶€ë¶„ (2 ì°¨ì› í…ì„œ) ë˜ëŠ” í–‰ë ¬ì˜ ë°°ì¹˜ input ì„ ë°˜í™˜í•©ë‹ˆë‹¤ .[í–‰ë ¬ì˜ ì˜¤ë¥¸ìª½ ë¶€ë¶„ì„(0ìœ¼ë¡œ ë§Œë“¬)] attention êµ¬ì¡°ì˜ maskë¥¼ ë§Œë“¤ ë•Œ ë§ì´ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ë¬´ìŠ¨ ë§ì¸ì§€ ì´í•´ê°€ ì˜ ì•ˆê°€ì‹¤ê²ë‹ˆë‹¤. ì˜ˆì œ ì¶œë ¥ ì½”ë“œë¥¼ ë³´ë©´ ë°”ë¡œ ì´í•´ê°€ ê°ˆê²ë‹ˆë‹¤. 12345678910111213141516171819a = torch.ones((5, 5))torch.tril(a)tensor([[1., 0., 0., 0., 0.], [1., 1., 0., 0., 0.], [1., 1., 1., 0., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 1., 1.]])a = torch.ones((5, 5))torch.tril(a, diagonal=1)tensor([[1., 1., 0., 0., 0.], [1., 1., 1., 0., 0.], [1., 1., 1., 1., 0.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]])","link":"/2023/01/07/Study_folder/Pytorch/2023-01-07-tril/"},{"title":"nn.Embedding","text":"nn.Embedding ì¶œì²˜ : &lt;ìœ„í‚¤ë…ìŠ¤&gt; ì„ë² ë”© ì¸µ(embedding layer)ì„ ë§Œë“¤ì–´ í›ˆë ¨ ë°ì´í„°ë¡œë¶€í„° ì²˜ìŒë¶€í„° ì„ë² ë”© ë²¡í„°ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ nn.Embeddingì„ ì´ìš©í•˜ì—¬ êµ¬í˜„í•©ë‹ˆë‹¤. ì£¼ìš” íŒŒë¼ë¯¸í„°ëŠ” 2ê°œì…ë‹ˆë‹¤. num_embeddings : ì„ë² ë”©ì„ í•  ë‹¨ì–´ë“¤ì˜ ê°œìˆ˜. (ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°) embedding_dim : ì„ë² ë”© í•  ë²¡í„°ì˜ ì°¨ì›ì…ë‹ˆë‹¤. (ì‚¬ìš©ì ì •ì˜) 1234567891011121314import torch.nn as nntrain_data = 'we can do lots of things like climbing do'# ì¤‘ë³µì„ ì œê±°í•œ ë‹¨ì–´ë“¤ì˜ ì§‘í•©ì¸ ë‹¨ì–´ ì§‘í•© ìƒì„±.(num_embeddings ì¸ì)word_set = set(train_data.split())# ë‹¨ì–´ ì§‘í•©ì˜ ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì •ìˆ˜ ë§µí•‘.vocab = {tkn: i+2 for i, tkn in enumerate(word_set)}vocab['&lt;unk&gt;'] = 0vocab['&lt;pad&gt;'] = 1print(vocab)# {'things': 2, 'lots': 3, 'can': 4, 'like': 5, 'do': 6, 'climbing': 7, 'of': 8, 'we': 9, '&lt;unk&gt;': 0, '&lt;pad&gt;': 1} 1234567891011121314151617181920212223# ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ì˜ í–‰ì„ ê°€ì§€ëŠ” ì„ë² ë”© í…Œì´ë¸” ìƒì„±import torch.nn as nnembedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=3)embedding_layer# Embedding(10, 3, padding_idx=1)```````pythonprint(embedding_layer.weight)Parameter containing:tensor([[ 0.2915, 0.8197, 0.1080], [ 0.4103, 1.2429, -0.7658], [ 0.4185, -0.0410, 2.1945], [-0.9706, -0.6196, -1.3778], [-1.8044, -0.8070, -1.0277], [ 0.7752, -0.1011, 1.5459], [ 0.2195, 1.2008, 0.1253], [ 0.6568, 1.3255, 0.5347], [-1.2790, 0.3015, -0.2819], [-0.0371, -0.0291, -0.2894]], requires_grad=True)","link":"/2023/01/07/Study_folder/Pytorch/2023-01-07-nn.Embedding/"},{"title":"pd.read_csv()","text":"pd.read_csv()ì—ì„œ ì¸ì½”ë”© ì˜µì…˜123456import pandas as pd# ì¸ì½”ë”©ì€ 3ì¢…ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë‚˜ë©´ 3ê°œ ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ë³´ì‹œë©´ ë©ë‹ˆë‹¤.df = pd.read_csv('/court_precedent.csv', encoding='euc-kr')df = pd.read_csv('/court_precedent.csv', encoding='utf-8')df = pd.read_csv('/court_precedent.csv', encoding='cp949') pd.read_csv()ì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì˜µì…˜ ì˜ˆì‹œ12345678910# ë§¨ ìœ„ì˜ ê°’ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì•ˆì“°ê³  í–‰ìœ¼ë¡œ ì‚¬ìš©í•  ê²½ìš°, header = Nonepd.read_csv('/court_precedent.csv', header = None)# ë§¨ ìœ„ì˜ ì´ìƒí•œ í–‰ì´ 2ê°œ ì´ìƒì¼ ê²½ìš° skiprowsë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤.pd.read_csv('/court_precedent.csv', skiprows = 2)# íŒŒì¼ì´ ê³µë°± 2ê°œë‚˜ 3ê°œ ë“±ìœ¼ë¡œ êµ¬ë¶„ ë˜ì–´ìˆì„ ê²½ìš°(ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš© ê°€ëŠ¥)pd.read_csv('/court_precedent.csv', sep ='\\s+')# íŒŒì¼ì´ íƒ­(ê³µë°± 4ì¹¸)ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ìˆì„ ê²½ìš°pd.read_csv('/court_precedent.csv', sep ='/t')","link":"/2022/11/22/Study_folder/Pandas,%20Numpy/2022-11-22-file-encoding/"},{"title":"ë°ì´í„°í”„ë ˆì„ í•„í„°ë§ í”¼ë´‡í…Œì´ë¸” - pd.pivot_table()","text":"pivot_table() ì•„ë˜ì™€ ê°™ì€ ë°ì´í„° í”„ë ˆì„ì´ ìˆì„ ë•Œ, â€˜Age_categoryâ€™ë¥¼ ì—‘ì…€ í•„í„°ë¥¼ ê±°ëŠ”ê²ƒ ì²˜ëŸ¼ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´, ë‹¤ì–‘í•œ ë°©ë²•ì´ ìˆì§€ë§Œ ê°€ì¥ ë³´ê¸° í¸í•œ ê²ƒ ì¤‘ í•˜ë‚˜ê°€ í”¼ë´‡í…Œì´ë¸”ì´ë‹¤. ì—‘ì…€ì´ë‚˜ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì˜ í”¼ë´‡í…Œì´ë¸”ê³¼ ìœ ì‚¬í•˜ë©° ë°©ë²•ë„ ê·¸ë¦¬ ì–´ë µì§€ ì•Šë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œì…ë‹ˆë‹¤. 12345678910111213141516171819202122232425262728293031323334353637#indexëŠ” ë§¨ ì™¼ìª½ì— gropbyí•  ì—´ì´ë¦„ì„ ì…ë ¥,#columnsëŠ” ë³´ê³  ì‹¶ì€ ì—´ì˜ ì´ë¦„ì„ ì…ë ¥,#fill_valueëŠ” ì—°ì‚°í•˜ê³  ì‹¶ì€ ì—´ì˜ ì´ë¦„ì„ ì…ë ¥(int,floatíƒ€ì…ë§Œ ê°€ëŠ¥) - ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ defaultê°’ìœ¼ë¡œ ìˆ˜ì¹˜í™”í•  ìˆ˜ ìˆëŠ” ì—´ë“¤ì´ ë“¤ì–´ê°.#aggfunc ì—ëŠ” ì—°ì‚°í•˜ê³  ì‹¶ì€ ë°©ì‹ ì„ íƒ ex) 'count', 'sum', 'mean', np.mean ë“±ì´ ìˆë‹¤.import pandas as pddf = pd.DataFrame({'Age' : range(1,101,10),'Number' :range(100,1001,100)})df['Age_category'] = pd.qcut(df['Age'],3,labels=['young','medium','older']) df Age Number Age_category0 1 100 young1 11 200 young2 21 300 young3 31 400 young4 41 500 medium5 51 600 medium6 61 700 medium7 71 800 older8 81 900 older9 91 1000 olderimport numpy as npdf.pivot_table(index='Age',columns='Age_category',aggfunc='mean')NumberAge_category young medium olderAge 1 100.0 NaN NaN11 200.0 NaN NaN21 300.0 NaN NaN31 400.0 NaN NaN41 NaN 500.0 NaN51 NaN 600.0 NaN61 NaN 700.0 NaN71 NaN NaN 800.081 NaN NaN 900.091 NaN NaN 1000.0 ì•„ë˜ëŠ” íŒë‹¤ìŠ¤ ë©”ë‰´ì–¼ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤ ê³µì‹ ë©”ë‰´ì–¼ì„ ë³´ë©´, í™•ì‹¤íˆ ì´í•´ í•  ìˆ˜ ìˆì„ê²ë‹ˆë‹¤. 12345678910111213141516171819202122232425262728293031323334df = pd.DataFrame({&quot;A&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;], &quot;B&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;, &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;], &quot;C&quot;: [&quot;small&quot;, &quot;large&quot;, &quot;large&quot;, &quot;small&quot;, &quot;small&quot;, &quot;large&quot;, &quot;small&quot;, &quot;small&quot;, &quot;large&quot;], &quot;D&quot;: [1, 2, 2, 3, 3, 4, 5, 6, 7], &quot;E&quot;: [2, 4, 5, 5, 6, 6, 8, 9, 9]})df A B C D E0 foo one small 1 21 foo one large 2 42 foo one large 2 53 foo two small 3 54 foo two small 3 65 bar one large 4 66 bar one small 5 87 bar two small 6 98 bar two large 7 9#pivot_tablepd.pivot_table(df, values=['D', 'E'], index=['A', 'C'], aggfunc={'D': np.mean, 'E': [min, max, np.mean]}) D E mean max mean minA C bar large 5.500000 9 7.500000 6small 5.500000 9 8.500000 8foo large 2.000000 5 4.500000 4small 2.333333 6 4.333333 2","link":"/2022/11/26/Study_folder/Pandas,%20Numpy/2022-11-26-pd.pivot_table()/"},{"title":"torchë¥¼ booleanê°’ìœ¼ë¡œ ë³€ê²½","text":"operation ì°¸ì¡° ì˜ˆì‹œë¥¼ í†µí•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. 12345678910import torchx=torch.tensor([1,2,3,4])print(x&gt;2)# tensor([False, False, True, True])print((x&gt;2).type(torch.float32))# tensor([0., 0., 1., 1.]) gt() í•¨ìˆ˜ë¥¼ í™œìš©12345678910import torchx=torch.tensor([1,2,3,4])print(x.gt(2))# tensor([False, False, True, True])print(x.gt(2).to(torch.int32))# tensor([0, 0, 1, 1], dtype=torch.int32)","link":"/2023/01/08/Study_folder/Pytorch/2023-01-08-boolean/"},{"title":"íŒŒì´í† ì¹˜ì—ì„œ model ì •ë³´(summary) í™•ì¸","text":"íŒŒì´í† ì¹˜ì—ì„œ ë§Œë“¤ì–´ì§„ ëª¨ë¸ ì •ë³´ í™•ì¸í•˜ê¸° kerasì—ì„œëŠ” model.summary()ì˜ ë‚´ì¥ í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ë©´ ê°„ë‹¨í•˜ê²Œ ëª¨ë¸ ì •ë³´ë¥¼ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŒŒì´í† ì¹˜ì—ì„œë„ ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì„ í†µí•´ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1. printë¥¼ í•˜ë©´ summaryê°€ ì¶œë ¥ëœë‹¤1print(model) 2. torchinfo í†µí•´ summaryë¥¼ ì¶œë ¥í•œë‹¤1234!pip install torchinfofrom torchinfo import summarysummary(model) 3. torchsummaryë¥¼ í†µí•´ summaryì¶œë ¥ (input_sizeë¥¼ ì•Œì•„ì•¼ë§Œ ì¶œë ¥ ê°€ëŠ¥)1234!pip install torchsummaryfrom torchsummary import summarysummary(model, input_size = (1,28,28), batch_size= 6)","link":"/2023/01/09/Study_folder/Pytorch/2023-01-09-model-info/"},{"title":"Tensorflow ë”¥ëŸ¬ë‹ CNN","text":"Fasion_mnist ë°ì´í„° ë”¥ëŸ¬ë‹ìœ¼ë¡œ ë¶„ë¥˜í•˜ê¸°12345678910111213141516171819202122232425262728293031323334353637383940import tensorflow as tffrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Densefrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStoppingfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categorical## tensorflow ë”¥ëŸ¬ë‹#ë°ì´í„°fashion_mnist = tf.keras.datasets.fashion_mnist(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()# ì°¨ì› ë³€í™˜ í›„, í…ŒìŠ¤íŠ¸ì…‹ê³¼ í•™ìŠµì…‹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¤ë‹ˆë‹¤.train_images = train_images.reshape(train_images.shape[0], 784).astype('float32') / 255test_images = test_images.reshape(test_images.shape[0], 784).astype('float32') / 255train_labels = to_categorical(train_labels, 10)test_labels = to_categorical(test_labels, 10)#ë”¥ëŸ¬ë‹ ëª¨ë¸ ì •ì˜model = Sequential()# ì¸í’‹ 784 ì•„ì›ƒí’‹ 1024 (íˆë“ ì¸µ)model.add(Dense(1024,input_dim = 784, activation= 'relu')) # ì¸í’‹ 1024(ìƒëµ), ì•„ì›ƒí’‹ 512 (íˆë“ ì¸µ)model.add(Dense(512, activation= 'relu')) # ì¸í’‹ 512(ìƒëµ), ì•„ì›ƒí’‹ 10 (ì¶œë ¥ì¸µ)model.add(Dense(10, activation = 'softmax')) #input_dimìƒëµ ê°€ëŠ¥model.summary()model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])#ì½œë°±ì˜µì…˜modelpath=&quot;./MODEL_DIR/MNIST_MLP.hdf5&quot;checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)#í•™ìŠµhistory = model.fit(train_images, train_labels, validation_split=0.25, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])#í‰ê°€print(&quot;\\n Test Accuracy: %.4f&quot; % (model.evaluate(test_images, test_labels)[1])) #0.8889 Fasion_mnist ë°ì´í„° CNNìœ¼ë¡œ ë¶„ë¥˜í•˜ê¸°123456789101112131415161718192021222324252627282930313233343536373839404142import tensorflow as tffrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStoppingfrom tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categoricalfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D##tensorflow CNN#ë°ì´í„°fashion_mnist = tf.keras.datasets.fashion_mnist(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()# ì°¨ì› ë³€í™˜ í›„, í…ŒìŠ¤íŠ¸ì…‹ê³¼ í•™ìŠµì…‹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¤ë‹ˆë‹¤. + RGBì°¨ì› ì¶”ê°€train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') / 255test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32') / 255train_labels = to_categorical(train_labels, 10)test_labels = to_categorical(test_labels, 10)#ëª¨ë¸ ì •ì˜model = Sequential()model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))model.add(Conv2D(64, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2,2)))model.add(Dropout(0.25))model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dropout(0.5))model.add(Dense(10, activation='softmax'))#ì»´íŒŒì¼ ë° ì½œë°±ì˜µì…˜model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])modelpath=&quot;./MODEL_DIR/MNIST_CNN.hdf5&quot;checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)#í•™ìŠµhistory = model.fit(train_images, train_labels, validation_split=0.25, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])#í‰ê°€print(&quot;\\n Test Accuracy: %.4f&quot; % (model.evaluate(test_images, test_labels)[1]))# Test Accuracy: 0.9237","link":"/2022/12/12/Study_folder/TensorFlow/2022-12-12-deep_CNN/"},{"title":"Tensorflow DATA Augmentation(ì´ë¯¸ì§€ ì¦ì‹)","text":"í…ì„œí”Œë¡œìš°ë¡œ ì´ë¯¸ì§€ ì¦ì‹í•˜ê¸°(ë°ì´í„° ë»¥íŠ€ê¸°)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120from zipfile import ZipFilefrom keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2Dfrom keras.preprocessing.image import ImageDataGenerator### ì´ë¯¸ì§€ ì¦ì‹ ì „ ë¶„ë¥˜í•˜ê¸°#zip í•´ì œí•˜ê¸°directory = './'with ZipFile('TeamA_name2.zip') as f : x = [f.extract(file, directory) for file in f.namelist() if file.endswith('jpg')] #jpgíŒŒì¼ë§Œ ì••ì¶• í•´ì œ# ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°train_datagen = ImageDataGenerator(rescale=1./255)train_generator = train_datagen.flow_from_directory(directory='./TeamA_name2/train', target_size = (24,24), batch_size = 3, class_mode = 'categorical') # &quot;binary&quot; : 1D numpy array of binary labels . # &quot;categorical&quot; : 2D numpy array of one-hot encoded labels. Supports multi-label output. # &quot;sparse&quot; : 1D numpy array of integer labels.test_datagen = ImageDataGenerator(rescale =1./255)test_generator = test_datagen.flow_from_directory(directory='./TeamA_name2/test', target_size = (24,24), batch_size = 3, class_mode = 'categorical')#ëª¨ë¸ ì„¸íŒ…model = Sequential()model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,3)))model.add(Conv2D(64, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dense(4, activation='softmax'))model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics =['accuracy'])model.fit( train_generator, steps_per_epoch=15, epochs=30, validation_data=test_generator, validation_steps=5)scores = model.evaluate(test_generator, steps=5)print(&quot;%s: %.2f%%&quot; %(model.metrics_names[1], scores[1]*100))# 100% ########## ì´ë¯¸ì§€ ì¦ì‹í•˜ì—¬ ì‹œë„#ì´ë¯¸ì§€ ì¦ì‹train_datagen = ImageDataGenerator( rescale=1./255, # rescale, fill_modeë¥¼ ì œì™¸í•œ ë³€ìˆ˜ëŠ” ì„¤ì •í•œ nê°’ì— ëŒ€í•´ -n ~ +nì˜ ëœë¤ê°’ì„ ê°€ì§‘ë‹ˆë‹¤ rotation_range=10, # íšŒì „ ë²”ìœ„ -10~10 width_shift_range=0.2, # ê°€ë¡œ ë°©í–¥ìœ¼ë¡œ ì´ë¯¸ì§€ ì´ë™ height_shift_range=0.2, # ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ ì´ë¯¸ì§€ ì´ë™ shear_range=0.7, # ì°Œê·¸ëŸ¬ì§(ì´ë¯¸ì§€ ë°€ë¦¼) zoom_range=[0.9, 2.2], # í™•ëŒ€ ë²”ìœ„ horizontal_flip=True, # ê°€ë¡œ ë°˜ì „ vertical_flip=True, # ì„¸ë¡œ ë°˜ì „ brightness_range=(0.1, 0.9), # ì´ë¯¸ì§€ ë°ê¸° fill_mode='nearest') # ì´ë¯¸ì§€ë¥¼ íšŒì „, ì´ë™í•˜ê±°ë‚˜ ì¶•ì†Œí•  ë•Œ ìƒê¸°ëŠ” ê³µê°„ì„ ì±„ìš°ëŠ” ë°©ì‹# fill_mode ì—ëŠ” ì•„ë˜ 4ì¢…ë¥˜ê°€ ìˆìœ¼ë©° nearestë¥¼ ê°€ì¥ ë§ì´ ì‚¬ìš©# 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)# 'nearest': aaaaaaaa|abcd|dddddddd# 'reflect': abcddcba|abcd|dcbaabcd# 'wrap': abcdabcd|abcd|abcdabcd#ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°train2_generator = train_datagen.flow_from_directory( './TeamA_name2/train', target_size=(24, 24), batch_size=3, class_mode='categorical') #2ë°°ë¡œ ì¦ì‹ë˜ì—ˆìœ¼ë‚˜ ë©”ì‹œì§€ë¡œëŠ” ì•ˆë‚˜ì˜´test2_datagen = ImageDataGenerator(rescale=1./255.)test2_generator=test2_datagen.flow_from_directory('./TeamA_name2/test', target_size=(24,24), batch_size=3, class_mode='categorical')#ëª¨ë¸ì€ ê¸°ì¡´ì˜ ëª¨ë¸ê³¼ ë™ì¼model = Sequential()model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,3)))model.add(Conv2D(64, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dense(4, activation='softmax'))model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics =['accuracy'])#í•™ìŠµ(ê¸°ì¡´ê³¼ ë™ì¼)model.fit( train2_generator, steps_per_epoch=15, epochs=30, validation_data=test2_generator, validation_steps=5)scores = model.evaluate(test2_generator, steps=5)print(&quot;%s: %.2f%%&quot; %(model.metrics_names[1], scores[1]*100))# 66%ë‚˜ì˜´. ì´ë¯¸ì§€ ì¦ì‹ë„ ì•Œë§ê²Œ ì„¸íŒ…ì„ í•´ì•¼í•  ê²ƒ ê°™ë‹¤.### ë”°ë¡œ ì´ë¯¸ì§€ 1ì¥ìœ¼ë¡œ í‰ê°€í•˜ê³  ì‹¶ì„ ê²½ìš°from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°def load_image(filename): img = load_img(filename, target_size=(24, 24)) img = img_to_array(img) img = img.reshape(1, 24, 24, 3) img = img.astype('float32') return img# í‰ê°€ ì˜ˆì¸¡ í•¨ìˆ˜def run_example(): img = load_image('file_name.png') #íŒŒì¼ ì´ë¦„ ì…ë ¥ result=model.predict(img) ans = [k for k, v in test_generator.class_indices.items() if v == np.argmax(result[0])][0] print(f'{max(result[0])*100}% í™•ë¥ ë¡œ &quot;{ans}&quot;ê°€ ì‘ì„±í•œ signature ì…ë‹ˆë‹¤.')run_example()","link":"/2022/12/15/Study_folder/TensorFlow/2022-12-15-img-generator/"},{"title":"DCGAN(DC ìƒì‚°ì  ì ëŒ€ ì‹ ê²½ë§)","text":"Deep Convolutional GAN(Generative Adversarial Nets) GAN ëª¨ë¸ì€ â€˜ìƒì„±ì ëª¨ë¸ Gâ€™(Generator)ì™€ â€˜íŒë…ì ëª¨ë¸ Dâ€™(Discriminator)ì„ ë§Œë“¤ê³  Dì™€ Gì˜ ê²½ì°°ê³¼ ë„ë‘‘ ê²Œì„í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±í•˜ëŠ” ë°©ì‹ì´ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— 2ê°€ì§€ ëª¨ë¸ì„ ìƒì„±í•´ì•¼ í•œë‹¤. Gëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ê·¸ ì´ë¯¸ì§€ì˜ íŒë… ê²°ê³¼ê°€ 0.5(ì§„ì§œë„ ê°€ì§œë„ ì•„ë‹Œ)ë  ë•Œê¹Œì§€ í•™ìŠµì‹œì¼œ ì´ë¯¸ì§€ ìƒì„± 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103from tensorflow.keras.datasets import mnistfrom tensorflow.keras.layers import Input, Dense, Reshape,Flatten, Dropoutfrom tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2Dfrom tensorflow.keras.models import Sequential, Modelimport numpy as npimport matplotlib.pyplot as plt##### ëª¨ë¸ G(ìƒì„±ì) #####generator = Sequential()generator.add(Dense(128*7*7 ,input_dim = 100 , activation = LeakyReLU(0.2))) generator.add(BatchNormalization())# 128ì€ ì„ì˜ì˜ ìˆ˜ë¥¼ ì…ë ¥# 7*7ì€ ë‚˜ì¤‘ì— *2 and *2ë¥¼ í•´ì„œ 28ì„ ë§ì¶”ê²Œ ë  ê¸°ì´ˆ ê°’# 28*28ë¡œ (mnist ì´ë¯¸ì§€ê°€ 28*28ì´ê¸° ë•Œë¬¸) # LeakyReLU ë’¤ì˜ ê°’ì€ ìŒìˆ˜ì¼ë•Œì˜ ê¸°ìš¸ê¸° ê°’ì´ë©° ë³´í†µ 0.1ì„ ì…ë ¥#upsamplingì‹œ ì´ë¯¸ì§€ í¬ê¸°ê°€ 2ë°°ê°€ ë¨generator.add(Reshape((7,7,128)))# Conv2Dê°€ ë°›ì„ ìˆ˜ìˆëŠ” êµ¬ì¡°ë¡œ ë³€ê²½generator.add(UpSampling2D()) # 14,14,128generator.add(Conv2D(64, kernel_size =5, padding='same'))generator.add(BatchNormalization())generator.add(Activation(LeakyReLU(0.2)))generator.add(UpSampling2D())# 28,28,64generator.add(Conv2D(1, kernel_size = 5, padding='same', activation='tanh')) #28,28,1##### ëª¨ë¸ D(íŒë…ì) #####discriminator = Sequential()discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=&quot;same&quot;))discriminator.add(Activation(LeakyReLU(0.2)))discriminator.add(Dropout(0.3))discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=&quot;same&quot;))discriminator.add(Activation(LeakyReLU(0.2)))discriminator.add(Dropout(0.3))discriminator.add(Flatten())discriminator.add(Dense(1, activation='sigmoid'))discriminator.compile(loss='binary_crossentropy', optimizer='adam')discriminator.trainable = False #íŒë³„ì, í•™ìŠµ ê°€ëŠ¥ ì—¬ë¶€ = False #ê°€ì¥ ì¤‘ìš”í•œ ë¬¸êµ¬!######Gëª¨ë¸ì˜ input_dimì´ 100ì´ê¸°ì— ê·¸ì— ë§ì¶°ì•¼í•¨g_input = Input(shape=(100,))dis_output = discriminator(generator(g_input))gan = Model(g_input, dis_output)gan.compile(loss='binary_crossentropy', optimizer = 'adam')##### íŠ¸ë ˆì¸ í•¨ìˆ˜ ìƒì„±, train_on_batchë¡œ í•™ìŠµ ###### gan_train(2001,32,200)ì„ ì‚¬ìš©í•  ì˜ˆì •def gan_train(epoch, batch_size, saving_interval): (X_train, _), (_, _) = mnist.load_data() #ganì—ì„œëŠ” íƒ€ê²Ÿ,vailidationì´ í•„ìš”ì—†ì–´ì„œ X_trainë§Œ ì €ì¥ X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32') # print(X_train.shape[0]) X_train = (X_train - 127.5) / 127.5 #-1 ~ +1ë¡œ ìŠ¤ì¼€ì¼ë§ # real = np.ones((batch_size,1)) #ì‹¤ì œ ì´ë¯¸ì§€ëŠ” ëª¨ë‘ ì°¸ì´ë¯€ë¡œ 1ë¡œ ì´ˆê¸°í™” fake = np.zeros((batch_size,1)) #32ê°œ(batch_size)ì˜ ê°€ì§œ ì´ë¯¸ì§€ëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™” for i in range(epoch): #ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ íŒë³„ìì— ì…ë ¥í•˜ëŠ” ë¶€ë¶„ idx = np.random.randint(0,X_train.shape[0], batch_size) imgs = X_train[idx] d_loss_real = discriminator.train_on_batch(imgs, real)#train_on_batch(ì‹¤ì œ ì´ë¯¸ì§€, ë ˆì´ë¸”(==1)) #ê°€ì§œ ì´ë¯¸ì§€ë¥¼ íŒë³„ìì— ì…ë ¥í•˜ëŠ” ë¶€ë¶„ noise = np.random.normal(0,1, (batch_size, 100)) gen_imgs = generator.predict(noise) d_loss_fake = discriminator.train_on_batch(gen_imgs, fake) #íŒë³„ìì™€ ìƒì„±ìì˜ ì˜¤ì°¨ë¥¼ ê³„ì‚° d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) #íŒë³„ìì˜ ì˜¤ì°¨ g_loss = gan.train_on_batch(noise, real) #ìƒì„±ìì˜ ì˜¤ì°¨, ì§„ì§œë¼ê³  ì†ì—¬ì•¼ë˜ì„œ realì„ ì¤Œ(ìƒì„±ìì—ì„œ ë ˆì´ë¸”ì„ 1(ones)ìœ¼ë¡œ ì„¤ì •í•´ì„œ íŒë³„ìë¡œ ì „ë‹¬) print(f'epoch: {i}, d_loss:{d_loss:.4f}, g_loss: {g_loss:.4f}') if i % saving_interval == 0: #r, c = 5, 5 noise = np.random.normal(0, 1, (25, 100)) gen_imgs = generator.predict(noise) # Rescale images 0 - 1 gen_imgs = 0.5 * gen_imgs + 0.5 fig, axs = plt.subplots(5, 5) count = 0 for j in range(5): for k in range(5): axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray') axs[j, k].axis('off') count += 1 fig.savefig(f'./gan_mnist_{i}.png')gan_train(2001,32,200) ê¸°ì¡´ì˜ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ê°€ì§œì˜ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤.(ìˆ«ìì§€ë§Œ ìˆ«ì ì•„ë‹Œë“¯í•œ ëŠë‚Œ?)","link":"/2022/12/20/Study_folder/TensorFlow/2022-12-20-DCGAN/"},{"title":"numpyì˜ ì°¨ì›ê³¼ axisì˜ ì´í•´","text":"ì°¨ì›ê³¼ axisì˜ ì´í•´(sumìœ¼ë¡œ)12345678910111213141516171819202122232425262728293031323334353637383940np_array = np.arange(0, 4*2*4)print(np_array) #32ì°¨ì› ë°°ì—´# array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,# 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])reshape = np_array.reshape(4,2,4)print(reshape) #x,y,zì°¨ì› == 4,2,4 ì°¨ì›# array([[[ 0, 1, 2, 3],# [ 4, 5, 6, 7]],# [[ 8, 9, 10, 11],# [12, 13, 14, 15]],# [[16, 17, 18, 19],# [20, 21, 22, 23]],# [[24, 25, 26, 27],# [28, 29, 30, 31]]])print(reshape.sum(axis=0)) #x,y,z ì°¨ì›ì—ì„œ y,z ì°¨ì›ìœ¼ë¡œ ë°”ë€œ# array([[48, 52, 56, 60],# [64, 68, 72, 76]])print(reshape.sum(axis=1)) #x,y,z ì°¨ì›ì—ì„œ x,z ì°¨ì›ìœ¼ë¡œ ë°”ë€œ# array([[ 4, 6, 8, 10],# [20, 22, 24, 26],# [36, 38, 40, 42],# [52, 54, 56, 58]])print(reshape.sum(axis=2)) #x,y,z ì°¨ì›ì—ì„œ x,y ì°¨ì›ìœ¼ë¡œ ë°”ë€œ# array([[ 6, 22],# [ 38, 54],# [ 70, 86],# [102, 118]])print(reshape.sum(axis=(1,2))) #x,y,z ì°¨ì›ì—ì„œ z ì°¨ì›ìœ¼ë¡œ ë°”ë€œ# array([ 28, 92, 156, 220])print(reshape.sum(axis=(0,2))) #x,y,z ì°¨ì›ì—ì„œ yì°¨ì›ìœ¼ë¡œ ë°”ë€œ# array([216, 280])","link":"/2022/12/14/Study_folder/Pandas,%20Numpy/2022-12-15-numpy-axis/"},{"title":"np.transpose()","text":"numpy.T T í•¨ìˆ˜(ë©”ì†Œë“œ)ëŠ” shapeì˜ ì°¨ì›ì„ ë’¤ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤ 2ì°¨ì›ì˜ ë°°ì—´ì—ì„œëŠ” Tì™€ transposeì˜ ê²°ê³¼ê°€ ê°™ì§€ë§Œ, 3ì°¨ì›ì´ ë„˜ëŠ” ê³ ì°¨ì›ì—ì„œëŠ” êµ¬ë¶„ í•  í•„ìš”ê°€ ìˆë‹¤. íŠ¹íˆ ì»¬ëŸ¬ì´ë¯¸ì§€ëŠ” 3ì°¨ì› ì´ìƒì´ê¸° ë•Œë¬¸ì— transpose í•¨ìˆ˜ë¥¼ ìì£¼ ì‚¬ìš©í•œë‹¤. 1234567891011121314a = np.random.randint(1,20,6).reshape(2,3)print(a)# [[18 14 5]# [ 1 3 18]]print(a.T)# [[18 1]# [14 3]# [ 5 18]]print(a.transpose())# [[18 1]# [14 3]# [ 5 18]] numpy.transpose()123456789101112131415161718192021222324252627282930a = np.random.randint(1,20,24).reshape(2,3,4)print(a)[[[ 4 7 12 14] [ 6 19 19 14] [ 4 6 2 12]] [[ 4 13 14 16] [ 7 1 19 19] [10 12 2 6]]]print(a.T)[[[ 4 4] [ 6 7] [ 4 10]] [[ 7 13] [19 1] [ 6 12]] [[12 14] [19 19] [ 2 2]] [[14 16] [14 19] [12 6]]]a.transpose(2,1,0)# ê²°ê³¼ëŠ” a.Tì™€ ê°™ìŒ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647a.transpose(1,2,0) # ì°¨ì› reshapeí•˜ëŠ” ëŠë‚Œ# ê·¸ëŸ¬ë‚˜ reshapeê³¼ ì°¨ì›ë¹¼ê³ ëŠ” ê²°ê³¼ê°€ ì „í˜€ ë‹¤ë¦„ì„ ìœ ì˜!array([[[ 4, 4], [ 7, 13], [12, 14], [14, 16]], [[ 6, 7], [19, 1], [19, 19], [14, 19]], [[ 4, 10], [ 6, 12], [ 2, 2], [12, 6]]])#transposeë‘ ì „í˜€ ë‹¤ë¦„!a.reshape(3,4,2)array([[[ 4, 7], [12, 14], [ 6, 19], [19, 14]], [[ 4, 6], [ 2, 12], [ 4, 13], [14, 16]], [[ 7, 1], [19, 19], [10, 12], [ 2, 6]]])a.shape# (2, 3, 4)a.T.shape# (4, 3, 2)a.transpose(2,1,0)# (4, 3, 2)# 2,3,4 -&gt; 4,3,2a.transpose(1,2,0) # (3, 4, 2)# 2,3,4 -&gt; 3,4,2","link":"/2022/12/24/Study_folder/Pandas,%20Numpy/2022-12-24-np-transpose/"},{"title":"AE(Auto_Encoder)","text":"AEì˜ ì›ë¦¬ íˆë“ ì¸µì„ ì…ë ¥ì¸µë³´ë‹¤ ì‘ì€ ê°’ì„ ì…ë ¥í•˜ê³ , ì••ì¶•(ì¸ì½”ë”)ê³¼ ë³µì›(ë””ì½”ë”)ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ìƒì„± encoderì™€ decoderë¡œ êµ¬ì„± ì´ ê³¼ì •ì—ì„œ ë§Œë“¤ì–´ì•¼ í•  ê²ƒ (ë°ì´í„° ì •ì œ -&gt; ì¸ì½”ë”-&gt; ë””ì½”ë” -&gt; ì»´íŒŒì¼, í•™ìŠµ -&gt; í…ŒìŠ¤íŠ¸) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from tensorflow.keras.datasets import mnistfrom tensorflow.keras.models import Sequential, Modelfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshapeimport tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt(X_train, _), (X_test, _) = mnist.load_data() #mnistë°ì´í„°ë¥¼ ê°€ì§€ê³  ì‘ì—…(x_trainìœ¼ë¡œ í•™ìŠµ, x_testë¡œ í‰ê°€)# ë°ì´í„° x,28,28,1 ì°¨ì›ìœ¼ë¡œ ë³€ê²½ í›„ nomalization í•´ì¤Œ(/255)X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32') / 255# ì¸ì½”ë” ìƒì„±(ì¶œë ¥ ì°¨ì›ì€ ì„ì˜ë¡œ ë°”ê¿”ë„ ë˜ë©°, ì••ì¶•(ì°¨ì›ì„ ì¤„ì„) -&gt; ë³µì›(ì°¨ì›ì„ ëŠ˜ë¦¼)ì´ í¬ì¸íŠ¸ì…ë‹ˆë‹¤.)autoencoder = Sequential()autoencoder.add(Conv2D(16, kernel_size = 3, input_shape = X_train.shape[1:], activation='relu', padding = 'same'))# ,28,28,16autoencoder.add(MaxPooling2D(2, padding='same'))# ,14,14,16autoencoder.add(Conv2D(8, kernel_size =3, activation = 'relu', padding = 'same'))# ,14,14,8autoencoder.add(MaxPooling2D(2, padding='same'))# , 7,7,8autoencoder.add(Conv2D(8, kernel_size = 3, strides =2, padding= 'same', activation = 'relu'))# , 4,4,8 (stridesê°€ 2ì´ê¸°ë•Œë¬¸)# ì¸ì½”ë”ì— ë°”ë¡œ ë””ì½”ë”ë¥¼ ì¶”ê°€ ìƒì„±í•¨!# ë””ì½”ë” ìƒì„±autoencoder.add(UpSampling2D())# , 8,8,8autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))# , 8,8,8autoencoder.add(UpSampling2D())# ,16,16,8autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))#no padding option# ,14,14,16autoencoder.add(UpSampling2D())# ,28,28,16autoencoder.add(Conv2D(1, kernel_size = 3, padding='same', activation='sigmoid'))# ,28,28,1# ì»´íŒŒì¼ ë° í•™ìŠµì„ í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.with tf.device(&quot;/GPU:0&quot;): #GPUê°€ ìˆì„ ê²½ìš° 0ë²ˆ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ autoencoder.compile(optimizer='adam', loss='binary_crossentropy') autoencoder.fit(X_train, X_train, epochs=20, batch_size=128, validation_data=(X_test, X_test))# ì›ë³¸ ì´ë¯¸ì§€ì™€ AEë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ ë¹„êµrandom_test = np.random.randint(X_test.shape[0], size=5)ae_imgs = autoencoder.predict(X_test)plt.figure(figsize=(7,2)) #ì‚¬ì´ì¦ˆ ì„¤ì •for i, image_idx in enumerate(random_test): ax = plt.subplot(2,7, i+1) plt.imshow(X_test[image_idx].reshape(28,28)) ax = plt.subplot(2,7, 7+i+1) plt.imshow(ae_imgs[image_idx].reshape(28,28)) ì²«ë²ˆì§¸ ì¤„ì´ ì›ë³¸ ì´ë¯¸ì§€ì•„ë˜ì¤„ì´ AEë¡œ ìƒì„±ëœ ì´ë¯¸ì§€","link":"/2022/12/21/Study_folder/TensorFlow/2022-12-21-Auto-encoder(AE)/"},{"title":"XAI(eXplainable AI) - ì„¤ëª…í•˜ëŠ” AI","text":"ì„¤ëª… ê°€ëŠ¥í•œ AI(eXplainable AI) - XAI XAIëŠ” ì¸ê³µì§€ëŠ¥ì˜ í–‰ìœ„ì™€ ë„ì¶œí•œ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì´ë¥¼ ì„¤ëª…í•˜ëŠ” ë°©ë²•ë¡ ê³¼ ë¶„ì•¼ë¥¼ ì¼ì»«ëŠ”ë‹¤. í”íˆ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì€ ë³µì¡í•œ ì¼ë ¨ì˜ ê³¼ì •(ë”¥ëŸ¬ë‹)ì„ í†µí•´ ê²°ë¡ ì„ ë„ì¶œí•˜ë‚˜, ê·¸ ê³¼ì •ì„ ì„¤ëª…í•  ìˆ˜ ì—†ëŠ” ë¸”ë™ ë°•ìŠ¤ë¡œ ì—¬ê²¨ì§„ë‹¤. XAIëŠ” ì´ë¥¼ í•´ì†Œ ì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°œë…ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ì—­í• í•˜ê³  ìˆìŠµë‹ˆë‹¤. (1) CAM1 - flatten ì‘ì—… ì§ì „ ë‹¨ê³„ì—ì„œ ì´ë•Œê¹Œì§€ ë§Œë“¤ì–´ì§„ ì¤‘ê°„ ê²°ê³¼ë“¤(feature map)ì„ ìˆ˜ì§‘ 2 - ì¤‘ê°„ ê²°ê³¼ë“¤ì— ëŒ€í•œ í‰ê· ê°’ì„ êµ¬í•¨ 3 - í‰ê· ê°’ê³¼ ìµœì¢… ì˜ˆì¸¡ê°’ ì‚¬ì´ì—ì„œ í•œë²ˆ ë” í•™ìŠµ -&gt; ì–´ë–¤ ì¤‘ê°„ê°’ì´ ìµœì¢… ê²°ì •ì— ì˜í–¥ì„ í¬ê²Œ ì¤¬ëŠ”ì§€ í™•ì¸ 12345678910111213141516!pip install tf-explainimport zipfilezipfile.ZipFile('img.zip').extractall()from tensorflow.keras.preprocessing.image import load_img, img_to_arrayfrom tensorflow.keras.applications import VGG16from tf_explain.core.grad_cam import GradCAMfrom tf_explain.core.occlusion_sensitivity import OcclusionSensitivityimport globimport matplotlib.pyplot as pltimport matplotlib.image as mpimg ì›ë³¸ ì‚¬ì§„ íŒŒì¼ í™•ì¸ 12345678910111213print(glob.glob('*_0.jpg'))# ['yawl_0.jpg', 'squirrel_monkey_0.jpg', 'persian_cat_0.jpg', # 'maltese_0.jpg', 'grand_piano_0.jpg']images_originals = []for img_name in glob.glob(&quot;*_0.jpg&quot;): images_originals.append(mpimg.imread(img_name))plt.figure(figsize = (20,20))for i, img in enumerate(images_originals): plt.subplot(5,5,i+1) plt.imshow(img) ì´ì œ VGG16ì—ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ëœ ê²°ê³¼ë¥¼ í†µí•´ ì›ë³¸ ì‚¬ì§„ì„ ì™œ ì¹´í…Œê³ ë¦¬(input_list)ë¡œ ë¶„ë¥˜í•˜ì˜€ëŠ”ì§€ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤. 12345678910111213141516171819model = VGG16(weights=&quot;imagenet&quot;, include_top=True)input_list = [&quot;maltese&quot;, &quot;persian_cat&quot;, &quot;squirrel_monkey&quot;, &quot;grand_piano&quot;, &quot;yawl&quot;]imagenet_index = [&quot;153&quot;, &quot;283&quot;, &quot;382&quot;, &quot;579&quot;, &quot;914&quot;]#gradient CAM ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ XAI ìƒì„±explainer = GradCAM()for li, i in zip(input_list, imagenet_index): print(i) img = (load_img(f'{li}_0.jpg', target_size=(224,224))) img = img_to_array(img) data = ([img], None) # print(data) # print('--'*50) grid = explainer.explain(data, model, int(i))# ì„¤ëª…í•˜ëŠ” ai ìƒì„± explainer.save(grid, '.', f'./{li}_cam.jpg') #_cam.jpgíŒŒì¼ì´ë€ ì´ë¦„ìœ¼ë¡œ ì €ì¥ ì €ì¥ëœ ì‚¬ì§„ì„ í™•ì¸í•´ë´…ì‹œë‹¤. 12345678910111213#gradient CAM ì•Œê³ ë¦¬ì¦˜ì´ ì ìš©ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì •ì˜images_cams = []plt.figure(figsize=(20,20))for img in glob.glob(&quot;*_cam.jpg&quot;): images_cams.append(mpimg.imread(img))# ì¶œë ¥for i, img in enumerate(images_cams): plt.subplot(5,5,i+1) plt.imshow(img) (2) ì´ë¯¸ì§€ë¥¼ ì¼ë¶€ë¥¼ ê°€ë ¤ì„œ, ê°€ë ¤ì§„ ì¼ë¶€ê°€ ì´ë¯¸ì§€ ë¶„ë¥˜í•˜ëŠ”ë° ìˆì–´ì„œ ì–´ëŠ ì •ë„ ì˜í–¥ì„ ì¤¬ëŠ”ì§€ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì‘ì„± ì¤‘","link":"/2023/01/10/Study_folder/TensorFlow/2023-01-10-XAI/"},{"title":"Image Classification fine tuning w ResNetV2","text":"Image Classification fine tuning w ResNetV21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import os import kerasimport numpy as np import pandas as pdfrom glob import globimport tensorflow as tffrom tensorflow.keras.utils import load_img, img_to_arrayfrom keras.preprocessing.image import ImageDataGeneratorfrom keras.models import Sequential, load_modelfrom keras.layers import GlobalAvgPool2D, Dense, Dropoutfrom keras.callbacks import EarlyStopping, ModelCheckpointfrom tensorflow.keras.applications import ResNet50V2# Data Visualizationimport plotly.express as pximport matplotlib.pyplot as pltfrom zipfile import ZipFilez = ZipFile('/content/drive/MyDrive/lesson_data/animal_data.zip')z.extractall()# Class Names(í´ë” ì´ë¦„ì´ í´ë˜ìŠ¤ ë„¤ì„(ì¢…ë¥˜))root_path = './Animal Classification/Animal Classification/Training Data/'test_path = './Animal Classification/Animal Classification/Testing Data/'valid_path = './Animal Classification/Animal Classification/Validation Data/'class_names = sorted(os.listdir(root_path))n_classes = len(class_names)# ì´ë¯¸ì§€ ì¦ì‹(ì´ë¯¸ì§€ë“¤ì€ rescale 1/255.ë¥¼ í•´ì¤˜ì•¼í•¨train_gen = ImageDataGenerator(rescale=1/255., rotation_range=10, horizontal_flip=True)valid_gen = ImageDataGenerator(rescale=1/255.)test_gen = ImageDataGenerator(rescale=1/255)# Load Datatrain_ds = train_gen.flow_from_directory(root_path, class_mode='binary', target_size=(256,256), shuffle=True, batch_size=32) valid_ds = valid_gen.flow_from_directory(valid_path, class_mode='binary', target_size=(256,256), shuffle=True, batch_size=32) test_ds = test_gen.flow_from_directory(test_path, class_mode='binary', target_size=(256,256), shuffle=True, batch_size=32)# 0ë²ˆ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµwith tf.device(&quot;/GPU:0&quot;): ## Pre-Trained Model base_model = ResNet50V2(input_shape=(256,256,3), include_top=False) # include_topì€ ë§ˆì§€ë§‰ ë ˆì´ì–´ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” Dense Layerë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. # ë ˆì´ì–´ì™€ ì´ë¯¸ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë§Œì„ ì‚¬ìš©í•œë‹¤ë©´ include_topì„ Falseë¡œ í•´ì•¼í•©ë‹ˆë‹¤. base_model.trainable = False # ê¸°ì¡´ ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ì˜ í•™ìŠµ ì•ˆí•¨ # Model Architecture name = 'ResNet50V2'#ì €ì¥í•  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì´ë¦„ #ResNet50V2ê°€ ì´ë¯¸ ê¹Šê²Œ ìŒ“ì—¬ì§„ ëª¨ë¸ì´ë¼ ë‹¤ë¥¸ ë ˆì´ì–´ë¥¼ ë§ì´ ë§Œë“¤ í•„ìš”ëŠ” ì—†ìŒ model = Sequential([ base_model, GlobalAvgPool2D(), Dense(256, activation='relu', kernel_initializer='he_normal'), #ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”(kenel_initailizerì—ëŠ” 3ì¢…ë¥˜ê°€ ìˆëŠ”ë° ì—¬ê¸°ì„œëŠ” HE ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©) Dropout(0.2), Dense(n_classes, activation='softmax') ], name=name) # Callbacks cbs = [EarlyStopping(patience=3, restore_best_weights=True), ModelCheckpoint(name + &quot;.h5&quot;, save_best_only=True)] # Model opt = tf.keras.optimizers.Adam(learning_rate=2e-3) model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) # Model Training history = model.fit(train_ds, validation_data=valid_ds, callbacks=cbs, epochs=15) 12345678910111213141516171819data = pd.DataFrame(history.history)data# loss accuracy val_loss val_accuracy# 0 0.224692 0.922000 0.142165 0.9544# 1 0.164413 0.943733 0.137304 0.9576# 2 0.126533 0.957733 0.126196 0.9596# 3 0.101600 0.964933 0.119228 0.9636# 4 0.090214 0.970933 0.113578 0.9668# 5 0.078054 0.974133 0.110474 0.9672# 6 0.071814 0.977467 0.105573 0.9668# 7 0.065274 0.981067 0.104021 0.9680# 8 0.065265 0.979867 0.101604 0.9684# 9 0.055805 0.982000 0.098761 0.9704# 10 0.047383 0.986267 0.098213 0.9692# 11 0.048346 0.983867 0.097358 0.9700# 12 0.040546 0.987733 0.097479 0.9700# 13 0.043776 0.987467 0.096769 0.9696# 14 0.034877 0.990000 0.095712 0.9704 12345678910111213141516171819202122232425262728293031323334353637383940model = load_model('./ResNet50V2.h5')model.summary()model.evaluate(test_ds)#0.9559#ì´ë¯¸ì§€ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê³ , ì´ë¯¸ì§€ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.def load_image(path): image = tf.cast(tf.image.resize(img_to_array(load_img(path))/255., (256,256)), tf.float32) return imagedef show_image(image, title=None): plt.imshow(image) plt.axis('off') plt.title(title)#ê²½ë¡œ ì„¤ì •path = './Animal Classification/Animal Classification/Interesting Images/'interesting_images = [glob(path + name + &quot;/*&quot;) for name in class_names]# ì˜ˆì¸¡ ê²°ê³¼(ì‹œê°í™”)for name in class_names: plt.figure(figsize=(25, 8)) cat_interesting = interesting_images[class_names.index(name)] for i, i_path in enumerate(cat_interesting): name = i_path.split(&quot;/&quot;)[-1].split(&quot;.&quot;)[0] image = load_image(i_path) plt.subplot(1,len(cat_interesting),i+1) # Model Prediction org_class = name.title() preds = model.predict(image[np.newaxis,...])[0] pred_class = class_names[np.argmax(preds)] confidence_score = np.round(preds[np.argmax(preds)],2) # Configure Title title = f&quot;Pred : {pred_class}\\nConfidence : {confidence_score:.2}&quot; show_image(image, title=title) plt.show()","link":"/2022/12/21/Study_folder/TensorFlow/2022-12-21-img-resnetv2/"},{"title":"í…ì„œí”Œë¡œ VGG16ëª¨ë¸ì„ ì´ìš©í•œ íŒŒì¸ íŠœë‹","text":"1234567891011# ì´ë¯¸ì§€ë„· ëŒ€íšŒ : 120ë§Œê°œ ì´ë¯¸ì§€ -&gt; ë¶„ë¥˜ê¸° -&gt; 1000í´ë˜ìŠ¤ ë¶„ë¥˜# VGG16ì´ë¼ëŠ” pretrained modelì„ ì‚¬ìš©í•´ì„œ -&gt; ì „ì´í•™ìŠµ# VGG16 ë¶ˆëŸ¬ì˜¤ê¸° + ìš°ë¦¬ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì—°ê²° -&gt; fine-tuning# í•™ìŠµ ìœ í˜•ì´ 2ê°€ì§€ ì¡´ì¬.# ì²« ë²ˆì§¸ ìœ í˜•ì€ ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµ(ê¸°ì¡´ ëª¨ë¸ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©) - ëŒ€ë¶€ë¶„ ì²« ë²ˆì§¸ ë°©ë²• ì‚¬ìš©# ë‘ ë²ˆì§¸ ìœ í˜•ì€ ì „ì²´ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµ(ì‹œê°„ì´ ì—„ì²­ë‚˜ê²Œ ì†Œìš”) - ê±°ì˜ ì•ˆí•¨# ì „ì²´ì ì¸ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤# ë°ì´í„° ì •ì œ(VGGì—ì„œ í•™ìŠµí•œ ì‚¬ì´ì¦ˆëŒ€ë¡œ) -&gt; VGGí˜¸ì¶œ -&gt; VGG í¬í•¨ëœ ëª¨ë¸ ìƒì„± -&gt; í•™ìŠµ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2Dfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.callbacks import EarlyStoppingfrom tensorflow.keras import optimizers, Input, models, layers, optimizers, metricsfrom tensorflow.keras.applications import VGG16, EfficientNetB7import numpy as npimport matplotlib.pyplot as plt#train,test ë°ì´í„°ì…‹ ì •ì œtrain_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)train_generator = train_datagen.flow_from_directory('./train',target_size =(150,150),batch_size=5, class_mode='binary')test_datagen = ImageDataGenerator(rescale=1/255.)test_generator = test_datagen.flow_from_directory('./test',target_size =(150,150),batch_size=5, class_mode='binary')# VGG16ì´ë¼ëŠ” ì´ë¯¸ì§€ë„·ì—ì„œ ì‚¬ìš©ëœ pre_trained ëª¨ë¸ í˜¸ì¶œ#include_topì„ Trueë¡œ í•  ê²½ìš° softmax 1000ìœ¼ë¡œ í´ë˜ìŠ¤ ë¶„ë¥˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ (ëŒ€ë¶€ë¶„ ì¶”ê°€ í•™ìŠµì˜ ê²½ìš° False ì‚¬ìš©)transfer_model = VGG16(include_top= False, input_shape=(150,150,3), weights='imagenet')#ìƒˆë¡­ê²Œ í•™ìŠµí•˜ì§€ ì•Šê³  ì´ì–´ì„œ í•™ìŠµí•˜ê¸°ì— Falseë¡œ ì„¤ì •transfer_model.trainable=False # transfer_model.summary()#ìƒˆë¡œìš´ ëª¨ë¸ì„ ì„¤ì •finetune_model = Sequential()finetune_model.add(transfer_model) #íŒŒì¸íŠœë‹ì´ê¸°ë•Œë¬¸ì— ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ ì¶”ê°€finetune_model.add(Flatten()) #1ì°¨ì›ìœ¼ë¡œ í†µì¼finetune_model.add(Dense(64)) #(None, 64) finetune_model.add(Activation('relu'))finetune_model.add(Dropout(0.5))finetune_model.add(Dense(1)) # (None, 1)finetune_model.add(Activation('sigmoid'))# finetune_model.summary() #ì»´íŒŒì¼ ë° ì½œë°±ì˜µì…˜finetune_model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)#í•™ìŠµhistory = finetune_model.fit(train_generator, epochs=20, validation_steps=10, validation_data=test_generator,callbacks=[early_stopping_callback])## epochsë‹¹ ë³€í™”ë¥¼ ì‹œê°í™” í•˜ê¸°y_vloss = history.history['val_loss']y_loss = history.history['loss']x_len = np.arange(len(y_loss))plt.plot(x_len, y_vloss,marker='.', c='red', label='testsetloss')plt.plot(x_len, y_loss,marker='.', c='blue', label='trainsetloss')plt.legend(loc='upper right')plt.grid()plt.xlabel('epoch')plt.ylabel('loss')plt.show() ë§Œì•½ íŒŒì¸íŠœë‹ì´ ì•„ë‹ˆê³  ê·¸ëƒ¥ í•™ìŠµ ì—†ì´ pre_trained_dataë¡œ í‰ê°€ë¥¼ í•˜ê³  ì‹¶ì€ ê²½ìš°12345678910111213141516171819from tensorflow.keras.preprocessing import imagefrom keras.applications import vgg16#í‰ê°€í•  ì‚¬ì§„ì„ ë¶ˆëŸ¬ì˜´img = image.load_img('flower.jpg', target_size=(224,224))# í‰ê°€í•  ì‚¬ì§„ì„ (x,224,224,3) ì°¨ì›ìœ¼ë¡œ ë°”ê¿”ì¤Œinput_img = np.expand_dims(img, axis = 0) print(np.shape(img)) #(224,224,3)print(np.shape(input_img)) # (1,224,224,3)#VGG16ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´model_1 = vgg16.VGG16() # í‰ê°€(ì˜ˆì¸¡)pred = model_1.predict(input_img)np.argmax(pred) #daisytop_ten = vgg16.decode_predictions(pred, top=10)top_ten # ì˜ˆì¸¡ê°’ ìƒìœ„ 10ê°œë¥¼ ë³´ì—¬ì¤Œ","link":"/2022/12/22/Study_folder/TensorFlow/2022-12-22-img-finetun/"},{"title":"tf.cast()","text":"tf.cast(x, dtype, name=None) The operation casts x (in case of Tensor) or x.values (in case of SparseTensor or IndexedSlices) to dtype.í•´ì„í•˜ìë©´ xê°’ì„ ìƒˆë¡œìš´ í˜•íƒœì˜ dtypeìœ¼ë¡œ ìºìŠ¤íŒ…í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.{:.prompt-info} ë¶€ë™ ì†Œìˆ˜ì í˜•ì—ì„œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë°”ê¾¼ ê²½ìš° ì†Œìˆ˜ì ì„ ë²„ë¦°ë‹¤. Booleanìœ¼ë¡œ ì°¸ì¡°í•œ ê²½ìš° Trueì´ë©´ 1, Falseì´ë©´ 0ì„ ì¶œë ¥í•œë‹¤. ì˜ˆì‹œë¥¼ ë³´ë©´ ì´í•´ê°€ ë ê²ë‹ˆë‹¤. 123456789101112x = tf.constant([1.8, 2.2, 3.3], dtype=tf.float32)print(x)# tf.Tensor([1.8 2.2 3.3], shape=(3,), dtype=float32)tf.cast(x, tf.int32)# ì¶œë ¥ ê²°ê³¼ë¥¼ ë³´ì‹œë©´ ë°˜ì˜¬ë¦¼, ë‚´ë¦¼ì´ ì•„ë‹Œ ì†Œìˆ˜ì ì„ ë²„ë¦½ë‹ˆë‹¤.# &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)&gt;tf.cast(x&gt;2, tf.float32)# &lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 1.], dtype=float32)&gt;","link":"/2023/01/08/Study_folder/TensorFlow/2023-01-08-cast/"}],"tags":[{"name":"Study","slug":"Study","link":"/tags/Study/"},{"name":"Study,Pytorch","slug":"Study-Pytorch","link":"/tags/Study-Pytorch/"},{"name":"Colab","slug":"Colab","link":"/tags/Colab/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Command","slug":"Command","link":"/tags/Command/"},{"name":"Errors","slug":"Errors","link":"/tags/Errors/"},{"name":"Logs","slug":"Logs","link":"/tags/Logs/"},{"name":"Errors,Logs","slug":"Errors-Logs","link":"/tags/Errors-Logs/"},{"name":"Review,Dacon","slug":"Review-Dacon","link":"/tags/Review-Dacon/"},{"name":"Samples","slug":"Samples","link":"/tags/Samples/"},{"name":"Command,Jupyternotebook","slug":"Command-Jupyternotebook","link":"/tags/Command-Jupyternotebook/"},{"name":"Command,Shell,Terminal","slug":"Command-Shell-Terminal","link":"/tags/Command-Shell-Terminal/"},{"name":"Command,Terminal,Shell","slug":"Command-Terminal-Shell","link":"/tags/Command-Terminal-Shell/"},{"name":"Shell,Study","slug":"Shell-Study","link":"/tags/Shell-Study/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Project","slug":"Project","link":"/tags/Project/"},{"name":"Study,Review","slug":"Study-Review","link":"/tags/Study-Review/"},{"name":"Project,Portfolio","slug":"Project-Portfolio","link":"/tags/Project-Portfolio/"},{"name":"Deeplearning,Study","slug":"Deeplearning-Study","link":"/tags/Deeplearning-Study/"},{"name":"Review,Study","slug":"Review-Study","link":"/tags/Review-Study/"},{"name":"Deeplearning,Study,Tensorflow","slug":"Deeplearning-Study-Tensorflow","link":"/tags/Deeplearning-Study-Tensorflow/"},{"name":"Study,Preprocessing","slug":"Study-Preprocessing","link":"/tags/Study-Preprocessing/"},{"name":"pandas,Study","slug":"pandas-Study","link":"/tags/pandas-Study/"},{"name":"sklean,Study","slug":"sklean-Study","link":"/tags/sklean-Study/"},{"name":"Study,Python","slug":"Study-Python","link":"/tags/Study-Python/"},{"name":"NLP,Study","slug":"NLP-Study","link":"/tags/NLP-Study/"},{"name":"OpenCV","slug":"OpenCV","link":"/tags/OpenCV/"},{"name":"Study,OpenCV","slug":"Study-OpenCV","link":"/tags/Study-OpenCV/"},{"name":"Webcam","slug":"Webcam","link":"/tags/Webcam/"},{"name":"Deeplearning,Study,Pytorch","slug":"Deeplearning-Study-Pytorch","link":"/tags/Deeplearning-Study-Pytorch/"},{"name":"Pytorch,Study","slug":"Pytorch-Study","link":"/tags/Pytorch-Study/"}],"categories":[{"name":"Study","slug":"Study","link":"/categories/Study/"},{"name":"Colab","slug":"Colab","link":"/categories/Colab/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Errors","slug":"Errors","link":"/categories/Errors/"},{"name":"Review","slug":"Review","link":"/categories/Review/"},{"name":"Samples","slug":"Samples","link":"/categories/Samples/"},{"name":"Command","slug":"Command","link":"/categories/Command/"},{"name":"Mac","slug":"Mac","link":"/categories/Mac/"},{"name":"Project","slug":"Project","link":"/categories/Project/"},{"name":"Portfolio","slug":"Portfolio","link":"/categories/Portfolio/"},{"name":"OpenCV","slug":"OpenCV","link":"/categories/OpenCV/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"About me","text":"Hi there, Iâ€™m Inhwan Cho ğŸ‘‹ğŸ“š my STACKSğŸ“š &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}]}