<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GPT(**G**enerative **P**re-**T**raining of Language Model) - Inhwan&#039;s Digital Space</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Digital Space"><meta name="msapplication-TileImage" content="/img/favicon-32x32.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Digital Space"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Click to read more in detail"><meta property="og:type" content="blog"><meta property="og:title" content="GPT(**G**enerative **P**re-**T**raining of Language Model)"><meta property="og:url" content="http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/"><meta property="og:site_name" content="Inhwan&#039;s Digital Space"><meta property="og:description" content="Click to read more in detail"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/adc5aa2d-d6f0-4f8a-b77f-910cf2947477"><meta property="og:image" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/13bf5a56-b10c-45c9-8f5d-5ab89e0cfdf6"><meta property="og:image" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/b8069bb4-bf20-4d82-a42f-5c7fd128177b"><meta property="og:image" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/f13f8a93-f1ae-48ff-bd98-f2b713b9d74f"><meta property="og:image" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/128700a9-4ead-4b1b-a98e-b54c45b4f728"><meta property="og:image" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/c20be424-7a76-4358-9afc-330a1448bf14"><meta property="article:published_time" content="2023-08-09T15:00:00.000Z"><meta property="article:modified_time" content="2023-08-09T15:00:00.000Z"><meta property="article:author" content="InhwanCho"><meta property="article:tag" content="paper"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/adc5aa2d-d6f0-4f8a-b77f-910cf2947477"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/"},"headline":"GPT(**G**enerative **P**re-**T**raining of Language Model)","image":[],"datePublished":"2023-08-09T15:00:00.000Z","dateModified":"2023-08-09T15:00:00.000Z","author":{"@type":"Person","name":"InhwanCho"},"publisher":{"@type":"Organization","name":"Inhwan's Digital Space","logo":{"@type":"ImageObject","url":{"text":"Inhwan's Digital Space"}}},"description":"Click to read more in detail"}</script><link rel="canonical" href="http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/"><link rel="icon" href="/img/favicon-32x32.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/github.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-8RGKYVDD5B" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-8RGKYVDD5B');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/rss2.xml" title="Inhwan's Digital Space" type="application/rss+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Inhwan&#039;s Digital Space</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/InhwanCho"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-7-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-9 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time datetime="2023-08-09T15:00:00.000Z" title="Invalid Date">2023-08-10</time></span><span class="level-item">Updated&nbsp;<time datetime="2023-08-09T15:00:00.000Z" title="2023. 8. 10. 오전 12:00:00">2023-08-10</time></span><span class="level-item"><a class="link-muted" href="/categories/Paper/">Paper</a></span><span class="level-item">10 minutes read (About 1557 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><h1 class="title is-3 is-size-4-mobile">GPT(**G**enerative **P**re-**T**raining of Language Model)</h1><div class="content"><h3 id="참고-문헌-Transformer에-관한-글"><a href="#참고-문헌-Transformer에-관한-글" class="headerlink" title="참고 문헌(Transformer에 관한 글)"></a>참고 문헌(Transformer에 관한 글)</h3><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf" title="GPT-1 논문">GPT-1 논문</a><br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" title="GPT-2 논문">GPT-2 논문</a><br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.youtube.com/watch?v=o_Wl29aW5XM&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=19" title="고려대 유튜브">고려대 유튜브</a><br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://jalammar.github.io/illustrated-gpt2/" title="Jay alammar blog">Jay alammar 블로그</a></p>
<h2 id="GPT-개요"><a href="#GPT-개요" class="headerlink" title="GPT 개요"></a>GPT 개요</h2><p>일반적으로 우리는 레이블이 있는 데이터를 사용하여 지도 학습을 수행해왔습니다. 그러나 대부분의 데이터는 레이블이 없는 데이터입니다.</p>
<p>실제로 레이블이 있는 데이터의 양은 제한적입니다.</p>
<p>GPT는 이러한 상황에서 발전할 수 있는 방안을 모색하기 위해 제안되었습니다. 이는 주로 레이블이 없는 다양한 텍스트 말뭉치에서 사전 훈련을 수행하고, 각 작업에 특화된 파인튜닝을 통해 이점을 얻을 수 있는 접근 방식입니다.</p>
<p>그러나 레이블이 없는 데이터를 다룰 때는 세 가지 주요 단점이 있습니다.</p>
<p><code>1. 단어 수준 이상의 정보를 추출하기 어렵습니다.</code></p>
<p><code>2. 어떤 최적화 목표가 전이 학습을 위한 효과적인 텍스트 표현을 학습하는 데 가장 효율적인지 불분명합니다.</code></p>
<p><code>3. 이러한 불확실성으로 인해 반지도 학습 접근 방식이 어려움을 겪습니다.</code></p>
<p>따라서 GPT에서는 다음과 같은 방식으로 이러한 문제를 해결하고자 합니다.</p>
<p><code>1. 비지도 사전 훈련과 지도 파인튜닝을 결합한 반지도 학습 접근 방식을 제안합니다. (ELMo와 유사하지만 ELMo는 양방향 LSTM을 사용합니다.)</code></p>
<p><code>2. 다양한 작업에 적용할 수 있는 범용적인 표현을 학습하기 위해 작업에 약간의 조정만으로 전이 가능하도록 합니다.</code></p>
<pre><code>학습은 다음의 단계를 거쳐 이루어집니다. 
1.먼저 레이블이 없는 데이터에서 언어 모델 목표를 사용하여 사전 훈련을 수행한 후, 
2.레이블이 있는 목표 작업에 맞추어 지도 학습을 진행합니다.
(이를 위해 Transformer 디코더 블록을 활용합니다.)
</code></pre>
<p>GPT는 기존 언어 모델의 트렌드를 이어가면서 유연한 전이(transfer)가 가능하며, 지도 학습 형태의 미세 조정(Fine-tuning) 없이도 제로샷(Zero-shot) 다운스트림 작업을 수행할 수 있는 일반화된 모델입니다.</p>
<p>쉽게 풀어서 말하자면 GPT-2에서는 먼저 레이블이 없는 데이터셋(Unlabeled corpora)을 언어 모델에 학습시킵니다. 이 과정을 <code>Pre-training(사전 학습)</code>이라고 합니다. pre-training을 마친 모델에 추가로 태스크에 맞는 데이터셋(Labeled corpora)을 추가 학습시킵니다. 이를 <code>Fine-tuning</code>이라고 합니다. GPT는 이러한 “전이 학습(Transfer learning) 방법으로 이전의 모델보다 더 좋은 성능을 낼 수 있을 것이다”라는 아이디어에서 고안되었습니다.</p>
<h2 id="GPT-2-pre-training-gt-fine-tuning"><a href="#GPT-2-pre-training-gt-fine-tuning" class="headerlink" title="GPT-2(pre-training -&gt; fine-tuning)"></a>GPT-2(pre-training -&gt; fine-tuning)</h2><img width="700" alt="GPT-2의 크기 비교" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/adc5aa2d-d6f0-4f8a-b77f-910cf2947477">



<img width="700" alt="GPT-2의 크기 비교2" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/13bf5a56-b10c-45c9-8f5d-5ab89e0cfdf6">

<p>GPT-2는 4가지 크기의 모델이 있으며, 각각의 파라미터와 decoder의 수 및 input encoding dim의 차이는 위의 그림과 같습니다.</p>
<img width="500" alt="GPT의 input encoding" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/b8069bb4-bf20-4d82-a42f-5c7fd128177b">

<p>위의 그림처럼 input encoding을 하였습니다.</p>
<h2 id="GPT-2-Model-Architecture"><a href="#GPT-2-Model-Architecture" class="headerlink" title="GPT-2 Model Architecture"></a>GPT-2 Model Architecture</h2><img width="200" alt="GPT의 decoder block" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/f13f8a93-f1ae-48ff-bd98-f2b713b9d74f">

<p>위의 그림의 <code>블럭</code>이 부분이 GPT-2의 <code>Decoder Block</code>입니다.</p>
<p>이러한 <code>Decoder Block</code>이 n 개로 구성된게 GPT-2입니다.</p>
<p>어떻게 GPT-2가 학습되는지 자세히 살펴보겠습니다.</p>
<img width="700" alt="gpt2 input" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/128700a9-4ead-4b1b-a98e-b54c45b4f728">

<ol>
<li>input으로는 <code>Transformer</code>의 decoder 방식과 동일하게 token embeddings + positional embeddings가 더한 백터값이 들어옵니다.</li>
</ol>
<img width="700" alt="gpt2" src="https://github.com/InhwanCho/InhwanCho.github.io/assets/111936229/c20be424-7a76-4358-9afc-330a1448bf14">

<ol start="2">
<li><p>첫 번째 블록은 이제 토큰을 처리할 수 있습니다.<br>먼저, self-attention 과정을 통해 토큰을 전달한 다음 신경망 계층을 통과시킵니다.<br>첫 번째 변환기 블록이 토큰을 처리하면 결과 벡터를 스택 상위 블록으로 보내 해당 블록에서 처리됩니다.<br>각 블록에서의 과정은 동일하지만, 각 블록은 self-attention과 신경망 서브레이어에서 고유한 가중치를 가지고 있습니다.</p>
</li>
<li><p>pre-training을 먼저 하는데 이때의 모델의 목적 함수 $L_1$은 다음과 같습니다.</p>
</li>
</ol>
<p>$$ L_1(u) &#x3D; \sum_{i} logP(u_i|u_{i-k}, … , u_{i-1};\Theta) $$</p>
<p>[여기서 input_tokens $u$는 unsupervised dataset에서의 input_tokens입니다.]<br>[확률 P, input_tokens $u$, 파라미터 $\Theta$, 목적 함수 $L_1$]</p>
<ol start="4">
<li>GPT : Supervised fine-tuning(3번의 pre-train과 달리 supervised dataset을 사용)</li>
</ol>
<ul>
<li><p>레이블이 지정된 데이터셋 $C$는 각 인스턴스가 입력 토큰의 시퀀스 [$x^l, … , x^m$]와 레이블 $y$로 구성됩니다.</p>
</li>
<li><p>입력은 사전 훈련된 모델을 통해 최종 변환기 블록의 활성화 $h_{l}^{m}$를 얻습니다. 이 활성화는 추가된 선형 출력 계층에 공급되며, 여기에는 매개변수 $W_y$가 있어 $y$를 예측합니다.</p>
</li>
</ul>
<p>$$ P(y|x^1, … , x^m) &#x3D; softmax(h_l^m W_y) $$</p>
<p>[확률 $P$, label $y$, input_tokens $x$, final_transformer_blokck’s_activation $h_l^m$, 최종 목적함수 $L_2$, 데이터셋 $C$],</p>
<p>[h_l^m W_y는 마지막 디코더 블럭의 아웃풋 값이Linear layer를 통과를 의미]</p>
<ul>
<li>위의 수식을 통해 아래의 목적 함수를 극대화할 수 있습니다.</li>
</ul>
<p>$$ L_2(C) &#x3D; \sum_{(x,y)} logP(y|x^1, … , x^m) $$</p>
<ol start="4">
<li>위의 목적 함수들을 합해서 GPT-2는 다음과 같은 목적 함수를 사용합니다.</li>
</ol>
<p>$$ L_3(C) &#x3D; L_2(C) + \lambda \cdot L_1(C) $$</p>
<ul>
<li>논문에서는 이와 같은 방법이 모델의 일반화를 돕고 수렴 속도를 더 빠르게 하는 효과가 있다고 합니다.</li>
</ul>
<p>요약 하자면,</p>
<pre><code>Unlabeled dataset에 대한 pre-training을 한 뒤,
Labeled dataset의 목적 함수와 같이 섞어 사용한 fine-tuning을 하고, 
그 두 가지를 조합하여 사용한 최종 목적 함수(objective function)를 사용하면,
더 나은 결과를 얻을 수 있다고 합니다.
</code></pre>
</div><div class="article-licensing box"><div class="licensing-title"><p>GPT(**G**enerative **P**re-**T**raining of Language Model)</p><p><a href="http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/">http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>InhwanCho</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-08-10</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-08-10</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="external nofollow noopener noreferrer" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="external nofollow noopener noreferrer" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="external nofollow noopener noreferrer" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/paper/">paper</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/08/09/Paper_Review/2023-08-09-transformer/"><span class="level-item">Transformer(Attention is all you need)</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://inhwancho.github.io/2023/08/10/Paper_Review/2023-08-10-GPT2/';
            this.page.identifier = '2023/08/10/Paper_Review/2023-08-10-GPT2/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'inhwancho-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Inhwan Cho"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Inhwan Cho</p><p class="is-size-6 is-block">Enjoy the life</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul in Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">107</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-info is-outlined is-rounded" href="/" target="_self" rel="noopener">Home</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="external nofollow noopener noreferrer" title="Github" href="https://github.com/InhwanCho"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="external nofollow noopener noreferrer" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Blog/"><span class="level-start"><span class="level-item">Blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Colab/"><span class="level-start"><span class="level-item">Colab</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Command/"><span class="level-start"><span class="level-item">Command</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Errors/"><span class="level-start"><span class="level-item">Errors</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Mac/"><span class="level-start"><span class="level-item">Mac</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/OpenCV/"><span class="level-start"><span class="level-item">OpenCV</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Portfolio/"><span class="level-start"><span class="level-item">Portfolio</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/Review/"><span class="level-start"><span class="level-item">Review</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Samples/"><span class="level-start"><span class="level-item">Samples</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/"><span class="level-start"><span class="level-item">Study</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Tensorflow/"><span class="level-start"><span class="level-item">Tensorflow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/VScode/"><span class="level-start"><span class="level-item">VScode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2023-08-09T15:00:00.000Z">2023-08-10</time></p><p class="title"><a href="/2023/08/10/Paper_Review/2023-08-10-GPT2/">GPT(**G**enerative **P**re-**T**raining of Language Model)</a></p><p class="categories"><a href="/categories/Paper/">Paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2023-08-08T15:00:00.000Z">2023-08-09</time></p><p class="title"><a href="/2023/08/09/Paper_Review/2023-08-09-transformer/">Transformer(Attention is all you need)</a></p><p class="categories"><a href="/categories/Paper/">Paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2023-07-15T15:00:00.000Z">2023-07-16</time></p><p class="title"><a href="/2023/07/16/Paper_Review/2023-07-16-test/">ViT(Vision Transformer)</a></p><p class="categories"><a href="/categories/Paper/">Paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2023-02-08T15:00:00.000Z">2023-02-09</time></p><p class="title"><a href="/2023/02/09/Paper_Review/2023-02-09-RCNN/">논문 리뷰 R-CNN</a></p><p class="categories"><a href="/categories/Paper/">Paper</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2023-01-30T15:00:00.000Z">2023-01-31</time></p><p class="title"><a href="/2023/01/31/Mac_Fundamental_Concept/2023-01-31-vscode/">VScode에서 유용한 정보</a></p><p class="categories"><a href="/categories/VScode/">VScode</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">49</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Inhwan&#039;s Digital Space</a><p class="is-size-7"><span>&copy; 2023 InhwanCho</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/InhwanCho"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>